{
  "last_updated": "2025-07-22T21:03:55.536961-04:00",
  "papers": [
    {
      "title": "Diffusion Beats Autoregressive in Data-Constrained Settings",
      "summary": "Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.",
      "url": "http://arxiv.org/abs/2507.15857v1",
      "published_time_eastern_timestamp": 1753120797.0
    },
    {
      "title": "Latent Denoising Makes Good Visual Tokenizers",
      "summary": "Despite their fundamental role, it remains unclear what properties could make\nvisual tokenizers more effective for generative modeling. We observe that\nmodern generative models share a conceptually similar training objective --\nreconstructing clean signals from corrupted inputs such as Gaussian noise or\nmasking -- a process we term denoising. Motivated by this insight, we propose\naligning tokenizer embeddings directly with the downstream denoising objective,\nencouraging latent embeddings to be more easily reconstructed even when heavily\ncorrupted. To achieve this, we introduce the Latent Denoising Tokenizer\n(l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images\nfrom latent embeddings corrupted by interpolative noise and random masking.\nExtensive experiments on ImageNet 256x256 demonstrate that our tokenizer\nconsistently outperforms standard tokenizers across six representative\ngenerative models. Our findings highlight denoising as a fundamental design\nprinciple for tokenizer development, and we hope it could motivate new\nperspectives for future tokenizer design.",
      "url": "http://arxiv.org/abs/2507.15856v1",
      "published_time_eastern_timestamp": 1753120796.0
    },
    {
      "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept\n  Construction",
      "summary": "Video Object Segmentation (VOS) is a core task in computer vision, requiring\nmodels to track and segment target objects across video frames. Despite notable\nadvances with recent efforts, current techniques still lag behind human\ncapabilities in handling drastic visual variations, occlusions, and complex\nscene changes. This limitation arises from their reliance on appearance\nmatching, neglecting the human-like conceptual understanding of objects that\nenables robust identification across temporal dynamics. Motivated by this gap,\nwe propose Segment Concept (SeC), a concept-driven segmentation framework that\nshifts from conventional feature matching to the progressive construction and\nutilization of high-level, object-centric representations. SeC employs Large\nVision-Language Models (LVLMs) to integrate visual cues across diverse frames,\nconstructing robust conceptual priors. During inference, SeC forms a\ncomprehensive semantic representation of the target based on processed frames,\nrealizing robust segmentation of follow-up frames. Furthermore, SeC adaptively\nbalances LVLM-based semantic reasoning with enhanced feature matching,\ndynamically adjusting computational efforts based on scene complexity. To\nrigorously assess VOS methods in scenarios demanding high-level conceptual\nreasoning and robust semantic understanding, we introduce the Semantic Complex\nScenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160\nmanually annotated multi-scenario videos designed to challenge models with\nsubstantial appearance variations and dynamic scene transformations. In\nparticular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,\nestablishing a new state-of-the-art in concept-aware video object segmentation.",
      "url": "http://arxiv.org/abs/2507.15852v2",
      "published_time_eastern_timestamp": 1753120742.0
    },
    {
      "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition",
      "summary": "As Large Language Models (LLMs) continue to advance, they exhibit certain\ncognitive patterns similar to those of humans that are not directly specified\nin training data. This study investigates this phenomenon by focusing on\ntemporal cognition in LLMs. Leveraging the similarity judgment task, we find\nthat larger models spontaneously establish a subjective temporal reference\npoint and adhere to the Weber-Fechner law, whereby the perceived distance\nlogarithmically compresses as years recede from this reference point. To\nuncover the mechanisms behind this behavior, we conducted multiple analyses\nacross neuronal, representational, and informational levels. We first identify\na set of temporal-preferential neurons and find that this group exhibits\nminimal activation at the subjective reference point and implements a\nlogarithmic coding scheme convergently found in biological systems. Probing\nrepresentations of years reveals a hierarchical construction process, where\nyears evolve from basic numerical values in shallow layers to abstract temporal\norientation in deep layers. Finally, using pre-trained embedding models, we\nfound that the training corpus itself possesses an inherent, non-linear\ntemporal structure, which provides the raw material for the model's internal\nconstruction. In discussion, we propose an experientialist perspective for\nunderstanding these findings, where the LLMs' cognition is viewed as a\nsubjective construction of the external world by its internal representational\nsystem. This nuanced perspective implies the potential emergence of alien\ncognitive frameworks that humans cannot intuitively predict, pointing toward a\ndirection for AI alignment that focuses on guiding internal constructions. Our\ncode is available at https://TheOtherMind.github.io.",
      "url": "http://arxiv.org/abs/2507.15851v1",
      "published_time_eastern_timestamp": 1753120741.0
    },
    {
      "title": "3LM: Bridging Arabic, STEM, and Code through Benchmarking",
      "summary": "Arabic is one of the most widely spoken languages in the world, yet efforts\nto develop and evaluate Large Language Models (LLMs) for Arabic remain\nrelatively limited. Most existing Arabic benchmarks focus on linguistic,\ncultural, or religious content, leaving a significant gap in domains like STEM\nand code which are increasingly relevant for real-world LLM applications. To\nhelp bridge this gap, we present 3LM, a suite of three benchmarks designed\nspecifically for Arabic. The first is a set of STEM-related question-answer\npairs, naturally sourced from Arabic textbooks and educational worksheets. The\nsecond consists of synthetically generated STEM questions, created using the\nsame sources. The third benchmark focuses on code generation, built through a\ncareful translation of two widely used code benchmarks, incorporating a\nhuman-in-the-loop process with several rounds of review to ensure high-quality\nand faithful translations. We release all three benchmarks publicly to support\nthe growth of Arabic LLM research in these essential but underrepresented\nareas.",
      "url": "http://arxiv.org/abs/2507.15850v1",
      "published_time_eastern_timestamp": 1753120707.0
    },
    {
      "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning",
      "summary": "Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet exhibit significant computational inefficiency\nby applying uniform reasoning strategies regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. HBPO addresses the fundamental challenge\nof exploration space collapse in efficiency-oriented training, where penalties\non long output length systematically bias models away from necessary long\nreasoning paths. Through hierarchical budget exploration, our approach\npartitions rollout samples into multiple subgroups with distinct token budgets,\naiming to enable efficient resource allocation while preventing degradation of\ncapability. We introduce differentiated reward mechanisms that create\nbudget-aware incentives aligned with the complexity of the problem, allowing\nmodels to discover natural correspondences between task requirements and\ncomputational effort. Extensive experiments demonstrate that HBPO reduces\naverage token usage by up to 60.6% while improving accuracy by 3.14% across\nfour reasoning benchmarks. Unlike existing methods that impose external\nconstraints or rely on discrete mode selection, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.",
      "url": "http://arxiv.org/abs/2507.15844v2",
      "published_time_eastern_timestamp": 1753120354.0
    },
    {
      "title": "Closure Conversion, Flat Environments, and the Complexity of Abstract\n  Machines",
      "summary": "Closure conversion is a program transformation at work in compilers for\nfunctional languages to turn inner functions into global ones, by building\nclosures pairing the transformed functions with the environment of their free\nvariables. Abstract machines rely on similar and yet different concepts of\nclosures and environments.\n  In this paper, we study the relationship between the two approaches. We adopt\na very simple {\\lambda}-calculus with tuples as source language and study\nabstract machines for both the source language and the target of closure\nconversion. Moreover, we focus on the simple case of flat\nclosures/environments, that is, with no sharing of environments. We provide\nthree contributions.\n  Firstly, a new simple proof technique for the correctness of closure\nconversion, inspired by abstract machines.\n  Secondly, we show how the closure invariants of the target language allow us\nto design a new way of handling environments in abstract machines, not\nsuffering the shortcomings of other styles.\n  Thirdly, we study the machines from the point of view of time complexity,\nadapting analyses by Accattoli and co-authors. We show that closure conversion\ndecreases various dynamic costs while increasing the size of the initial code.\nDespite these changes, the overall complexity of the machines before and after\nclosure conversion turns out to be the same.",
      "url": "http://arxiv.org/abs/2507.15843v1",
      "published_time_eastern_timestamp": 1753120349.0
    },
    {
      "title": "Observing Fine-Grained Changes in Jupyter Notebooks During Development\n  Time",
      "summary": "In software engineering, numerous studies have focused on the analysis of\nfine-grained logs, leading to significant innovations in areas such as\nrefactoring, security, and code completion. However, no similar studies have\nbeen conducted for computational notebooks in the context of data science.\n  To help bridge this research gap, we make three scientific contributions: we\n(1) introduce a toolset for collecting code changes in Jupyter notebooks during\ndevelopment time; (2) use it to collect more than 100 hours of work related to\na data analysis task and a machine learning task (carried out by 20 developers\nwith different levels of expertise), resulting in a dataset containing 2,655\ncells and 9,207 cell executions; and (3) use this dataset to investigate the\ndynamic nature of the notebook development process and the changes that take\nplace in the notebooks.\n  In our analysis of the collected data, we classified the changes made to the\ncells between executions and found that a significant number of these changes\nwere relatively small fixes and code iteration modifications. This suggests\nthat notebooks are used not only as a development and exploration tool but also\nas a debugging tool. We report a number of other insights and propose potential\nfuture research directions on the novel data.",
      "url": "http://arxiv.org/abs/2507.15831v1",
      "published_time_eastern_timestamp": 1753119711.0
    },
    {
      "title": "LLM Economist: Large Population Models and Mechanism Design in\n  Multi-Agent Generative Simulacra",
      "summary": "We present the LLM Economist, a novel framework that uses agent-based\nmodeling to design and assess economic policies in strategic environments with\nhierarchical decision-making. At the lower level, bounded rational worker\nagents -- instantiated as persona-conditioned prompts sampled from U.S.\nCensus-calibrated income and demographic statistics -- choose labor supply to\nmaximize text-based utility functions learned in-context. At the upper level, a\nplanner agent employs in-context reinforcement learning to propose\npiecewise-linear marginal tax schedules anchored to the current U.S. federal\nbrackets. This construction endows economic simulacra with three capabilities\nrequisite for credible fiscal experimentation: (i) optimization of\nheterogeneous utilities, (ii) principled generation of large, demographically\nrealistic agent populations, and (iii) mechanism design -- the ultimate nudging\nproblem -- expressed entirely in natural language. Experiments with populations\nof up to one hundred interacting agents show that the planner converges near\nStackelberg equilibria that improve aggregate social welfare relative to Saez\nsolutions, while a periodic, persona-level voting procedure furthers these\ngains under decentralized governance. These results demonstrate that large\nlanguage model-based agents can jointly model, simulate, and govern complex\neconomic systems, providing a tractable test bed for policy evaluation at the\nsocietal scale to help build better civilizations.",
      "url": "http://arxiv.org/abs/2507.15815v1",
      "published_time_eastern_timestamp": 1753118474.0
    },
    {
      "title": "True Multimodal In-Context Learning Needs Attention to the Visual\n  Context",
      "summary": "Multimodal Large Language Models (MLLMs), built on powerful language\nbackbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new\ntasks from a few multimodal demonstrations consisting of images, questions, and\nanswers. Despite showing noticeable improvement on standard vision-language\ndatasets, current MLLMs struggle to leverage visual information in the\ndemonstrations. Specifically, they tend to neglect visual cues and over-rely on\ntextual patterns, leading to mere text imitation rather than genuine multimodal\nadaptation. This behavior makes MICL still unimodal and largely restricts its\npractical utility. More importantly, this limitation is often concealed by the\nimproved performance on tasks that do not require understanding the visual\ncontext. As a result, how to effectively enhance MICL ability and reliably\nevaluate the MICL performance remains underexplored. To address these issues,\nwe first introduce Dynamic Attention Reallocation (DARA), an efficient\nfine-tuning strategy that encourages models to attend to the visual context by\nrebalancing attention across visual and textual tokens. In addition, we present\nTrueMICL, an MICL-dedicated dataset with both support and test sets that\nexplicitly requires the integration of multimodal information-particularly\nvisual content-for correct task completion. Extensive experiments demonstrate\nthe effectiveness of our holistic solution, showcasing substantial improvements\nin the true multimodal in-context learning capabilities. Code and datasets are\navailable at https://chenxshuo.github.io/true-micl-colm .",
      "url": "http://arxiv.org/abs/2507.15807v1",
      "published_time_eastern_timestamp": 1753117698.0
    },
    {
      "title": "Identifying Solution Constraints for ODE Systems",
      "summary": "This work develops a framework to discover relations between the components\nof the solution to a given initial-value problem for a first-order system of\nordinary differential equations. This is done by using sparse identification\ntechniques on the data represented by the numerical solution of the\ninitial-value problem at hand. The only assumption is that there are only a few\nterms that connects the components, so that the mathematical relations to be\ndiscovered are sparse in the set of possible functions. We illustrate the\nmethod through examples of applications.",
      "url": "http://arxiv.org/abs/2507.15805v1",
      "published_time_eastern_timestamp": 1753117512.0
    },
    {
      "title": "1D Vlasov Simulations of QED Cascades Over Pulsar Polar Caps",
      "summary": "Recent developments in the study of pulsar radio emission revealed that the\nmicrophysics of quantum electrodynamic (QED) pair cascades at pulsar polar caps\nmay be responsible for generating the observed coherent radio waves. However,\nmodeling the pair cascades in the polar cap region poses significant\nchallenges, particularly under conditions of high plasma multiplicity.\nTraditional Particle-in-Cell (PIC) methods often face rapidly increasing\ncomputational costs as the multiplicity grows exponentially. To address this\nissue, we present a new simulation code using the Vlasov method, which\nefficiently simulates the evolution of charged particle distribution functions\nin phase space without a proportional increase in computational expense at high\nmultiplicities. We apply this code to study $e^\\pm$ pair cascades in 1D,\nincorporating key physical processes such as curvature radiation, radiative\ncooling, and magnetic pair production. We study both the Ruderman-Sutherland\n(RS) and the Space-charge-limited Flow (SCLF) regimes, and find quasiperiodic\ngap formation and pair production bursts in both cases. These features produce\nstrong electric field oscillations, potentially enabling coherent low-frequency\nradio emission. We construct a unified analytic model that describes the key\nfeatures of the polar cap cascade, which can be used to estimate the return\ncurrent heating rate that can be used to inform X-ray hotspot models. Spectral\nanalysis shows that a significant amount of energy is carried in superluminal\nmodes -- collective excitations that could connect to observed radio features.\nOur results align with previous PIC studies while offering enhanced fidelity in\nboth dense and rarefied regions.",
      "url": "http://arxiv.org/abs/2507.15804v1",
      "published_time_eastern_timestamp": 1753117411.0
    },
    {
      "title": "Deterministic Quantum Search via Recursive Oracle Expansion",
      "summary": "We introduce a novel deterministic quantum search algorithm that provides a\npractical alternative to conventional probabilistic search approaches. Our\nscheme eliminates the inherent uncertainty of quantum search without relying on\narbitrary phase rotations, a key limitation of other deterministic methods. The\nalgorithm achieves certainty by recursively expanding the base oracle so that\nit marks all states prefixed by the same two bits as the target, encompassing\nexactly one-quarter of the search space. This enables a step-by-step reduction\nof the superposition until the target state can be measured with certainty. The\nalgorithm achieves deterministic success with a query complexity of\n$O(N^{\\log_2(3)/2}) \\approx O(N^{0.7925})$, falling between Grover's\n$O(\\sqrt{N})$ scaling and the classical $O(N)$. Our approach relies exclusively\non two-qubit nearest-neighbour diffusion operators, avoiding global diffusion\nentirely. We show that, despite the increased query complexity, this design\nreduces the total number of two-qubit gates required for diffusion by more than\nan order of magnitude for search spaces up to at least 18 qubits, with even\ngreater advantages on hardware with limited qubit connectivity. The scheme's\ninherent determinism, reliance on simple nearest-neighbour, low-depth\noperations, and scalable recursive structure make it well-suited for hardware\nimplementation. Additionally, we show that the algorithm naturally supports\npartial database search, enabling deterministic identification of selected\ntarget bits without requiring a full search, further broadening its\napplicability.",
      "url": "http://arxiv.org/abs/2507.15797v1",
      "published_time_eastern_timestamp": 1753117035.0
    },
    {
      "title": "Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation",
      "summary": "Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is\nincreasingly attracting interest in medical imaging due to its effectiveness\nand computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)\nis a notable approach based on the assumption that the adaptation inherently\noccurs in a low-dimensional subspace. While it has shown good performance, its\nimplementation requires a fixed and unalterable rank, which might be\nchallenging to select given the unique complexities and requirements of each\nmedical imaging downstream task. Inspired by advancements in natural image\nprocessing, we introduce a novel approach for medical image segmentation that\ndynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank\nrepresentation of the trainable weight matrices as a singular value\ndecomposition, we introduce an l_1 sparsity regularizer to the loss function,\nand tackle it with a proximal optimizer. The regularizer could be viewed as a\npenalty on the decomposition rank. Hence, its minimization enables to find\ntask-adapted ranks automatically. Our method is evaluated in a realistic\nfew-shot fine-tuning setting, where we compare it first to the standard LoRA\nand then to several other PEFT methods across two distinguishable tasks: base\norgans and novel organs. Our extensive experiments demonstrate the significant\nperformance improvements driven by our method, highlighting its efficiency and\nrobustness against suboptimal rank initialization. Our code is publicly\navailable: https://github.com/ghassenbaklouti/ARENA",
      "url": "http://arxiv.org/abs/2507.15793v1",
      "published_time_eastern_timestamp": 1753116713.0
    },
    {
      "title": "\\texttt{GWBird}: a toolkit for the characterization of the Stochastic\n  Gravitational Wave Background for Ground, Space, and Pulsar Timing Array\n  detectors",
      "summary": "The detection of the Stochastic Gravitational Wave Background (SGWB) is one\nof the most challenging tasks for both current and next-generation detectors.\nSuccessfully distinguishing the SGWB from instrumental noise and environmental\neffects requires accurate and flexible analysis tools capable of detecting the\nsignal and determining its origin. In this paper, we introduce a unified\nframework and a user-friendly tool for SGWB characterization: \\texttt{GWBird}\n(Gravitational Wave Background Inventory of Response functions for Detectors).\nThis code enables the computation of overlap reduction functions (ORFs),\npower-law integrated sensitivity curves (PLS), angular response functions, and\nangular PLS (APLS). It supports the full range of gravitational wave\npolarization modes (tensor, scalar, and vector), allowing for the\ncharacterization of both isotropic and anisotropic SGWB components for all the\npolarizations. Additionally, the code includes functions for circular\npolarization characterization, which is particularly relevant for probing\nparity-violating signals. The framework integrates analyses for ground-based,\nspace-based, and Pulsar Timing Array (PTA) detectors, offering a versatile\nframework for SGWB analysis. The \\texttt{GWBird} code is publicly available\nat:~\\github{https://github.com/ilariacaporali/GWBird}",
      "url": "http://arxiv.org/abs/2507.15791v1",
      "published_time_eastern_timestamp": 1753116594.0
    },
    {
      "title": "Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for\n  RLVR",
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective\npost-training method for improving the reasoning abilities of Large Language\nModels (LLMs), mainly by shaping higher-order behaviors such as reflection and\nplanning. However, previous RLVR algorithms often apply uniform training\nsignals to all tokens, without considering the different roles of low-entropy\nknowledge-related tokens and high-entropy reasoning-related tokens. Some recent\nmethods try to separate these token types by gradient masking or asynchronous\nupdates, but these approaches may break semantic dependencies in the model\noutput and hinder effective learning. In this work, we propose Archer, an\nentropy-aware RLVR approach with dual-token constraints and synchronous\nupdates. Specifically, our method applies weaker KL regularization and higher\nclipping thresholds to reasoning tokens to encourage exploration, while using\nstronger constraints on knowledge tokens to maintain factual knowledge.\nExperimental results on several mathematical reasoning and code generation\nbenchmarks show that our approach significantly outperforms previous RLVR\nmethods, reaching or exceeding state-of-the-art performance among models of\ncomparable size. The code is available at\nhttps://github.com/wizard-III/ArcherCodeR.",
      "url": "http://arxiv.org/abs/2507.15778v1",
      "published_time_eastern_timestamp": 1753115641.0
    },
    {
      "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems\n  Through LLM-based Agent Intention Mining",
      "summary": "With the rise of service computing, cloud computing, and IoT, service\necosystems are becoming increasingly complex. The intricate interactions among\nintelligent agents make abnormal emergence analysis challenging, as traditional\ncausal methods focus on individual trajectories. Large language models offer\nnew possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)\nreasoning to reveal agent intentions. However, existing approaches remain\nlimited to microscopic and static analysis. This paper introduces a framework:\nEmergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic\nand interpretable emergence analysis. EAMI first employs a dual-perspective\nthought track mechanism, where an Inspector Agent and an Analysis Agent extract\nagent intentions under bounded and perfect rationality. Then, k-means\nclustering identifies phase transition points in group intentions, followed by\na Intention Temporal Emergence diagram for dynamic analysis. The experiments\nvalidate EAMI in complex online-to-offline (O2O) service system and the\nStanford AI Town experiment, with ablation studies confirming its\neffectiveness, generalizability, and efficiency. This framework provides a\nnovel paradigm for abnormal emergence and causal analysis in service\necosystems. The code is available at\nhttps://anonymous.4open.science/r/EAMI-B085.",
      "url": "http://arxiv.org/abs/2507.15770v1",
      "published_time_eastern_timestamp": 1753115209.0
    },
    {
      "title": "Learning from Heterogeneity: Generalizing Dynamic Facial Expression\n  Recognition via Distributionally Robust Optimization",
      "summary": "Dynamic Facial Expression Recognition (DFER) plays a critical role in\naffective computing and human-computer interaction. Although existing methods\nachieve comparable performance, they inevitably suffer from performance\ndegradation under sample heterogeneity caused by multi-source data and\nindividual expression variability. To address these challenges, we propose a\nnovel framework, called Heterogeneity-aware Distributional Framework (HDF), and\ndesign two plug-and-play modules to enhance time-frequency modeling and\nmitigate optimization imbalance caused by hard samples. Specifically, the\nTime-Frequency Distributional Attention Module (DAM) captures both temporal\nconsistency and frequency robustness through a dual-branch attention design,\nimproving tolerance to sequence inconsistency and visual style shifts. Then,\nbased on gradient sensitivity and information bottleneck principles, an\nadaptive optimization module Distribution-aware Scaling Module (DSM) is\nintroduced to dynamically balance classification and contrastive losses,\nenabling more stable and discriminative representation learning. Extensive\nexperiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF\nsignificantly improves both recognition accuracy and robustness. Our method\nachieves superior weighted average recall (WAR) and unweighted average recall\n(UAR) while maintaining strong generalization across diverse and imbalanced\nscenarios. Codes are released at https://github.com/QIcita/HDF_DFER.",
      "url": "http://arxiv.org/abs/2507.15765v1",
      "published_time_eastern_timestamp": 1753114907.0
    },
    {
      "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in\n  Smart Contracts",
      "summary": "Smart contracts are trustworthy, immutable, and automatically executed\nprograms on the blockchain. Their execution requires the Gas mechanism to\nensure efficiency and fairness. However, due to non-optimal coding practices,\nmany contracts contain Gas waste patterns that need to be optimized. Existing\nsolutions mostly rely on manual discovery, which is inefficient, costly to\nmaintain, and difficult to scale. Recent research uses large language models\n(LLMs) to explore new Gas waste patterns. However, it struggles to remain\ncompatible with existing patterns, often produces redundant patterns, and\nrequires manual validation/rewriting. To address this gap, we present GasAgent,\nthe first multi-agent system for smart contract Gas optimization that combines\ncompatibility with existing patterns and automated discovery/validation of new\npatterns, enabling end-to-end optimization. GasAgent consists of four\nspecialized agents, Seeker, Innovator, Executor, and Manager, that collaborate\nin a closed loop to identify, validate, and apply Gas-saving improvements.\nExperiments on 100 verified real-world contracts demonstrate that GasAgent\nsuccessfully optimizes 82 contracts, achieving an average deployment Gas\nsavings of 9.97%. In addition, our evaluation confirms its compatibility with\nexisting tools and validates the effectiveness of each module through ablation\nstudies. To assess broader usability, we further evaluate 500 contracts\ngenerated by five representative LLMs across 10 categories and find that\nGasAgent optimizes 79.8% of them, with deployment Gas savings ranging from\n4.79% to 13.93%, showing its usability as the optimization layer for\nLLM-assisted smart contract development.",
      "url": "http://arxiv.org/abs/2507.15761v1",
      "published_time_eastern_timestamp": 1753114645.0
    },
    {
      "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue",
      "summary": "Collecting human-chatbot dialogues typically demands substantial manual\neffort and is time-consuming, which limits and poses challenges for research on\nconversational AI. In this work, we propose DialogueForge - a framework for\ngenerating AI-simulated conversations in human-chatbot style. To initialize\neach generated conversation, DialogueForge uses seed prompts extracted from\nreal human-chatbot interactions. We test a variety of LLMs to simulate the\nhuman chatbot user, ranging from state-of-the-art proprietary models to\nsmall-scale open-source LLMs, and generate multi-turn dialogues tailored to\nspecific tasks. In addition, we explore fine-tuning techniques to enhance the\nability of smaller models to produce indistinguishable human-like dialogues. We\nevaluate the quality of the simulated conversations and compare different\nmodels using the UniEval and GTEval evaluation protocols. Our experiments show\nthat large proprietary models (e.g., GPT-4o) generally outperform others in\ngenerating more realistic dialogues, while smaller open-source models (e.g.,\nLlama, Mistral) offer promising performance with greater customization. We\ndemonstrate that the performance of smaller models can be significantly\nimproved by employing supervised fine-tuning techniques. Nevertheless,\nmaintaining coherent and natural long-form human-like dialogues remains a\ncommon challenge across all models.",
      "url": "http://arxiv.org/abs/2507.15752v1",
      "published_time_eastern_timestamp": 1753114099.0
    }
  ]
}
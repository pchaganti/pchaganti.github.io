{
  "last_updated": "2025-08-04T11:14:14.611103-04:00",
  "papers": [
    {
      "title": "Beyond Fixed: Variable-Length Denoising for Diffusion Large Language\n  Models",
      "summary": "Diffusion Large Language Models (DLLMs) are emerging as a powerful\nalternative to the dominant Autoregressive Large Language Models, offering\nefficient parallel generation and capable global context modeling. However, the\npractical application of DLLMs is hindered by a critical architectural\nconstraint: the need for a statically predefined generation length. This static\nlength allocation leads to a problematic trade-off: insufficient lengths\ncripple performance on complex tasks, while excessive lengths incur significant\ncomputational overhead and sometimes result in performance degradation. While\nthe inference framework is rigid, we observe that the model itself possesses\ninternal signals that correlate with the optimal response length for a given\ntask. To bridge this gap, we leverage these latent signals and introduce\nDAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive\nLength Expansion for Diffusion Large Language Models. DAEDAL operates in two\nphases: 1) Before the denoising process, DAEDAL starts from a short initial\nlength and iteratively expands it to a coarse task-appropriate length, guided\nby a sequence completion metric. 2) During the denoising process, DAEDAL\ndynamically intervenes by pinpointing and expanding insufficient generation\nregions through mask token insertion, ensuring the final output is fully\ndeveloped. Extensive experiments on DLLMs demonstrate that DAEDAL achieves\nperformance comparable, and in some cases superior, to meticulously tuned\nfixed-length baselines, while simultaneously enhancing computational efficiency\nby achieving a higher effective token ratio. By resolving the static length\nconstraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap\nwith their Autoregressive counterparts and paving the way for more efficient\nand capable generation.",
      "url": "http://arxiv.org/abs/2508.00819v1",
      "published_time_eastern_timestamp": 1754070967.0
    },
    {
      "title": "A Large Catalog of DA White Dwarf Characteristics Using SDSS and Gaia\n  Observations",
      "summary": "We present a catalog of 8545 and 19,257 unique DA white dwarfs observed in\nSDSS Data Release 19 and previous SDSS data releases, respectively. This is the\nlargest catalog of both spectroscopic and photometric measurements of DA white\ndwarfs available to date, and we make this catalog and all code used to create\nit publicly available. We measure the apparent radial velocity, spectroscopic\neffective temperature and surface gravity, and photometric effective\ntemperature and radius for all objects in our catalog. We validate our\nmeasurements against other published white dwarf catalogs. For apparent radial\nvelocities, surface gravities, and effective temperatures measured from spectra\nwith signal-to-noise ratios $>50$, our measurements agree with published SDSS\nwhite dwarf catalogs to within 7.5 km/s, 0.060 dex, and $2.4\\%$, respectively.\nFor radii and effective temperatures measured with Gaia photometry, our\nmeasurements agree with other published Gaia datasets to within $0.0005$\n$R_\\odot$ and $3\\%$, respectively. We use this catalog to investigate\nsystematic discrepancies between white dwarfs observed in SDSS-V and previous\ngenerations of SDSS. For objects observed in both SDSS-V and previous\ngenerations, we uncover systematic differences between measured spectroscopic\nparameters depending on which set of survey data is used. On average, the\nmeasured apparent radial velocity of a DA white dwarf is $11.5$ km/s larger and\nthe surface gravity is $0.015$ dex smaller when a white dwarf's spectroscopic\nparameters are measured using SDSS-V data compared to using data from previous\ngenerations of SDSS. These differences may be due to changes in the wavelength\nsolution across survey generations.",
      "url": "http://arxiv.org/abs/2508.00818v1",
      "published_time_eastern_timestamp": 1754070910.0
    },
    {
      "title": "Unraveling Hidden Representations: A Multi-Modal Layer Analysis for\n  Better Synthetic Content Forensics",
      "summary": "Generative models achieve remarkable results in multiple data domains,\nincluding images and texts, among other examples. Unfortunately, malicious\nusers exploit synthetic media for spreading misinformation and disseminating\ndeepfakes. Consequently, the need for robust and stable fake detectors is\npressing, especially when new generative models appear everyday. While the\nmajority of existing work train classifiers that discriminate between real and\nfake information, such tools typically generalize only within the same family\nof generators and data modalities, yielding poor results on other generative\nclasses and data domains. Towards a universal classifier, we propose the use of\nlarge pre-trained multi-modal models for the detection of generative content.\nEffectively, we show that the latent code of these models naturally captures\ninformation discriminating real from fake. Building on this observation, we\ndemonstrate that linear classifiers trained on these features can achieve\nstate-of-the-art results across various modalities, while remaining\ncomputationally efficient, fast to train, and effective even in few-shot\nsettings. Our work primarily focuses on fake detection in audio and images,\nachieving performance that surpasses or matches that of strong baseline\nmethods.",
      "url": "http://arxiv.org/abs/2508.00784v1",
      "published_time_eastern_timestamp": 1754068020.0
    },
    {
      "title": "Ï„-Ring: A Smart Ring Platform for Multimodal Physiological and\n  Behavioral Sensing",
      "summary": "Smart rings have emerged as uniquely convenient devices for continuous\nphysiological and behavioral sensing, offering unobtrusive, constant access to\nmetrics such as heart rate, motion, and skin temperature. Yet most commercial\nsolutions remain proprietary, hindering reproducibility and slowing innovation\nin wearable research. We introduce {\\tau}-Ring, a commercial-ready platform\nthat bridges this gap through: (i) accessible hardware combining\ntime-synchronized multi-channel PPG, 6-axis IMU, temperature sensing, NFC, and\non-board storage; (ii) adjustable firmware that lets researchers rapidly\nreconfigure sampling rates, power modes, and wireless protocols; and (iii) a\nfully open-source Android software suite that supports both real-time streaming\nand 8-hour offline logging. Together, these features enable out-of-the-box,\nreproducible acquisition of rich physiological and behavioral datasets,\naccelerating prototyping and standardizing experimentation. We validate the\nplatform with demonstration studies in heart-rate monitoring and ring-based\nhandwriting recognition. Source code is available at GitHub:\nhttps://github.com/thuhci/OpenRing.",
      "url": "http://arxiv.org/abs/2508.00778v1",
      "published_time_eastern_timestamp": 1754067633.0
    },
    {
      "title": "Contact Sensors to Remote Cameras: Quantifying Cardiorespiratory\n  Coupling in High-Altitude Exercise Recovery",
      "summary": "Cardiorespiratory coupling (CRC) captures the dynamic interaction between the\ncardiac and respiratory systems--an interaction strengthened by physical\nexercise and linked to improved physiological function. We examined CRC at high\naltitude in two states, rest and post-exercise recovery, and found significant\ndifferences (p < 0.05). Quantitative analysis revealed that recovery involved\nmore frequent yet less stable episodes of synchronization between respiration\nand pulse. Furthermore, we explored the feasibility of non-contact CRC\nmeasurement with remote photoplethysmography (rPPG), observing a strong\ncorrelation with oximeter-based metrics (Pearson r = 0.96). These findings\nhighlight the potential of CRC as a sensitive marker for autonomic regulation\nand its future application in contactless monitoring. Source code is available\nat GitHub: https://github.com/McJackTang/CRC.",
      "url": "http://arxiv.org/abs/2508.00773v1",
      "published_time_eastern_timestamp": 1754067287.0
    },
    {
      "title": "From Code to Career: Assessing Competitive Programmers for Industry\n  Placement",
      "summary": "In today's fast-paced tech industry, there is a growing need for tools that\nevaluate a programmer's job readiness based on their coding performance. This\nstudy focuses on predicting the potential of Codeforces users to secure various\nlevels of software engineering jobs. The primary objective is to analyze how a\nuser's competitive programming activity correlates with their chances of\nobtaining positions, ranging from entry-level roles to jobs at major tech\ncompanies. We collect user data using the Codeforces API, process key\nperformance metrics, and build a prediction model using a Random Forest\nclassifier. The model categorizes users into four levels of employability,\nranging from those needing further development to those ready for top-tier tech\njobs. The system is implemented using Flask and deployed on Render for\nreal-time predictions. Our evaluation demonstrates that the approach\neffectively distinguishes between different skill levels based on coding\nproficiency and participation. This work lays a foundation for the use of\nmachine learning in career assessment and could be extended to predict job\nreadiness in broader technical fields.",
      "url": "http://arxiv.org/abs/2508.00772v1",
      "published_time_eastern_timestamp": 1754067164.0
    },
    {
      "title": "Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation",
      "summary": "Image-to-image translation has emerged as a powerful technique in medical\nimaging, enabling tasks such as image denoising and cross-modality conversion.\nHowever, it suffers from limitations in handling out-of-distribution samples\nwithout causing performance degradation. To address this limitation, we propose\na novel Test-Time Adaptation (TTA) framework that dynamically adjusts the\ntranslation process based on the characteristics of each test sample. Our\nmethod introduces a Reconstruction Module to quantify the domain shift and a\nDynamic Adaptation Block that selectively modifies the internal features of a\npretrained translation model to mitigate the shift without compromising the\nperformance on in-distribution samples that do not require adaptation. We\nevaluate our approach on two medical image-to-image translation tasks: low-dose\nCT denoising and T1 to T2 MRI translation, showing consistent improvements over\nboth the baseline translation model without TTA and prior TTA methods. Our\nanalysis highlights the limitations of the state-of-the-art that uniformly\napply the adaptation to both out-of-distribution and in-distribution samples,\ndemonstrating that dynamic, sample-specific adjustment offers a promising path\nto improve model resilience in real-world scenarios. The code is available at:\nhttps://github.com/cosbidev/Sample-Aware_TTA.",
      "url": "http://arxiv.org/abs/2508.00766v1",
      "published_time_eastern_timestamp": 1754066475.0
    },
    {
      "title": "ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A\n  Zero-Shot Approach using LLM-Driven Code Generation",
      "summary": "This paper presents our system for SemEval-2025 Task 8: DataBench,\nQuestion-Answering over Tabular Data. The primary objective of this task is to\nperform question answering on given tabular datasets from diverse domains under\ntwo subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To\ntackle both subtasks, we developed a zero-shot solution with a particular\nemphasis on leveraging Large Language Model (LLM)-based code generation.\nSpecifically, we propose a Python code generation framework utilizing\nstate-of-the-art open-source LLMs to generate executable Pandas code via\noptimized prompting strategies. Our experiments reveal that different LLMs\nexhibit varying levels of effectiveness in Python code generation.\nAdditionally, results show that Python code generation achieves superior\nperformance in tabular question answering compared to alternative approaches.\nAlthough our ranking among zero-shot systems is unknown at the time of this\npaper's submission, our system achieved eighth place in Subtask I and sixth\nplace in Subtask~II among the 30 systems that outperformed the baseline in the\nopen-source models category.",
      "url": "http://arxiv.org/abs/2508.00762v1",
      "published_time_eastern_timestamp": 1754066298.0
    },
    {
      "title": "Can cosmic rotation resolve the Hubble tension? Constraints from CMB and\n  large-scale structure",
      "summary": "We investigate a relativistic cosmological model with background rotation,\nsourced by a non-perfect fluid with anisotropic stress. A modified version of\nthe CLASS Boltzmann code is employed to perform MCMC analyses against Cosmic\nMicrowave Background (CMB) and late-time datasets. The results show that\ncurrent CMB data constrain the present-day rotation parameter to be negligible.\nAs a consequence, the derived cosmological parameters remain consistent with\nthe standard $\\Lambda$CDM values. In contrast, late-time probes such as Type Ia\nsupernovae (SNe) and Baryonic Acoustic Oscillations (BAO) allow for a higher\nlevel of rotation and yield an increased Hubble constant. However, this comes\nat the cost of a higher $\\sigma_8$, which remains in tension with DES-Y3\nmeasurement. Combining CMB, SNe and BAO data confirms the preference for\nnon-rotation.",
      "url": "http://arxiv.org/abs/2508.00759v1",
      "published_time_eastern_timestamp": 1754066011.0
    },
    {
      "title": "GLiDRE: Generalist Lightweight model for Document-level Relation\n  Extraction",
      "summary": "Relation Extraction (RE) is a fundamental task in Natural Language\nProcessing, and its document-level variant poses significant challenges, due to\nthe need to model complex interactions between entities across sentences.\nCurrent approaches, largely based on the ATLOP architecture, are commonly\nevaluated on benchmarks like DocRED and Re-DocRED. However, their performance\nin zero-shot or few-shot settings remains largely underexplored due to the\ntask's complexity. Recently, the GLiNER model has shown that a compact NER\nmodel can outperform much larger Large Language Models. With a similar\nmotivation, we introduce GLiDRE, a new model for document-level relation\nextraction that builds on the key ideas of GliNER. We benchmark GLiDRE against\nstate-of-the-art models across various data settings on the Re-DocRED dataset.\nOur results demonstrate that GLiDRE achieves state-of-the-art performance in\nfew-shot scenarios. Our code is publicly available.",
      "url": "http://arxiv.org/abs/2508.00757v1",
      "published_time_eastern_timestamp": 1754065993.0
    },
    {
      "title": "A normalizing flow approach for the inference of star cluster properties\n  from unresolved broadband photometry I: Comparison to spectral energy\n  distribution fitting",
      "summary": "Estimating properties of star clusters from unresolved broadband photometry\nis a challenging problem that is classically tackled by spectral energy\ndistribution (SED) fitting methods that are based on simple stellar population\n(SSP) models. However, because of their exponential scaling, grid-based methods\nsuffer from computational limitations. In addition, stochastic latent variables\nin the model can make the computation of the likelihood function intractable.\nThese limitations can be overcome by modern generative deep learning methods\nthat offer flexible and powerful tools for modeling high-dimensional posterior\ndistributions and fast inference from learned data. We present a normalizing\nflow approach for the inference of cluster age, mass, and reddening from Hubble\nSpace Telescope (HST) broadband photometry. In particular, we explore our\nnetwork's behavior on an inference problem that has been analyzed in previous\nworks. We used the SED modeling code CIGALE to create a dataset of synthetic\nphotometric observations for $5 \\times 10^6$ mock star clusters. Subsequently,\nthis data set was used to train a coupling-based flow in the form of a\nconditional invertible neural network (cINN) to predict posterior probability\ndistributions for cluster age, mass, and reddening from photometric\nobservations. We predicted cluster parameters for the 'Physics at High Angular\nresolution in Nearby GalaxieS' (PHANGS) Data Release 3 catalog. To evaluate the\ncapabilities of the network, we compared our results to the publicly available\nPHANGS estimates and found that the estimates agree reasonably well. We\ndemonstrate that normalizing flow methods can be a viable tool for the\ninference of cluster parameters, and argue that this approach is especially\nuseful when latent variables make the computation of the likelihood intractable\nand in scenarios that require efficient density estimation.",
      "url": "http://arxiv.org/abs/2508.00736v1",
      "published_time_eastern_timestamp": 1754064373.0
    },
    {
      "title": "Deep Joint Source-Channel Coding for Small Satellite Applications",
      "summary": "Small satellites used for Earth observation generate vast amounts of\nhigh-dimensional data, but their operation in low Earth orbit creates a\nsignificant communication bottleneck due to limited contact times and harsh,\nvarying channel conditions. While deep joint source-channel coding (DJSCC) has\nemerged as a promising technique, its practical application to the complex\nsatellite environment remains an open question. This paper presents a\ncomprehensive DJSCC framework tailored for satellite communications. We first\nestablish a basic system, DJSCC-SAT, and integrate a realistic, multi-state\nstatistical channel model to guide its training and evaluation. To overcome the\nimpracticality of using separate models for every channel condition, we then\nintroduce an adaptable architecture, ADJSCC-SAT, which leverages attention\nmodules to allow a single neural network to adjust to a wide range of channel\nstates with minimal overhead. Through extensive evaluation on Sentinel-2\nmulti-spectral data, we demonstrate that our adaptable approach achieves\nperformance comparable to using multiple specialized networks while\nsignificantly reducing model storage requirements. Furthermore, the adaptable\nmodel shows enhanced robustness to channel estimation errors, outperforming the\nnon-adaptable baseline. The proposed framework is a practical and efficient\nstep toward deploying robust, adaptive DJSCC systems for real-world satellite\nmissions.",
      "url": "http://arxiv.org/abs/2508.00715v1",
      "published_time_eastern_timestamp": 1754062145.0
    },
    {
      "title": "D3: Training-Free AI-Generated Video Detection Using Second-Order\n  Features",
      "summary": "The evolution of video generation techniques, such as Sora, has made it\nincreasingly easy to produce high-fidelity AI-generated videos, raising public\nconcern over the dissemination of synthetic content. However, existing\ndetection methodologies remain limited by their insufficient exploration of\ntemporal artifacts in synthetic videos. To bridge this gap, we establish a\ntheoretical framework through second-order dynamical analysis under Newtonian\nmechanics, subsequently extending the Second-order Central Difference features\ntailored for temporal artifact detection. Building on this theoretical\nfoundation, we reveal a fundamental divergence in second-order feature\ndistributions between real and AI-generated videos. Concretely, we propose\nDetection by Difference of Differences (D3), a novel training-free detection\nmethod that leverages the above second-order temporal discrepancies. We\nvalidate the superiority of our D3 on 4 open-source datasets (Gen-Video,\nVideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,\nD3 outperforms the previous best method by 10.39% (absolute) mean Average\nPrecision. Additional experiments on time cost and post-processing operations\ndemonstrate D3's exceptional computational efficiency and strong robust\nperformance. Our code is available at https://github.com/Zig-HS/D3.",
      "url": "http://arxiv.org/abs/2508.00701v1",
      "published_time_eastern_timestamp": 1754061471.0
    },
    {
      "title": "Is LLM-Generated Code More Maintainable \\& Reliable than Human-Written\n  Code?",
      "summary": "Background: The rise of Large Language Models (LLMs) in software development\nhas opened new possibilities for code generation. Despite the widespread use of\nthis technology, it remains unclear how well LLMs generate code solutions in\nterms of software quality and how they compare to human-written code. Aims:\nThis study compares the internal quality attributes of LLM-generated and\nhuman-written code. Method: Our empirical study integrates datasets of coding\ntasks, three LLM configurations (zero-shot, few-shot, and fine-tuning), and\nSonarQube to assess software quality. The dataset comprises Python code\nsolutions across three difficulty levels: introductory, interview, and\ncompetition. We analyzed key code quality metrics, including maintainability\nand reliability, and the estimated effort required to resolve code issues.\nResults: Our analysis shows that LLM-generated code has fewer bugs and requires\nless effort to fix them overall. Interestingly, fine-tuned models reduced the\nprevalence of high-severity issues, such as blocker and critical bugs, and\nshifted them to lower-severity categories, but decreased the model's\nperformance. In competition-level problems, the LLM solutions sometimes\nintroduce structural issues that are not present in human-written code.\nConclusion: Our findings provide valuable insights into the quality of\nLLM-generated code; however, the introduction of critical issues in more\ncomplex scenarios highlights the need for a systematic evaluation and\nvalidation of LLM solutions. Our work deepens the understanding of the\nstrengths and limitations of LLMs for code generation.",
      "url": "http://arxiv.org/abs/2508.00700v1",
      "published_time_eastern_timestamp": 1754061454.0
    },
    {
      "title": "Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement\n  Techniques and Applications",
      "summary": "The proliferation of Large Language Models (LLMs) in medicine has enabled\nimpressive capabilities, yet a critical gap remains in their ability to perform\nsystematic, transparent, and verifiable reasoning, a cornerstone of clinical\npractice. This has catalyzed a shift from single-step answer generation to the\ndevelopment of LLMs explicitly designed for medical reasoning. This paper\nprovides the first systematic review of this emerging field. We propose a\ntaxonomy of reasoning enhancement techniques, categorized into training-time\nstrategies (e.g., supervised fine-tuning, reinforcement learning) and test-time\nmechanisms (e.g., prompt engineering, multi-agent systems). We analyze how\nthese techniques are applied across different data modalities (text, image,\ncode) and in key clinical applications such as diagnosis, education, and\ntreatment planning. Furthermore, we survey the evolution of evaluation\nbenchmarks from simple accuracy metrics to sophisticated assessments of\nreasoning quality and visual interpretability. Based on an analysis of 60\nseminal studies from 2022-2025, we conclude by identifying critical challenges,\nincluding the faithfulness-plausibility gap and the need for native multimodal\nreasoning, and outlining future directions toward building efficient, robust,\nand sociotechnically responsible medical AI.",
      "url": "http://arxiv.org/abs/2508.00669v1",
      "published_time_eastern_timestamp": 1754059291.0
    },
    {
      "title": "Multi-Band Variable-Lag Granger Causality: A Unified Framework for\n  Causal Time Series Inference across Frequencies",
      "summary": "Understanding causal relationships in time series is fundamental to many\ndomains, including neuroscience, economics, and behavioral science. Granger\ncausality is one of the well-known techniques for inferring causality in time\nseries. Typically, Granger causality frameworks have a strong fix-lag\nassumption between cause and effect, which is often unrealistic in complex\nsystems. While recent work on variable-lag Granger causality (VLGC) addresses\nthis limitation by allowing a cause to influence an effect with different time\nlags at each time point, it fails to account for the fact that causal\ninteractions may vary not only in time delay but also across frequency bands.\nFor example, in brain signals, alpha-band activity may influence another region\nwith a shorter delay than slower delta-band oscillations. In this work, we\nformalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a\nnovel framework that generalizes traditional VLGC by explicitly modeling\nfrequency-dependent causal delays. We provide a formal definition of MB-VLGC,\ndemonstrate its theoretical soundness, and propose an efficient inference\npipeline. Extensive experiments across multiple domains demonstrate that our\nframework significantly outperforms existing methods on both synthetic and\nreal-world datasets, confirming its broad applicability to any type of time\nseries data. Code and datasets are publicly available.",
      "url": "http://arxiv.org/abs/2508.00658v1",
      "published_time_eastern_timestamp": 1754058171.0
    },
    {
      "title": "Revisiting Adversarial Patch Defenses on Object Detectors: Unified\n  Evaluation, Large-Scale Dataset, and New Insights",
      "summary": "Developing reliable defenses against patch attacks on object detectors has\nattracted increasing interest. However, we identify that existing defense\nevaluations lack a unified and comprehensive framework, resulting in\ninconsistent and incomplete assessments of current methods. To address this\nissue, we revisit 11 representative defenses and present the first patch\ndefense benchmark, involving 2 attack goals, 13 patch attacks, 11 object\ndetectors, and 4 diverse metrics. This leads to the large-scale adversarial\npatch dataset with 94 types of patches and 94,000 images. Our comprehensive\nanalyses reveal new insights: (1) The difficulty in defending against\nnaturalistic patches lies in the data distribution, rather than the commonly\nbelieved high frequencies. Our new dataset with diverse patch distributions can\nbe used to improve existing defenses by 15.09% AP@0.5. (2) The average\nprecision of the attacked object, rather than the commonly pursued patch\ndetection accuracy, shows high consistency with defense performance. (3)\nAdaptive attacks can substantially bypass existing defenses, and defenses with\ncomplex/stochastic models or universal patch properties are relatively robust.\nWe hope that our analyses will serve as guidance on properly evaluating patch\nattacks/defenses and advancing their design. Code and dataset are available at\nhttps://github.com/Gandolfczjh/APDE, where we will keep integrating new\nattacks/defenses.",
      "url": "http://arxiv.org/abs/2508.00649v1",
      "published_time_eastern_timestamp": 1754057180.0
    },
    {
      "title": "Pull Requests From The Classroom: Co-Developing Curriculum And Code",
      "summary": "Educational technologies often misalign with instructors' pedagogical goals,\nforcing adaptations that compromise teaching efficacy. In this paper, we\npresent a case study on the co-development of curriculum and technology in the\ncontext of a university course on scientific writing. Specifically, we examine\nhow a custom-built peer feedback system was iteratively developed alongside the\ncourse to support annotation, feedback exchange, and revision. Results show\nthat while co-development fostered stronger alignment between software features\nand course goals, it also exposed usability limitations and\ninfrastructure-related frustrations, emphasizing the need for closer\ncoordination between teaching and technical teams.",
      "url": "http://arxiv.org/abs/2508.00646v1",
      "published_time_eastern_timestamp": 1754057049.0
    },
    {
      "title": "SmartFlow: A CFD-solver-agnostic deep reinforcement learning framework\n  for computational fluid dynamics on HPC platforms",
      "summary": "Deep reinforcement learning (DRL) is emerging as a powerful tool for\nfluid-dynamics research, encompassing active flow control, autonomous\nnavigation, turbulence modeling and discovery of novel numerical schemes. We\nintroduce SmartFlow, a CFD-solver-agnostic framework for both single- and\nmulti-agent DRL algorithms that can easily integrate with MPI-parallel CPU and\nGPU-accelerated solvers. Built on Relexi and SmartSOD2D, SmartFlow uses the\nSmartSim infrastructure library and our newly developed SmartRedis-MPI library\nto enable asynchronous, low-latency, in-memory communication between CFD\nsolvers and Python-based DRL algorithms. SmartFlow leverages PyTorch's\nStable-Baselines3 for training, which provides a modular, Gym-like environment\nAPI. We demonstrate its versatility via three case studies: single-agent\nsynthetic-jet control for drag reduction in a cylinder flow simulated by the\nhigh-order FLEXI solver, multi-agent cylinder wake control using the\nGPU-accelerated spectral-element code SOD2D, and multi-agent wall-model\nlearning for large-eddy simulation with the finite-difference solver CaLES.\nSmartFlow's CFD-solver-agnostic design and seamless HPC integration is\npromising to accelerate RL-driven fluid-mechanics studies.",
      "url": "http://arxiv.org/abs/2508.00645v1",
      "published_time_eastern_timestamp": 1754057021.0
    },
    {
      "title": "Reinforcement Learning for Decision-Level Interception Prioritization in\n  Drone Swarm Defense",
      "summary": "The growing threat of low-cost kamikaze drone swarms poses a critical\nchallenge to modern defense systems demanding rapid and strategic\ndecision-making to prioritize interceptions across multiple effectors and\nhigh-value target zones. In this work, we present a case study demonstrating\nthe practical advantages of reinforcement learning in addressing this\nchallenge. We introduce a high-fidelity simulation environment that captures\nrealistic operational constraints, within which a decision-level reinforcement\nlearning agent learns to coordinate multiple effectors for optimal interception\nprioritization. Operating in a discrete action space, the agent selects which\ndrone to engage per effector based on observed state features such as\npositions, classes, and effector status. We evaluate the learned policy against\na handcrafted rule-based baseline across hundreds of simulated attack\nscenarios. The reinforcement learning based policy consistently achieves lower\naverage damage and higher defensive efficiency in protecting critical zones.\nThis case study highlights the potential of reinforcement learning as a\nstrategic layer within defense architectures, enhancing resilience without\ndisplacing existing control systems. All code and simulation assets are\npublicly released for full reproducibility, and a video demonstration\nillustrates the policy's qualitative behavior.",
      "url": "http://arxiv.org/abs/2508.00641v1",
      "published_time_eastern_timestamp": 1754056539.0
    }
  ]
}
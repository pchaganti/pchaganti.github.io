{
  "last_updated": "2025-10-21T02:18:35.608857-04:00",
  "papers": [
    {
      "title": "Glyph: Scaling Context Windows via Visual-Text Compression",
      "summary": "Large language models (LLMs) increasingly rely on long-context modeling for\ntasks such as document understanding, code analysis, and multi-step reasoning.\nHowever, scaling context windows to the million-token level brings prohibitive\ncomputational and memory costs, limiting the practicality of long-context LLMs.\nIn this work, we take a different perspective-visual context scaling-to tackle\nthis challenge. Instead of extending token-based sequences, we propose Glyph, a\nframework that renders long texts into images and processes them with\nvision-language models (VLMs). This approach substantially compresses textual\ninput while preserving semantic information, and we further design an\nLLM-driven genetic search to identify optimal visual rendering configurations\nfor balancing accuracy and compression. Through extensive experiments, we\ndemonstrate that our method achieves 3-4x token compression while maintaining\naccuracy comparable to leading LLMs such as Qwen3-8B on various long-context\nbenchmarks. This compression also leads to around 4x faster prefilling and\ndecoding, and approximately 2x faster SFT training. Furthermore, under extreme\ncompression, a 128K-context VLM could scale to handle 1M-token-level text\ntasks. In addition, the rendered text data benefits real-world multimodal\ntasks, such as document understanding. Our code and model are released at\nhttps://github.com/thu-coai/Glyph.",
      "url": "http://arxiv.org/abs/2510.17800v1",
      "published_time_eastern_timestamp": 1760983136.0
    },
    {
      "title": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for\n  Enterprise Analytics",
      "summary": "As information grows exponentially, enterprises face increasing pressure to\ntransform unstructured data into coherent, actionable insights. While\nautonomous agents show promise, they often struggle with domain-specific\nnuances, intent alignment, and enterprise integration. We present Enterprise\nDeep Research (EDR), a multi-agent system that integrates (1) a Master Planning\nAgent for adaptive query decomposition, (2) four specialized search agents\n(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool\necosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a\nVisualization Agent for data-driven insights, and (5) a reflection mechanism\nthat detects knowledge gaps and updates research direction with optional\nhuman-in-the-loop steering guidance. These components enable automated report\ngeneration, real-time streaming, and seamless enterprise deployment, as\nvalidated on internal datasets. On open-ended benchmarks including DeepResearch\nBench and DeepConsult, EDR outperforms state-of-the-art agentic systems without\nany human steering. We release the EDR framework and benchmark trajectories to\nadvance research on multi-agent reasoning applications.\n  Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and\nDataset at https://huggingface.co/datasets/Salesforce/EDR-200",
      "url": "http://arxiv.org/abs/2510.17797v1",
      "published_time_eastern_timestamp": 1760982911.0
    },
    {
      "title": "Executable Knowledge Graphs for Replicating AI Research",
      "summary": "Replicating AI research is a crucial yet challenging task for large language\nmodel (LLM) agents. Existing approaches often struggle to generate executable\ncode, primarily due to insufficient background knowledge and the limitations of\nretrieval-augmented generation (RAG) methods, which fail to capture latent\ntechnical details hidden in referenced papers. Furthermore, previous approaches\ntend to overlook valuable implementation-level code signals and lack structured\nknowledge representations that support multi-granular retrieval and reuse. To\novercome these challenges, we propose Executable Knowledge Graphs (xKG), a\nmodular and pluggable knowledge base that automatically integrates technical\ninsights, code snippets, and domain-specific knowledge extracted from\nscientific literature. When integrated into three agent frameworks with two\ndifferent LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on\nPaperBench, demonstrating its effectiveness as a general and extensible\nsolution for automated AI research replication. Code will released at\nhttps://github.com/zjunlp/xKG.",
      "url": "http://arxiv.org/abs/2510.17795v1",
      "published_time_eastern_timestamp": 1760982803.0
    },
    {
      "title": "Functional Distribution Networks (FDN)",
      "summary": "Modern probabilistic regressors often remain overconfident under distribution\nshift. We present Functional Distribution Networks (FDN), an input-conditioned\ndistribution over network weights that induces predictive mixtures whose\ndispersion adapts to the input. FDN is trained with a beta-ELBO and Monte Carlo\nsampling. We further propose an evaluation protocol that cleanly separates\ninterpolation from extrapolation and stresses OOD sanity checks (e.g., that\npredictive likelihood degrades under shift while in-distribution accuracy and\ncalibration are maintained). On standard regression tasks, we benchmark against\nstrong Bayesian, ensemble, dropout, and hypernetwork baselines under matched\nparameter and update budgets, and assess accuracy, calibration, and\nshift-awareness with standard diagnostics. Together, the framework and protocol\naim to make OOD-aware, well-calibrated neural regression practical and modular.",
      "url": "http://arxiv.org/abs/2510.17794v1",
      "published_time_eastern_timestamp": 1760982762.0
    },
    {
      "title": "Foundational Automatic Evaluators: Scaling Multi-Task Generative\n  Evaluator Training for Reasoning-Centric Domains",
      "summary": "Finetuning specialized generative evaluators has emerged as a popular\nparadigm to meet the increasing demand for scalable evaluation during both\ntraining and test-time. However, recent work has largely focused on applying\nnew methodology, such as reinforcement learning (RL), to training evaluators,\nshying away from large-scale, data-driven development. In this work, we focus\non data scaling, curating a set of 2.5M samples spanning five unique evaluation\ntasks (pairwise, step-level, reference-free and reference-based verification,\nand single rating) and multiple domains focused on reasoning evaluation. With\nour data, we train Foundational Automatic Reasoning Evaluators (FARE), a family\nof 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative\nrejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges\nlarger specialized RL-trained evaluators and FARE-20B sets the new standard for\nopen-source evaluators, surpassing specialized 70B+ evaluators. Beyond static\nbenchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers,\nFARE-20B achieves near-oracle performance on MATH. As verifiers in RL training,\nFARE improves the downstream RL-trained model performance by up to 14.1% vs.\nstring-matching verifiers. When initialized from FARE, a continually-finetuned\nFARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.",
      "url": "http://arxiv.org/abs/2510.17793v1",
      "published_time_eastern_timestamp": 1760982726.0
    },
    {
      "title": "UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action",
      "summary": "Multimodal agents for computer use rely exclusively on primitive actions\n(click, type, scroll) that require accurate visual grounding and lengthy\nexecution chains, leading to cascading failures and performance bottlenecks.\nWhile other agents leverage rich programmatic interfaces (APIs, MCP servers,\ntools), computer-use agents (CUAs) remain isolated from these capabilities. We\npresent UltraCUA, a foundation model that bridges this gap through hybrid\naction -- seamlessly integrating GUI primitives with high-level programmatic\ntool calls. To achieve this, our approach comprises four key components: (1) an\nautomated pipeline that scales programmatic tools from software documentation,\nopen-source repositories, and code generation; (2) a synthetic data engine\nproducing over 17,000 verifiable tasks spanning real-world computer-use\nscenarios; (3) a large-scale high-quality hybrid action trajectory collection\nwith both low-level GUI actions and high-level programmatic tool calls; and (4)\na two-stage training pipeline combining supervised fine-tuning with online\nreinforcement learning, enabling strategic alternation between low-level and\nhigh-level actions. Experiments with our 7B and 32B models demonstrate\nsubstantial improvements over state-of-the-art agents. On OSWorld, UltraCUA\nmodels achieve an average 22% relative improvement over base models, while\nbeing 11% faster in terms of steps. Out-of-domain evaluation on\nWindowsAgentArena shows our model reaches 21.7% success rate, outperforming\nbaselines trained on Windows data. The hybrid action mechanism proves critical,\nreducing error propagation while maintaining execution efficiency.",
      "url": "http://arxiv.org/abs/2510.17790v1",
      "published_time_eastern_timestamp": 1760982506.0
    },
    {
      "title": "Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant\n  Structures with Gaussian Splats",
      "summary": "Commercial plant phenotyping systems using fixed cameras cannot perceive many\nplant details due to leaf occlusion. In this paper, we present Botany-Bot, a\nsystem for building detailed \"annotated digital twins\" of living plants using\ntwo stereo cameras, a digital turntable inside a lightbox, an industrial robot\narm, and 3D segmentated Gaussian Splat models. We also present robot algorithms\nfor manipulating leaves to take high-resolution indexable images of occluded\ndetails such as stem buds and the underside/topside of leaves. Results from\nexperiments suggest that Botany-Bot can segment leaves with 90.8% accuracy,\ndetect leaves with 86.2% accuracy, lift/push leaves with 77.9% accuracy, and\ntake detailed overside/underside images with 77.3% accuracy. Code, videos, and\ndatasets are available at https://berkeleyautomation.github.io/Botany-Bot/.",
      "url": "http://arxiv.org/abs/2510.17783v1",
      "published_time_eastern_timestamp": 1760982140.0
    },
    {
      "title": "On the Capacity of Erasure-prone Quantum Storage with Erasure-prone\n  Entanglement Assistance",
      "summary": "A quantum message is encoded into $N$ storage nodes (quantum systems\n$Q_1\\dots Q_N$) with assistance from $N_B$ maximally entangled bi-partite\nquantum systems $A_1B_1, \\dots, A_{N_B}B_{N_B}$, that are prepared in advance\nsuch that $B_1\\dots B_{N_B}$ are stored separately as entanglement assistance\n(EA) nodes, while $A_1\\dots A_{N_B}$ are made available to the encoder. Both\nthe storage nodes and EA nodes are erasure-prone. The quantum message must be\nrecoverable given any $K$ of the $N$ storage nodes along with any $K_B$ of the\n$N_B$ EA nodes. The capacity for this setting is the maximum size of the\nquantum message, given that the size of each EA node is $\\lambda_B$. All node\nsizes are relative to the size of a storage node, which is normalized to unity.\nThe exact capacity is characterized as a function of $N,K,N_B,K_B, \\lambda_B$\nin all cases, with one exception. The capacity remains open for an intermediate\nrange of $\\lambda_B$ values when a strict majority of the $N$ storage nodes,\nand a strict non-zero minority of the $N_B$ EA nodes, are erased. As a key\nstepping stone, an analogous classical storage (with shared-randomness\nassistance) problem is introduced. A set of constraints is identified for the\nclassical problem, such that classical linear code constructions translate to\nquantum storage codes, and the converse bounds for the two settings utilize\nsimilar insights. In particular, the capacity characterizations for the\nclassical and quantum settings are shown to be identical in all cases where the\ncapacity is settled.",
      "url": "http://arxiv.org/abs/2510.17781v1",
      "published_time_eastern_timestamp": 1760982021.0
    },
    {
      "title": "Train for Truth, Keep the Skills: Binary Retrieval-Augmented Reward\n  Mitigates Hallucinations",
      "summary": "Language models often generate factually incorrect information unsupported by\ntheir training data, a phenomenon known as extrinsic hallucination. Existing\nmitigation approaches often degrade performance on open-ended generation and\ndownstream tasks, limiting their practical utility. We propose an online\nreinforcement learning method using a novel binary retrieval-augmented reward\n(RAR) to address this tradeoff. Unlike continuous reward schemes, our approach\nassigns a reward of one only when the model's output is entirely factually\ncorrect, and zero otherwise. We evaluate our method on Qwen3 reasoning models\nacross diverse tasks. For open-ended generation, binary RAR achieves a 39.3%\nreduction in hallucination rates, substantially outperforming both supervised\ntraining and continuous-reward RL baselines. In short-form question answering,\nthe model learns calibrated abstention, strategically outputting \"I don't know\"\nwhen faced with insufficient parametric knowledge. This yields 44.4% and 21.7%\nfewer incorrect answers on PopQA and GPQA, respectively. Crucially, these\nfactuality gains come without performance degradation on instruction following,\nmath, or code, whereas continuous-reward RL, despite improving factuality,\ninduces quality regressions.",
      "url": "http://arxiv.org/abs/2510.17733v1",
      "published_time_eastern_timestamp": 1760978743.0
    },
    {
      "title": "AcademicEval: Live Long-Context LLM Benchmark",
      "summary": "Large Language Models (LLMs) have recently achieved remarkable performance in\nlong-context understanding. However, current long-context LLM benchmarks are\nlimited by rigid context length, labor-intensive annotation, and the pressing\nchallenge of label leakage issues during LLM training. Therefore, we propose\n\\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context\ngeneration tasks. \\textsc{AcademicEval} adopts papers on arXiv to introduce\nseveral academic writing tasks with long-context inputs, \\textit{i.e.},\n\\textsc{Title}, \\textsc{Abstract}, \\textsc{Introduction}, and \\textsc{Related\nWork}, which cover a wide range of abstraction levels and require no manual\nlabeling. Moreover, \\textsc{AcademicEval} integrates high-quality and\nexpert-curated few-shot demonstrations from a collected co-author graph to\nenable flexible context length. Especially, \\textsc{AcademicEval} features an\nefficient live evaluation, ensuring no label leakage. We conduct a holistic\nevaluation on \\textsc{AcademicEval}, and the results illustrate that LLMs\nperform poorly on tasks with hierarchical abstraction levels and tend to\nstruggle with long few-shot demonstrations, highlighting the challenge of our\nbenchmark. Through experimental analysis, we also reveal some insights for\nenhancing LLMs' long-context modeling capabilities. Code is available at\nhttps://github.com/ulab-uiuc/AcademicEval",
      "url": "http://arxiv.org/abs/2510.17725v1",
      "published_time_eastern_timestamp": 1760978550.0
    },
    {
      "title": "Graph-Based Light-Curve Features for Robust Transient Classification",
      "summary": "We investigate graph-based representations of astronomical light curves for\ntransient classification on the MANTRA benchmark. Each series is mapped to\nthree visibility-graph views-horizontal (HVG), directed (DHVG), and weighted\n(W-HVG)-from which we extract compact, length-aware network descriptors\n(degree/strength moments, clustering and motifs, assortativity,\npath/efficiency, and spectral summaries). Using stratified five-fold validation\nand tree-based learners, the best configuration (LightGBM with HVG+DHVG+W-HVG\nfeatures) attains a macro-F1 of 0.622 +/- 0.010 and accuracy of 0.661 +/-\n0.010, improving over the MANTRA baseline (F1 macro = 0.528). Ablations show\nthat weighted contrasts and directed asymmetry contribute complementary gains\nto undirected topology. Per-class analysis highlights strong performance for\nCV, HPM, and Non-Tr., with residual confusions concentrated in the\nAGN-Blazar-SN block. These results indicate that visibility graphs offer a\nsimple, survey-agnostic bridge between irregular photometric time series and\nstandard classifiers, yielding competitive multiclass performance without\nbespoke deep architectures. We release code and feature definitions to\nfacilitate reproducibility and future extensions.",
      "url": "http://arxiv.org/abs/2510.17721v1",
      "published_time_eastern_timestamp": 1760978270.0
    },
    {
      "title": "QueST: Incentivizing LLMs to Generate Difficult Problems",
      "summary": "Large Language Models have achieved strong performance on reasoning tasks,\nsolving competition-level coding and math problems. However, their scalability\nis limited by human-labeled datasets and the lack of large-scale, challenging\ncoding problem training data. Existing competitive coding datasets contain only\nthousands to tens of thousands of problems. Previous synthetic data generation\nmethods rely on either augmenting existing instruction datasets or selecting\nchallenging problems from human-labeled data. In this paper, we propose QueST,\na novel framework which combines difficulty-aware graph sampling and\ndifficulty-aware rejection fine-tuning that directly optimizes specialized\ngenerators to create challenging coding problems. Our trained generators\ndemonstrate superior capability compared to even GPT-4o at creating challenging\nproblems that benefit downstream performance. We leverage QueST to generate\nlarge-scale synthetic coding problems, which we then use to distill from strong\nteacher models with long chain-of-thought or to conduct reinforcement learning\nfor smaller models, proving effective in both scenarios. Our distillation\nexperiments demonstrate significant performance gains. Specifically, after\nfine-tuning Qwen3-8B-base on 100K difficult problems generated by QueST, we\nsurpass the performance of the original Qwen3-8B on LiveCodeBench. With an\nadditional 112K examples (i.e., 28K human-written problems paired with multiple\nsynthetic solutions), our 8B model matches the performance of the much larger\nDeepSeek-R1-671B. These findings indicate that generating complex problems via\nQueST offers an effective and scalable approach to advancing the frontiers of\ncompetitive coding and reasoning for large language models.",
      "url": "http://arxiv.org/abs/2510.17715v1",
      "published_time_eastern_timestamp": 1760977793.0
    },
    {
      "title": "Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation\n  in Large Language Models",
      "summary": "Large Language Models (LLMs) possess remarkable generalization capabilities\nbut struggle with multi-task adaptation, particularly in balancing knowledge\nretention with task-specific specialization. Conventional fine-tuning methods\nsuffer from catastrophic forgetting and substantial resource consumption, while\nexisting parameter-efficient methods perform suboptimally in complex multi-task\nscenarios. To address this, we propose Contextual Attention Modulation (CAM), a\nnovel mechanism that dynamically modulates the representations of\nself-attention modules in LLMs. CAM enhances task-specific features while\npreserving general knowledge, thereby facilitating more effective and efficient\nadaptation. For effective multi-task adaptation, CAM is integrated into our\nHybrid Contextual Attention Modulation (HyCAM) framework, which combines a\nshared, full-parameter CAM module with multiple specialized, lightweight CAM\nmodules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.\nExtensive experiments on heterogeneous tasks, including question answering,\ncode generation, and logical reasoning, demonstrate that our approach\nsignificantly outperforms existing approaches, achieving an average performance\nimprovement of 3.65%. The implemented code and data are available to ease\nreproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.",
      "url": "http://arxiv.org/abs/2510.17705v1",
      "published_time_eastern_timestamp": 1760977167.0
    },
    {
      "title": "Elastic ViTs from Pretrained Models without Retraining",
      "summary": "Vision foundation models achieve remarkable performance but are only\navailable in a limited set of pre-determined sizes, forcing sub-optimal\ndeployment choices under real-world constraints. We introduce SnapViT:\nSingle-shot network approximation for pruned Vision Transformers, a new\npost-pretraining structured pruning method that enables elastic inference\nacross a continuum of compute budgets. Our approach efficiently combines\ngradient information with cross-network structure correlations, approximated\nvia an evolutionary algorithm, does not require labeled data, generalizes to\nmodels without a classification head, and is retraining-free. Experiments on\nDINO, SigLIPv2, DeIT, and AugReg models demonstrate superior performance over\nstate-of-the-art methods across various sparsities, requiring less than five\nminutes on a single A100 GPU to generate elastic models that can be adjusted to\nany computational budget. Our key contributions include an efficient pruning\nstrategy for pretrained Vision Transformers, a novel evolutionary approximation\nof Hessian off-diagonal structures, and a self-supervised importance scoring\nmechanism that maintains strong performance without requiring retraining or\nlabels. Code and pruned models are available at: https://elastic.ashita.nl/",
      "url": "http://arxiv.org/abs/2510.17700v1",
      "published_time_eastern_timestamp": 1760976903.0
    },
    {
      "title": "GAS: Improving Discretization of Diffusion ODEs via Generalized\n  Adversarial Solver",
      "summary": "While diffusion models achieve state-of-the-art generation quality, they\nstill suffer from computationally expensive sampling. Recent works address this\nissue with gradient-based optimization methods that distill a few-step ODE\ndiffusion solver from the full sampling process, reducing the number of\nfunction evaluations from dozens to just a few. However, these approaches often\nrely on intricate training techniques and do not explicitly focus on preserving\nfine-grained details. In this paper, we introduce the Generalized Solver: a\nsimple parameterization of the ODE sampler that does not require additional\ntraining tricks and improves quality over existing approaches. We further\ncombine the original distillation loss with adversarial training, which\nmitigates artifacts and enhances detail fidelity. We call the resulting method\nthe Generalized Adversarial Solver and demonstrate its superior performance\ncompared to existing solver training methods under similar resource\nconstraints. Code is available at https://github.com/3145tttt/GAS.",
      "url": "http://arxiv.org/abs/2510.17699v1",
      "published_time_eastern_timestamp": 1760976878.0
    },
    {
      "title": "Semantic Joint Source Channel Coding for Distributed Subsurface Imaging\n  in Multi-Agent Systems",
      "summary": "Multi-agent systems (MAS) are a promising solution for autonomous exploration\ntasks in hazardous or remote environments, such as planetary surveys. In such\nsettings, communication among agents is essential to ensure collaborative task\nexecution, yet conventional approaches treat exploration and communication as\ndecoupled subsystems. This work presents a novel framework that tightly\nintegrates semantic communication into the MAS exploration process, adapting\ncommunication strategies to the exploration methodology to improve overall task\nperformance. Specifically, we investigate the application of semantic joint\nsource-channel coding (JSCC) with over-the-air computation (AirComp) for\ndistributed function computation for the application of cooperative subsurface\nimaging using the adapt-then-combine full waveform inversion (ATC-FWI)\nalgorithm. Our results demonstrate that semantic JSCC significantly outperforms\nclassical point-to-point and standard JSCC methods, especially in\nhigh-connectivity networks. Furthermore, incorporating side information at the\nreceiving agent enhances communication efficiency and imaging accuracy, a\nfeature previously unexplored in MAS-based exploration. We validate our\napproach through a use case inspired by subsurface anomaly detection, showing\nmeasurable improvements in imaging performance per agent. This work underscores\nthe potential of semantic communication in distributed multi-agent exploration,\noffering a communication-aware exploration paradigm that achieves task-relevant\nperformance gains.",
      "url": "http://arxiv.org/abs/2510.17695v1",
      "published_time_eastern_timestamp": 1760976547.0
    },
    {
      "title": "Quantum Reverse Mapping: Synthesizing an Optimal Spin Qubit Shuttling\n  Bus Architecture for the Surface Code",
      "summary": "As quantum computers scale toward millions of physical qubits, it becomes\nessential to robustly encode individual logical qubits to ensure fault\ntolerance under realistic noise. A high-quality foundational encoding allows\nfuture compilation techniques and heuristics to build on optimal or\nnear-optimal layouts, improving scalability and error resilience. In this work,\nwe synthesize a one-dimensional shuttling bus architecture for the rotated\nsurface code, leveraging coherent spin-qubit shuttling. We formulate a\nmixed-integer optimization model that yields optimal solutions with relatively\nlow execution time for small code distances, and propose a scalable heuristic\nthat matches optimal results while maintaining linear computational complexity.\nWe evaluate the synthesized architecture using architectural metrics, such as\nshuttling distance and cycle time, and full quantum simulations under realistic\nnoise models, showing that the proposed design can sustain logical error rates\nas low as $2\\cdot 10^{-10}$ per round at code distance 21, showcasing its\nfeasibility for scalable quantum error correction in spin-based quantum\nprocessors.",
      "url": "http://arxiv.org/abs/2510.17689v1",
      "published_time_eastern_timestamp": 1760976336.0
    },
    {
      "title": "Multilingual Text-to-Image Person Retrieval via Bidirectional Relation\n  Reasoning and Aligning",
      "summary": "Text-to-image person retrieval (TIPR) aims to identify the target person\nusing textual descriptions, facing challenge in modality heterogeneity. Prior\nworks have attempted to address it by developing cross-modal global or local\nalignment strategies. However, global methods typically overlook fine-grained\ncross-modal differences, whereas local methods require prior information to\nexplore explicit part alignments. Additionally, current methods are\nEnglish-centric, restricting their application in multilingual contexts. To\nalleviate these issues, we pioneer a multilingual TIPR task by developing a\nmultilingual TIPR benchmark, for which we leverage large language models for\ninitial translations and refine them by integrating domain-specific knowledge.\nCorrespondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation\nReasoning and Aligning framework to learn alignment across languages and\nmodalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module\nenables bidirectional prediction of masked image and text, implicitly enhancing\nthe modeling of local relations across languages and modalities, a\nmulti-dimensional global alignment module is integrated to bridge the modality\nheterogeneity. The proposed method achieves new state-of-the-art results on all\nmultilingual TIPR datasets. Data and code are presented in\nhttps://github.com/Flame-Chasers/Bi-IRRA.",
      "url": "http://arxiv.org/abs/2510.17685v1",
      "published_time_eastern_timestamp": 1760976071.0
    },
    {
      "title": "ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data\n  Augmentation for Robust Lung Ultrasound Classification",
      "summary": "Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and\nstructurally normal lungs in lung ultrasound (LUS) videos remains challenging\ndue to the high visual variability of non-cardiogenic inflammatory patterns\n(NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This\nheterogeneity complicates automated classification as overlapping B-lines and\npleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive\nCompact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer\nvariant that removes both positional embeddings and the [CLS] token, making it\nfully permutation-invariant and suitable for unordered medical image data. To\nenhance generalization, we propose ShuffleStrides Data Augmentation (SSDA),\nwhich permutes probe-view sequences and frame orders while preserving\nanatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95\ncritically ill patients against nine state-of-the-art baselines. Despite the\nheterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest\nvalidation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60)\nand specificity (0.91), while all competing models collapsed to trivial\nclassification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with\n2.5x fewer parameters, supporting real-time clinical deployment. These results\nshow that aligning architectural design with data structure can outperform\nscale in small-data medical imaging.",
      "url": "http://arxiv.org/abs/2510.17650v1",
      "published_time_eastern_timestamp": 1760973998.0
    },
    {
      "title": "Space-Time Rate-Splitting Multiple Access for Multibeam LEO Satellite\n  Networks",
      "summary": "This paper proposes a novel space-time rate-splitting multiple access\n(ST-RSMA) framework for multibeam low Earth orbit (LEO) satellite\ncommunications (SATCOM) systems, where space-time coding is integrated into the\ncommon stream transmission. This design enables full diversity gain in the\ncommon stream transmission for all users, regardless of the uncertainty of the\nchannel state information (CSI) and network load conditions, thereby overcoming\nthe performance limitations of conventional RSMA that employs a single\nbeamforming vector for all users. To further enhance performance, we develop a\nweighted minimum mean square error (WMMSE)-based algorithm tailored to ST-RSMA\nthat jointly optimizes the power allocation for the common stream and the\npower/beamforming vectors for private streams, aiming to maximize the minimum\nuser rate. Numerical results show that ST-RSMA significantly outperforms\nconventional RSMA and other multiple access techniques, offering a robust and\nscalable solution for LEO SATCOM.",
      "url": "http://arxiv.org/abs/2510.17625v1",
      "published_time_eastern_timestamp": 1760973018.0
    }
  ]
}
{
  "last_updated": "2026-01-10T13:18:26.629255-05:00",
  "papers": [
    {
      "title": "Pixel-Perfect Visual Geometry Estimation",
      "summary": "Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.",
      "url": "http://arxiv.org/abs/2601.05246v1",
      "published_time_eastern_timestamp": 1767898789.0
    },
    {
      "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
      "summary": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.",
      "url": "http://arxiv.org/abs/2601.05242v1",
      "published_time_eastern_timestamp": 1767898764.0
    },
    {
      "title": "Three-dimensional scene reconstruction using Roman slitless spectra",
      "summary": "The Nancy Grace Roman Space Telescope will carry out a wide-field imaging and slitless spectroscopic survey of Type Ia Supernovae to improve our understanding of dark energy. Crucial to this endeavor is obtaining supernova spectra uncontaminated by light from their host galaxies. However, obtaining such spectra is made more difficult by the inherent problem in wide-field slitless spectroscopic surveys: the blending of spectra of close objects. The spectrum of a supernova will blend with the host galaxy, even from regions distant from the supernova on the sky. If not properly removed, this contamination will introduce systematic bias when the supernova spectra are later used to determine intrinsic supernova parameters and to infer the parameters of dark energy. To address this problem we developed an algorithm that makes use of the spectroscopic observations of the host galaxy at all available observatory roll angles to reconstruct a three-dimensional (3d; 2d spatial, 1d spectral) representation of the underlying host galaxy that accurately matches the 2d slitless spectrum of the host galaxy when projected to an arbitrary rotation angle. We call this ``scene reconstruction''. The projection of the reconstructed scene can be subtracted from an observation of a supernova to remove the contamination from the underlying host. Using simulated Roman data, we show that our method has extremely small systematic errors and significantly less random noise than if we subtracted a single perfectly aligned spectrum of the host obtained before or after the supernova was visible.",
      "url": "http://arxiv.org/abs/2601.05233v1",
      "published_time_eastern_timestamp": 1767898627.0
    },
    {
      "title": "MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents",
      "summary": "We present \\textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \\emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.\n  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \\textbf{216} subtasks across \\textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.",
      "url": "http://arxiv.org/abs/2601.05215v1",
      "published_time_eastern_timestamp": 1767897592.0
    },
    {
      "title": "SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning",
      "summary": "Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.",
      "url": "http://arxiv.org/abs/2601.05187v1",
      "published_time_eastern_timestamp": 1767895835.0
    },
    {
      "title": "Spacecube: A fast inverse hyperspectral georectification system",
      "summary": "Hyperspectral cameras provide numerous advantages in terms of the utility of the data captured. They capture hundreds of data points per sample (pixel) instead of only the few of RGB or multispectral camera systems. Aerial systems sense such data remotely, but the data must be georectified to produce consistent images before analysis. We find the traditional direct georectification method to be slow, and it is prone to artifacts. To address its downsides, we propose Spacecube, a program that implements a complete hyperspectral georectification pipeline, including our own fast inverse georectification technique, using OpenGL graphics programming technologies. Spacecube operates substantially faster than real-time and eliminates pixel coverage artifacts. It facilitates high quality interactive viewing, data exploration, and export of final products. We release Spacecube's source code publicly for the community to use.",
      "url": "http://arxiv.org/abs/2601.05181v1",
      "published_time_eastern_timestamp": 1767895449.0
    },
    {
      "title": "A new code for computing differentially rotating neutron stars",
      "summary": "We present new initial data codes for constructing stationary, axisymmetric equilibrium models of differentially rotating neutron stars in full general relativity within the Frankfurt University/KADATH (FUKA) suite of initial data codes. FUKA leverages the KADATH spectral library to solve the Einstein equations under the assumption of an isentropic fluid without magnetic fields while incorporating GRHayLEOS to support 3D tabulated equations of state in \\textit{stellar collapse} format. The two solvers explored in this work include one using quasi-isotropic coordinates (QIC) in Spherical coordinates while the other solves the eXtended Conformal Thin Sandwich (XCTS) decomposition in Cartesian coordinates, enabling the construction of equilibrium configurations with high accuracy and efficiency. In this work we adopt the Komatsu-Eriguchi-Hachisu differential rotation law, however, the code is designed to be extensible to other rotation laws, allowing for exploration of physically relevant sequences and critical rotation thresholds. Furthermore, we perform convergence tests demonstrating the exponential accuracy of the spectral approach, we validate QIC and XCTS solutions against models well-studied in the literature, and we also compare FUKA solutions against the well-known RNS code. Finally, we explore the impact that initial data resolution has on dynamical simulations and recover the convergence order of the evolution scheme, the dominate source of error in this study. The new FUKA codes and results presented here lay the foundation for future extensions to more general configurations, including magnetic fields, removal of isentropic assumptions, and binary systems, and have been made publicly available to support community efforts in modeling differentially rotating relativistic stars.",
      "url": "http://arxiv.org/abs/2601.05176v1",
      "published_time_eastern_timestamp": 1767895352.0
    },
    {
      "title": "FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts",
      "summary": "Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.",
      "url": "http://arxiv.org/abs/2601.05174v1",
      "published_time_eastern_timestamp": 1767895258.0
    },
    {
      "title": "Fundamental Tradeoffs for ISAC Multiple Access in Finite-Blocklength Regime",
      "summary": "This paper investigates the fundamental communication--sensing tradeoffs of uplink dual-functional integrated sensing and communication (ISAC) multiple access under finite blocklength (FBL) constraints. Unlike conventional asymptotic analyses, we explicitly account for the limitations under FBL constraints imposed by short packets and low-latency transmission. By examining the unbiased channel state sensing estimator, we establish a geometric decomposition of the sensing error, indicating that it is jointly determined by the signal-to-noise ratio and the correlation structure of the information codebook. This insight reveals how cross-correlation among active users in the codebook geometry fundamentally constrains dual-functional ISAC performance. Consequently, we derive achievability and converse bounds that characterize the tradeoff between communication code rate and sensing accuracy in the FBL regime, with the converse further bounded by Shannon capacity. Moreover, by treating channel state sensing as a high-level sensing objective, a universal Cramér--Rao bound is derived to link channel estimation accuracy to practical sensing parameters. Examples of parameter sensing are also provided based on 3GPP standard. Numerical results validate the theoretical analysis and demonstrate the impact of blocklength, antenna dimensions, and sensing requirements.",
      "url": "http://arxiv.org/abs/2601.05165v1",
      "published_time_eastern_timestamp": 1767894955.0
    },
    {
      "title": "GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation",
      "summary": "Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.",
      "url": "http://arxiv.org/abs/2601.05162v1",
      "published_time_eastern_timestamp": 1767894695.0
    },
    {
      "title": "Machine learning for radiative hydrodynamics in astrophysics",
      "summary": "Radiation hydrodynamics describes the interaction between high-temperature hypersonic plasmas and the radiation they emit or absorb, a coupling that plays a central role in many astrophysical phenomena related to accretion and ejection processes. The HADES code was developed to model such systems by coupling hydrodynamics with M1-gray or M1-multigroup radiative transfer models, which are well suited to optically intermediate media.\n  Despite its accuracy, radiation hydrodynamics simulations remain extremely demanding in terms of computational cost. Two main limitations are responsible for this. First, the M1-multigroup model relies on a closure relation with no analytic expression, requiring expensive numerical evaluations. Second, the Courant-Friedrichs-Lewy condition strongly restricts the time step of the explicit schemes used in HADES. To overcome these difficulties, two complementary Artificial Intelligence based strategies were developed in this thesis.\n  The first approach consists in training a Multi-Layer Perceptron to approximate the M1-multigroup closure relation. This method achieves excellent accuracy while reducing the computational cost by a factor of 3000, making it the most efficient approach currently available for this task. This performance gain enables high-fidelity simulations of radiative shocks, in which radiation directly influences the shock structure. In particular, increasing spectral resolution slows down the shock and enlarges the radiative precursor.\n  The second approach explores the use of Physics-Informed Neural Networks to directly solve the radiation hydrodynamics equations and extrapolate simulations beyond their initial time range. Tests on purely hydrodynamic shocks show accurate handling of discontinuities, but application to radiative shocks remains challenging and requires further investigation.",
      "url": "http://arxiv.org/abs/2601.05155v1",
      "published_time_eastern_timestamp": 1767894293.0
    },
    {
      "title": "Multigroup Radiation Diffusion on a Moving Mesh: Implementation in RICH and Application to Tidal Disruption Events",
      "summary": "Radiation-hydrodynamics (RHD) determines the bulk evolution and observable emission in a wide variety of high-energy astrophysical phenomena. Due to their complexity, RHD problems must usually be studied through numerical simulation. We have extended the publicly available RICH code, which previously solved the equations of RHD in the limit of grey flux-limited diffusion (FLD), to operate with a multigroup FLD solver. RICH is a semi-Lagrangian code that solves the equations of RHD on an unstructured moving mesh, and is the first multigroup RHD moving mesh code, making it uniquely applicable to problems with extreme dynamic range and dynamically important radiation forces. We validate our multigroup module against multiple analytic benchmarks, including a novel test of the RHD Doppler term. The computational efficiency of the code is aided by a novel scheme to accelerate convergence in optically thick cells. Finally, we apply multigroup RICH in a pilot study of a stellar tidal disruption event (TDE), using a $10^4 M_\\odot$ intermediate-mass black hole. Our simulations self-consistently produce a bright early-time X-ray flash prior to peak optical/UV light, in qualitative agreement with post-processing of (grey) RICH simulations of supermassive black hole TDEs, as well as X-ray observations of the TDE AT 2022dsb.",
      "url": "http://arxiv.org/abs/2601.05120v1",
      "published_time_eastern_timestamp": 1767892119.0
    },
    {
      "title": "Evaluative Fingerprints: Stable and Systematic Differences in LLM Evaluator Behavior",
      "summary": "LLM-as-judge systems promise scalable, consistent evaluation. We find the opposite: judges are consistent, but not with each other; they are consistent with themselves. Across 3,240 evaluations (9 judges x 120 unique video x pack items x 3 independent runs), inter-judge agreement is near-zero (Krippendorff's α = 0.042). On two dimensions, judges disagree more than random noise would predict (α < 0). Yet this disagreement isn't chaos; it's structured. A classifier identifies which judge produced an evaluation with 77.1% accuracy from rubric scores alone, rising to 89.9% with disposition features. Within model families, the signal is even stronger: GPT-4.1 and GPT-5.2 are distinguishable with 99.6% accuracy. We call this the reliability paradox: judges cannot agree on what constitutes quality, yet their disagreement patterns are so stable they function as fingerprints. Each judge implements a distinct, stable theory of quality: an \"evaluative disposition\" that shapes how it interprets any rubric. We characterize these dispositions along multiple axes: harshness/leniency, dimension emphasis, within-judge stability (ICC), and evidence behavior (receipt validity, semantic linkage via NLI, and shotgun index). The implication is stark: LLM judges are not interchangeable instruments measuring a shared construct. They are distinct measurement devices, each encoding its own implicit theory of quality. Averaging their scores produces a synthetic verdict that corresponds to no judge's actual values.",
      "url": "http://arxiv.org/abs/2601.05114v1",
      "published_time_eastern_timestamp": 1767891742.0
    },
    {
      "title": "Unitary fault-tolerant encoding of Pauli states in surface codes",
      "summary": "In fault-tolerant quantum computation, the preparation of logical states is a ubiquitous subroutine, yet significant challenges persist even for the simplest states required. In the present work, we present a unitary, scalable, distance-preserving encoding scheme for preparing Pauli eigenstates in surface codes. Unlike previous unitary approaches whose fault-distance remains constant with increasing code distance, our scheme ensures that the protection offered by the code is preserved during state preparation. Building on strategies discovered by reinforcement learning for the surface-17 code, we generalize the construction to arbitrary code distances and both rotated and unrotated surface codes. The proposed encoding relies only on geometrically local gates, and is therefore fully compatible with planar 2D qubit connectivity, and it achieves circuit depth scaling as $\\mathcal{O}(d)$, consistent with fundamental entanglement-generation bounds. We design explicit stabilizer-expanding circuits with and without ancilla-mediated connectivity and analyze their error-propagation behavior. Numerical simulations under depolarizing noise show that our unitary encoding without ancillas outperforms standard stabilizer-measurement-based schemes, reducing logical error rates by up to an order of magnitude. These results make the scheme particularly relevant for platforms such as trapped ions and neutral atoms, where measurements are costly relative to gates and idling noise is considerably weaker than gate noise. Our work bridges the gap between measurement-based and unitary encodings of surface-code states and opens new directions for distance-preserving state preparation in fault-tolerant quantum computation.",
      "url": "http://arxiv.org/abs/2601.05113v1",
      "published_time_eastern_timestamp": 1767891625.0
    },
    {
      "title": "GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts",
      "summary": "Large Reasoning Models (LRMs) achieve remarkable performance by explicitly generating multi-step chains of thought, but this capability incurs substantial inference latency and computational cost. Collaborative inference offers a promising solution by selectively allocating work between lightweight and large models, yet a fundamental challenge remains: determining when a reasoning step requires the capacity of a large model or the efficiency of a small model. Existing routing strategies either rely on local token probabilities or post-hoc verification, introducing significant inference overhead. In this work, we propose a novel perspective on step-wise collaboration: the difficulty of a reasoning step can be inferred from its very first token. Inspired by the \"Aha Moment\" phenomenon in LRMs, we show that the entropy of the initial token serves as a strong predictor of step difficulty. Building on this insight, we introduce GlimpRouter, a training-free step-wise collaboration framework. GlimpRouter employs a lightweight model to generate only the first token of each reasoning step and routes the step to a larger model only when the initial token entropy exceeds a threshold. Experiments on multiple benchmarks demonstrate that our approach significantly reduces inference latency while preserving accuracy. For instance, GlimpRouter attains a substantial 10.7% improvement in accuracy while reducing inference latency by 25.9% compared to a standalone large model on AIME25. These results suggest a simple yet effective mechanism for reasoning: allocating computation based on a glimpse of thought rather than full-step evaluation.",
      "url": "http://arxiv.org/abs/2601.05110v1",
      "published_time_eastern_timestamp": 1767891487.0
    },
    {
      "title": "Token-Level LLM Collaboration via FusionRoute",
      "summary": "Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.",
      "url": "http://arxiv.org/abs/2601.05106v1",
      "published_time_eastern_timestamp": 1767891196.0
    },
    {
      "title": "Semantically Orthogonal Framework for Citation Classification: Disentangling Intent and Content",
      "summary": "Understanding the role of citations is essential for research assessment and citation-aware digital libraries. However, existing citation classification frameworks often conflate citation intent (why a work is cited) with cited content type (what part is cited), limiting their effectiveness in auto classification due to a dilemma between fine-grained type distinctions and practical classification reliability. We introduce SOFT, a Semantically Orthogonal Framework with Two dimensions that explicitly separates citation intent from cited content type, drawing inspiration from semantic role theory. We systematically re-annotate the ACL-ARC dataset using SOFT and release a cross-disciplinary test set sampled from ACT2. Evaluation with both zero-shot and fine-tuned Large Language Models demonstrates that SOFT enables higher agreement between human annotators and LLMs, and supports stronger classification performance and robust cross-domain generalization compared to ACL-ARC and SciCite annotation frameworks. These results confirm SOFT's value as a clear, reusable annotation standard, improving clarity, consistency, and generalizability for digital libraries and scholarly communication infrastructures. All code and data are publicly available on GitHub https://github.com/zhiyintan/SOFT.",
      "url": "http://arxiv.org/abs/2601.05103v1",
      "published_time_eastern_timestamp": 1767890916.0
    },
    {
      "title": "Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts",
      "summary": "Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword overlap, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-preserving entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).",
      "url": "http://arxiv.org/abs/2601.05099v1",
      "published_time_eastern_timestamp": 1767890766.0
    },
    {
      "title": "Code-Mix Sentiment Analysis on Hinglish Tweets",
      "summary": "The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.",
      "url": "http://arxiv.org/abs/2601.05091v1",
      "published_time_eastern_timestamp": 1767890366.0
    },
    {
      "title": "Driving on Registers",
      "summary": "We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.",
      "url": "http://arxiv.org/abs/2601.05083v1",
      "published_time_eastern_timestamp": 1767889704.0
    }
  ]
}
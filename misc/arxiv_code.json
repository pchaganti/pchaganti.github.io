{
  "last_updated": "2025-06-24T23:46:28.762244-04:00",
  "papers": [
    {
      "title": "Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for\n  Long Video Generation",
      "summary": "Recent advances in diffusion models have enabled high-quality video\ngeneration, but the additional temporal dimension significantly increases\ncomputational costs, making training and inference on long videos prohibitively\nexpensive. In this paper, we identify a phenomenon we term Spatiotemporal\nEnergy Decay in video diffusion models: post-softmax attention scores diminish\nas spatial and temporal distance between tokens increase, akin to the physical\ndecay of signal or waves over space and time in nature. Motivated by this, we\npropose Radial Attention, a scalable sparse attention mechanism with $O(n \\log\nn)$ complexity that translates energy decay into exponentially decaying compute\ndensity, which is significantly more efficient than standard $O(n^2)$ dense\nattention and more expressive than linear attention. Specifically, Radial\nAttention employs a simple, static attention mask where each token attends to\nspatially nearby tokens, with the attention window size shrinking with temporal\ndistance. Moreover, it allows pre-trained video diffusion models to extend\ntheir generation length with efficient LoRA-based fine-tuning. Extensive\nexperiments show that Radial Attention maintains video quality across\nWan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$\\times$ speedup\nover the original dense attention. With minimal tuning, it enables video\ngeneration up to 4$\\times$ longer while reducing training costs by up to\n4.4$\\times$ compared to direct fine-tuning and accelerating inference by up to\n3.7$\\times$ compared to dense attention inference.",
      "url": "http://arxiv.org/abs/2506.19852v1",
      "published_time_eastern_timestamp": 1750787999.0
    },
    {
      "title": "ScaleCap: Inference-Time Scalable Image Captioning via Dual-Modality\n  Debiasing",
      "summary": "This paper presents ScaleCap, an inference-time scalable image captioning\nstrategy that generates comprehensive and detailed image captions. The key\nchallenges of high-quality image captioning lie in the inherent biases of\nLVLMs: multimodal bias resulting in imbalanced descriptive granularity,\noffering detailed accounts of some elements while merely skimming over others;\nlinguistic bias leading to hallucinated descriptions of non-existent objects.\nTo address these issues, we propose a scalable debiased captioning strategy,\nwhich continuously enriches and calibrates the caption with increased inference\nbudget. Specifically, we propose two novel components: heuristic question\nanswering and contrastive sentence rating. The former generates\ncontent-specific questions based on the image and answers them to progressively\ninject relevant information into the caption. The latter employs sentence-level\noffline contrastive decoding to effectively identify and eliminate\nhallucinations caused by linguistic biases. With increased inference cost, more\nheuristic questions are raised by ScaleCap to progressively capture additional\nvisual details, generating captions that are more accurate, balanced, and\ninformative. Extensive modality alignment experiments demonstrate the\neffectiveness of ScaleCap. Annotating 450K images with ScaleCap and using them\nfor LVLM pretraining leads to consistent performance gains across 11 widely\nused benchmarks. Furthermore, ScaleCap showcases superb richness and fidelity\nof generated captions with two additional tasks: replacing images with captions\nin VQA task, and reconstructing images from captions to assess semantic\ncoverage. Code is available at https://github.com/Cooperx521/ScaleCap.",
      "url": "http://arxiv.org/abs/2506.19848v1",
      "published_time_eastern_timestamp": 1750787995.0
    },
    {
      "title": "ManiGaussian++: General Robotic Bimanual Manipulation with Hierarchical\n  Gaussian World Model",
      "summary": "Multi-task robotic bimanual manipulation is becoming increasingly popular as\nit enables sophisticated tasks that require diverse dual-arm collaboration\npatterns. Compared to unimanual manipulation, bimanual tasks pose challenges to\nunderstanding the multi-body spatiotemporal dynamics. An existing method\nManiGaussian pioneers encoding the spatiotemporal dynamics into the visual\nrepresentation via Gaussian world model for single-arm settings, which ignores\nthe interaction of multiple embodiments for dual-arm systems with significant\nperformance drop. In this paper, we propose ManiGaussian++, an extension of\nManiGaussian framework that improves multi-task bimanual manipulation by\ndigesting multi-body scene dynamics through a hierarchical Gaussian world\nmodel. To be specific, we first generate task-oriented Gaussian Splatting from\nintermediate visual features, which aims to differentiate acting and\nstabilizing arms for multi-body spatiotemporal dynamics modeling. We then build\na hierarchical Gaussian world model with the leader-follower architecture,\nwhere the multi-body spatiotemporal dynamics is mined for intermediate visual\nrepresentation via future scene prediction. The leader predicts Gaussian\nSplatting deformation caused by motions of the stabilizing arm, through which\nthe follower generates the physical consequences resulted from the movement of\nthe acting arm. As a result, our method significantly outperforms the current\nstate-of-the-art bimanual manipulation techniques by an improvement of 20.2% in\n10 simulated tasks, and achieves 60% success rate on average in 9 challenging\nreal-world tasks. Our code is available at\nhttps://github.com/April-Yz/ManiGaussian_Bimanual.",
      "url": "http://arxiv.org/abs/2506.19842v1",
      "published_time_eastern_timestamp": 1750787946.0
    },
    {
      "title": "MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via\n  Role-Specialized Collaboration",
      "summary": "Recent advancements in medical Large Language Models (LLMs) have showcased\ntheir powerful reasoning and diagnostic capabilities. Despite their success,\ncurrent unified multimodal medical LLMs face limitations in knowledge update\ncosts, comprehensiveness, and flexibility. To address these challenges, we\nintroduce the Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis\n(MAM). Inspired by our empirical findings highlighting the benefits of role\nassignment and diagnostic discernment in LLMs, MAM decomposes the medical\ndiagnostic process into specialized roles: a General Practitioner, Specialist\nTeam, Radiologist, Medical Assistant, and Director, each embodied by an\nLLM-based agent. This modular and collaborative framework enables efficient\nknowledge updates and leverages existing medical LLMs and knowledge bases.\nExtensive experimental evaluations conducted on a wide range of publicly\naccessible multimodal medical datasets, incorporating text, image, audio, and\nvideo modalities, demonstrate that MAM consistently surpasses the performance\nof modality-specific LLMs. Notably, MAM achieves significant performance\nimprovements ranging from 18% to 365% compared to baseline models. Our code is\nreleased at https://github.com/yczhou001/MAM.",
      "url": "http://arxiv.org/abs/2506.19835v1",
      "published_time_eastern_timestamp": 1750787563.0
    },
    {
      "title": "Scaling Speculative Decoding with Lookahead Reasoning",
      "summary": "Reasoning models excel by generating long chain-of-thoughts, but decoding the\nresulting thousands of tokens is slow. Token-level speculative decoding (SD)\nhelps, but its benefit is capped, because the chance that an entire\n$\\gamma$-token guess is correct falls exponentially as $\\gamma$ grows. This\nmeans allocating more compute for longer token drafts faces an algorithmic\nceiling -- making the speedup modest and hardware-agnostic. We raise this\nceiling with Lookahead Reasoning, which exploits a second, step-level layer of\nparallelism. Our key insight is that reasoning models generate step-by-step,\nand each step needs only to be semantically correct, not exact token matching.\nIn Lookahead Reasoning, a lightweight draft model proposes several future\nsteps; the target model expands each proposal in one batched pass, and a\nverifier keeps semantically correct steps while letting the target regenerate\nany that fail. Token-level SD still operates within each reasoning step, so the\ntwo layers of parallelism multiply. We show Lookahead Reasoning lifts the peak\nspeedup of SD both theoretically and empirically. Across GSM8K, AIME, and other\nbenchmarks, Lookahead Reasoning improves the speedup of SD from 1.4x to 2.1x\nwhile preserving answer quality, and its speedup scales better with additional\nGPU throughput. Our code is available at\nhttps://github.com/hao-ai-lab/LookaheadReasoning",
      "url": "http://arxiv.org/abs/2506.19830v1",
      "published_time_eastern_timestamp": 1750787290.0
    },
    {
      "title": "Persona Features Control Emergent Misalignment",
      "summary": "Understanding how language models generalize behaviors from their training to\na broader deployment distribution is an important problem in AI safety. Betley\net al. discovered that fine-tuning GPT-4o on intentionally insecure code causes\n\"emergent misalignment,\" where models give stereotypically malicious responses\nto unrelated prompts. We extend this work, demonstrating emergent misalignment\nacross diverse conditions, including reinforcement learning on reasoning\nmodels, fine-tuning on various synthetic datasets, and in models without safety\ntraining. To investigate the mechanisms behind this generalized misalignment,\nwe apply a \"model diffing\" approach using sparse autoencoders to compare\ninternal model representations before and after fine-tuning. This approach\nreveals several \"misaligned persona\" features in activation space, including a\ntoxic persona feature which most strongly controls emergent misalignment and\ncan be used to predict whether a model will exhibit such behavior.\nAdditionally, we investigate mitigation strategies, discovering that\nfine-tuning an emergently misaligned model on just a few hundred benign samples\nefficiently restores alignment.",
      "url": "http://arxiv.org/abs/2506.19823v1",
      "published_time_eastern_timestamp": 1750786701.0
    },
    {
      "title": "Exact Matrix Seriation through Mathematical Optimization: Stress and\n  Effectiveness-Based Models",
      "summary": "Matrix seriation, the problem of permuting the rows and columns of a matrix\nto uncover latent structure, is a fundamental technique in data science,\nparticularly in the visualization and analysis of relational data. Applications\nspan clustering, anomaly detection, and beyond. In this work, we present a\nunified framework grounded in mathematical optimization to address matrix\nseriation from a rigorous, model-based perspective. Our approach leverages\ncombinatorial and mixed-integer optimization to represent seriation objectives\nand constraints with high fidelity, bridging the gap between traditional\nheuristic methods and exact solution techniques.\n  We introduce new mathematical programming models for neighborhood-based\nstress criteria, including nonlinear formulations and their linearized\ncounterparts. For structured settings such as Moore and von Neumann\nneighborhoods, we develop a novel Hamiltonian path-based reformulation that\nenables effective control over spatial arrangement and interpretability in the\nreordered matrix.\n  To assess the practical impact of our models, we carry out an extensive set\nof experiments on synthetic and real-world datasets, as well as on a newly\ncurated benchmark based on a coauthorship network from the matrix seriation\nliterature. Our results show that these optimization-based formulations not\nonly enhance solution quality and interpretability but also provide a versatile\nfoundation for extending matrix seriation to new domains in data science.",
      "url": "http://arxiv.org/abs/2506.19821v1",
      "published_time_eastern_timestamp": 1750786555.0
    },
    {
      "title": "One Prototype Is Enough: Single-Prototype Activation for Interpretable\n  Image Classification",
      "summary": "In this paper, we propose ProtoSolo, a novel deep neural architecture for\ninterpretable image classification inspired by prototypical networks such as\nProtoPNet. Existing prototype networks usually rely on the collaborative\ndecision-making of multiple prototypes to achieve the classification and\ninterpretation of a single category. In contrast, ProtoSolo only requires the\nactivation of a single prototype to complete the classification. This allows\nthe network to explain each category decision by only providing the features\nthat are most similar to the prototype of that category, significantly reducing\nthe cognitive complexity of the explanation. Secondly, we propose a\nfeature-based comparison method, which uses feature map instead of full-channel\nfeature vector as the object of similarity comparison and prototype learning.\nThis design enables ProtoSolo to utilize richer global information for\nclassification while relying on a single prototype activation. In addition, we\npropose a non-prototype projection learning strategy, which preserves the\ninformation association between the prototype and the training image patches\nwhile avoiding the sharp change of the network structure caused by the\nprojection operation, thus avoiding its negative impact on the classification\nperformance. Experiments on the CUB-200-2011 and Stanford Cars datasets show\nthat ProtoSolo achieves superior performance in classification tasks and\nreaches the best level in terms of cognitive complexity of explanations\ncompared to state-of-the-art interpretable methods. The code is available at\nhttps://github.com/pyt19/ProtoSolo.",
      "url": "http://arxiv.org/abs/2506.19808v1",
      "published_time_eastern_timestamp": 1750785515.0
    },
    {
      "title": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality",
      "summary": "Large Language Models (LLMs), particularly slow-thinking models, often\nexhibit severe hallucination, outputting incorrect content due to an inability\nto accurately recognize knowledge boundaries during reasoning. While\nReinforcement Learning (RL) can enhance complex reasoning abilities, its\noutcome-oriented reward mechanism often lacks factual supervision over the\nthinking process, further exacerbating the hallucination problem. To address\nthe high hallucination in slow-thinking models, we propose Knowledge-enhanced\nRL, KnowRL. KnowRL guides models to perform fact-based slow thinking by\nintegrating a factuality reward, based on knowledge verification, into the RL\ntraining process, helping them recognize their knowledge boundaries. KnowRL\nguides models to perform fact-based slow thinking by integrating a factuality\nreward, based on knowledge verification, into the RL training process, helping\nthem recognize their knowledge boundaries. This targeted factual input during\nRL training enables the model to learn and internalize fact-based reasoning\nstrategies. By directly rewarding adherence to facts within the reasoning\nsteps, KnowRL fosters a more reliable thinking process. Experimental results on\nthree hallucination evaluation datasets and two reasoning evaluation datasets\ndemonstrate that KnowRL effectively mitigates hallucinations in slow-thinking\nmodels while maintaining their original strong reasoning capabilities. Our code\nis available at https://github.com/zjunlp/KnowRL.",
      "url": "http://arxiv.org/abs/2506.19807v1",
      "published_time_eastern_timestamp": 1750785437.0
    },
    {
      "title": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic\n  Empirical Study",
      "summary": "Large Language Models (LLMs) hold promise in automating data analysis tasks,\nyet open-source models face significant limitations in these kinds of\nreasoning-intensive scenarios. In this work, we investigate strategies to\nenhance the data analysis capabilities of open-source LLMs. By curating a seed\ndataset of diverse, realistic scenarios, we evaluate models across three\ndimensions: data understanding, code generation, and strategic planning. Our\nanalysis reveals three key findings: (1) Strategic planning quality serves as\nthe primary determinant of model performance; (2) Interaction design and task\ncomplexity significantly influence reasoning capabilities; (3) Data quality\ndemonstrates a greater impact than diversity in achieving optimal performance.\nWe leverage these insights to develop a data synthesis methodology,\ndemonstrating significant improvements in open-source LLMs' analytical\nreasoning capabilities.",
      "url": "http://arxiv.org/abs/2506.19794v1",
      "published_time_eastern_timestamp": 1750784663.0
    },
    {
      "title": "The Voronoi Spherical CDF for Lattices and Linear Codes: New Bounds for\n  Quantization and Coding",
      "summary": "For a lattice/linear code, we define the Voronoi spherical cumulative density\nfunction (CDF) as the CDF of the $\\ell_2$-norm/Hamming weight of a random\nvector uniformly distributed over the Voronoi cell. Using the first moment\nmethod together with a simple application of Jensen's inequality, we develop\nlower bounds on the expected Voronoi spherical CDF of a random lattice/linear\ncode. Our bounds are quite close to a trivial ball-based lower bound and\nimmediately translate to improved upper bounds on the normalized second moment\nand the error probability of a random lattice over the additive white Gaussian\nnoise channel, as well as improved upper bounds on the Hamming distortion and\nthe error probability of a random linear code over the binary symmetric\nchannel.",
      "url": "http://arxiv.org/abs/2506.19791v1",
      "published_time_eastern_timestamp": 1750784374.0
    },
    {
      "title": "Line ratio identification of external photoevaporation",
      "summary": "External photoevaporation of protoplanetary discs, by massive O stars in\nstellar clusters, is thought to be a significant process in the evolution of a\ndisc. It has been shown to result in significant mass loss and disc truncation,\nultimately reducing the lifetime of the discs, and possibly affecting potential\nplanet populations. It is a well-studied process in the Orion Nebula Cluster\n(ONC) where the cometary morphology of proplyds is spatially resolvable due to\nits proximity to Earth. However, we need to study external photoevaporation in\nadditional stellar clusters to better understand its prevalence and\nsignificance more globally. Unfortunately, more massive stellar clusters where\nthe majority of stars form are much farther away than the ONC. In these more\ndistant clusters the proplyds are spatially unresolvable with current\nfacilities, hence the cometary morphology is not a useful identification of\nexternal photoevaporation. Therefore, in order to identify and interpret\nexternal photoevaporation, the only observations we have are of spatially\nunresolved emission lines. To resolve this issue we have used the CLOUDY code\nto develop an approximate general model of the emission lines emanating from\nthe hot ionized wind of a proplyd. We have used the model to determine which\nline ratios are most sensitive to the distance from an OB star, and found that\nthe most sensitive line ratios vary by multiple orders of magnitude over an FUV\nfield of between 10$^3$ G$_0$ to 10$^6$ G$_0$. By identifying spatial gradients\nof line ratios in stellar clusters, we can identify regions of ongoing external\nphotoevaporation.",
      "url": "http://arxiv.org/abs/2506.19788v1",
      "published_time_eastern_timestamp": 1750783993.0
    },
    {
      "title": "Multi-Preference Lambda-weighted Listwise DPO for Dynamic Preference\n  Alignment",
      "summary": "While large-scale unsupervised language models (LMs) capture broad world\nknowledge and reasoning capabilities, steering their behavior toward desired\nobjectives remains challenging due to the lack of explicit supervision.\nExisting alignment techniques, such as reinforcement learning from human\nfeedback (RLHF), rely on training a reward model and performing reinforcement\nlearning to align with human preferences. However, RLHF is often\ncomputationally intensive, unstable, and sensitive to hyperparameters.\n  To address these limitations, Direct Preference Optimization (DPO) was\nintroduced as a lightweight and stable alternative, enabling direct alignment\nof language models with pairwise preference data via classification loss.\nHowever, DPO and its extensions generally assume a single static preference\ndistribution, limiting flexibility in multi-objective or dynamic alignment\nsettings.\n  In this paper, we propose a novel framework: Multi-Preference Lambda-weighted\nListwise DPO, which extends DPO to incorporate multiple human preference\ndimensions (e.g., helpfulness, harmlessness, informativeness) and enables\ndynamic interpolation through a controllable simplex-weighted formulation. Our\nmethod supports both listwise preference feedback and flexible alignment across\nvarying user intents without re-training. Empirical and theoretical analysis\ndemonstrates that our method is as effective as traditional DPO on static\nobjectives while offering greater generality and adaptability for real-world\ndeployment.",
      "url": "http://arxiv.org/abs/2506.19780v1",
      "published_time_eastern_timestamp": 1750783637.0
    },
    {
      "title": "Quantum Resource Correction",
      "summary": "Resource theories play a crucial role in characterizing states and properties\nessential for quantum information processing. A significant challenge is\nprotecting resources from errors. We explore strategies for correcting quantum\nresources. We show that resource preserving operations in resource theory\ndefine a gauge freedom on code spaces, which allows for recovery strategies\nthat can correct the resource while changing non-essential properties. This\nallows decoding to be simplified. The results are applicable to various\nresource theories and quantum information applications.",
      "url": "http://arxiv.org/abs/2506.19776v1",
      "published_time_eastern_timestamp": 1750783316.0
    },
    {
      "title": "Optimization Studies of Radiation Shielding for the PIP-II Project at\n  Fermilab",
      "summary": "The PIP-II project at Fermilab, which includes an 800-MeV superconducting\nLINAC, demands rigorous radiation shielding optimization to meet safety\nrequirements. We updated the MARS geometry model to reflect new magnet and\ncollimator designs and introduced high-resolution detector planes to better\ncapture radiation field distributions. To overcome the significant\ncomputational demands, we implemented a well-known branching technique that\ndrastically reduced simulation runtimes while maintaining statistical\nintegrity. This was achieved through particle splitting and the application of\nRussian Roulette techniques. Additionally, new graphical tools were created to\nstreamline data visualization and MARS code usability.",
      "url": "http://arxiv.org/abs/2506.19763v1",
      "published_time_eastern_timestamp": 1750782225.0
    },
    {
      "title": "NeRF-based CBCT Reconstruction needs Normalization and Initialization",
      "summary": "Cone Beam Computed Tomography (CBCT) is widely used in medical imaging.\nHowever, the limited number and intensity of X-ray projections make\nreconstruction an ill-posed problem with severe artifacts. NeRF-based methods\nhave achieved great success in this task. However, they suffer from a\nlocal-global training mismatch between their two key components: the hash\nencoder and the neural network. Specifically, in each training step, only a\nsubset of the hash encoder's parameters is used (local sparse), whereas all\nparameters in the neural network participate (global dense). Consequently, hash\nfeatures generated in each step are highly misaligned, as they come from\ndifferent subsets of the hash encoder. These misalignments from different\ntraining steps are then fed into the neural network, causing repeated\ninconsistent global updates in training, which leads to unstable training,\nslower convergence, and degraded reconstruction quality. Aiming to alleviate\nthe impact of this local-global optimization mismatch, we introduce a\nNormalized Hash Encoder, which enhances feature consistency and mitigates the\nmismatch. Additionally, we propose a Mapping Consistency Initialization(MCI)\nstrategy that initializes the neural network before training by leveraging the\nglobal mapping property from a well-trained model. The initialized neural\nnetwork exhibits improved stability during early training, enabling faster\nconvergence and enhanced reconstruction performance. Our method is simple yet\neffective, requiring only a few lines of code while substantially improving\ntraining efficiency on 128 CT cases collected from 4 different datasets,\ncovering 7 distinct anatomical regions.",
      "url": "http://arxiv.org/abs/2506.19742v1",
      "published_time_eastern_timestamp": 1750780905.0
    },
    {
      "title": "Noise Consistency Training: A Native Approach for One-Step Generator in\n  Learning Additional Controls",
      "summary": "The pursuit of efficient and controllable high-quality content generation\nremains a central challenge in artificial intelligence-generated content\n(AIGC). While one-step generators, enabled by diffusion distillation\ntechniques, offer excellent generation quality and computational efficiency,\nadapting them to new control conditions--such as structural constraints,\nsemantic guidelines, or external inputs--poses a significant challenge.\nConventional approaches often necessitate computationally expensive\nmodifications to the base model and subsequent diffusion distillation. This\npaper introduces Noise Consistency Training (NCT), a novel and lightweight\napproach to directly integrate new control signals into pre-trained one-step\ngenerators without requiring access to original training images or retraining\nthe base diffusion model. NCT operates by introducing an adapter module and\nemploys a noise consistency loss in the noise space of the generator. This loss\naligns the adapted model's generation behavior across noises that are\nconditionally dependent to varying degrees, implicitly guiding it to adhere to\nthe new control. Theoretically, this training objective can be understood as\nminimizing the distributional distance between the adapted generator and the\nconditional distribution induced by the new conditions. NCT is modular,\ndata-efficient, and easily deployable, relying only on the pre-trained one-step\ngenerator and a control signal model. Extensive experiments demonstrate that\nNCT achieves state-of-the-art controllable generation in a single forward pass,\nsurpassing existing multi-step and distillation-based methods in both\ngeneration quality and computational efficiency. Code is available at\nhttps://github.com/Luo-Yihong/NCT",
      "url": "http://arxiv.org/abs/2506.19741v1",
      "published_time_eastern_timestamp": 1750780735.0
    },
    {
      "title": "From Reproduction to Replication: Evaluating Research Agents with\n  Progressive Code Masking",
      "summary": "Recent progress in autonomous code generation has fueled excitement around AI\nagents capable of accelerating scientific discovery by running experiments.\nHowever, there is currently no benchmark that evaluates whether such agents can\nimplement scientific ideas when given varied amounts of code as a starting\npoint, interpolating between reproduction (running code) and from-scratch\nreplication (fully re-implementing and running code). We introduce\nAutoExperiment, a benchmark that evaluates AI agents' ability to implement and\nrun machine learning experiments based on natural language descriptions in\nresearch papers. In each task, agents are given a research paper, a codebase\nwith key functions masked out, and a command to run the experiment. The goal is\nto generate the missing code, execute the experiment in a sandboxed\nenvironment, and reproduce the results. AutoExperiment scales in difficulty by\nvarying the number of missing functions $n$, ranging from partial reproduction\nto full replication. We evaluate state-of-the-art agents and find that\nperformance degrades rapidly as $n$ increases. Agents that can dynamically\ninteract with the environment (e.g. to debug their code) can outperform agents\nin fixed \"agentless\" harnesses, and there exists a significant gap between\nsingle-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating\nverifier approaches to our benchmark. Our findings highlight critical\nchallenges in long-horizon code generation, context retrieval, and autonomous\nexperiment execution, establishing AutoExperiment as a new benchmark for\nevaluating progress in AI-driven scientific experimentation. Our data and code\nare open-sourced at https://github.com/j1mk1m/AutoExperiment .",
      "url": "http://arxiv.org/abs/2506.19724v1",
      "published_time_eastern_timestamp": 1750779560.0
    },
    {
      "title": "Decision-Focused Learning for Neural Network-Constrained Optimization:\n  Application to HVAC Management System",
      "summary": "Heating, Ventilation, and Air Conditioning (HVAC) is a major electricity\nend-use with a substantial potential for grid services such as demand response.\nHarnessing this flexibility requires accurate modeling of the thermal dynamics\nof buildings, which is challenging due to their nonlinear and repetitive\nbehavior (e.g., daily pattern), which reduce the value of historical data. To\naddress this issue, this paper presents an HVAC management system formulated as\na Mixed Integer Quadratic Program (MIQP), where Neural Network (NN) models of\nthermal dynamics are embedded as exact mixed-integer linear constraints. We\nemploy Decision-Focused Learning (DFL) which tunes the NN parameters to improve\nthe HVAC performance rather than prediction metrics. However, the discrete\nnature of the MIQP poses challenges for this approach, as it leads to gradients\nthat are undefined or discontinuous, thus impeding standard gradient-based\ntraining. Here, we employ Stochastic Smoothing (SS), which enables efficient\ngradient computation without the need to differentiate through the MIQP.\nExperiments on a realistic five-zone building using a high-fidelity building\nsimulator demonstrate that the proposed SS-DFL approach outperforms\nconventional two-stage and relaxed DFL methods in both cost savings and grid\nservice performance, highlighting its potential for scalable, grid-interactive\nbuilding control.",
      "url": "http://arxiv.org/abs/2506.19717v1",
      "published_time_eastern_timestamp": 1750778852.0
    },
    {
      "title": "LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology\n  and Differential Diagnosis",
      "summary": "Medical document analysis plays a crucial role in extracting essential\nclinical insights from unstructured healthcare records, supporting critical\ntasks such as differential diagnosis. Determining the most probable condition\namong overlapping symptoms requires precise evaluation and deep medical\nexpertise. While recent advancements in large language models (LLMs) have\nsignificantly enhanced performance in medical document analysis, privacy\nconcerns related to sensitive patient data limit the use of online LLMs\nservices in clinical settings. To address these challenges, we propose a\ntrustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using\nlow-rank adaptation, specifically optimized for differential diagnosis tasks.\nOur approach utilizes DDXPlus, the largest benchmark dataset for differential\ndiagnosis, and demonstrates superior performance in pathology prediction and\nvariable-length differential diagnosis compared to existing methods. The\ndeveloped web-based platform allows users to submit their own unstructured\nmedical documents and receive accurate, explainable diagnostic results. By\nincorporating advanced explainability techniques, the system ensures\ntransparent and reliable predictions, fostering user trust and confidence.\nExtensive evaluations confirm that the proposed method surpasses current\nstate-of-the-art models in predictive accuracy while offering practical utility\nin clinical settings. This work addresses the urgent need for reliable,\nexplainable, and privacy-preserving artificial intelligence solutions,\nrepresenting a significant advancement in intelligent medical document analysis\nfor real-world healthcare applications. The code can be found at\n\\href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.",
      "url": "http://arxiv.org/abs/2506.19702v1",
      "published_time_eastern_timestamp": 1750777962.0
    }
  ]
}
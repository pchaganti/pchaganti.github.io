{
  "last_updated": "2025-09-04T08:22:32.310677-04:00",
  "papers": [
    {
      "title": "Can LLMs Lie? Investigation beyond Hallucination",
      "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\na variety of tasks, but their increasing autonomy in real-world applications\nraises concerns about their trustworthiness. While hallucinations-unintentional\nfalsehoods-have been widely studied, the phenomenon of lying, where an LLM\nknowingly generates falsehoods to achieve an ulterior objective, remains\nunderexplored. In this work, we systematically investigate the lying behavior\nof LLMs, differentiating it from hallucinations and testing it in practical\nscenarios. Through mechanistic interpretability techniques, we uncover the\nneural mechanisms underlying deception, employing logit lens analysis, causal\ninterventions, and contrastive activation steering to identify and control\ndeceptive behavior. We study real-world lying scenarios and introduce\nbehavioral steering vectors that enable fine-grained manipulation of lying\ntendencies. Further, we explore the trade-offs between lying and end-task\nperformance, establishing a Pareto frontier where dishonesty can enhance goal\noptimization. Our findings contribute to the broader discourse on AI ethics,\nshedding light on the risks and potential safeguards for deploying LLMs in\nhigh-stakes environments. Code and more illustrations are available at\nhttps://llm-liar.github.io/",
      "url": "http://arxiv.org/abs/2509.03518v1",
      "published_time_eastern_timestamp": 1756922385.0
    },
    {
      "title": "Parameter-Efficient Adaptation of mPLUG-Owl2 via Pixel-Level Visual\n  Prompts for NR-IQA",
      "summary": "In this paper, we propose a novel parameter-efficient adaptation method for\nNo- Reference Image Quality Assessment (NR-IQA) using visual prompts optimized\nin pixel-space. Unlike full fine-tuning of Multimodal Large Language Models\n(MLLMs), our approach trains only 600K parameters at most (< 0.01% of the base\nmodel), while keeping the underlying model fully frozen. During inference,\nthese visual prompts are combined with images via addition and processed by\nmPLUG-Owl2 with the textual query \"Rate the technical quality of the image.\"\nEvaluations across distortion types (synthetic, realistic, AI-generated) on\nKADID- 10k, KonIQ-10k, and AGIQA-3k demonstrate competitive performance against\nfull finetuned methods and specialized NR-IQA models, achieving 0.93 SRCC on\nKADID-10k. To our knowledge, this is the first work to leverage pixel-space\nvisual prompts for NR-IQA, enabling efficient MLLM adaptation for low-level\nvision tasks. The source code is publicly available at https: // github. com/\nyahya-ben/ mplug2-vp-for-nriqa .",
      "url": "http://arxiv.org/abs/2509.03494v1",
      "published_time_eastern_timestamp": 1756920204.0
    },
    {
      "title": "SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation\n  Models",
      "summary": "Proteins play crucial roles in almost all biological processes. The\nadvancement of deep learning has greatly accelerated the development of protein\nfoundation models, leading to significant successes in protein understanding\nand design. However, the lack of systematic red-teaming for these models has\nraised serious concerns about their potential misuse, such as generating\nproteins with biological safety risks. This paper introduces SafeProtein, the\nfirst red-teaming framework designed for protein foundation models to the best\nof our knowledge. SafeProtein combines multimodal prompt engineering and\nheuristic beam search to systematically design red-teaming methods and conduct\ntests on protein foundation models. We also curated SafeProtein-Bench, which\nincludes a manually constructed red-teaming benchmark dataset and a\ncomprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks\non state-of-the-art protein foundation models (up to 70% attack success rate\nfor ESM3), revealing potential biological safety risks in current protein\nfoundation models and providing insights for the development of robust security\nprotection technologies for frontier models. The codes will be made publicly\navailable at https://github.com/jigang-fan/SafeProtein.",
      "url": "http://arxiv.org/abs/2509.03487v1",
      "published_time_eastern_timestamp": 1756919636.0
    },
    {
      "title": "Four-channel Imaging Based on Reconfigurable Metasurfaces: Hyperchaotic\n  Encryption under Physical Protection",
      "summary": "Metasurfaces facilitate high-capacity optical information integration by\nsimultaneously supporting near-field nanoprinting and far-field holography on a\nsingle platform. However, conventional multi-channel designs face critical\nsecurity vulnerabilities for sensitive information due to insufficient\nencryption mechanisms. In this work, we propose a four-channel phase-change\nmetasurface featuring algorithm-physical co-security-a dual-protection\nframework combining intrinsic metasurface physical security with chaotic\nencryption. Our polarization-multiplexed metasurface generates four optical\nimaging channels through meta-atom design, including two far-field holograms\nand two near-field patterns. To enhance system security, we apply Chen\nhyperchaotic encryption combined with the Logistic map and DNA encoding to\nconvert near-field information into secure QR codes; far-field holograms are\nretained to demonstrate the metasurface's information capacity and for attack\ndetection. Phase-change metasurface further provides physical-layer security by\ndynamically switching imaging channels via crystalline-to-amorphous state\ntransitions, enhancing anti-counterfeiting and reliability. The proposed\nmetasurface achieves high-fidelity imaging, robust anti-attack performance, and\nindependent channel control. This integrated approach pioneers a secure\nparadigm for high-density optical information processing.",
      "url": "http://arxiv.org/abs/2509.03453v1",
      "published_time_eastern_timestamp": 1756916419.0
    },
    {
      "title": "Universal representation of the long-range entanglement in the family of\n  Toric Code states",
      "summary": "Since the long range entanglement is a universal characteristic of\ntopological quantum states belonging to the same class, a suitable mathematical\nrepresentation of the long range entanglement has to be also universal. In this\nLetter, we introduce such a representation for the family of Toric Code states\nby using Kitaev's Ladders as building blocks. We consider Toric Code states\ncorresponding to various planar graphs and apply non-local dientanglers to\nqubits corresponding to non-contractible cycles that satisfy a topological\nconstraint. We demonstrate that, independent of the geometry of the underlying\ngraph, disentanglers convert Toric Code states into a tensor product of\nKitaev's Ladder states. Since Kitaev's Ladders with arbitrary geometric\nconfigurations include the short-range entanglements, we conclude that the\nabove universal and non-local pattern of entanglement between ladders is\nresponsible of the long-range entanglement inherent in Toric Code states. Our\nresult emphasizes in the capability of such non-local representations to\ndescribe topological order in ground-state wave functions of topological\nquantum systems.",
      "url": "http://arxiv.org/abs/2509.03422v1",
      "published_time_eastern_timestamp": 1756914597.0
    },
    {
      "title": "Initialization Schemes for Kolmogorov-Arnold Networks: An Empirical\n  Study",
      "summary": "Kolmogorov-Arnold Networks (KANs) are a recently introduced neural\narchitecture that replace fixed nonlinearities with trainable activation\nfunctions, offering enhanced flexibility and interpretability. While KANs have\nbeen applied successfully across scientific and machine learning tasks, their\ninitialization strategies remain largely unexplored. In this work, we study\ninitialization schemes for spline-based KANs, proposing two theory-driven\napproaches inspired by LeCun and Glorot, as well as an empirical power-law\nfamily with tunable exponents. Our evaluation combines large-scale grid\nsearches on function fitting and forward PDE benchmarks, an analysis of\ntraining dynamics through the lens of the Neural Tangent Kernel, and\nevaluations on a subset of the Feynman dataset. Our findings indicate that the\nGlorot-inspired initialization significantly outperforms the baseline in\nparameter-rich models, while power-law initialization achieves the strongest\nperformance overall, both across tasks and for architectures of varying size.\nAll code and data accompanying this manuscript are publicly available at\nhttps://github.com/srigas/KAN_Initialization_Schemes.",
      "url": "http://arxiv.org/abs/2509.03417v1",
      "published_time_eastern_timestamp": 1756914328.0
    },
    {
      "title": "An angular momentum approach to quantum insertion errors",
      "summary": "Quantum insertion errors are a class of errors that increase the number of\nqubits in a quantum system. Despite a wealth of research on classical insertion\nerrors, there has been limited progress towards a general framework for\ncorrecting quantum insertion errors. We detail a quantum error correction\nprotocol that can correct single insertion errors on a class of gapped\npermutation-invariant codes. We provide a simple two-stage syndrome extraction\nprotocol that yields a two-bit syndrome, by measuring the total angular\nmomentum and its projection along the $z$-axis (modulo the code gap) of the\npost-insertion state. We demonstrate that these measurements project the state\nonto a new codespace, and we detail a teleportation protocol to map the\nprojected state back to a permutation-invariant code on the desired number of\nqubits.",
      "url": "http://arxiv.org/abs/2509.03413v1",
      "published_time_eastern_timestamp": 1756913964.0
    },
    {
      "title": "Beyond Correctness: Harmonizing Process and Outcome Rewards through RL\n  Training",
      "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged to be a\npredominant paradigm for mathematical reasoning tasks, offering stable\nimprovements in reasoning ability. However, Outcome Reward Models (ORMs) in\nRLVR are too coarse-grained to distinguish flawed reasoning within correct\nanswers or valid reasoning within incorrect answers. This lack of granularity\nintroduces noisy and misleading gradients significantly and hinders further\nprogress in reasoning process quality. While Process Reward Models (PRMs) offer\nfine-grained guidance for intermediate steps, they frequently suffer from\ninaccuracies and are susceptible to reward hacking.\n  To resolve this dilemma, we introduce PRocess cOnsistency Filter (PROF), an\neffective data process curation method that harmonizes noisy, fine-grained\nprocess rewards with accurate, coarse-grained outcome rewards. Rather than\nnaively blending PRM and ORM in the objective function\n(arXiv:archive/2506.18896), PROF leverages their complementary strengths\nthrough consistency-driven sample selection. Our approach retains correct\nresponses with higher averaged process values and incorrect responses with\nlower averaged process values, while maintaining positive/negative training\nsample balance. Extensive experiments demonstrate that our method not only\nconsistently improves the final accuracy over $4\\%$ compared to the blending\napproaches, but also strengthens the quality of intermediate reasoning steps.\nCodes and training recipes are available at https://github.com/Chenluye99/PROF.",
      "url": "http://arxiv.org/abs/2509.03403v1",
      "published_time_eastern_timestamp": 1756913331.0
    },
    {
      "title": "ANNIE: Be Careful of Your Robots",
      "summary": "The integration of vision-language-action (VLA) models into embodied AI (EAI)\nrobots is rapidly advancing their ability to perform complex, long-horizon\ntasks in humancentric environments. However, EAI systems introduce critical\nsecurity risks: a compromised VLA model can directly translate adversarial\nperturbations on sensory input into unsafe physical actions. Traditional safety\ndefinitions and methodologies from the machine learning community are no longer\nsufficient. EAI systems raise new questions, such as what constitutes safety,\nhow to measure it, and how to design effective attack and defense mechanisms in\nphysically grounded, interactive settings. In this work, we present the first\nsystematic study of adversarial safety attacks on embodied AI systems, grounded\nin ISO standards for human-robot interactions. We (1) formalize a principled\ntaxonomy of safety violations (critical, dangerous, risky) based on physical\nconstraints such as separation distance, velocity, and collision boundaries;\n(2) introduce ANNIEBench, a benchmark of nine safety-critical scenarios with\n2,400 video-action sequences for evaluating embodied safety; and (3)\nANNIE-Attack, a task-aware adversarial framework with an attack leader model\nthat decomposes long-horizon goals into frame-level perturbations. Our\nevaluation across representative EAI models shows attack success rates\nexceeding 50% across all safety categories. We further demonstrate sparse and\nadaptive attack strategies and validate the real-world impact through physical\nrobot experiments. These results expose a previously underexplored but highly\nconsequential attack surface in embodied AI systems, highlighting the urgent\nneed for security-driven defenses in the physical AI era. Code is available at\nhttps://github.com/RLCLab/Annie.",
      "url": "http://arxiv.org/abs/2509.03383v1",
      "published_time_eastern_timestamp": 1756911628.0
    },
    {
      "title": "First detection of ethylene oxide and acetaldehyde in hot core\n  G358.93$-$0.03 MM1: Tracing prebiotic oxygen chemistry",
      "summary": "Ethylene oxide (c-C$_{2}$H$_{4}$O) and its isomer, acetaldehyde\n(CH$_{3}$CHO), are important complex organic molecules owing to their potential\nrole in the formation of amino acids (R-CH(NH$_{2}$)-COOH) in ISM. The\ndetection of c-C$_{2}$H$_{4}$O in hot molecular cores suggests that the\npossible existence of larger ring-shaped molecules containing more than three\ncarbon atoms, such as furan (c-C$_{4}$H$_{4}$O), which shares structural\nsimilarities with ribose (C$_{5}$H$_{10}$O5), the sugar component of DNA. In\nthis study, we report the first detection of the rotational emission lines of\nc-C$_{2}$H$_{4}$O and CH$_{3}$CHO towards the hot molecular core G358.93$-$0.03\nMM1, based on observations from the Atacama Large Millimeter/Submillimeter\nArray (ALMA) in band 7. The fractional abundances of c-C$_{2}$H$_{4}$O and\nCH$_{3}$CHO relative to H$_{2}$ are $(2.1\\pm0.2)\\times10^{-9}$ and\n$(7.1\\pm0.9)\\times10^{-9}$, respectively. The column density ratio between\nCH$_{3}$CHO and c-C$_{2}$H$_{4}$O is $3.4\\pm0.7$. A Pearson correlation heat\nmap reveals strong positive correlations ($r$ $>$ 0.5) between the abundances\nand excitation temperatures of c-C$_{2}$H$_{4}$O and CH$_{3}$CHO, suggesting a\npossible chemical connection between those two molecules. To investigate this\nfurther, we conducted a two-phase warm-up chemical model using the gas-grain\nchemical code UCLCHEM. A comparison between our derived abundances and the\npredictions from our chemical model and existence model demonstrates good\nagreement within factors of 0.73 and 0.74, respectively. We propose that\nc-C$_{2}$H$_{4}$O may form in G358.93$-$0.03 MM1 via the grain surface reaction\nbetween C$_{2}$H$_{4}$ and O, but CH$_{3}$CHO may be produced through the\nsurface reaction between CH$_{3}$ and HCO.",
      "url": "http://arxiv.org/abs/2509.03382v1",
      "published_time_eastern_timestamp": 1756911508.0
    },
    {
      "title": "Transformer-Guided Content-Adaptive Graph Learning for Hyperspectral\n  Unmixing",
      "summary": "Hyperspectral unmixing (HU) targets to decompose each mixed pixel in remote\nsensing images into a set of endmembers and their corresponding abundances.\nDespite significant progress in this field using deep learning, most methods\nfail to simultaneously characterize global dependencies and local consistency,\nmaking it difficult to preserve both long-range interactions and boundary\ndetails. This letter proposes a novel transformer-guided content-adaptive graph\nunmixing framework (T-CAGU), which overcomes these challenges by employing a\ntransformer to capture global dependencies and introducing a content-adaptive\ngraph neural network to enhance local relationships. Unlike previous work,\nT-CAGU integrates multiple propagation orders to dynamically learn the graph\nstructure, ensuring robustness against noise. Furthermore, T-CAGU leverages a\ngraph residual mechanism to preserve global information and stabilize training.\nExperimental results demonstrate its superiority over the state-of-the-art\nmethods. Our code is available at https://github.com/xianchaoxiu/T-CAGU.",
      "url": "http://arxiv.org/abs/2509.03376v1",
      "published_time_eastern_timestamp": 1756911213.0
    },
    {
      "title": "New Bounds for Linear Codes with Applications",
      "summary": "Bounds on linear codes play a central role in coding theory, as they capture\nthe fundamental trade-off between error-correction capability (minimum\ndistance) and information rate (dimension relative to length). Classical\nresults characterize this trade-off solely in terms of the parameters $n$, $k$,\n$d$ and $q$. In this work we derive new bounds under the additional assumption\nthat the code contains a nonzero codeword of weight $w$.By combining\nresidual-code techniques with classical results such as the Singleton and\nGriesmer bounds,we obtain explicit inequalities linking $n$, $k$, $d$, $q$ and\n$w$. These bounds impose sharper restrictions on admissible codeword weights,\nparticularly those close to the minimum distance or to the code length.\nApplications include refined constraints on the weights of MDS codes, numerical\nrestrictions on general linear codes, and excluded weight ranges in the weight\ndistribution. Numerical comparisons across standard parameter sets demonstrate\nthat these $w$-aware bounds strictly enlarge known excluded weight ranges and\nsharpen structural limitations on linear codes.",
      "url": "http://arxiv.org/abs/2509.03337v1",
      "published_time_eastern_timestamp": 1756908853.0
    },
    {
      "title": "EvolveSignal: A Large Language Model Powered Coding Agent for\n  Discovering Traffic Signal Control Algorithms",
      "summary": "In traffic engineering, the fixed-time traffic signal control remains widely\nused for its low cost, stability, and interpretability. However, its design\ndepends on hand-crafted formulas (e.g., Webster) and manual re-timing by\nengineers to adapt to demand changes, which is labor-intensive and often yields\nsuboptimal results under heterogeneous or congested conditions. This paper\nintroduces the EvolveSignal, a large language models (LLMs) powered coding\nagent to automatically discover new traffic signal control algorithms. We\nformulate the problem as program synthesis, where candidate algorithms are\nrepresented as Python functions with fixed input-output structures, and\niteratively optimized through external evaluations (e.g., a traffic simulator)\nand evolutionary search. Experiments on a signalized intersection demonstrate\nthat the discovered algorithms outperform Webster's baseline, reducing average\ndelay by 20.1% and average stops by 47.1%. Beyond performance, ablation and\nincremental analyses reveal that EvolveSignal modifications-such as adjusting\ncycle length bounds, incorporating right-turn demand, and rescaling green\nallocations-can offer practically meaningful insights for traffic engineers.\nThis work opens a new research direction by leveraging AI for algorithm design\nin traffic signal control, bridging program synthesis with transportation\nengineering.",
      "url": "http://arxiv.org/abs/2509.03335v1",
      "published_time_eastern_timestamp": 1756908656.0
    },
    {
      "title": "VulnRepairEval: An Exploit-Based Evaluation Framework for Assessing\n  Large Language Model Vulnerability Repair Capabilities",
      "summary": "The adoption of Large Language Models (LLMs) for automated software\nvulnerability patching has shown promising outcomes on carefully curated\nevaluation sets. Nevertheless, existing datasets predominantly rely on\nsuperficial validation methods rather than exploit-based verification, leading\nto overestimated performance in security-sensitive applications. This paper\nintroduces VulnRepairEval, an evaluation framework anchored in functional\nProof-of-Concept (PoC) exploits. Our framework delivers a comprehensive,\ncontainerized evaluation pipeline that enables reproducible differential\nassessment, where repair success requires the original exploit to fail\nexecution against the modified code. The benchmark construction involved\nextensive data curation: we processed over 400 CVEs and approximately 2,500\npotential sources to extract a collection of authentic vulnerability instances\n(23 Python CVEs) amenable to automated testing with working PoCs. Through\nVulnRepairEval, we conduct a comprehensive evaluation of 12 popular LLMs and\nobserve a significant performance deficit: even the top-performing model\nsuccessfully addresses merely 5/23 instances (about 21.7%), exposing critical\nweaknesses in security-focused applications. Our failure analysis reveals that\nmost unsuccessful attempts stem from imprecise vulnerability identification and\npatches containing syntactic or semantic errors. Enhanced prompting strategies\nand multi-agent approaches yield minimal improvements, with overall\neffectiveness remaining largely unaffected. This work contributes a stringent,\npractical evaluation framework for LLM-driven vulnerability remediation and\nunderscores the necessity for assessment protocols that authentically reflect\nreal-world exploitation scenarios.",
      "url": "http://arxiv.org/abs/2509.03331v1",
      "published_time_eastern_timestamp": 1756908370.0
    },
    {
      "title": "InfraDiffusion: zero-shot depth map restoration with diffusion models\n  and prompted segmentation from sparse infrastructure point clouds",
      "summary": "Point clouds are widely used for infrastructure monitoring by providing\ngeometric information, where segmentation is required for downstream tasks such\nas defect detection. Existing research has automated semantic segmentation of\nstructural components, while brick-level segmentation (identifying defects such\nas spalling and mortar loss) has been primarily conducted from RGB images.\nHowever, acquiring high-resolution images is impractical in low-light\nenvironments like masonry tunnels. Point clouds, though robust to dim lighting,\nare typically unstructured, sparse, and noisy, limiting fine-grained\nsegmentation. We present InfraDiffusion, a zero-shot framework that projects\nmasonry point clouds into depth maps using virtual cameras and restores them by\nadapting the Denoising Diffusion Null-space Model (DDNM). Without task-specific\ntraining, InfraDiffusion enhances visual clarity and geometric consistency of\ndepth maps. Experiments on masonry bridge and tunnel point cloud datasets show\nsignificant improvements in brick-level segmentation using the Segment Anything\nModel (SAM), underscoring its potential for automated inspection of masonry\nassets. Our code and data is available at\nhttps://github.com/Jingyixiong/InfraDiffusion-official-implement.",
      "url": "http://arxiv.org/abs/2509.03324v1",
      "published_time_eastern_timestamp": 1756908070.0
    },
    {
      "title": "The super learner for time-to-event outcomes: A tutorial",
      "summary": "Estimating risks or survival probabilities conditional on individual\ncharacteristics based on censored time-to-event data is a commonly faced task.\nThis may be for the purpose of developing a prediction model or may be part of\na wider estimation procedure, such as in causal inference. A challenge is that\nit is impossible to know at the outset which of a set of candidate models will\nprovide the best predictions. The super learner is a powerful approach for\nfinding the best model or combination of models ('ensemble') among a\npre-specified set of candidate models or 'learners', which can include\nparametric and machine learning models. Super learners for time-to-event\noutcomes have been developed, but the literature is technical and a reader may\nfind it challenging to gather together the full details of how these methods\nwork and can be implemented. In this paper we provide a practical tutorial on\nsuper learner methods for time-to-event outcomes. An overview of the general\nsteps involved in the super learner is given, followed by details of three\nspecific implementations for time-to-event outcomes. We cover discrete-time and\ncontinuous-time versions of the super learner, as described by Polley and van\nder Laan (2011), Westling et al. (2023) and Munch and Gerds (2024). We compare\nthe properties of the methods and provide information on how they can be\nimplemented in R. The methods are illustrated using an open access data set and\nR code is provided.",
      "url": "http://arxiv.org/abs/2509.03315v1",
      "published_time_eastern_timestamp": 1756907093.0
    },
    {
      "title": "RTGMFF: Enhanced fMRI-based Brain Disorder Diagnosis via ROI-driven Text\n  Generation and Multimodal Feature Fusion",
      "summary": "Functional magnetic resonance imaging (fMRI) is a powerful tool for probing\nbrain function, yet reliable clinical diagnosis is hampered by low\nsignal-to-noise ratios, inter-subject variability, and the limited frequency\nawareness of prevailing CNN- and Transformer-based models. Moreover, most fMRI\ndatasets lack textual annotations that could contextualize regional activation\nand connectivity patterns. We introduce RTGMFF, a framework that unifies\nautomatic ROI-level text generation with multimodal feature fusion for\nbrain-disorder diagnosis. RTGMFF consists of three components: (i) ROI-driven\nfMRI text generation deterministically condenses each subject's activation,\nconnectivity, age, and sex into reproducible text tokens; (ii) Hybrid\nfrequency-spatial encoder fuses a hierarchical wavelet-mamba branch with a\ncross-scale Transformer encoder to capture frequency-domain structure alongside\nlong-range spatial dependencies; and (iii) Adaptive semantic alignment module\nembeds the ROI token sequence and visual features in a shared space, using a\nregularized cosine-similarity loss to narrow the modality gap. Extensive\nexperiments on the ADHD-200 and ABIDE benchmarks show that RTGMFF surpasses\ncurrent methods in diagnostic accuracy, achieving notable gains in sensitivity,\nspecificity, and area under the ROC curve. Code is available at\nhttps://github.com/BeistMedAI/RTGMFF.",
      "url": "http://arxiv.org/abs/2509.03214v1",
      "published_time_eastern_timestamp": 1756897557.0
    },
    {
      "title": "Long QMDS additive code",
      "summary": "We investigate additive codes, defined as $\\mathbb{F}_q$-linear subspaces $C\n\\subseteq \\mathbb{F}_{q^h}^n$ of length $n$ and dimension $r$ over\n$\\mathbb{F}_q$. An additive code is said to be of type $[n, r/h, d]_q^h$, where\n$d$ denotes the minimum Hamming distance and the normalized dimension $r/h$ may\nbe fractional. A central object of interest is the class of quasi-MDS (QMDS)\ncodes, those additive codes achieving the generalized Singleton bound:\n  $$ d = n - \\left\\lceil \\frac{r}{h} \\right\\rceil + 1. $$\n  In this work, we construct explicit families of additive QMDS codes whose\nlengths exceed those of the best-known $\\mathbb{F}_{q^h}$-linear MDS codes\nwhich is $q^h+1$, and we will call these types of codes ``Long'' . By\nleveraging $\\mathbb{F}_q$-linearity and geometric tools like partial spreads\nand dimensional dual arcs, we show that additive structures allow longer codes\nwithout sacrificing optimality in distance. We also examine dual codes and give\nconditions under which the QMDS property is preserved under duality.",
      "url": "http://arxiv.org/abs/2509.03186v1",
      "published_time_eastern_timestamp": 1756894481.0
    },
    {
      "title": "Temporally-Aware Diffusion Model for Brain Progression Modelling with\n  Bidirectional Temporal Regularisation",
      "summary": "Generating realistic MRIs to accurately predict future changes in the\nstructure of brain is an invaluable tool for clinicians in assessing clinical\noutcomes and analysing the disease progression at the patient level. However,\ncurrent existing methods present some limitations: (i) some approaches fail to\nexplicitly capture the relationship between structural changes and time\nintervals, especially when trained on age-imbalanced datasets; (ii) others rely\nonly on scan interpolation, which lack clinical utility, as they generate\nintermediate images between timepoints rather than future pathological\nprogression; and (iii) most approaches rely on 2D slice-based architectures,\nthereby disregarding full 3D anatomical context, which is essential for\naccurate longitudinal predictions. We propose a 3D Temporally-Aware Diffusion\nModel (TADM-3D), which accurately predicts brain progression on MRI volumes. To\nbetter model the relationship between time interval and brain changes, TADM-3D\nuses a pre-trained Brain-Age Estimator (BAE) that guides the diffusion model in\nthe generation of MRIs that accurately reflect the expected age difference\nbetween baseline and generated follow-up scans. Additionally, to further\nimprove the temporal awareness of TADM-3D, we propose the Back-In-Time\nRegularisation (BITR), by training TADM-3D to predict bidirectionally from the\nbaseline to follow-up (forward), as well as from the follow-up to baseline\n(backward). Although predicting past scans has limited clinical applications,\nthis regularisation helps the model generate temporally more accurate scans. We\ntrain and evaluate TADM-3D on the OASIS-3 dataset, and we validate the\ngeneralisation performance on an external test set from the NACC dataset. The\ncode will be available upon acceptance.",
      "url": "http://arxiv.org/abs/2509.03141v1",
      "published_time_eastern_timestamp": 1756889498.0
    },
    {
      "title": "Successive Cancellation Decoding For General Monotone Chain Polar Codes",
      "summary": "Monotone chain polar codes generalize classical polar codes to multivariate\nsettings, offering a flexible approach for achieving the entire admissible rate\nregion in the distributed lossless coding problem. However, this flexibility\nalso introduces significant challenges for existing successive cancellation\n(SC) based decoding schemes. Motivated by the need for a general SC decoding\nsolution, we present a comprehensive decoding strategy for monotone chain polar\ncodes that can handle arbitrary numbers of terminals, non-binary alphabets, and\ndecoding along arbitrary monotone chains. Specifically, we formulate the SC\ndecoding task as a series of inference subtasks over the polar transform and\npropose a computational graph framework based on probability propagation\nprinciples. This approach highlights the impact of variable switching during\ndecoding and shows that time complexity varies between $O(N\\log{N})$ and\n$O(N^2)$, depending on the specific chain structure. Moreover, we demonstrate\nthat the widely used $O(N)$ space optimization is not universally applicable to\nmonotone chain polar codes, which prompts us to introduce a constant-time\ndecoder forking strategy based on the proposed logical computation graphs. This\nstrategy enables time-efficient list decoding without relying on $O(N)$-space\ntechniques. Numerical results verify the superior performance of the proposed\nscheme compared with the classical lazy-copy scheme.",
      "url": "http://arxiv.org/abs/2509.03128v1",
      "published_time_eastern_timestamp": 1756888100.0
    }
  ]
}
{
  "last_updated": "2026-01-12T10:17:36.967372-05:00",
  "papers": [
    {
      "title": "AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs",
      "summary": "Large language models (LLMs) exhibit complementary strengths arising from differences in pretraining data, model architectures, and decoding behaviors. Inference-time ensembling provides a practical way to combine these capabilities without retraining. However, existing ensemble approaches suffer from fundamental limitations. Most rely on fixed fusion granularity, which lacks the flexibility required for mid-generation adaptation and fails to adapt to different generation characteristics across tasks. To address these challenges, we propose AdaFuse, an adaptive ensemble decoding framework that dynamically selects semantically appropriate fusion units during generation. Rather than committing to a fixed granularity, AdaFuse adjusts fusion behavior on the fly based on the decoding context, with words serving as basic building blocks for alignment. To be specific, we introduce an uncertainty-based criterion to decide whether to apply ensembling at each decoding step. Under confident decoding states, the model continues generation directly. In less certain states, AdaFuse invokes a diversity-aware scaling strategy to explore alternative candidate continuations and inform ensemble decisions. This design establishes a synergistic interaction between adaptive ensembling and test-time scaling, where ensemble decisions guide targeted exploration, and the resulting diversity in turn strengthens ensemble quality. Experiments on open-domain question answering, arithmetic reasoning, and machine translation demonstrate that AdaFuse consistently outperforms strong ensemble baselines, achieving an average relative improvement of 6.88%. The code is available at https://github.com/CCM0111/AdaFuse.",
      "url": "http://arxiv.org/abs/2601.06022v1",
      "published_time_eastern_timestamp": 1767985102.0
    },
    {
      "title": "Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards",
      "summary": "Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \\textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \\textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.",
      "url": "http://arxiv.org/abs/2601.06021v1",
      "published_time_eastern_timestamp": 1767985073.0
    },
    {
      "title": "Open-Vocabulary 3D Instruction Ambiguity Detection",
      "summary": "In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like \"Pass me the vial\" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.",
      "url": "http://arxiv.org/abs/2601.05991v1",
      "published_time_eastern_timestamp": 1767982631.0
    },
    {
      "title": "Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation",
      "summary": "Deformable multi-contrast image registration is a challenging yet crucial task due to the complex, non-linear intensity relationships across different imaging contrasts. Conventional registration methods typically rely on iterative optimization of the deformation field, which is time-consuming. Although recent learning-based approaches enable fast and accurate registration during inference, their generalizability remains limited to the specific contrasts observed during training. In this work, we propose an adaptive conditional contrast-agnostic deformable image registration framework (AC-CAR) based on a random convolution-based contrast augmentation scheme. AC-CAR can generalize to arbitrary imaging contrasts without observing them during training. To encourage contrast-invariant feature learning, we propose an adaptive conditional feature modulator (ACFM) that adaptively modulates the features and the contrast-invariant latent regularization to enforce the consistency of the learned feature across different imaging contrasts. Additionally, we enable our framework to provide contrast-agnostic registration uncertainty by integrating a variance network that leverages the contrast-agnostic registration encoder to improve the trustworthiness and reliability of AC-CAR. Experimental results demonstrate that AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts. Code is available at https://github.com/Yinsong0510/AC-CAR.",
      "url": "http://arxiv.org/abs/2601.05981v1",
      "published_time_eastern_timestamp": 1767981649.0
    },
    {
      "title": "Radial differential rotation leading to dipole collapse in pre-main-sequence stars",
      "summary": "Despite progress in the observations of stellar magnetic fields, their physical mechanisms remain poorly understood. During the pre-main sequence (PMS) phase, the inner layers of stars contract and a radiative core gradually develops. In contrast, the convective envelope is gradually braked through magnetic interactions with the accretion disk and winds. With developing differential rotation inside the star, PMS phase is thus a critical period for magnetic properties of stars when strong initial dipoles can get perturbed, leading to the observed diversity in the magnetism on the main sequence (MS). In this work, we study the impact of differential rotation on such fields. We perform three-dimensional anelastic convective dynamo simulations of rotating spherical shells with an imposed differential rotation (shear) between the boundaries. Density, gravity profiles and convective zone thicknesses were set close to those predicted in PMS low-mass stars by one-dimensional stellar evolution code Cesam2k20. Our results show that radial differential rotation can induce dipole collapse leading to weaker, oscillatory magnetic fields. Differential rotation seems to perturb $α^2$ dynamo mechanism, responsible for dipolar magnetic fields, by shearing poloidal field lines and by affecting turbulent magnetic transport processes. This collapse is moderated by the relative importance of shear compared to the vigor of convective motions, with exact stability criterion depending on the field strength and the size of the radiative core. Applying DNS-based stability criterion in PMS stellar evolution models, we qualitatively reproduce the trends observed in the magnetic topologies of low-mass stars when assuming an efficient internal angular momentum redistribution. This suggests that stellar magnetic properties are intimately related to the PMS angular momentum evolution.",
      "url": "http://arxiv.org/abs/2601.05980v1",
      "published_time_eastern_timestamp": 1767981466.0
    },
    {
      "title": "Distilling Feedback into Memory-as-a-Tool",
      "summary": "We propose a framework that amortizes the cost of inference-time reasoning by converting transient critiques into retrievable guidelines, through a file-based memory system and agent-controlled tool calls. We evaluate this method on the Rubric Feedback Bench, a novel dataset for rubric-based learning. Experiments demonstrate that our augmented LLMs rapidly match the performance of test-time refinement pipelines while drastically reducing inference cost.",
      "url": "http://arxiv.org/abs/2601.05960v1",
      "published_time_eastern_timestamp": 1767979612.0
    },
    {
      "title": "WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation",
      "summary": "Domain-generalized retinal vessel segmentation is critical for automated ophthalmic diagnosis, yet faces significant challenges from domain shift induced by non-uniform illumination and varying contrast, compounded by the difficulty of preserving fine vessel structures. While the Segment Anything Model (SAM) exhibits remarkable zero-shot capabilities, existing SAM-based methods rely on simple adapter fine-tuning while overlooking frequency-domain information that encodes domain-invariant features, resulting in degraded generalization under illumination and contrast variations. Furthermore, SAM's direct upsampling inevitably loses fine vessel details. To address these limitations, we propose WaveRNet, a wavelet-guided frequency learning framework for robust multi-source domain-generalized retinal vessel segmentation. Specifically, we devise a Spectral-guided Domain Modulator (SDM) that integrates wavelet decomposition with learnable domain tokens, enabling the separation of illumination-robust low-frequency structures from high-frequency vessel boundaries while facilitating domain-specific feature generation. Furthermore, we introduce a Frequency-Adaptive Domain Fusion (FADF) module that performs intelligent test-time domain selection through wavelet-based frequency similarity and soft-weighted fusion. Finally, we present a Hierarchical Mask-Prompt Refiner (HMPR) that overcomes SAM's upsampling limitation through coarse-to-fine refinement with long-range dependency modeling. Extensive experiments under the Leave-One-Domain-Out protocol on four public retinal datasets demonstrate that WaveRNet achieves state-of-the-art generalization performance. The source code is available at https://github.com/Chanchan-Wang/WaveRNet.",
      "url": "http://arxiv.org/abs/2601.05942v1",
      "published_time_eastern_timestamp": 1767977909.0
    },
    {
      "title": "Can We Predict Before Executing Machine Learning Agents?",
      "summary": "Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.",
      "url": "http://arxiv.org/abs/2601.05930v1",
      "published_time_eastern_timestamp": 1767977057.0
    },
    {
      "title": "Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens",
      "summary": "Current approaches for segmenting ultra high resolution images either slide a window, thereby discarding global context, or downsample and lose fine detail. We propose a simple yet effective method that brings explicit multi scale reasoning to vision transformers, simultaneously preserving local details and global awareness. Concretely, we process each image in parallel at a local scale (high resolution, small crops) and a global scale (low resolution, large crops), and aggregate and propagate features between the two branches with a small set of learnable relay tokens. The design plugs directly into standard transformer backbones (eg ViT and Swin) and adds fewer than 2 % parameters. Extensive experiments on three ultra high resolution segmentation benchmarks, Archaeoscape, URUR, and Gleason, and on the conventional Cityscapes dataset show consistent gains, with up to 15 % relative mIoU improvement. Code and pretrained models are available at https://archaeoscape.ai/work/relay-tokens/ .",
      "url": "http://arxiv.org/abs/2601.05927v1",
      "published_time_eastern_timestamp": 1767976868.0
    },
    {
      "title": "Evaluating star formation rates at z = 5",
      "summary": "Inferring the star formation rates (SFR) in high redshift galaxies remains challenging, owing to observational limitations or uncertainties in calibration methods that link luminosities to SFRs. We utilize two state-of-the-art hydrodynamical simulations NewHorizon and NewCluster, post-processed with the radiative transfer code Skirt, to investigate the systematic uncertainties and biases in the inferred SFRs for z=5 galaxies; an epoch where galaxies build-up their stellar mass. We create synthetic observables for widely-used tracers: Halpha nebular line, [CII] 158 micron fine-structure line, total infrared (IR) continuum luminosity, and hybrid (IR + UV). We find that Halpha-inferred SFRs, time-averaged over 10 Myr, are sensitive to the choice of calibration and exhibit substantial scatter driven by dust attenuation, viewing angle, and dust-to-metal ratio. Adopting a steeper attenuation curve reduces this scatter significantly but does not fully eliminate systematic uncertainties. IR continuum-based SFRs trace intrinsic SFRs time-averaged over 100 Myr timescales when a well-sampled continuum emission between restframe 8 and 1000 micron is available and underestimate them with typical approaches when IR data are limited. Nevertheless, IR SFRs display a considerable scatter, largely due to UV photon leakage and strong variations in the star formation history. When UV data are available, hybrid (IR + UV) SFRs provide a more robust estimate, reducing scatter compared to IR-based SFRs while avoiding explicit attenuation corrections. Finally, we derive a [CII]-SFR relation finding a steeper relation than previous studies, however with significant scatter linked to gas density and metallicity. Overall, IR-, hybrid-, and [CII]-based tracers remain more robust than Halpha against variations in optical depth.",
      "url": "http://arxiv.org/abs/2601.05916v1",
      "published_time_eastern_timestamp": 1767976273.0
    },
    {
      "title": "Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency",
      "summary": "As Large Language Models (LLMs) are increasingly deployed in real-world settings, correctness alone is insufficient. Reliable deployment requires maintaining truthful beliefs under contextual perturbations. Existing evaluations largely rely on point-wise confidence like Self-Consistency, which can mask brittle belief. We show that even facts answered with perfect self-consistency can rapidly collapse under mild contextual interference. To address this gap, we propose Neighbor-Consistency Belief (NCB), a structural measure of belief robustness that evaluates response coherence across a conceptual neighborhood. To validate the efficiency of NCB, we introduce a new cognitive stress-testing protocol that probes outputs stability under contextual interference. Experiments across multiple LLMs show that the performance of high-NCB data is relatively more resistant to interference. Finally, we present Structure-Aware Training (SAT), which optimizes context-invariant belief structure and reduces long-tail knowledge brittleness by approximately 30%. Code will be available at https://github.com/zjunlp/belief.",
      "url": "http://arxiv.org/abs/2601.05905v1",
      "published_time_eastern_timestamp": 1767975801.0
    },
    {
      "title": "HAPS: Hierarchical LLM Routing with Joint Architecture and Parameter Search",
      "summary": "Large language model (LLM) routing aims to exploit the specialized strengths of different LLMs for diverse tasks. However, existing approaches typically focus on selecting LLM architectures while overlooking parameter settings, which are critical for task performance. In this paper, we introduce HAPS, a hierarchical LLM routing framework that jointly searches over model architectures and parameters. Specifically, we use a high-level router to select among candidate LLM architectures, and then search for the optimal parameters for the selected architectures based on a low-level router. We design a parameter generation network to share parameters between the two routers to mutually enhance their capabilities. In the training process, we design a reward-augmented objective to effectively optimize our framework. Experiments on two commonly used benchmarks show that HAPS consistently outperforms strong routing baselines. We have released our code at https://github.com/zihangtian/HAPS.",
      "url": "http://arxiv.org/abs/2601.05903v1",
      "published_time_eastern_timestamp": 1767975745.0
    },
    {
      "title": "TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents",
      "summary": "Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).",
      "url": "http://arxiv.org/abs/2601.05899v1",
      "published_time_eastern_timestamp": 1767975488.0
    },
    {
      "title": "Dynamics of ion temperature gradient modes in burning plasma conditions in the presence of energetic particles",
      "summary": "The interaction between energetic particles (EPs) and ion temperature gradient (ITG) modes is studied using the global particle in cell ORB5 code. In this work, we extend previous studies to a broader range of EP temperatures, including the burning plasma regime and to wider variety of EP distribution functions. Two main stabilization mechanisms are found to be effective in ITG stabilization confirming previous studies: direct dispersion relation modification (DDRM) effective only at intermediate EP temperatures and dilution effect (DE) which is independent of EP temperature and becomes dominant in burning plasma regime ($T_f > 50T_i$). The study is further extended to slowing-down EP distributions which in contrast exhibit no DDRM-related stabilization. The findings are further validated in an ITER pre-fusion operation scenario and additionally compared with electromagnetic effects. In this scenario EP stabilization is found to be weaker than $β$-stabilization. Overall, these results provide better understanding of EP-ITG interactions over a wider range of EP parameters relevant to burning plasma regime which is important for predicting turbulence and confinement in future devices such as ITER.",
      "url": "http://arxiv.org/abs/2601.05886v1",
      "published_time_eastern_timestamp": 1767974719.0
    },
    {
      "title": "Non Destructive Testing",
      "summary": "The contribution introduces the principles, methods, and applications of non-destructive testing in the context of particle accelerators and related technologies is presented. Both surface inspection methods (visual testing, penetrant testing, magnetic particle testing, eddy current testing) and volumetric methods (radiographic testing, ultrasonic testing) are presented, with examples drawn from CERN projects. Emphasis is placed on the capabilities, limitations, and practical considerations of each technique, highlighting their role in ensuring quality and safety during fabrication, procurement, and in-service inspections. The contribution also addresses standards, codes, and personnel qualification schemes, underlining their regulatory impact in fields such as pressure equipment and industrial piping. Finally, the importance of early integration of NDT into project planning is stressed, not only for compliance but also as a proactive quality and efficiency measure.",
      "url": "http://arxiv.org/abs/2601.05880v1",
      "published_time_eastern_timestamp": 1767974143.0
    },
    {
      "title": "Continual-learning for Modelling Low-Resource Languages from Large Language Models",
      "summary": "Modelling a language model for a multi-lingual scenario includes several potential challenges, among which catastrophic forgetting is the major challenge. For example, small language models (SLM) built for low-resource languages by adapting large language models (LLMs) pose the challenge of catastrophic forgetting. This work proposes to employ a continual learning strategy using parts-of-speech (POS)-based code-switching along with a replay adapter strategy to mitigate the identified gap of catastrophic forgetting while training SLM from LLM. Experiments conducted on vision language tasks such as visual question answering and language modelling task exhibits the success of the proposed architecture.",
      "url": "http://arxiv.org/abs/2601.05874v1",
      "published_time_eastern_timestamp": 1767973872.0
    },
    {
      "title": "Neural Methods for Multiple Systems Estimation Models",
      "summary": "Estimating the size of hidden populations using Multiple Systems Estimation (MSE) is a critical task in quantitative sociology; however, practical application is often hindered by imperfect administrative data and computational constraints. Real-world datasets frequently suffer from censoring and missingness due to privacy concerns, while standard inference methods, such as Maximum Likelihood Estimation (MLE) and Markov chain Monte Carlo (MCMC), can become computationally intractable or fail to converge when data are sparse. To address these limitations, we propose a novel simulation-based Bayesian inference framework utilizing Neural Bayes Estimators (NBE) and Neural Posterior Estimators (NPE). These neural methods are amortized: once trained, they provide instantaneous, computationally efficient posterior estimates, making them ideal for use in secure research environments where computational resources are limited. Through extensive simulation studies, we demonstrate that neural estimators achieve accuracy comparable to MCMC while being orders of magnitude faster and robust to the convergence failures that plague traditional samplers in sparse settings. We demonstrate our method on two real-world cases estimating the prevalence of modern slavery in the UK and female drug use in North East England.",
      "url": "http://arxiv.org/abs/2601.05859v1",
      "published_time_eastern_timestamp": 1767972879.0
    },
    {
      "title": "CLewR: Curriculum Learning with Restarts for Machine Translation Preference Learning",
      "summary": "Large language models (LLMs) have demonstrated competitive performance in zero-shot multilingual machine translation (MT). Some follow-up works further improved MT performance via preference optimization, but they leave a key aspect largely underexplored: the order in which data samples are given during training. We address this topic by integrating curriculum learning into various state-of-the-art preference optimization algorithms to boost MT performance. We introduce a novel curriculum learning strategy with restarts (CLewR), which reiterates easy-to-hard curriculum multiple times during training to effectively mitigate the catastrophic forgetting of easy examples. We demonstrate consistent gains across several model families (Gemma2, Qwen2.5, Llama3.1) and preference optimization techniques. We publicly release our code at https://github.com/alexandra-dragomir/CLewR.",
      "url": "http://arxiv.org/abs/2601.05858v1",
      "published_time_eastern_timestamp": 1767972871.0
    },
    {
      "title": "Bidirectional Channel-selective Semantic Interaction for Semi-Supervised Medical Segmentation",
      "summary": "Semi-supervised medical image segmentation is an effective method for addressing scenarios with limited labeled data. Existing methods mainly rely on frameworks such as mean teacher and dual-stream consistency learning. These approaches often face issues like error accumulation and model structural complexity, while also neglecting the interaction between labeled and unlabeled data streams. To overcome these challenges, we propose a Bidirectional Channel-selective Semantic Interaction~(BCSI) framework for semi-supervised medical image segmentation. First, we propose a Semantic-Spatial Perturbation~(SSP) mechanism, which disturbs the data using two strong augmentation operations and leverages unsupervised learning with pseudo-labels from weak augmentations. Additionally, we employ consistency on the predictions from the two strong augmentations to further improve model stability and robustness. Second, to reduce noise during the interaction between labeled and unlabeled data, we propose a Channel-selective Router~(CR) component, which dynamically selects the most relevant channels for information exchange. This mechanism ensures that only highly relevant features are activated, minimizing unnecessary interference. Finally, the Bidirectional Channel-wise Interaction~(BCI) strategy is employed to supplement additional semantic information and enhance the representation of important channels. Experimental results on multiple benchmarking 3D medical datasets demonstrate that the proposed method outperforms existing semi-supervised approaches.",
      "url": "http://arxiv.org/abs/2601.05855v1",
      "published_time_eastern_timestamp": 1767972777.0
    },
    {
      "title": "LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting",
      "summary": "We propose a novel framework for decomposing arbitrarily posed humans into animatable multi-layered 3D human avatars, separating the body and garments. Conventional single-layer reconstruction methods lock clothing to one identity, while prior multi-layer approaches struggle with occluded regions. We overcome both limitations by encoding each layer as a set of 2D Gaussians for accurate geometry and photorealistic rendering, and inpainting hidden regions with a pretrained 2D diffusion model via score-distillation sampling (SDS). Our three-stage training strategy first reconstructs the coarse canonical garment via single-layer reconstruction, followed by multi-layer training to jointly recover the inner-layer body and outer-layer garment details. Experiments on two 3D human benchmark datasets (4D-Dress, Thuman2.0) show that our approach achieves better rendering quality and layer decomposition and recomposition than the previous state-of-the-art, enabling realistic virtual try-on under novel viewpoints and poses, and advancing practical creation of high-fidelity 3D human assets for immersive applications. Our code is available at https://github.com/RockyXu66/LayerGS",
      "url": "http://arxiv.org/abs/2601.05853v1",
      "published_time_eastern_timestamp": 1767972612.0
    }
  ]
}
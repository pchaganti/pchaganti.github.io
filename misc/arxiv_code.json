{
  "last_updated": "2026-01-26T07:29:31.275127-05:00",
  "papers": [
    {
      "title": "AnyView: Synthesizing Any Novel View in Dynamic Scenes",
      "summary": "Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \\textbf{AnyView}, a diffusion-based video generation framework for \\emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \\textbf{AnyViewBench}, a challenging new benchmark tailored towards \\emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \\emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/",
      "url": "http://arxiv.org/abs/2601.16982v1",
      "published_time_eastern_timestamp": 1769194798.0
    },
    {
      "title": "VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents",
      "summary": "Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.",
      "url": "http://arxiv.org/abs/2601.16973v1",
      "published_time_eastern_timestamp": 1769193814.0
    },
    {
      "title": "Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians",
      "summary": "In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.",
      "url": "http://arxiv.org/abs/2601.16967v1",
      "published_time_eastern_timestamp": 1769193595.0
    },
    {
      "title": "AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems",
      "summary": "The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive",
      "url": "http://arxiv.org/abs/2601.16964v1",
      "published_time_eastern_timestamp": 1769193221.0
    },
    {
      "title": "Experimental investigation of nonclassicality in the simplest scenario via the degrees of freedom of light",
      "summary": "In this work, we experimentally investigate the classical-light emulation of different notions of nonclassicality in the simplest scenario. We implement this prepare-and-measure scenario involving four preparations and two binary-outcome measurements using two distinct experimental setups that exploit different degrees of freedom of light: polarization and first-order Hermite-Gaussian transverse modes. We additionally model experimental noise through an all-optical setup that reproduces the operational effect of a depolarizing channel. Our experimental results are consistent with the findings of Khoshbin et al. [Phys. Rev. A 109, 032212 (2024)]: under the assumption that the two measurements performed form a tomographically complete set, the observed statistics violate their noise-robust inequalities, indicating inconsistencies with preparation noncontextuality and bounded ontological distinctness for preparations. Although our implementation uses classical light, it reproduces the statistics predicted for the simplest scenario. Since the states and measurements of this scenario underpin computational advantages in tasks such as two-bit quantum random access codes -- among the simplest communication primitives enabling semi-device-independent certification of nonclassicality -- our implementation is directly relevant for such applications.",
      "url": "http://arxiv.org/abs/2601.16952v1",
      "published_time_eastern_timestamp": 1769192236.0
    },
    {
      "title": "Evaluating Wi-Fi Performance for VR Streaming: A Study on Realistic HEVC Video Traffic",
      "summary": "Cloud-based Virtual Reality (VR) streaming presents significant challenges for 802.11 networks due to its high throughput and low latency requirements. When multiple VR users share a Wi-Fi network, the resulting uplink and downlink traffic can quickly saturate the channel. This paper investigates the capacity of 802.11 networks for supporting realistic VR streaming workloads across varying frame rates, bitrates, codec settings, and numbers of users. We develop an emulation framework that reproduces Air Light VR (ALVR) operation, where real HEVC video traffic is fed into an 802.11 simulation model. Our findings explore Wi-Fi's performance anomaly and demonstrate that Intra-refresh (IR) coding effectively reduces latency variability and improves QoS, supporting up to 4 concurrent VR users with Constant Bitrate (CBR) 100 Mbps before the channel is saturated.",
      "url": "http://arxiv.org/abs/2601.16950v1",
      "published_time_eastern_timestamp": 1769192125.0
    },
    {
      "title": "Identifying heat-related diagnoses in emergency department visits among adults in Chicago: a heat-wide association study",
      "summary": "Extreme heat is an escalating public health concern. Although prior studies have examined heat-health associations, their reliance on restricted diagnoses and diagnostic categories misses or misclassifies heat-related illness. We conducted a heat-wide association study to identify acute-care diagnoses associated with extreme heat in Chicago, Illinois. Using 916,904 acute-care visits -- including emergency department and urgent care encounters -- among 372,140 adults across five healthcare systems from 2011-2023, we applied a two-stage analytic approach: quasi-Poisson regression to screen 1,803 diagnosis codes for heat-related risks, followed by distributed lag non-linear models in a time-stratified case-crossover design to refine the list of heat-related diagnoses and estimate same-day and short-term cumulative odds ratios of acute-care visits during extreme heat versus reference temperature. We observed same-day increases in visits for heat illness, volume depletion, hypotension, edema, acute kidney failure, and multiple injuries. By analyzing the full diagnostic spectrum of acute-care services, this study comprehensively characterizes heat-associated morbidity, reinforcing and advancing existing literature.",
      "url": "http://arxiv.org/abs/2601.16932v1",
      "published_time_eastern_timestamp": 1769190370.0
    },
    {
      "title": "Drawing the line between explosion and collapse in electron-capture supernovae -- I. Impact of conductive flame speeds and ignition conditions on the explosion mechanism",
      "summary": "Electron-capture supernovae (ECSNe) are commonly thought to result in a collapse to a neutron star. Recent work has shown that a thermonuclear explosion is also a possible outcome. The division between the two regimes has not yet been mapped out. In this study, we investigate the conditions under which the transition from thermonuclear explosion to collapse occurs, and what physical mechanisms drive each outcome. We conducted a parameter study of 56 3D hydrodynamic simulations of ECSN in ONe white dwarfs using a level set based flame model implemented in the Leafs code. We varied both the ignition location and the central density at ignition to determine the conditions of the transition regime. Additionally, we explored two different laminar flame parameterizations and how they impact the simulation outcome. From our parameter study, we find a transition density in the range of $\\logρ_c^{ini}=10.0$ and $10.15$ g cm$^{-3}$, depending on the ignition location and utilized laminar flame speed parameterization. Importantly, we find that for sufficiently high central densities, the burned ashes can sink into the core and trap large amounts of neutron-rich material in the bound remnant. In the transition regime between explosion and collapse, we find that the laminar flame speed plays a critical role by suppressing the formation of instabilities and thereby reducing the nuclear energy generation needed to overcome the collapse. We find that a thermonuclear explosion is possible for a wide range of parameters, whereby a more off-center ignition allows for higher central densities to still result in an explosion. Both the conditions at ignition and the flame physics are critical in determining the outcome. Detailed 3D hydrodynamic simulations of the preceding stellar evolution and the ignition process of the thermonuclear flame are necessary to accurately predict the outcome of ECSNe.",
      "url": "http://arxiv.org/abs/2601.16918v1",
      "published_time_eastern_timestamp": 1769189238.0
    },
    {
      "title": "GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss",
      "summary": "Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.",
      "url": "http://arxiv.org/abs/2601.16885v1",
      "published_time_eastern_timestamp": 1769186819.0
    },
    {
      "title": "Assessing the Feasibility of Selective Instrumentation for Runtime Code Coverage in Large C++ Game Engines",
      "summary": "Code coverage is a valuable guide for testing, but in AAA games the overhead of instrumentation conflicts with strict performance requirements and can destabilize automated tests. We propose and assess a selective instrumentation approach tailored to large game engines written in \\texttt{C++}, which reduces the scope of instrumentation while preserving relevant coverage data to developer commits. Our framework integrates into an industrial game testing pipeline, enabling developers to receive immediate coverage feedback on tests run against their changes. The compilation overhead of our approach is minimal, allowing instrumentation of over 2,000 commits before doubling build time. In performance evaluations, even the worst-case scenario maintains frame rates above 50\\% of the non-instrumented baseline. Across two production test suites maintained by our industry partner, our framework caused no automated test failures, avoiding the instability observed under full instrumentation. Our work shows that commit-level or build-level coverage of large \\texttt{C++} game engines can be achieved with minimal overhead and without compromising test stability.",
      "url": "http://arxiv.org/abs/2601.16881v1",
      "published_time_eastern_timestamp": 1769186519.0
    },
    {
      "title": "The Origins of Planets for ArieL (OPAL) Key Science Project: the end-to-end planet formation campaign for the ESA space mission Ariel",
      "summary": "The growing body of atmospheric observations of exoplanets from space and ground-based facilities showcases how the great diversity of the planetary population is not limited to their physical properties but extends to their compositions. The ESA space mission Ariel will observe and characterise hundreds of exoplanetary atmospheres to explore and understand the roots of this compositional diversity. To lay the foundations for the Ariel mission, the OPAL Key Science Project is tasked with creating an unprecedented library of realistic synthetic atmospheres spanning tens of elements and hundreds of molecules on which the Ariel consortium will test and validate its codes and pipelines ahead of launch. In this work we describe the aims and the pipeline of codes of the OPAL project, as well as the process through which we trace the genetic link connecting planets to their native protoplanetary disks and host stars. We present the early results of this complex and unprecedented endeavour and discuss how they highlight the great diversity of outcomes that emerge from the large degeneracy in the parameter space of possible initial conditions to the planet formation process. This, in turn, illustrates the growing importance of interdisciplinary modelling studies supported by high-performance computing methods and infrastructures to properly investigate this class of high-dimensionality problems.",
      "url": "http://arxiv.org/abs/2601.16841v1",
      "published_time_eastern_timestamp": 1769182981.0
    },
    {
      "title": "AI builds, We Analyze: An Empirical Study of AI-Generated Build Code Quality",
      "summary": "The rapid adoption of AI coding agents for software development has raised important questions about the quality and maintainability of the code they produce. While prior studies have examined AI-generated source code, the impact of AI coding agents on build systems-a critical yet understudied component of the software lifecycle-remains largely unexplored. This data mining challenge focuses on AIDev, the first large-scale, openly available dataset capturing agent-authored pull requests (Agentic-PRs) from real-world GitHub repositories. Our paper leverages this dataset to investigate (RQ1) whether AI coding agents generate build code with quality issues (e.g., code smells), (RQ2) to what extent AI agents can eliminate code smells from build code, and (RQ3) to what extent Agentic-PRs are accepted by developers. We identified 364 maintainability and security-related build smells across varying severity levels, indicating that AI-generated build code can introduce quality issues-such as lack of error handling, and hardcoded paths or URLs-while also, in some cases, removing existing smells through refactorings (e.g., Pull Up Module and Externalize Properties). Notably, more than 61\\% of Agentic-PRs are approved and merged with minimal human intervention. This dual impact underscores the need for future research on AI-aware build code quality assessment to systematically evaluate, guide, and govern AI-generated build systems code.",
      "url": "http://arxiv.org/abs/2601.16839v1",
      "published_time_eastern_timestamp": 1769182828.0
    },
    {
      "title": "ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models",
      "summary": "While text-to-image (T2I) models have advanced considerably, their capability to associate colors with implicit concepts remains underexplored. To address the gap, we introduce ColorConceptBench, a new human-annotated benchmark to systematically evaluate color-concept associations through the lens of probabilistic color distributions. ColorConceptBench moves beyond explicit color names or codes by probing how models translate 1,281 implicit color concepts using a foundation of 6,369 human annotations. Our evaluation of seven leading T2I models reveals that current models lack sensitivity to abstract semantics, and crucially, this limitation appears resistant to standard interventions (e.g., scaling and guidance). This demonstrates that achieving human-like color semantics requires more than larger models, but demands a fundamental shift in how models learn and represent implicit meaning.",
      "url": "http://arxiv.org/abs/2601.16836v1",
      "published_time_eastern_timestamp": 1769182562.0
    },
    {
      "title": "Will It Survive? Deciphering the Fate of AI-Generated Code in Open Source",
      "summary": "The integration of AI agents as coding assistants into software development has raised questions about the long-term viability of AI agent-generated code. A prevailing hypothesis within the software engineering community suggests this code is \"disposable\", meaning it is merged quickly but discarded shortly thereafter. If true, organizations risk shifting maintenance burden from generation to post-deployment remediation. We investigate this hypothesis through survival analysis of 201 open-source projects, tracking over 200,000 code units authored by AI agents versus humans. Contrary to the disposable code narrative, agent-authored code survives significantly longer: at the line level, it exhibits a 15.8 percentage-point lower modification rate and 16% lower hazard of modification (HR = 0.842, p < 0.001). However, modification profiles differ. Agent-authored code shows modestly elevated corrective rates (26.3% vs. 23.0%), while human code shows higher adaptive rates. However, the effect sizes are small (Cramér's V = 0.116), and per-agent variation exceeds the agent-human gap. Turning to prediction, textual features can identify modification-prone code (AUC-ROC = 0.671), but predicting when modifications occur remains challenging (Macro F1 = 0.285), suggesting timing depends on external organizational dynamics. The bottleneck for agent-generated code may not be generation quality, but the organizational practices that govern its long-term evolution.",
      "url": "http://arxiv.org/abs/2601.16809v1",
      "published_time_eastern_timestamp": 1769180446.0
    },
    {
      "title": "Mercury-Ar$χ$es: a high-performance n-body code for planet formation studies",
      "summary": "Forming planetary systems are populated by large numbers of gravitationally interacting planetary bodies, spanning from massive giant planets to small planetesimals akin to present-day asteroids and comets. All these planetary bodies are embedded in the gaseous embrace of their native protoplanetary disks, and their interactions with the disk gas play a central role in shaping their dynamical evolution and the outcomes of planet formation. These factors make realistic planet formation simulations extremely computationally demanding, which in turn means that accurately modeling the formation of planetary systems requires the use of high-performance methods. The planet formation code Mercury-Ar$χ$es was developed to address these challenges and, since its first implementation, has been used in multiple exoplanetary and Solar System studies. Mercury-Ar$χ$es is a parallel n-body code that builds on the widely used Mercury code and is capable of modeling the growth and migration of forming planets, the interactions between planetary bodies and the disk gas, as well as the evolving impact flux of planetesimals on forming planets across the different stages of their formation process. In this work we provide the up-to-date overview of its physical modeling capabilities and the first detailed description of its high-performance implementation based on the OpenMP directive-based parallelism for shared memory environments, to harness the multi-thread and vectorization features of modern processor architectures.",
      "url": "http://arxiv.org/abs/2601.16791v1",
      "published_time_eastern_timestamp": 1769179063.0
    },
    {
      "title": "From Noisy News Sentiment Scores to Interpretable Temporal Dynamics: A Bayesian State-Space Model",
      "summary": "Text-based sentiment indicators are widely used to monitor public and market mood, but weekly sentiment series are noisy by construction. A main reason is that the amount of relevant news changes over time and across categories. As a result, some weekly averages are based on many articles, while others rely on only a few. Existing approaches do not explicitly account for changes in data availability when measuring uncertainty. We present a Bayesian state-space framework that turns aggregated news sentiment into a smoothed time series with uncertainty. The model treats each weekly sentiment value as a noisy measurement of an underlying sentiment process, with observation uncertainty scaled by the effective information weight $n_{tj}$: when coverage is high, latent sentiment is anchored more strongly to the observed aggregate; when coverage is low, inference relies more on the latent dynamics and uncertainty increases. Using news data grouped into multiple categories, we find broadly similar latent dynamics across categories, while larger differences appear in observation noise. The framework is designed for descriptive monitoring and can be extended to other text sources where information availability varies over time.",
      "url": "http://arxiv.org/abs/2601.16769v1",
      "published_time_eastern_timestamp": 1769177662.0
    },
    {
      "title": "SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents",
      "summary": "LLM agents have demonstrated remarkable capabilities in software development, but their performance is hampered by long interaction contexts, which incur high API costs and latency. While various context compression approaches such as LongLLMLingua have emerged to tackle this challenge, they typically rely on fixed metrics such as PPL, ignoring the task-specific nature of code understanding. As a result, they frequently disrupt syntactic and logical structure and fail to retain critical implementation details. In this paper, we propose SWE-Pruner, a self-adaptive context pruning framework tailored for coding agents. Drawing inspiration from how human programmers \"selectively skim\" source code during development and debugging, SWE-Pruner performs task-aware adaptive pruning for long contexts. Given the current task, the agent formulates an explicit goal (e.g., \"focus on error handling\") as a hint to guide the pruning targets. A lightweight neural skimmer (0.6B parameters) is trained to dynamically select relevant lines from the surrounding context given the goal. Evaluations across four benchmarks and multiple models validate SWE-Pruner's effectiveness in various scenarios, achieving 23-54% token reduction on agent tasks like SWE-Bench Verified and up to 14.84x compression on single-turn tasks like LongCodeQA with minimal performance impact.",
      "url": "http://arxiv.org/abs/2601.16746v1",
      "published_time_eastern_timestamp": 1769176319.0
    },
    {
      "title": "Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition",
      "summary": "Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.",
      "url": "http://arxiv.org/abs/2601.16711v1",
      "published_time_eastern_timestamp": 1769173146.0
    },
    {
      "title": "Developer Perspectives on REST API Usability: A Study of REST API Guidelines",
      "summary": "REST is today's most widely used architectural style for providing web-based services. In the age of service-orientation (a.k.a. Software as a Service (SaaS)) APIs have become core business assets and can easily expose hundreds of operations. While well-designed APIs contribute to the commercial success of a service, poorly designed APIs can threaten entire organizations. Recognizing their relevance and value, many guidelines have been proposed for designing usable APIs, similar to design patterns and coding standards. For example, Zalando and Microsoft provide popular REST API guidelines. However, they are often considered as too large and inapplicable, so many companies create and maintain their own guidelines, which is a challenge in itself. In practice, however, developers still struggle to design effective REST APIs. To improve the situation, we need to improve our empirical understanding of adopting, using, and creating REST API guidelines.\n  We present an interview study with 16 REST API experts from industry. We determine the notion of API usability, guideline effectiveness factors, challenges of adopting and designing guidelines, and best practices. We identified eight factors influencing REST API usability, among which the adherence to conventions is the most important one. While guidelines can in fact be an effective means to improve API usability, there is significant resistance from developers against strict guidelines. Guideline size and how it fits with organizational needs are two important factors to consider. REST guidelines also have to grow with the organization, while all stakeholders need to be involved in their development and maintenance. Automated linting provides an opportunity to not only embed compliance enforcement into processes, but also to justify guideline rules with educational explanations.",
      "url": "http://arxiv.org/abs/2601.16705v1",
      "published_time_eastern_timestamp": 1769172301.0
    },
    {
      "title": "Affinity Contrastive Learning for Skeleton-based Human Activity Understanding",
      "summary": "In skeleton-based human activity understanding, existing methods often adopt the contrastive learning paradigm to construct a discriminative feature space. However, many of these approaches fail to exploit the structural inter-class similarities and overlook the impact of anomalous positive samples. In this study, we introduce ACLNet, an Affinity Contrastive Learning Network that explores the intricate clustering relationships among human activity classes to improve feature discrimination. Specifically, we propose an affinity metric to refine similarity measurements, thereby forming activity superclasses that provide more informative contrastive signals. A dynamic temperature schedule is also introduced to adaptively adjust the penalty strength for various superclasses. In addition, we employ a margin-based contrastive strategy to improve the separation of hard positive and negative samples within classes. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, Kinetics-Skeleton, PKU-MMD, FineGYM, and CASIA-B demonstrate the superiority of our method in skeleton-based action recognition, gait recognition, and person re-identification. The source code is available at https://github.com/firework8/ACLNet.",
      "url": "http://arxiv.org/abs/2601.16694v1",
      "published_time_eastern_timestamp": 1769170836.0
    }
  ]
}
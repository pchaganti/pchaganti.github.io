{
  "last_updated": "2026-02-15T23:53:23.038327-05:00",
  "papers": [
    {
      "title": "$\\texttt{GPUmonty}$: A GPU-accelerated relativistic Monte Carlo radiative transfer code",
      "summary": "We introduce $\\texttt{GPUmonty}$, a CUDA/C-based Monte Carlo radiative transfer code accelerated using graphics processing units (GPUs). $\\texttt{GPUmonty}$ derives from the CPU-based code $\\texttt{grmonty}$ and offloads the most computationally expensive stages of the calculation -- superphoton generation, sampling, tracking, and scattering -- to the GPU. Whereas $\\texttt{grmonty}$ handles photons sequentially, $\\texttt{GPUmonty}$ processes large numbers of superphotons concurrently, leveraging the single-instruction, multiple-thread (SIMT) execution model of modern GPUs. Benchmarks demonstrate a speedup of about $12\\times$ relative to the original CPU implementation on a single GPU, with runtime limited primarily by register pressure rather than compute or memory bandwidth saturation. We validate the implementation through analytic tests for a optically thin synchrotron sphere, as well as comparisons with $\\texttt{igrmonty}$ for scattering synchrotron sphere and GRMHD simulation data. Relative errors remain below a percent level and convergence is consistent with the expected $N_{\\rm s}^{-1/2}$ Monte Carlo scaling. By significantly reducing computational costs, GPUmonty enables the extensive parameter space surveys and faster spectra modeling required to interpret horizon-scale observations of supermassive black holes. $\\texttt{GPUmonty}$ is publicly available under the GNU General Public License.",
      "url": "http://arxiv.org/abs/2602.13198v1",
      "published_time_eastern_timestamp": 1771009199.0
    },
    {
      "title": "Fix Before Search: Benchmarking Agentic Query Visual Pre-processing in Multimodal Retrieval-augmented Generation",
      "summary": "Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a key paradigm for grounding MLLMs with external knowledge. While query pre-processing (e.g., rewriting) is standard in text-based RAG, existing MRAG pipelines predominantly treat visual inputs as static and immutable, implicitly assuming they are noise-free. However, real-world visual queries are often ``imperfect'' -- suffering from geometric distortions, quality degradation, or semantic ambiguity -- leading to catastrophic retrieval failures. To address this gap, we propose V-QPP-Bench, the first comprehensive benchmark dedicated to Visual Query Pre-processing (V-QPP). We formulate V-QPP as an agentic decision-making task where MLLMs must autonomously diagnose imperfections and deploy perceptual tools to refine queries. Our extensive evaluation across 46,700 imperfect queries and diverse MRAG paradigms reveals three critical insights: (1) Vulnerability -- visual imperfections severely degrade both retrieval recall and end-to-end MRAG performance; (2) Restoration Potential \\& Bottleneck -- while oracle preprocessing recovers near-perfect performance, off-the-shelf MLLMs struggle with tool selection and parameter prediction without specialized training; and (3) Training Enhancement -- supervised fine-tuning enables compact models to achieve comparable or superior performance to larger proprietary models, demonstrating the benchmark's value for developing robust MRAG systems The code is available at https://github.com/phycholosogy/VQQP_Bench",
      "url": "http://arxiv.org/abs/2602.13179v1",
      "published_time_eastern_timestamp": 1771007988.0
    },
    {
      "title": "Source Code Hotspots: A Diagnostic Method for Quality Issues",
      "summary": "Software source code often harbours \"hotspots\": small portions of the code that change far more often than the rest of the project and thus concentrate maintenance activity. We mine the complete version histories of 91 evolving, actively developed GitHub repositories and identify 15 recurring line-level hotspot patterns that explain why these hotspots emerge. The three most prevalent patterns are Pinned Version Bump (26%), revealing brittle release practices; Long Line Change (17%), signalling deficient layout; and Formatting Ping-Pong (9%), indicating missing or inconsistent style automation. Surprisingly, automated accounts generate 74% of all hotspot edits, suggesting that bot activity is a dominant but largely avoidable source of noise in change histories. By mapping each pattern to concrete refactoring guidelines and continuous integration checks, our taxonomy equips practitioners with actionable steps to curb hotspots and systematically improve software quality in terms of configurability, stability, and changeability.",
      "url": "http://arxiv.org/abs/2602.13170v1",
      "published_time_eastern_timestamp": 1771007352.0
    },
    {
      "title": "New irreducible components of $\\mathcal{B}(0,c_2)$ and Computation of the Dimension of its tangent space",
      "summary": "We provide a Macaulay2 code for computing the dimension of the tangent space to $\\mathcal{B}(e,c_2)$ in certain cases. Using this code, we identify components of $\\mathcal{B}(e,c_2)$ containing singular points and compute the dimension of the irreducible component $M_4$ of $\\mathcal{B}(-1,6)$, whose existence was proved in \\cite{MF2021}. Furthermore, we prove the existence of infinite families of irreducible components of $\\mathcal{B}(0,c_2)$.",
      "url": "http://arxiv.org/abs/2602.13162v1",
      "published_time_eastern_timestamp": 1771006977.0
    },
    {
      "title": "TrustMee: Self-Verifying Remote Attestation Evidence",
      "summary": "Hardware-secured remote attestation is essential to establishing trust in the integrity of confidential virtual machines (cVMs), but is difficult to use in practice because verifying attestation evidence requires the use of hardware-specific cryptographic logic. This increases both maintenance costs and the verifiers' trusted computing base. We introduce the concept of self-verifying remote attestation evidence. Each attestation bundle includes verification logic as a WebAssembly component signed by a trusted party. This approach transforms evidence verification into a standard code-signing problem: the verifier checks the signature on the embedded logic and then executes it to validate the evidence. As a result, verifiers can validate attestation evidence without any platform-specific knowledge. We implement this concept as TrustMee, a platform-agnostic verification driver for the Trustee framework. We demonstrate its functionality with self-verifying evidence for AMD SEV-SNP and Intel TDX attestations, producing attestation claims in the standard EAT Attestation Result (EAR) format.",
      "url": "http://arxiv.org/abs/2602.13148v1",
      "published_time_eastern_timestamp": 1771005368.0
    },
    {
      "title": "FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics",
      "summary": "Graph neural network (GNN) potentials such as SchNet improve the accuracy and transferability of molecular dynamics (MD) simulation by learning many-body interactions, but remain slower than classical force fields due to fragmented kernels and memory-bound pipelines that underutilize GPUs. We show that a missing principle is making GNN-MD IO-aware, carefully accounting for reads and writes between GPU high-bandwidth memory (HBM) and on-chip SRAM. We present FlashSchNet, an efficient and accurate IO-aware SchNet-style GNN-MD framework built on four techniques: (1) flash radial basis, which fuses pairwise distance computation, Gaussian basis expansion, and cosine envelope into a single tiled pass, computing each distance once and reusing it across all basis functions; (2) flash message passing, which fuses cutoff, neighbor gather, filter multiplication, and reduction to avoid materializing edge tensors in HBM; (3) flash aggregation, which reformulates scatter-add via CSR segment reduce, reducing atomic writes by a factor of feature dimension and enabling contention-free accumulation in both forward and backward passes; (4) channel-wise 16-bit quantization that exploits the low per-channel dynamic range in SchNet MLP weights to further improve throughput with negligible accuracy loss. On a single NVIDIA RTX PRO 6000, FlashSchNet achieves 1000 ns/day aggregate simulation throughput over 64 parallel replicas on coarse-grained (CG) protein containing 269 beads (6.5x faster than CGSchNet baseline with 80% reduction of peak memory), surpassing classical force fields (e.g. MARTINI) while retaining SchNet-level accuracy and transferability.",
      "url": "http://arxiv.org/abs/2602.13140v1",
      "published_time_eastern_timestamp": 1771004952.0
    },
    {
      "title": "LinkedNN: a neural model of linkage disequilibrium decay for recent effective population size inference",
      "summary": "Summary: A bioinformatics tool is presented for estimating recent effective population size by using a neural network to automatically compute linkage disequilibrium-related features as a function of genomic distance between polymorphisms. The new method outperforms existing deep learning and summary statistic-based approaches using relatively few sequenced individuals and variant sites, making it particularly valuable for molecular ecology applications with sparse, unphased data. Availability and implementation: The program is available as an easily installable Python package with documentation here: https://pypi.org/project/linkedNN/. The open source code is available from: https://github.com/the-smith-lab/LinkedNN.",
      "url": "http://arxiv.org/abs/2602.13121v1",
      "published_time_eastern_timestamp": 1771003101.0
    },
    {
      "title": "Intersecting Codes and the Connectivity of $q$-Matroids",
      "summary": "We investigate the structure of intersecting error-correcting codes, with a particular focus on their connection to matroid theory. We establish properties and bounds for intersecting codes with the Hamming metric and illustrate how these distinguish the subfamily of minimal codes within the family of intersecting codes. We prove that the property of a code being intersecting is characterized by the matroid-theoretic notion of vertical connectivity, showing that intersecting codes are precisely those achieving the highest possible value of this parameter. We then introduce the concept of vertical connectivity for $q$-matroids and link it to the theory of intersecting codes endowed with the rank metric.",
      "url": "http://arxiv.org/abs/2602.13107v1",
      "published_time_eastern_timestamp": 1771002597.0
    },
    {
      "title": "R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training",
      "summary": "Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhibit non-sustained improvement, where early gains degrade as self-play continues. We identify a key failure mode, Diversity Illusion, where the Solver's training signals appear diverse yet collapse into recurring underlying patterns. It manifests as (1) Local Diversity Illusion, where diversity is enforced only within-batch, inducing cross-iteration mode cycling; and (2) Surface Diversity Illusion, where questions vary superficially but require near-identical reasoning skills. To mitigate them, we propose R-Diverse with two aligned innovations: Memory-Augmented Penalty (MAP), which uses a persistent memory bank to discourage recycling across iterations, and Skill-Aware Measurement (SAM), which evaluates diversity by the reasoning skills exercised rather than surface variation of questions. Across 10 math and general reasoning benchmarks, R-Diverse sustains gains over more iterations and consistently outperforms prior self-play methods. Code is available at https://github.com/Gengsheng-Li/R-Diverse.",
      "url": "http://arxiv.org/abs/2602.13103v1",
      "published_time_eastern_timestamp": 1771002462.0
    },
    {
      "title": "Curriculum-DPO++: Direct Preference Optimization via Data and Model Curricula for Text-to-Image Generation",
      "summary": "Direct Preference Optimization (DPO) has been proposed as an effective and efficient alternative to reinforcement learning from human feedback (RLHF). However, neither RLHF nor DPO take into account the fact that learning certain preferences is more difficult than learning other preferences, rendering the optimization process suboptimal. To address this gap in text-to-image generation, we recently proposed Curriculum-DPO, a method that organizes image pairs by difficulty. In this paper, we introduce Curriculum-DPO++, an enhanced method that combines the original data-level curriculum with a novel model-level curriculum. More precisely, we propose to dynamically increase the learning capacity of the denoising network as training advances. We implement this capacity increase via two mechanisms. First, we initialize the model with only a subset of the trainable layers used in the original Curriculum-DPO. As training progresses, we sequentially unfreeze layers until the configuration matches the full baseline architecture. Second, as the fine-tuning is based on Low-Rank Adaptation (LoRA), we implement a progressive schedule for the dimension of the low-rank matrices. Instead of maintaining a fixed capacity, we initialize the low-rank matrices with a dimension significantly smaller than that of the baseline. As training proceeds, we incrementally increase their rank, allowing the capacity to grow until it converges to the same rank value as in Curriculum-DPO. Furthermore, we propose an alternative ranking strategy to the one employed by Curriculum-DPO. Finally, we compare Curriculum-DPO++ against Curriculum-DPO and other state-of-the-art preference optimization approaches on nine benchmarks, outperforming the competing methods in terms of text alignment, aesthetics and human preference. Our code is available at https://github.com/CroitoruAlin/Curriculum-DPO.",
      "url": "http://arxiv.org/abs/2602.13055v1",
      "published_time_eastern_timestamp": 1770998971.0
    },
    {
      "title": "FedHENet: A Frugal Federated Learning Framework for Heterogeneous Environments",
      "summary": "Federated Learning (FL) enables collaborative training without centralizing data, essential for privacy compliance in real-world scenarios involving sensitive visual information. Most FL approaches rely on expensive, iterative deep network optimization, which still risks privacy via shared gradients. In this work, we propose FedHENet, extending the FedHEONN framework to image classification. By using a fixed, pre-trained feature extractor and learning only a single output layer, we avoid costly local fine-tuning. This layer is learned by analytically aggregating client knowledge in a single round of communication using homomorphic encryption (HE). Experiments show that FedHENet achieves competitive accuracy compared to iterative FL baselines while demonstrating superior stability performance and up to 70\\% better energy efficiency. Crucially, our method is hyperparameter-free, removing the carbon footprint associated with hyperparameter tuning in standard FL. Code available in https://github.com/AlejandroDopico2/FedHENet/",
      "url": "http://arxiv.org/abs/2602.13024v1",
      "published_time_eastern_timestamp": 1770996618.0
    },
    {
      "title": "DynaGuide: A Generalizable Dynamic Guidance Framework for Unsupervised Semantic Segmentation",
      "summary": "Unsupervised image segmentation is a critical task in computer vision. It enables dense scene understanding without human annotations, which is especially valuable in domains where labelled data is scarce. However, existing methods often struggle to reconcile global semantic structure with fine-grained boundary accuracy. This paper introduces DynaGuide, an adaptive segmentation framework that addresses these challenges through a novel dual-guidance strategy and dynamic loss optimization. Building on our previous work, DynaSeg, DynaGuide combines global pseudo-labels from zero-shot models such as DiffSeg or SegFormer with local boundary refinement using a lightweight CNN trained from scratch. This synergy allows the model to correct coarse or noisy global predictions and produce high-precision segmentations. At the heart of DynaGuide is a multi-component loss that dynamically balances feature similarity, Huber-smoothed spatial continuity, including diagonal relationships, and semantic alignment with the global pseudo-labels. Unlike prior approaches, DynaGuide trains entirely without ground-truth labels in the target domain and supports plug-and-play integration of diverse guidance sources. Extensive experiments on BSD500, PASCAL VOC2012, and COCO demonstrate that DynaGuide achieves state-of-the-art performance, improving mIoU by 17.5% on BSD500, 3.1% on PASCAL VOC2012, and 11.66% on COCO. With its modular design, strong generalization, and minimal computational footprint, DynaGuide offers a scalable and practical solution for unsupervised segmentation in real-world settings. Code available at: https://github.com/RyersonMultimediaLab/DynaGuide",
      "url": "http://arxiv.org/abs/2602.13020v1",
      "published_time_eastern_timestamp": 1770996334.0
    },
    {
      "title": "Multimodal Classification via Total Correlation Maximization",
      "summary": "Multimodal learning integrates data from diverse sensors to effectively harness information from different modalities. However, recent studies reveal that joint learning often overfits certain modalities while neglecting others, leading to performance inferior to that of unimodal learning. Although previous efforts have sought to balance modal contributions or combine joint and unimodal learning, thereby mitigating the degradation of weaker modalities with promising outcomes, few have examined the relationship between joint and unimodal learning from an information-theoretic perspective. In this paper, we theoretically analyze modality competition and propose a method for multimodal classification by maximizing the total correlation between multimodal features and labels. By maximizing this objective, our approach alleviates modality competition while capturing inter-modal interactions via feature alignment. Building on Mutual Information Neural Estimation (MINE), we introduce Total Correlation Neural Estimation (TCNE) to derive a lower bound for total correlation. Subsequently, we present TCMax, a hyperparameter-free loss function that maximizes total correlation through variational bound optimization. Extensive experiments demonstrate that TCMax outperforms state-of-the-art joint and unimodal learning approaches. Our code is available at https://github.com/hubaak/TCMax.",
      "url": "http://arxiv.org/abs/2602.13015v1",
      "published_time_eastern_timestamp": 1770996105.0
    },
    {
      "title": "MASAR: Motion-Appearance Synergy Refinement for Joint Detection and Trajectory Forecasting",
      "summary": "Classical autonomous driving systems connect perception and prediction modules via hand-crafted bounding-box interfaces, limiting information flow and propagating errors to downstream tasks. Recent research aims to develop end-to-end models that jointly address perception and prediction; however, they often fail to fully exploit the synergy between appearance and motion cues, relying mainly on short-term visual features. We follow the idea of \"looking backward to look forward\", and propose MASAR, a novel fully differentiable framework for joint 3D detection and trajectory forecasting compatible with any transformer-based 3D detector. MASAR employs an object-centric spatio-temporal mechanism that jointly encodes appearance and motion features. By predicting past trajectories and refining them using guidance from appearance cues, MASAR captures long-term temporal dependencies that enhance future trajectory forecasting. Experiments conducted on the nuScenes dataset demonstrate MASAR's effectiveness, showing improvements of over 20% in minADE and minFDE while maintaining robust detection performance. Code and models are available at https://github.com/aminmed/MASAR.",
      "url": "http://arxiv.org/abs/2602.13003v1",
      "published_time_eastern_timestamp": 1770995510.0
    },
    {
      "title": "Stratified Sampling for Model-Assisted Estimation with Surrogate Outcomes",
      "summary": "In many randomized trials, outcomes such as essays or open-ended responses must be manually scored as a preliminary step to impact analysis, a process that is costly and limiting. Model-assisted estimation offers a way to combine surrogate outcomes generated by machine learning or large language models with a human-coded subset, yet typical implementations use simple random sampling and therefore overlook systematic variation in surrogate prediction error. We extend this framework by incorporating stratified sampling to more efficiently allocate human coding effort. We derive the exact variance of the stratified model-assisted estimator, characterize conditions under which stratification improves precision, and identify a Neyman-type optimal allocation rule that oversamples strata with larger residual variance. We evaluate our methods through a comprehensive simulation study to assess finite-sample performance. Overall, we find stratification consistently improves efficiency when surrogate prediction errors exhibit structured bias or heteroskedasticity. We also present two empirical applications, one using data from an education RCT and one using a large observational corpus, to illustrate how these methods can be implemented in practice using ChatGPT-generated surrogate outcomes. Overall, this framework provides a practical design-based approach for leveraging surrogate outcomes and strategically allocating human coding effort to obtain unbiased estimates with greater efficiency. While motivated by text-as-data applications, the methodology applies broadly to any setting where outcome measurement is costly or prohibitive, and can be applied to comparisons across groups or estimating the mean of a single group.",
      "url": "http://arxiv.org/abs/2602.12992v1",
      "published_time_eastern_timestamp": 1770994876.0
    },
    {
      "title": "Evaluating the Homogeneity of Keyphrase Prediction Models",
      "summary": "Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a document's text called `absent keyphrases`. This ability means that keyphrase generation models can associate a document to a notion that is not explicitly mentioned in its text. Intuitively, this suggests that for two documents treating the same subjects, a keyphrase generation model is more likely to be homogeneous in their indexing i.e. predict the same keyphrase for both documents, regardless of those keyphrases appearing in their respective text or not; something a keyphrase extraction model would fail to do. Yet, homogeneity of keyphrase prediction models is not covered by current benchmarks. In this work, we introduce a method to evaluate the homogeneity of keyphrase prediction models and study if absent keyphrase generation capabilities actually help the model to be more homogeneous. To our surprise, we show that keyphrase extraction methods are competitive with generative models, and that the ability to generate absent keyphrases can actually have a negative impact on homogeneity. Our data, code and prompts are available on huggingface and github.",
      "url": "http://arxiv.org/abs/2602.12989v1",
      "published_time_eastern_timestamp": 1770994835.0
    },
    {
      "title": "Represent Micro-Doppler Signature in Orders",
      "summary": "Non-line-of-sight sensing of human activities in complex environments is enabled by multiple-input multiple-output through-the-wall radar (TWR). However, the distinctiveness of micro-Doppler signature between similar indoor human activities such as gun carrying and normal walking is minimal, while the large scale of input images required for effective identification utilizing time-frequency spectrograms creates challenges for model training and inference efficiency. To address this issue, the Chebyshev-time map is proposed in this paper, which is a method characterizing micro-Doppler signature using polynomial orders. The parametric kinematic models for human motion and the TWR echo model are first established. Then, a time-frequency feature representation method based on orthogonal Chebyshev polynomial decomposition is proposed. The kinematic envelopes of the torso and limbs are extracted, and the time-frequency spectrum slices are mapped into a robust Chebyshev-time coefficient space, preserving the multi-order morphological detail information of time-frequency spectrum. Numerical simulations and experiments are conducted to verify the effectiveness of the proposed method, which demonstrates the capability to characterize armed and unarmed indoor human activities while effectively compressing the scale of the time-frequency spectrum to achieve a balance between recognition accuracy and input data dimensions. The open-source code of this paper can be found in: https://github.com/JoeyBGOfficial/Represent-Micro-Doppler-Signature-in-Orders.",
      "url": "http://arxiv.org/abs/2602.12985v1",
      "published_time_eastern_timestamp": 1770994721.0
    },
    {
      "title": "Meta-Monomorphizing Specializations",
      "summary": "Achieving zero-cost specialization remains a fundamental challenge in programming language and compiler design. It often necessitates trade-offs between expressive power and type system soundness, as the interaction between conditional compilation and static dispatch can easily lead to unforeseen coherence violations and increased complexity in the formal model. This paper introduces meta-monomorphizing specializations, a novel framework that achieves specialization by repurposing monomorphization through compile-time metaprogramming. Instead of modifying the host compiler, our approach generates meta-monomorphized traits and implementations that encode specialization constraints directly into the type structure, enabling deterministic, coherent dispatch without overlapping instances. We formalize this method for first-order, predicate-based, and higher-ranked polymorphic specialization, also in presence of lifetime parameters. Our evaluation, based on a Rust implementation using only existing macro facilities, demonstrates that meta-monomorphization enables expressive specialization patterns -- previously rejected by the compiler -- while maintaining full compatibility with standard optimization pipelines. We show that specialization can be realized as a disciplined metaprogramming layer, offering a practical, language-agnostic path to high-performance abstraction. A comprehensive study of public Rust codebases further validates our approach, revealing numerous workarounds that meta-monomorphization can eliminate, leading to more idiomatic and efficient code.",
      "url": "http://arxiv.org/abs/2602.12973v1",
      "published_time_eastern_timestamp": 1770994064.0
    },
    {
      "title": "Role of the radial electric field in the confinement of energetic ions in the Wendelstein 7-X stellarator",
      "summary": "Good fast-ion confinement is an essential requirement for a fusion reactor. The magnetic configuration of the Wendelstein 7-X (W7-X) stellarator is partially optimized in this regard in a reactor-relevant scenario: it is expected to show improved fast-ion confinement when $β$ is high and the effect of the radial electric field is negligible. The experimental validation of this optimization is difficult since, with the available power, achieving high $β$ under appropriate conditions for the validation is challenging and the effect of the radial electric field is inevitable. In this work, the confinement of fast ions in W7-X has been studied numerically for a variety of scenarios via the ASCOT5 code. The effect of the radial electric field on fast-ion losses is confirmed to be equivalent to the one produced by $β$, and this is characterized by means of scans on both parameters. Through a preliminary study with experimentally-based profiles, a viable scenario is identified that takes advantage of this effect for the experimental validation of the optimization strategy of W7-X.",
      "url": "http://arxiv.org/abs/2602.12969v1",
      "published_time_eastern_timestamp": 1770993781.0
    },
    {
      "title": "Training-Free Acceleration for Document Parsing Vision-Language Model with Hierarchical Speculative Decoding",
      "summary": "Document parsing is a fundamental task in multimodal understanding, supporting a wide range of downstream applications such as information extraction and intelligent document analysis. Benefiting from strong semantic modeling and robust generalization, VLM-based end-to-end approaches have emerged as the mainstream paradigm in recent years. However, these models often suffer from substantial inference latency, as they must auto-regressively generate long token sequences when processing long-form documents. In this work, motivated by the extremely long outputs and complex layout structures commonly found in document parsing, we propose a training-free and highly efficient acceleration method. Inspired by speculative decoding, we employ a lightweight document parsing pipeline as a draft model to predict batches of future tokens, while the more accurate VLM verifies these draft predictions in parallel. Moreover, we further exploit the layout-structured nature of documents by partitioning each page into independent regions, enabling parallel decoding of each region using the same draft-verify strategy. The final predictions are then assembled according to the natural reading order. Experimental results demonstrate the effectiveness of our approach: on the general-purpose OmniDocBench, our method provides a 2.42x lossless acceleration for the dots.ocr model, and achieves up to 4.89x acceleration on long-document parsing tasks. We will release our code to facilitate reproducibility and future research.",
      "url": "http://arxiv.org/abs/2602.12957v1",
      "published_time_eastern_timestamp": 1770992530.0
    }
  ]
}
{
  "last_updated": "2026-02-01T23:51:42.446892-05:00",
  "papers": [
    {
      "title": "Weight-four parity checks with silicon spin qubits",
      "summary": "Recent advances in coherent spin shuttling have made sparse semiconductor spin qubit arrays an appealing solid-state platform to realize quantum processors. The dynamic and long-range connectivity enabled by shuttling is also essential for many quantum error-correction (QEC) schemes. Here, we demonstrate a silicon spin-qubit device that comprises a shuttling bus for coherently transporting qubits that can interact at four isolated locations we call bus stops. We dynamically populate the array and tune all single- and two-qubit operations using shuttling and quantum non-demolition (QND) spin measurements, without access to charge sensing in most of the device. We achieve universal control of the effective five-qubit processor and select the connectivity required to form a surface-code stabilizer plaquette that supports X- and Z-type parity checks up to weight-four. We use the parity checks to generate multi-qubit entanglement between all qubit combinations in the array and report the genuine entanglement of a five-qubit Greenberger-Horne-Zeilinger (GHZ) state, constituting the largest such state ever constructed with gate-defined semiconductor spins. This work opens immediate opportunities to pursue QEC experiments with spin qubits, and the protocols developed here lay the groundwork for the modular calibration and operation of sparse spin qubit arrays.",
      "url": "http://arxiv.org/abs/2601.23267v1",
      "published_time_eastern_timestamp": 1769798067.0
    },
    {
      "title": "IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models",
      "summary": "This paper proposes a novel inverse reinforcement learning framework using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. Reinforcement learning (RL) is then performed with a hybrid reward that combines diffuse environmental feedback and targeted IRL rewards. A conditional diffusion model, which acts as a safety supervisor, plans safe paths. It stays in its lane, avoids obstacles, and moves smoothly. Then, a learnable adaptive mask (LAM) improves perception. It shifts visual attention based on vehicle speed and nearby hazards. After FSM-based imitation, the policy is fine-tuned with Proximal Policy Optimization (PPO). Training is run in the Webots simulator with a two-stage curriculum. A 96\\% success rate is reached, and collisions are reduced to 0.05 per 1k steps, marking a new benchmark for safe navigation. By applying the proposed approach, the agent not only drives in lane but also handles unsafe conditions at an expert level, increasing robustness.We make our code publicly available.",
      "url": "http://arxiv.org/abs/2601.23266v1",
      "published_time_eastern_timestamp": 1769798050.0
    },
    {
      "title": "GrepRAG: An Empirical Study and Optimization of Grep-Like Retrieval for Code Completion",
      "summary": "Repository-level code completion remains challenging for large language models (LLMs) due to cross-file dependencies and limited context windows. Prior work addresses this challenge using Retrieval-Augmented Generation (RAG) frameworks based on semantic indexing or structure-aware graph analysis, but these approaches incur substantial computational overhead for index construction and maintenance. Motivated by common developer workflows that rely on lightweight search utilities (e.g., ripgrep), we revisit a fundamental yet underexplored question: how far can simple, index-free lexical retrieval support repository-level code completion before more complex retrieval mechanisms become necessary? To answer this question, we systematically investigate lightweight, index-free, intent-aware lexical retrieval through extensive empirical analysis. We first introduce Naive GrepRAG, a baseline framework in which LLMs autonomously generate ripgrep commands to retrieve relevant context. Despite its simplicity, Naive GrepRAG achieves performance comparable to sophisticated graph-based baselines. Further analysis shows that its effectiveness stems from retrieving lexically precise code fragments that are spatially closer to the completion site. We also identify key limitations of lexical retrieval, including sensitivity to noisy matches from high-frequency ambiguous keywords and context fragmentation caused by rigid truncation boundaries. To address these issues, we propose GrepRAG, which augments lexical retrieval with a lightweight post-processing pipeline featuring identifier-weighted re-ranking and structure-aware deduplication. Extensive evaluation on CrossCodeEval and RepoEval-Updated demonstrates that GrepRAG consistently outperforms state-of-the-art (SOTA) methods, achieving 7.04-15.58 percent relative improvement in code exact match (EM) over the best baseline on CrossCodeEval.",
      "url": "http://arxiv.org/abs/2601.23254v1",
      "published_time_eastern_timestamp": 1769797335.0
    },
    {
      "title": "Physical origin of very-high-energy gamma rays from the low-luminosity active galactic nucleus NGC 4278 and implications for neutrino observations",
      "summary": "Relativistic jets in active galactic nuclei (AGNs) are known to accelerate particles to extreme energies, yet the physical origin of very-high-energy (VHE) emission from low-luminosity AGNs (LL AGNs) remains unclear. NGC 4278, a local LLAGN, has recently been identified as a VHE source following detections by LHAASO. In this study, we present a multi-wavelength and multi-messenger analysis to investigate the physical origin of this emission. Swift-XRT monitoring reveals a quasi-quiescent state characterized by a low X-ray flux. Modeling the broadband spectral energy distribution with the leptohadronic code AMES, we find that a standard one-zone synchrotron self-Compton (SSC) model underpredicts the VHE flux by $\\sim$70% due to the insufficient target photon density provided by the weak X-ray emission, unless a high Doppler factor ($δ\\gtrsim 5$) is invoked. Alternatively, an external inverse-Compton (EIC) scenario-scattering seed photons from a radiatively inefficient accretion flow (RIAF)-successfully reproduces the broadband spectral energy distribution with a modest jet power and Doppler factor. We further explore the neutrino production within a leptohadronic framework. The predicted muon neutrino event rate is highest in the EIC quiescent model, reaching $N_{ν_μ} \\sim 0.001$ for a 15-year IceCube observation (assuming 0.1% of the Eddington luminosity is partitioned into high-energy protons). Future multi-messenger observations are essential to unveil the details of the high-energy processes of NGC 4278.",
      "url": "http://arxiv.org/abs/2601.23242v1",
      "published_time_eastern_timestamp": 1769796770.0
    },
    {
      "title": "Are you going to finish that? A Practical Study of the Tokenization Boundary Problem",
      "summary": "Language models (LMs) are trained over sequences of tokens, whereas users interact with LMs via text. This mismatch gives rise to the partial token problem, which occurs when a user ends their prompt in the middle of the expected next-token, leading to distorted next-token predictions. Although this issue has been studied using arbitrary character prefixes, its prevalence and severity in realistic prompts respecting word boundaries remains underexplored. In this work, we identify three domains where token and \"word\" boundaries often do not line up: languages that do not use whitespace, highly compounding languages, and code. In Chinese, for example, up to 25% of word boundaries do not line up with token boundaries, making even natural, word-complete prompts susceptible to this problem. We systematically construct semantically natural prompts ending with a partial tokens; in experiments, we find that they comprise a serious failure mode: frontier LMs consistently place three orders of magnitude less probability on the correct continuation compared to when the prompt is \"backed-off\" to be token-aligned. This degradation does not diminish with scale and often worsens for larger models. Finally, we evaluate inference-time mitigations to the partial token problem and validate the effectiveness of recent exact solutions. Overall, we demonstrate the scale and severity of probability distortion caused by tokenization in realistic use cases, and provide practical recommentions for model inference providers.",
      "url": "http://arxiv.org/abs/2601.23223v1",
      "published_time_eastern_timestamp": 1769795236.0
    },
    {
      "title": "Secure Integrated Sensing and Communication against Communication and Sensing Eavesdropping",
      "summary": "Sensing privacy and communication confidentiality play fundamentally different but interconnected roles in adversarial wireless environments. Capturing this interplay within a single physical-layer framework is particularly challenging in integrated sensing and communication (ISAC) systems, where the same waveform simultaneously serves dual purposes. We study a secure ISAC system in which a monostatic transmitter simultaneously sends a confidential message to a legitimate receiver and senses an environmental state, while a passive adversary attempts both message decoding and state estimation. We partially characterize the fundamental trade-offs among three performance measures: the transmitter's secrecy rate, its detection exponent, and the adversary's detection exponent. Beyond the joint input distribution that governs overall performance, the trade-offs are further shaped by the transmitter's ability to extract keys via feedback and hide both the content and structure of the codewords via wiretap and resolvability codes. We derive an achievable region, and illustrate the resulting design trade-offs through a numerical example.",
      "url": "http://arxiv.org/abs/2601.23216v1",
      "published_time_eastern_timestamp": 1769795003.0
    },
    {
      "title": "Tackling air quality with SAPIENS",
      "summary": "Air pollution is a chronic problem in large cities worldwide and awareness is rising as the long-term health implications become clearer. Vehicular traffic has been identified as a major contributor to poor air quality. In a lot of cities the publicly available air quality measurements and forecasts are coarse-grained both in space and time. However, in general, real-time traffic intensity data is openly available in various forms and is fine-grained. In this paper, we present an in-depth study of pollution sensor measurements combined with traffic data from Mexico City. We analyse and model the relationship between traffic intensity and air quality with the aim to provide hyper-local, dynamic air quality forecasts. We developed an innovative method to represent traffic intensities by transforming simple colour-coded traffic maps into concentric ring-based descriptions, enabling improved characterisation of traffic conditions. Using Partial Least Squares Regression, we predict pollution levels based on these newly defined traffic intensities. The model was optimised with various training samples to achieve the best predictive performance and gain insights into the relationship between pollutants and traffic. The workflow we have designed is straightforward and adaptable to other contexts, like other cities beyond the specifics of our dataset.",
      "url": "http://arxiv.org/abs/2601.23215v1",
      "published_time_eastern_timestamp": 1769794898.0
    },
    {
      "title": "Disentangling multispecific antibody function with graph neural networks",
      "summary": "Multispecific antibodies offer transformative therapeutic potential by engaging multiple epitopes simultaneously, yet their efficacy is an emergent property governed by complex molecular architectures. Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of comprehensive experimental data. Here, we introduce a computational framework to address part of this gap. First, we present a generative method for creating large-scale, realistic synthetic functional landscapes that capture non-linear interactions where biological activity depends on domain connectivity. Second, we propose a graph neural network architecture that explicitly encodes these topological constraints, distinguishing between format configurations that appear identical to sequence-only models. We demonstrate that this model, trained on synthetic landscapes, recapitulates complex functional properties and, via transfer learning, has the potential to achieve high predictive accuracy on limited biological datasets. We showcase the model's utility by optimizing trade-offs between efficacy and toxicity in trispecific T-cell engagers and retrieving optimal common light chains. This work provides a robust benchmarking environment for disentangling the combinatorial complexity of multispecifics, accelerating the design of next-generation therapeutics.",
      "url": "http://arxiv.org/abs/2601.23212v1",
      "published_time_eastern_timestamp": 1769794579.0
    },
    {
      "title": "Large Language Models for Patent Classification: Strengths, Trade-offs, and the Long Tail Effect",
      "summary": "Patent classification into CPC codes underpins large scale analyses of technological change but remains challenging due to its hierarchical, multi label, and highly imbalanced structure. While pre Generative AI supervised encoder based models became the de facto standard for large scale patent classification, recent advances in large language models (LLMs) raise questions about whether they can provide complementary capabilities, particularly for rare or weakly represented technological categories. In this work, we perform a systematic comparison of encoder based classifiers (BERT, SciBERT, and PatentSBERTa) and open weight LLMs on a highly imbalanced benchmark dataset (USPTO 70k). We evaluate LLMs under zero shot, few shot, and retrieval augmented prompting, and further assess parameter efficient fine tuning of the best performing model. Our results show that encoder based models achieve higher aggregate performance, driven by strong results on frequent CPC subclasses, but struggle on rare ones. In contrast, LLMs achieve relatively higher performance on infrequent subclasses, often associated with early stage, cross domain, or weakly institutionalised technologies, particularly at higher hierarchical levels. These findings indicate that encoder based and LLM based approaches play complementary roles in patent classification. We additionally quantify inference time and energy consumption, showing that encoder based models are up to three orders of magnitude more efficient than LLMs. Overall, our results inform responsible patentometrics and technology mapping, and motivate hybrid classification approaches that combine encoder efficiency with the long tail coverage of LLMs under computational and environmental constraints.",
      "url": "http://arxiv.org/abs/2601.23200v1",
      "published_time_eastern_timestamp": 1769793791.0
    },
    {
      "title": "Sunspot simulations with MURaM -- I. Parameter study using potential field initial conditions",
      "summary": "Context. Existing sunspot simulations fail to reproduce the observed magnetic field distribution due to an artificially increased $B_{hor}$ at the upper boundary.\n  Aims. We explore alternative ways to better reproduce the magnetic and dynamic properties of observed sunspots.\n  Methods. We use the radiative MHD code MURaM. As initial conditions, we placed a potential magnetic field into small-scale dynamo simulations and used potential-field extrapolation at the top.\n  Results. We find that: (1) Simulations with increasing initial magnetic field strengths (20, 40, 80, and 160 kG) show larger spots, umbrae, and penumbrae. (2) The penumbral-to-spot sizes are smaller than those measured in observed sunspots. (3) In none of the runs are pure Evershed (radially outward) flows. Instead, bi-directional flows with inflows in the inner penumbra and outflows in the outer penumbra were measured, similar to early observations of penumbra formation for runs with $\\ge80$ kG at 96/32 km resolution, whereas runs with 40 kG or less showed pure inflows. (4) Simulations with 160 kG at 32/16 km resolution contain filaments with bi-directional and Evershed flows. (5) Simulations with fluxes $>10^{22}$ Mx show unrealistically strong fields in the umbra. (6) The best runs with 160 kG and $10^{22}$ Mx give realistic radial profiles of $B_z$ and $B_r$, although stronger fields than observed. (7) Increasing the width of the box and reducing the overall flux by subtracting a uniform opposing vertical field have little influence on internal spot dynamics and fields, but change the mean vertical field outside the spot.\n  Conclusions. Simulations of small ($10^{22}$) sunspots with an initial potential field and intensified bottom magnetic field strength best reproduce observations of the initial stages of sunspot formation. Numerical resolution may be critical for achieving fully developed penumbrae.",
      "url": "http://arxiv.org/abs/2601.23189v1",
      "published_time_eastern_timestamp": 1769793157.0
    },
    {
      "title": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
      "summary": "While Chain-of-Thought (CoT) significantly enhances the performance of Large Language Models (LLMs), explicit reasoning chains introduce substantial computational redundancy. Recent latent reasoning methods attempt to mitigate this by compressing reasoning processes into latent space, but often suffer from severe performance degradation due to the lack of appropriate compression guidance. In this study, we propose Rendered CoT-Guided variational Latent Reasoning (ReGuLaR), a simple yet novel latent learning paradigm resolving this issue. Fundamentally, we formulate latent reasoning within the Variational Auto-Encoding (VAE) framework, sampling the current latent reasoning state from the posterior distribution conditioned on previous ones. Specifically, when learning this variational latent reasoning model, we render explicit reasoning chains as images, from which we extract dense visual-semantic representations to regularize the posterior distribution, thereby achieving efficient compression with minimal information loss. Extensive experiments demonstrate that ReGuLaR significantly outperforms existing latent reasoning methods across both computational efficiency and reasoning effectiveness, and even surpasses CoT through multi-modal reasoning, providing a new and insightful solution to latent reasoning. Code: https://github.com/FanmengWang/ReGuLaR.",
      "url": "http://arxiv.org/abs/2601.23184v1",
      "published_time_eastern_timestamp": 1769792886.0
    },
    {
      "title": "DIFFA-2: A Practical Diffusion Large Language Model for General Audio Understanding",
      "summary": "Autoregressive (AR) large audio language models (LALMs) such as Qwen-2.5-Omni have achieved strong performance on audio understanding and interaction, but scaling them remains costly in data and computation, and strictly sequential decoding limits inference efficiency. Diffusion large language models (dLLMs) have recently been shown to make effective use of limited training data, and prior work on DIFFA indicates that replacing an AR backbone with a diffusion counterpart can substantially improve audio understanding under matched settings, albeit at a proof-of-concept scale without large-scale instruction tuning, preference alignment, or practical decoding schemes. We introduce DIFFA-2, a practical diffusion-based LALM for general audio understanding. DIFFA-2 upgrades the speech encoder, employs dual semantic and acoustic adapters, and is trained with a four-stage curriculum that combines semantic and acoustic alignment, large-scale supervised fine-tuning, and variance-reduced preference optimization, using only fully open-source corpora. Experiments on MMSU, MMAU, and MMAR show that DIFFA-2 consistently improves over DIFFA and is competitive to strong AR LALMs under practical training budgets, supporting diffusion-based modeling is a viable backbone for large-scale audio understanding. Our code is available at https://github.com/NKU-HLT/DIFFA.git.",
      "url": "http://arxiv.org/abs/2601.23161v1",
      "published_time_eastern_timestamp": 1769791463.0
    },
    {
      "title": "Behemoth: Benchmarking Unlearning in LLMs Using Fully Synthetic Data",
      "summary": "As artificial neural networks, and specifically large language models, have improved rapidly in capabilities and quality, they have increasingly been deployed in real-world applications, from customer service to Google search, despite the fact that they frequently make factually incorrect or undesirable statements. This trend has inspired practical and academic interest in model editing, that is, in adjusting the weights of the model to modify its likely outputs for queries relating to a specific fact or set of facts. This may be done either to amend a fact or set of facts, for instance, to fix a frequent error in the training data, or to suppress a fact or set of facts entirely, for instance, in case of dangerous knowledge. Multiple methods have been proposed to do such edits. However, at the same time, it has been shown that such model editing can be brittle and incomplete. Moreover the effectiveness of any model editing method necessarily depends on the data on which the model is trained, and, therefore, a good understanding of the interaction of the training data distribution and the way it is stored in the network is necessary and helpful to reliably perform model editing. However, working with large language models trained on real-world data does not allow us to understand this relationship or fully measure the effects of model editing. We therefore propose Behemoth, a fully synthetic data generation framework. To demonstrate the practical insights from the framework, we explore model editing in the context of simple tabular data, demonstrating surprising findings that, in some cases, echo real-world results, for instance, that in some cases restricting the update rank results in a more effective update. The code is available at https://github.com/IST-DASLab/behemoth.git.",
      "url": "http://arxiv.org/abs/2601.23153v1",
      "published_time_eastern_timestamp": 1769791182.0
    },
    {
      "title": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models",
      "summary": "Large reasoning models (LRMs) achieve remarkable performance by leveraging reinforcement learning (RL) on reasoning tasks to generate long chain-of-thought (CoT) reasoning. However, this over-optimization often prioritizes compliance, making models vulnerable to harmful prompts. To mitigate this safety degradation, recent approaches rely on external teacher distillation, yet this introduces a distributional discrepancy that degrades native reasoning. We propose ThinkSafe, a self-generated alignment framework that restores safety alignment without external teachers. Our key insight is that while compliance suppresses safety mechanisms, models often retain latent knowledge to identify harm. ThinkSafe unlocks this via lightweight refusal steering, guiding the model to generate in-distribution safety reasoning traces. Fine-tuning on these self-generated responses effectively realigns the model while minimizing distribution shift. Experiments on DeepSeek-R1-Distill and Qwen3 show ThinkSafe significantly improves safety while preserving reasoning proficiency. Notably, it achieves superior safety and comparable reasoning to GRPO, with significantly reduced computational cost. Code, models, and datasets are available at https://github.com/seanie12/ThinkSafe.git.",
      "url": "http://arxiv.org/abs/2601.23143v1",
      "published_time_eastern_timestamp": 1769790662.0
    },
    {
      "title": "Regularisation in neural networks: a survey and empirical analysis of approaches",
      "summary": "Despite huge successes on a wide range of tasks, neural networks are known to sometimes struggle to generalise to unseen data. Many approaches have been proposed over the years to promote the generalisation ability of neural networks, collectively known as regularisation techniques. These are used as common practice under the assumption that any regularisation added to the pipeline would result in a performance improvement. In this study, we investigate whether this assumption holds in practice. First, we provide a broad review of regularisation techniques, including modern theories such as double descent. We propose a taxonomy of methods under four broad categories, namely: (1) data-based strategies, (2) architecture strategies, (3) training strategies, and (4) loss function strategies. Notably, we highlight the contradictions and correspondences between the approaches in these broad classes. Further, we perform an empirical comparison of the various regularisation techniques on classification tasks for ten numerical and image datasets applied to the multi-layer perceptron and convolutional neural network architectures. Results show that the efficacy of regularisation is dataset-dependent. For example, the use of a regularisation term only improved performance on numeric datasets, whereas batch normalisation improved performance on image datasets only. Generalisation is crucial to machine learning; thus, understanding the effects of applying regularisation techniques, and considering the connections between them is essential to the appropriate use of these methods in practice.",
      "url": "http://arxiv.org/abs/2601.23131v1",
      "published_time_eastern_timestamp": 1769790131.0
    },
    {
      "title": "TopoLS: Lattice Surgery Compilation via Topological Program Transformations",
      "summary": "Fault-tolerant quantum computing with surface codes can be achieved by compiling logical circuits into lattice-surgery instructions. To minimize space-time volume, we present TopoLS, a topological compiler that combines ZX-diagram optimizations with Monte Carlo tree search guided by different operation placements and topology-aware circuit partitioning. Our approach enables scalable exploration of lattice surgery structures and consistently reduces resource overhead. Evaluations of various benchmark algorithms across multiple architectures show that TopoLS achieves an average 33% reduction in space-time volume over prior heuristic-based compilers, while maintaining linear compilation time scaling. Compared to the SAT-solver-based compiler, which provides optimal results only for small circuits before becoming intractable, TopoLS offers an effective and scalable solution for lattice-surgery compilation.",
      "url": "http://arxiv.org/abs/2601.23109v1",
      "published_time_eastern_timestamp": 1769788497.0
    },
    {
      "title": "Lossy Compression of Cellular Network KPIs",
      "summary": "Network Key Performance Indicators (KPIs) are a fundamental component of mobile cellular network monitoring and optimization. Their massive volume, resulting from fine-grained measurements collected across many cells over long time horizons, poses significant challenges for storage, transport, and large-scale analysis. In this letter, we show that common cellular KPIs can be efficiently compressed using standard lossy compression schemes based on prediction, quantization, and entropy coding, achieving substantial reductions in reporting overhead. Focusing on traffic volume KPIs, we first characterize their intrinsic compressibility through a rate-distortion analysis, showing that signal-to-noise ratios around 30 dB can be achieved using only 3-4 bits per sample, corresponding to an 8-10x reduction with respect to 32-bit floating-point representations. We then assess the impact of KPI compression on representative downstream analytics tasks. Our results show that aggregation across cells mitigates quantization errors and that prediction accuracy is unaffected beyond a moderate reporting rate. These findings indicate that KPI compression is feasible and transparent to network-level analytics in cellular systems.",
      "url": "http://arxiv.org/abs/2601.23105v1",
      "published_time_eastern_timestamp": 1769788266.0
    },
    {
      "title": "Vision-Language Controlled Deep Unfolding for Joint Medical Image Restoration and Segmentation",
      "summary": "We propose VL-DUN, a principled framework for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding. While standard pipelines treat these tasks in isolation, our core insight is that they are fundamentally synergistic: restoration provides clean anatomical structures to improve segmentation, while semantic priors regularize the restoration process. VL-DUN resolves the sub-optimality of sequential processing through two primary innovations. (1) We formulate AiOMIRS as a unified optimization problem, deriving an interpretable joint unfolding mechanism where restoration and segmentation are mathematically coupled for mutual refinement. (2) We introduce a frequency-aware Mamba mechanism to capture long-range dependencies for global segmentation while preserving the high-frequency textures necessary for restoration. This allows for efficient global context modeling with linear complexity, effectively mitigating the spectral bias of standard architectures. As a pioneering work in the AiOMIRS task, VL-DUN establishes a new state-of-the-art across multi-modal benchmarks, improving PSNR by 0.92 dB and the Dice coefficient by 9.76\\%. Our results demonstrate that joint collaborative learning offers a superior, more robust solution for complex clinical workflows compared to isolated task processing. The codes are provided in https://github.com/cipi666/VLDUN.",
      "url": "http://arxiv.org/abs/2601.23103v1",
      "published_time_eastern_timestamp": 1769788115.0
    },
    {
      "title": "Rethinking Transferable Adversarial Attacks on Point Clouds from a Compact Subspace Perspective",
      "summary": "Transferable adversarial attacks on point clouds remain challenging, as existing methods often rely on model-specific gradients or heuristics that limit generalization to unseen architectures. In this paper, we rethink adversarial transferability from a compact subspace perspective and propose CoSA, a transferable attack framework that operates within a shared low-dimensional semantic space. Specifically, each point cloud is represented as a compact combination of class-specific prototypes that capture shared semantic structure, while adversarial perturbations are optimized within a low-rank subspace to induce coherent and architecture-agnostic variations. This design suppresses model-dependent noise and constrains perturbations to semantically meaningful directions, thereby improving cross-model transferability without relying on surrogate-specific artifacts. Extensive experiments on multiple datasets and network architectures demonstrate that CoSA consistently outperforms state-of-the-art transferable attacks, while maintaining competitive imperceptibility and robustness under common defense strategies. Codes will be made public upon paper acceptance.",
      "url": "http://arxiv.org/abs/2601.23102v1",
      "published_time_eastern_timestamp": 1769788091.0
    },
    {
      "title": "Omni-fMRI: A Universal Atlas-Free fMRI Foundation Model",
      "summary": "Self-supervised fMRI foundation models have shown promising transfer performance, yet most rely on predefined region-level parcellations that discard fine-grained voxel information and introduce atlas-dependent biases. We propose Omni-fMRI, an atlas-free foundation model that operates directly on voxel-level signals. To enable scalable pretraining on 49,497 fMRI sessions across nine datasets, Omni-fMRI introduces a dynamic patching mechanism that substantially reduces computational cost while preserving informative spatial structure. To support reproducibility and fair comparison, we establish a comprehensive benchmark suite spanning 11 datasets and a diverse set of resting-state and task-based fMRI tasks. Experimental results demonstrate that Omni-fMRI consistently outperforms existing foundation models, providing a scalable and reproducible framework for atlas-free brain representation learning. Code and logs are available.",
      "url": "http://arxiv.org/abs/2601.23090v1",
      "published_time_eastern_timestamp": 1769787580.0
    }
  ]
}
{
  "last_updated": "2025-08-20T02:18:48.004663-04:00",
  "papers": [
    {
      "title": "Beyond Simple Edits: Composed Video Retrieval with Dense Modifications",
      "summary": "Composed video retrieval is a challenging task that strives to retrieve a\ntarget video based on a query video and a textual description detailing\nspecific modifications. Standard retrieval frameworks typically struggle to\nhandle the complexity of fine-grained compositional queries and variations in\ntemporal understanding limiting their retrieval ability in the fine-grained\nsetting. To address this issue, we introduce a novel dataset that captures both\nfine-grained and composed actions across diverse video segments, enabling more\ndetailed compositional changes in retrieved video content. The proposed\ndataset, named Dense-WebVid-CoVR, consists of 1.6 million samples with dense\nmodification text that is around seven times more than its existing\ncounterpart. We further develop a new model that integrates visual and textual\ninformation through Cross-Attention (CA) fusion using grounded text encoder,\nenabling precise alignment between dense query modifications and target videos.\nThe proposed model achieves state-of-the-art results surpassing existing\nmethods on all metrics. Notably, it achieves 71.3\\% Recall@1 in visual+text\nsetting and outperforms the state-of-the-art by 3.4\\%, highlighting its\nefficacy in terms of leveraging detailed video descriptions and dense\nmodification texts. Our proposed dataset, code, and model are available at\n:https://github.com/OmkarThawakar/BSE-CoVR",
      "url": "http://arxiv.org/abs/2508.14039v1",
      "published_time_eastern_timestamp": 1755626379.0
    },
    {
      "title": "Distilled-3DGS:Distilled 3D Gaussian Splatting",
      "summary": "3D Gaussian Splatting (3DGS) has exhibited remarkable efficacy in novel view\nsynthesis (NVS). However, it suffers from a significant drawback: achieving\nhigh-fidelity rendering typically necessitates a large number of 3D Gaussians,\nresulting in substantial memory consumption and storage requirements. To\naddress this challenge, we propose the first knowledge distillation framework\nfor 3DGS, featuring various teacher models, including vanilla 3DGS,\nnoise-augmented variants, and dropout-regularized versions. The outputs of\nthese teachers are aggregated to guide the optimization of a lightweight\nstudent model. To distill the hidden geometric structure, we propose a\nstructural similarity loss to boost the consistency of spatial geometric\ndistributions between the student and teacher model. Through comprehensive\nquantitative and qualitative evaluations across diverse datasets, the proposed\nDistilled-3DGS, a simple yet effective framework without bells and whistles,\nachieves promising rendering results in both rendering quality and storage\nefficiency compared to state-of-the-art methods. Project page:\nhttps://distilled3dgs.github.io . Code:\nhttps://github.com/lt-xiang/Distilled-3DGS .",
      "url": "http://arxiv.org/abs/2508.14037v1",
      "published_time_eastern_timestamp": 1755626366.0
    },
    {
      "title": "Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation",
      "summary": "Beyond simple text generation, Large Language Models (LLMs) have evolved into\nagentic systems capable of planning and interacting with external tools to\nsolve complex tasks. This evolution involves fine-tuning LLMs on agent-specific\ntasks to enhance their proficiency. However, safety concerns are frequently\noverlooked during this fine-tuning process. In this work, we show that aligned\nLLMs can become unintentionally misaligned, leading to a higher likelihood of\nexecuting harmful tasks and a reduced tendency to refuse them when fine-tuned\nto execute agentic tasks. To address these safety challenges, we propose Prefix\nINjection Guard (PING), a simple yet effective method that prepends\nautomatically generated natural language prefixes to agent responses, guiding\nthem to refuse harmful requests while preserving performance on benign tasks.\nSpecifically, we introduce an iterative approach that alternates between (1)\ngenerating candidate prefixes and (2) selecting those that optimize both task\nperformance and refusal behavior. Experimental results demonstrate that PING\nsignificantly enhances the safety of fine-tuned LLM agents without sacrificing\ntheir effectiveness. PING consistently outperforms existing prompting\napproaches across diverse benchmarks in both web navigation and code generation\ntasks. Our analysis of internal hidden states via linear probes reveals that\nprefix tokens are crucial for behavior modification, explaining the performance\ngains. WARNING: This paper contains contents that are unethical or offensive in\nnature.",
      "url": "http://arxiv.org/abs/2508.14031v1",
      "published_time_eastern_timestamp": 1755626015.0
    },
    {
      "title": "Backdooring Self-Supervised Contrastive Learning by Noisy Alignment",
      "summary": "Self-supervised contrastive learning (CL) effectively learns transferable\nrepresentations from unlabeled data containing images or image-text pairs but\nsuffers vulnerability to data poisoning backdoor attacks (DPCLs). An adversary\ncan inject poisoned images into pretraining datasets, causing compromised CL\nencoders to exhibit targeted misbehavior in downstream tasks. Existing DPCLs,\nhowever, achieve limited efficacy due to their dependence on fragile implicit\nco-occurrence between backdoor and target object and inadequate suppression of\ndiscriminative features in backdoored images. We propose Noisy Alignment (NA),\na DPCL method that explicitly suppresses noise components in poisoned images.\nInspired by powerful training-controllable CL attacks, we identify and extract\nthe critical objective of noisy alignment, adapting it effectively into\ndata-poisoning scenarios. Our method implements noisy alignment by\nstrategically manipulating contrastive learning's random cropping mechanism,\nformulating this process as an image layout optimization problem with\ntheoretically derived optimal parameters. The resulting method is simple yet\neffective, achieving state-of-the-art performance compared to existing DPCLs,\nwhile maintaining clean-data accuracy. Furthermore, Noisy Alignment\ndemonstrates robustness against common backdoor defenses. Codes can be found at\nhttps://github.com/jsrdcht/Noisy-Alignment.",
      "url": "http://arxiv.org/abs/2508.14015v1",
      "published_time_eastern_timestamp": 1755624343.0
    },
    {
      "title": "Efficient Knowledge Graph Unlearning with Zeroth-order Information",
      "summary": "Due to regulations like the Right to be Forgotten, there is growing demand\nfor removing training data and its influence from models. Since full retraining\nis costly, various machine unlearning methods have been proposed. In this\npaper, we firstly present an efficient knowledge graph (KG) unlearning\nalgorithm. We remark that KG unlearning is nontrivial due to the distinctive\nstructure of KG and the semantic relations between entities. Also, unlearning\nby estimating the influence of removed components incurs significant\ncomputational overhead when applied to large-scale knowledge graphs. To this\nend, we define an influence function for KG unlearning and propose to\napproximate the model's sensitivity without expensive computation of\nfirst-order and second-order derivatives for parameter updates. Specifically,\nwe use Taylor expansion to estimate the parameter changes caused by data\nremoval. Given that the first-order gradients and second-order derivatives\ndominate the computational load, we use the Fisher matrices and zeroth-order\noptimization to approximate the inverse-Hessian vector product without\nconstructing the computational graphs. Our experimental results demonstrate\nthat the proposed method outperforms other state-of-the-art graph unlearning\nbaselines significantly in terms of unlearning efficiency and unlearning\nquality. Our code is released at https://github.com/NKUShaw/ZOWFKGIF.",
      "url": "http://arxiv.org/abs/2508.14013v1",
      "published_time_eastern_timestamp": 1755624170.0
    },
    {
      "title": "Brace for impact: ECDLP challenges for quantum cryptanalysis",
      "summary": "Precise suites of benchmarks are required to assess the progress of early\nfault-tolerant quantum computers at economically impactful applications such as\ncryptanalysis. Appropriate challenges exist for factoring but those for\nelliptic curve cryptography are either too sparse or inadequate for standard\napplications of Shor's algorithm. We introduce a difficulty-graded suite of\nelliptic curve discrete logarithm (ECDLP) challenges that use Bitcoin's curve\n$y^{2}=x^{3}+7 \\pmod p$ while incrementally lowering the prime field from 256\ndown to 6 bits. For each bit-length, we provide the prime, the base point and\nan example public key. All challenges are generated by a deterministic,\nreproducible procedure. We calibrate classical cost against Pollard's rho\nrecords and quantum cost against resource estimation results for Shor's\nalgorithm. We compile Shor's ECDLP circuit to logical counts and map them to\nphysical resources for various parameters of the surface code, the repetition\ncat code and the LDPC cat codes. Under explicit and testable assumptions on\nphysical error rates, code distances, and non-Clifford supply, our scenarios\nplace the full 256-bit instance within a 2027--2033 window. The challenge\nladder thus offers a transparent ruler to track fault-tolerant progress on a\ncryptanalytic target of immediate relevance, and it motivates proactive\nmigration of digital assets to post-quantum signatures.",
      "url": "http://arxiv.org/abs/2508.14011v1",
      "published_time_eastern_timestamp": 1755623791.0
    },
    {
      "title": "Chunks as Arms: Multi-Armed Bandit-Guided Sampling for Long-Context LLM\n  Preference Optimization",
      "summary": "Long-context modeling is critical for a wide range of real-world tasks,\nincluding long-context question answering, summarization, and complex reasoning\ntasks. Recent studies have explored fine-tuning Large Language Models (LLMs)\nwith synthetic data to enhance their long-context capabilities. However, the\neffectiveness of such approaches is often limited by the low diversity and\nfactual inconsistencies in the generated data. To address these challenges, we\npropose LongMab-PO, a novel framework that leverages a Multi-Armed Bandit (MAB)\nrollout strategy to identify the most informative chunks from the given long\ncontext for sampling high-quality and diverse responses and constructing\npreference data pairs for Direct Preference Optimization (DPO) training.\nSpecifically, we treat context chunks as arms of MAB, select chunks based on\ntheir expected reward scores to input into LLMs to generate responses, and\niteratively update these scores based on reward feedback. This exploration and\nexploitation process enables the model to focus on the most relevant context\nsegments, thereby generating and collecting high-quality and diverse responses.\nFinally, we collect these generated responses from the rollout process and\napply the DPO method to further optimize the LLM. Experimental results show\nthat LongMab-PO significantly improves the diversity and quality of preference\ndata pairs, achieving state-of-the-art performance on long-context reasoning\nbenchmarks. All code and data will be released on\nhttps://github.com/NEUIR/LongMab-PO.",
      "url": "http://arxiv.org/abs/2508.13993v1",
      "published_time_eastern_timestamp": 1755621235.0
    },
    {
      "title": "MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic\n  Evaluation of Audio General Intelligence",
      "summary": "Audio comprehension-including speech, non-speech sounds, and music-is\nessential for achieving human-level intelligence. Consequently, AI agents must\ndemonstrate holistic audio understanding to qualify as generally intelligent.\nHowever, evaluating auditory intelligence comprehensively remains challenging.\nTo address this gap, we introduce MMAU-Pro, the most comprehensive and\nrigorously curated benchmark for assessing audio intelligence in AI systems.\nMMAU-Pro contains 5,305 instances, where each instance has one or more audios\npaired with human expert-generated question-answer pairs, spanning speech,\nsound, music, and their combinations. Unlike existing benchmarks, MMAU-Pro\nevaluates auditory intelligence across 49 unique skills and multiple complex\ndimensions, including long-form audio comprehension, spatial audio reasoning,\nmulti-audio understanding, among others. All questions are meticulously\ndesigned to require deliberate multi-hop reasoning, including both\nmultiple-choice and open-ended response formats. Importantly, audio data is\nsourced directly ``from the wild\" rather than from existing datasets with known\ndistributions. We evaluate 22 leading open-source and proprietary multimodal AI\nmodels, revealing significant limitations: even state-of-the-art models such as\nGemini 2.5 Flash and Audio Flamingo 3 achieve only 59.2% and 51.7% accuracy,\nrespectively, approaching random performance in multiple categories. Our\nextensive analysis highlights specific shortcomings and provides novel\ninsights, offering actionable perspectives for the community to enhance future\nAI systems' progression toward audio general intelligence. The benchmark and\ncode is available at https://sonalkum.github.io/mmau-pro.",
      "url": "http://arxiv.org/abs/2508.13992v1",
      "published_time_eastern_timestamp": 1755621229.0
    },
    {
      "title": "Democratizing News Recommenders: Modeling Multiple Perspectives for News\n  Candidate Generation with VQ-VAE",
      "summary": "Current News Recommender Systems based on past clicks are designed for\nengagement, but come at the cost of limiting diversity in the suggested\ncontent. While diversity-aware algorithms exist, they suffer from two major\nlimitations. First, they fail to account for normative diversity, which\nrequires fair access to a broad range of perspectives. Second, they typically\napply diversity late in the system's pipeline, after a lot of content has\nalready been filtered out. Both limitations confine their effectiveness and\nprevent them from promoting true normative diversity in news recommendations.\n  We propose Aspect-Aware Candidate Generation (A2CG) to address these\nlimitations. Our framework introduces diversity into the earliest pipeline\nstage and uses a configurable mechanism to align diversity with specific\ndemocratic goals. A2CG represents each news article using multiple aspects of\nperspectives (e.g., sentiment, political leaning, frame) and uses a Vector\nQuantized Variational Autoencoder (VQ-VAE) to create a discrete, multi-faceted\nrepresentation. A decoder-only model then learns user preferences over these\naspect codes. We then inject diversity directly by reversing the sign on some\nof the query vector's aspects during the candidate retrieval process, ensuring\na more diverse set of candidates.\n  Our method, evaluated on the MIND dataset, enables a flexible trade-off\nbetween personalization and diversity early in the recommendation pipeline. It\nalso generates more novel, diverse, and serendipitous candidates while\neffectively taking into account aspects that strengthen democratic values.\nThese empirical results make it a promising approach for downstream\ndemocratized news recommendation systems.",
      "url": "http://arxiv.org/abs/2508.13978v1",
      "published_time_eastern_timestamp": 1755620034.0
    },
    {
      "title": "ChronoLLM: Customizing Language Models for Physics-Based Simulation Code\n  Generation",
      "summary": "This contribution is concerned with the following issue: can pretrained large\nlanguage models (LLMs) be refined and customized to the point where they become\nvirtual assistants helping experts with the effective use of a simulation tool?\nIn this case study, the ``simulation tool'' considered is PyChrono, an open\nsource multi-physics dynamics engine for multibody systems. We present a\nframework for refining and customizing both open- and closed-source LLMs to\nharness the power of AI in generating scripts that perform PyChrono virtual\nexperiments. We refine and customize several classes of LLMs through a process\nthat leads to a quantifiable improvement in the quality of the generated\nPyChrono simulation scripts. These scripts can range from simple\nsingle-pendulum simulations to complex virtual experiments involving full\nvehicles on deformable terrain. While the generated scripts are rarely perfect,\nthey often serve as strong starting points for the user to modify and improve\non. Additionally, the LLM can answer specific API questions about the\nsimulator, or recommend modeling approaches. The framework discussed is general\nand can be applied to lower the entry barrier for simulation tools associated\nwith other application domains.",
      "url": "http://arxiv.org/abs/2508.13975v1",
      "published_time_eastern_timestamp": 1755619971.0
    },
    {
      "title": "RotBench: Evaluating Multimodal Large Language Models on Identifying\n  Image Rotation",
      "summary": "We investigate to what extent Multimodal Large Language Models (MLLMs) can\naccurately identify the orientation of input images rotated 0{\\deg}, 90{\\deg},\n180{\\deg}, and 270{\\deg}. This task demands robust visual reasoning\ncapabilities to detect rotational cues and contextualize spatial relationships\nwithin images, regardless of their orientation. To evaluate MLLMs on these\nabilities, we introduce RotBench -- a 350-image manually-filtered benchmark\ncomprising lifestyle, portrait, and landscape images. Despite the relatively\nsimple nature of this task, we show that several state-of-the-art open and\nproprietary MLLMs, including GPT-5, o3, and Gemini-2.5-Pro, do not reliably\nidentify rotation in input images. Providing models with auxiliary information\n-- including captions, depth maps, and more -- or using chain-of-thought\nprompting offers only small and inconsistent improvements. Our results indicate\nthat most models are able to reliably identify right-side-up (0{\\deg}) images,\nwhile certain models are able to identify upside-down (180{\\deg}) images. None\ncan reliably distinguish between 90{\\deg} and 270{\\deg}. Simultaneously showing\nthe image rotated in different orientations leads to moderate performance gains\nfor reasoning models, while a modified setup using voting improves the\nperformance of weaker models. We further show that fine-tuning does not improve\nmodels' ability to distinguish 90{\\deg} and 270{\\deg} rotations, despite\nsubstantially improving the identification of 180{\\deg} images. Together, these\nresults reveal a significant gap between MLLMs' spatial reasoning capabilities\nand human perception in identifying rotation.",
      "url": "http://arxiv.org/abs/2508.13968v1",
      "published_time_eastern_timestamp": 1755619105.0
    },
    {
      "title": "Programmable Anyon Mobility through Higher Order Cellular Automata",
      "summary": "Controlling anyon mobility is critical for robust quantum memory and\nunderstanding symmetry-enriched topological (SET) phases with subsystem\nsymmetries (e.g., line-like, fractal, chaotic, or mixed supports). However, a\nunified framework for anyon mobility in SET phases with such diverse geometric\npatterns of symmetry supports has remained a major challenge. In this Letter,\nby introducing higher-order cellular automata (HOCA) -- a powerful computer\nscience tool -- to SET physics, we establish a unified approach for complete\ncharacterization of anyon mobility induced by the complexity of subsystem\nsymmetries. First, we design finite-depth HOCA-controlled unitary quantum\ncircuits, yielding exactly solvable SET models with Abelian anyons and all\npossible locally generated subsystem symmetries. Then, we present a theorem\nthat precisely programs all excitation mobilities (fractons, lineons, or fully\nmobile anyons) directly from the HOCA rule, representing the first complete\ncharacterization of anyon mobility in SET phases. As a corollary, this theorem\nyields symmetry-enriched fusion rules which govern mobility transmutation\nduring fusion. Fusion rules with multiple channels are identified, exhibiting\nnon-Abelian characteristics in Abelian anyon systems. Leveraging HOCA, this\nLetter opens new avenues for characterization of SET phases of matter and\nprogrammability of topological quantum codes.",
      "url": "http://arxiv.org/abs/2508.13961v1",
      "published_time_eastern_timestamp": 1755618825.0
    },
    {
      "title": "MME-SCI: A Comprehensive and Challenging Science Benchmark for\n  Multimodal Large Language Models",
      "summary": "Recently, multimodal large language models (MLLMs) have achieved significant\nadvancements across various domains, and corresponding evaluation benchmarks\nhave been continuously refined and improved. In this process, benchmarks in the\nscientific domain have played an important role in assessing the reasoning\ncapabilities of MLLMs. However, existing benchmarks still face three key\nchallenges: 1) Insufficient evaluation of models' reasoning abilities in\nmultilingual scenarios; 2) Inadequate assessment of MLLMs' comprehensive\nmodality coverage; 3) Lack of fine-grained annotation of scientific knowledge\npoints. To address these gaps, we propose MME-SCI, a comprehensive and\nchallenging benchmark. We carefully collected 1,019 high-quality\nquestion-answer pairs, which involve 3 distinct evaluation modes. These pairs\ncover four subjects, namely mathematics, physics, chemistry, and biology, and\nsupport five languages: Chinese, English, French, Spanish, and Japanese. We\nconducted extensive experiments on 16 open-source models and 4 closed-source\nmodels, and the results demonstrate that MME-SCI is widely challenging for\nexisting MLLMs. For instance, under the Image-only evaluation mode, o4-mini\nachieved accuracy of only 52.11%, 24.73%, 36.57%, and 29.80% in mathematics,\nphysics, chemistry, and biology, respectively, indicating a significantly\nhigher difficulty level compared to existing benchmarks. More importantly,\nusing MME-SCI's multilingual and fine-grained knowledge attributes, we analyzed\nexisting models' performance in depth and identified their weaknesses in\nspecific domains. The Data and Evaluation Code are available at\nhttps://github.com/JCruan519/MME-SCI.",
      "url": "http://arxiv.org/abs/2508.13938v1",
      "published_time_eastern_timestamp": 1755617275.0
    },
    {
      "title": "InPars+: Supercharging Synthetic Data Generation for Information\n  Retrieval Systems",
      "summary": "This work revisits and extends synthetic query generation pipelines for\nNeural Information Retrieval (NIR) by leveraging the InPars Toolkit, a\nreproducible, end-to-end framework for generating training data using large\nlanguage models (LLMs). We first assess the reproducibility of the original\nInPars, InPars-V2, and Promptagator pipelines on the SciFact benchmark and\nvalidate their effectiveness using open-source reranker and generator models.\nBuilding on this foundation, we introduce two key extensions to the pipeline:\n(1) fine-tuning a query generator LLM via Contrastive Preference Optimization\n(CPO) to improve the signal quality in generated queries, and (2) replacing\nstatic prompt templates with dynamic, Chain-of-Thought (CoT) optimized prompts\nusing the DSPy framework. Our results show that both extensions reduce the need\nfor aggressive filtering while improving retrieval performance. All code,\nmodels, and synthetic datasets are publicly released to support further\nresearch at: \\href{https://github.com/danilotpnta/IR2-project}{this https URL}.",
      "url": "http://arxiv.org/abs/2508.13930v1",
      "published_time_eastern_timestamp": 1755616998.0
    },
    {
      "title": "LLMind 2.0: Distributed IoT Automation with Natural Language M2M\n  Communication and Lightweight LLM Agents",
      "summary": "Recent advances in large language models (LLMs) have sparked interest in\ntheir application to IoT and automation systems, particularly for facilitating\ndevice management through natural language instructions. However, existing\ncentralized approaches face significant scalability challenges when managing\nand coordinating the collaboration between IoT devices of diverse capabilities\nin large-scale heterogeneous IoT systems. This paper introduces LLMind 2.0, a\ndistributed IoT automation framework that addresses the scalability challenges\nthrough lightweight LLM-empowered device agents via natural language-based\nmachine-to-machine (M2M) communication. Unlike previous LLM-controlled\nautomation systems that rely on a centralized coordinator to generate\ndevice-specific code to be executed on individual devices, LLMind 2.0\ndistributes intelligence across individual devices through lightweight LLMs\nembedded in IoT devices. The central coordinator translates human instructions\ninto simple subtasks described in natural human language, which are then\nprocessed by device-specific agents to generate device-specific code locally at\nthe associated devices. This approach transcends device heterogeneity barriers\nby using natural language as a unified communication medium, enabling seamless\ncollaboration between devices from different manufacturers. The system\nincorporates several key innovations: a Retrieval-Augmented Generation (RAG)\nmechanism for accurate subtask-to-API mapping, fine-tuned lightweight LLMs for\nreliable code generation, and a finite state machine-based task execution\nframework. Experimental validation in multi-robot warehouse scenarios and\nreal-world WiFi network deployments demonstrates significant improvements in\nscalability, reliability, and privacy protection compared to the centralized\napproach.",
      "url": "http://arxiv.org/abs/2508.13920v1",
      "published_time_eastern_timestamp": 1755616651.0
    },
    {
      "title": "Structured Agentic Workflows for Financial Time-Series Modeling with\n  LLMs and Reflective Feedback",
      "summary": "Time-series data is central to decision-making in financial markets, yet\nbuilding high-performing, interpretable, and auditable models remains a major\nchallenge. While Automated Machine Learning (AutoML) frameworks streamline\nmodel development, they often lack adaptability and responsiveness to\ndomain-specific needs and evolving objectives. Concurrently, Large Language\nModels (LLMs) have enabled agentic systems capable of reasoning, memory\nmanagement, and dynamic code generation, offering a path toward more flexible\nworkflow automation. In this paper, we introduce \\textsf{TS-Agent}, a modular\nagentic framework designed to automate and enhance time-series modeling\nworkflows for financial applications. The agent formalizes the pipeline as a\nstructured, iterative decision process across three stages: model selection,\ncode refinement, and fine-tuning, guided by contextual reasoning and\nexperimental feedback. Central to our architecture is a planner agent equipped\nwith structured knowledge banks, curated libraries of models and refinement\nstrategies, which guide exploration, while improving interpretability and\nreducing error propagation. \\textsf{TS-Agent} supports adaptive learning,\nrobust debugging, and transparent auditing, key requirements for high-stakes\nenvironments such as financial services. Empirical evaluations on diverse\nfinancial forecasting and synthetic data generation tasks demonstrate that\n\\textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic\nbaselines, achieving superior accuracy, robustness, and decision traceability.",
      "url": "http://arxiv.org/abs/2508.13915v1",
      "published_time_eastern_timestamp": 1755616489.0
    },
    {
      "title": "Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs\n  for Resilient Combined Sewer Overflow Management",
      "summary": "Extreme weather events, intensified by climate change, increasingly challenge\naging combined sewer systems, raising the risk of untreated wastewater\noverflow. Accurate forecasting of sewer overflow basin filling levels can\nprovide actionable insights for early intervention, helping mitigating\nuncontrolled discharge. In recent years, AI-based forecasting methods have\noffered scalable alternatives to traditional physics-based models, but their\nreliance on cloud computing limits their reliability during communication\noutages. To address this, we propose an end-to-end forecasting framework that\nenables energy-efficient inference directly on edge devices. Our solution\nintegrates lightweight Transformer and Long Short-Term Memory (LSTM) models,\ncompressed via integer-only quantization for efficient on-device execution.\nMoreover, an automated hardware-aware deployment pipeline is used to search for\noptimal model configurations by jointly minimizing prediction error and energy\nconsumption on an AMD Spartan-7 XC7S15 FPGA. Evaluated on real-world sewer\ndata, the selected 8-bit Transformer model, trained on 24 hours of historical\nmeasurements, achieves high accuracy (MSE 0.0376) at an energy cost of 0.370 mJ\nper inference. In contrast, the optimal 8-bit LSTM model requires significantly\nless energy (0.009 mJ, over 40x lower) but yields 14.89% worse accuracy (MSE\n0.0432) and much longer training time. This trade-off highlights the need to\nalign model selection with deployment priorities, favoring LSTM for ultra-low\nenergy consumption or Transformer for higher predictive accuracy. In general,\nour work enables local, energy-efficient forecasting, contributing to more\nresilient combined sewer systems. All code can be found in the GitHub\nRepository (https://github.com/tianheng-ling/EdgeOverflowForecast).",
      "url": "http://arxiv.org/abs/2508.13905v1",
      "published_time_eastern_timestamp": 1755615964.0
    },
    {
      "title": "In-hoc Concept Representations to Regularise Deep Learning in Medical\n  Imaging",
      "summary": "Deep learning models in medical imaging often achieve strong in-distribution\nperformance but struggle to generalise under distribution shifts, frequently\nrelying on spurious correlations instead of clinically meaningful features. We\nintroduce LCRReg, a novel regularisation approach that leverages Latent Concept\nRepresentations (LCRs) (e.g., Concept Activation Vectors (CAVs)) to guide\nmodels toward semantically grounded representations. LCRReg requires no concept\nlabels in the main training set and instead uses a small auxiliary dataset to\nsynthesise high-quality, disentangled concept examples. We extract LCRs for\npredefined relevant features, and incorporate a regularisation term that guides\na Convolutional Neural Network (CNN) to activate within latent subspaces\nassociated with those concepts. We evaluate LCRReg across synthetic and\nreal-world medical tasks. On a controlled toy dataset, it significantly\nimproves robustness to injected spurious correlations and remains effective\neven in multi-concept and multiclass settings. On the diabetic retinopathy\nbinary classification task, LCRReg enhances performance under both synthetic\nspurious perturbations and out-of-distribution (OOD) generalisation. Compared\nto baselines, including multitask learning, linear probing, and post-hoc\nconcept-based models, LCRReg offers a lightweight, architecture-agnostic\nstrategy for improving model robustness without requiring dense concept\nsupervision. Code is available at the following link:\nhttps://github.com/Trustworthy-AI-UU-NKI/lcr\\_regularization",
      "url": "http://arxiv.org/abs/2508.13880v1",
      "published_time_eastern_timestamp": 1755614610.0
    },
    {
      "title": "RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental\n  Learning in Object Detection",
      "summary": "Incremental Learning (IL) trains models sequentially on new data without full\nretraining, offering privacy, efficiency, and scalability. IL must balance\nadaptability to new data with retention of old knowledge. However, evaluations\noften rely on synthetic, simplified benchmarks, obscuring real-world IL\nperformance. To address this, we introduce two Realistic Incremental Object\nDetection Benchmarks (RICO): Domain RICO (D-RICO) features domain shifts with a\nfixed class set, and Expanding-Classes RICO (EC-RICO) integrates new domains\nand classes per IL step. Built from 14 diverse datasets covering real and\nsynthetic domains, varying conditions (e.g., weather, time of day), camera\nsensors, perspectives, and labeling policies, both benchmarks capture\nchallenges absent in existing evaluations. Our experiments show that all IL\nmethods underperform in adaptability and retention, while replaying a small\namount of previous data already outperforms all methods. However, individual\ntraining on the data remains superior. We heuristically attribute this gap to\nweak teachers in distillation, single models' inability to manage diverse\ntasks, and insufficient plasticity. Our code will be made publicly available.",
      "url": "http://arxiv.org/abs/2508.13878v1",
      "published_time_eastern_timestamp": 1755614539.0
    },
    {
      "title": "Improved Generalized Planning with LLMs through Strategy Refinement and\n  Reflection",
      "summary": "LLMs have recently been used to generate Python programs representing\ngeneralized plans in PDDL planning, i.e., plans that generalize across the\ntasks of a given PDDL domain. Previous work proposed a framework consisting of\nthree steps: the LLM first generates a summary and then a strategy for the\ndomain, both in natural language, and then implements that strategy as a Python\nprogram, that gets debugged on example planning tasks. In that work, only one\nstrategy is generated and passed directly to the program generation. If the\nstrategy is incorrect, its implementation will therefore result in an incorrect\ngeneralized plan. Here, we introduce an approach that generates the strategy in\nthe form of pseudocode and enables automatic debugging of the pseudocode, hence\nallowing us to identify and fix errors prior to the generation of the\ngeneralized plan itself. Additionally, we extend the Python debugging phase\nwith a reflection step prompting the LLM to pinpoint the reason for the\nobserved plan failure. Finally, we take inspiration from LLM code generation to\nproduce several program variants and pick the best one. Running experiments on\n17 benchmark domains, we show that these extensions substantially improve (and\nnever deteriorate) the quality of the generalized plans. In 12 of the domains,\nour best Python programs solve all tasks that can be generated with the\nrespective instance generator.",
      "url": "http://arxiv.org/abs/2508.13876v1",
      "published_time_eastern_timestamp": 1755614538.0
    }
  ]
}
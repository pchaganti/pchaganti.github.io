{
  "last_updated": "2025-11-08T07:20:54.438343-05:00",
  "papers": [
    {
      "title": "Tracking and Understanding Object Transformations",
      "summary": "Real-world objects frequently undergo state transformations. From an apple\nbeing cut into pieces to a butterfly emerging from its cocoon, tracking through\nthese changes is important for understanding real-world objects and dynamics.\nHowever, existing methods often lose track of the target object after\ntransformation, due to significant changes in object appearance. To address\nthis limitation, we introduce the task of Track Any State: tracking objects\nthrough transformations while detecting and describing state changes,\naccompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we\npresent TubeletGraph, a zero-shot system that recovers missing objects after\ntransformation and maps out how object states are evolving over time.\nTubeletGraph first identifies potentially overlooked tracks, and determines\nwhether they should be integrated based on semantic and proximity priors. Then,\nit reasons about the added tracks and generates a state graph describing each\nobserved transformation. TubeletGraph achieves state-of-the-art tracking\nperformance under transformations, while demonstrating deeper understanding of\nobject transformations and promising capabilities in temporal grounding and\nsemantic reasoning for complex object transformations. Code, additional\nresults, and the benchmark dataset are available at\nhttps://tubelet-graph.github.io.",
      "url": "http://arxiv.org/abs/2511.04678v1",
      "published_time_eastern_timestamp": 1762455570.0
    },
    {
      "title": "KGB-evolution: a relativistic $N$-body code for kinetic gravity braiding\n  models",
      "summary": "We present KGB-evolution, a relativistic $N$-body simulation code that\nextends the $k$-evolution code by incorporating an effective field theory\nparameterization of kinetic gravity braiding, while also including the\n$k$-essence model as a limiting case. As a first step, we implement the\nlinearized dark energy stress-energy tensor and scalar field equations,\nproviding the groundwork for a future full Horndeski theory extension. We\nvalidate KGB-evolution by comparing its power spectra against linear\npredictions from hi$\\_$class, finding excellent agreement on large scales at\nlow redshifts and over all scales at high redshifts. We demonstrate that\nnonlinear growth of matter and metric perturbations on small scales drives the\nlinearized dark energy field into a nonlinear clustering regime, which in turn\nfeeds back on the growth of cosmic structure. In contrast to the $k$-essence\nlimit, a nonzero braiding considerably amplifies this backreaction, producing a\nsignificantly stronger alteration of structure formation in the kinetic gravity\nbraiding model.",
      "url": "http://arxiv.org/abs/2511.04676v1",
      "published_time_eastern_timestamp": 1762455495.0
    },
    {
      "title": "InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual\n  Generation",
      "summary": "We introduce InfinityStar, a unified spacetime autoregressive framework for\nhigh-resolution image and dynamic video synthesis. Building on the recent\nsuccess of autoregressive modeling in both vision and language, our purely\ndiscrete approach jointly captures spatial and temporal dependencies within a\nsingle architecture. This unified design naturally supports a variety of\ngeneration tasks such as text-to-image, text-to-video, image-to-video, and long\ninteractive video synthesis via straightforward temporal autoregression.\nExtensive experiments demonstrate that InfinityStar scores 83.74 on VBench,\noutperforming all autoregressive models by large margins, even surpassing some\ndiffusion competitors like HunyuanVideo. Without extra optimizations, our model\ngenerates a 5s, 720p video approximately 10x faster than leading\ndiffusion-based methods. To our knowledge, InfinityStar is the first discrete\nautoregressive video generator capable of producing industrial level 720p\nvideos. We release all code and models to foster further research in efficient,\nhigh-quality video generation.",
      "url": "http://arxiv.org/abs/2511.04675v1",
      "published_time_eastern_timestamp": 1762455483.0
    },
    {
      "title": "On the Exoplanet Yield of Gaia Astrometry",
      "summary": "We re-examine the expected yield of Gaia astrometric planet detections using\nupdated models for giant-planet occurrence, the local stellar population, and\nGaia's demonstrated astrometric precision. Our analysis combines a\nsemi-analytic model that clarifies key scaling relations with more realistic\nMonte Carlo simulations. We predict $7{,}500 \\pm 2{,}100$ planet discoveries in\nthe 5-year dataset (DR4) and $120{,}000 \\pm 22{,}000$ over the full 10-year\nmission (DR5), with the dominant error arising from uncertainties in\ngiant-planet occurrence. We evaluate the sensitivity of these forecasts to the\ndetection threshold and the desired precision for measurements of planet masses\nand orbital parameters. Roughly $1{,}900 \\pm 540$ planets in DR4 and $38{,}000\n\\pm 7{,}300$ planets in DR5 should have masses and orbital periods determined\nto better than $20$%. Most detections will be super-Jupiters ($3$ - $13 M_{\\rm\nJ}$) on $2$ - $5$AU orbits around GKM-type stars ($0.4$ - $1.3 M_\\odot$) within\n$500$ pc. Unresolved binary stars will lead to spurious planet detections, but\nwe estimate that genuine planets will outnumber them by a factor of $5$ or\nmore. An exception is planets around M-dwarfs with $a < 1$AU, for which the\nfalse-positive rate is expected to be about $50$%. To support community\npreparation for upcoming data releases, we provide mock catalogs of Gaia\nexoplanets and planet-impostor binaries.",
      "url": "http://arxiv.org/abs/2511.04673v1",
      "published_time_eastern_timestamp": 1762455420.0
    },
    {
      "title": "Twist and higher modes of a complex scalar field at the threshold of\n  collapse",
      "summary": "We investigate the threshold of collapse of a massless complex scalar field\nin axisymmetric spacetimes under the ansatz of Choptuik et al. 2004, in which a\nsymmetry depending on the azimuthal parameter $m$ is imposed on the scalar\nfield. This allows for both non-vanishing twist and angular momentum. We extend\nearlier work to include higher angular modes. Using the pseudospectral code\nbamps with a new adapted symmetry reduction method, which we call $m$-cartoon,\nand a generalized twist-compatible apparent horizon finder, we evolve\nnear-critical initial data to the verge of black hole formation for the lowest\nnontrivial modes, $m=1$ and $m=2$. For $m=1$ we recover discrete\nself-similarity with echoing period $\\Delta\\simeq0.42$ and power-law scaling\nwith exponent $\\gamma\\simeq0.11$, consistent with earlier work. For $m=2$ we\nfind that universality is maintained within this nonzero fixed-$m$ symmetry\nclass but with smaller period and critical exponents, $\\Delta\\simeq0.09$ and\n$\\gamma\\simeq0.035$, establishing an explicit dependence of the critical\nsolution on the angular mode. Analysis of the relation between the angular\nmomentum and the mass of apparent horizons at the instant of formation,\n$J_{\\mathrm{AH}}{-}M_{\\mathrm{AH}}$, shows that the effect of angular momentum\nis minimal at the threshold, with\n$\\chi_{\\mathrm{AH}}=J_{\\mathrm{AH}}/M_{\\mathrm{AH}}^2\\to0$, and, therefore,\nexcludes extremal black holes for the families under consideration. Our results\ndemonstrate that while universality and DSS hold within each $m$-sector, the\ncritical universal values vary with $m$, and neither extremality nor\nbifurcation occur in the complex scalar field model within the families\nconsidered here.",
      "url": "http://arxiv.org/abs/2511.04649v1",
      "published_time_eastern_timestamp": 1762454402.0
    },
    {
      "title": "Random Construction of Quantum LDPC Codes",
      "summary": "We propose a method for modifying orthogonal sparse matrix pairs used in CSS\ncodes while preserving their matrix row and column weight distributions, which\nplay a crucial role in determining the performance of belief-propagation\ndecoding. Unlike simple row or column permutations that merely reorder existing\nelements, the proposed local modification introduces genuine structural\nrandomness through small $2\\times2$ cross-swap operations followed by\ninteger-linear-program-based local repairs that restore orthogonality. By\napplying this procedure repeatedly in a random manner, ensembles of randomized\nquantum LDPC codes can be constructed. The computational complexity of each\nrepair depends only on the maximum row and column weights and is independent of\nthe overall matrix size, ensuring scalability to large code blocks.",
      "url": "http://arxiv.org/abs/2511.04634v1",
      "published_time_eastern_timestamp": 1762453885.0
    },
    {
      "title": "Students' Acceptance of Arduino Technology Integration in Student-Led\n  Science Inquiry: Insights from the Technology Acceptance Model",
      "summary": "This study examines high school students' acceptance of Arduino technology in\na student-led, inquiry-based science class, using the extended Technology\nAcceptance Model (TAM2) as a guiding framework. Through qualitative analysis of\ninterviews and classroom observations, we explored how students perceived\nArduino's usefulness and ease of use. Going beyond traditional quantitative TAM\nstudies, this qualitative TAM research provides a nuanced, in-depth\nunderstanding of the contextual factors shaping technology acceptance. Key\nfindings reveal that acceptance was driven not only by instrumental factors\nlike job relevance and output quality but also by the unique sociocultural\ncontext of the Korean education system, where technology use was perceived as\nvaluable for university admissions (subjective norm and image). Critically,\nunlike earlier research that emphasized programming challenges, participants in\nthis study found Arduino accessible and intuitive, thanks to integrated visual\nblock-coding tools. These findings highlight the importance of both\ntechnological design and pedagogical support in shaping students' experiences.\nImplications for science curriculum design, teacher preparation, and equitable\ntechnology integration in secondary education are discussed.",
      "url": "http://arxiv.org/abs/2511.04614v1",
      "published_time_eastern_timestamp": 1762452435.0
    },
    {
      "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration\n  from a Baseline Paper",
      "summary": "Understanding the current capabilities and risks of AI Scientist systems is\nessential for ensuring trustworthy and sustainable AI-driven scientific\nprogress while preserving the integrity of the academic ecosystem. To this end,\nwe develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system\nthat mimics the core research workflow of a novice student researcher: Given\nthe baseline paper from the human mentor, it analyzes its limitations,\nformulates novel hypotheses for improvement, validates them through rigorous\nexperimentation, and writes a paper with the results. Unlike previous\napproaches that assume full automation or operate on small-scale code, Jr. AI\nScientist follows a well-defined research workflow and leverages modern coding\nagents to handle complex, multi-file implementations, leading to scientifically\nvaluable contributions. For evaluation, we conducted automated assessments\nusing AI Reviewers, author-led evaluations, and submissions to Agents4Science,\na venue dedicated to AI-driven scientific contributions. The findings\ndemonstrate that Jr. AI Scientist generates papers receiving higher review\nscores than existing fully automated systems. Nevertheless, we identify\nimportant limitations from both the author evaluation and the Agents4Science\nreviews, indicating the potential risks of directly applying current AI\nScientist systems and key challenges for future research. Finally, we\ncomprehensively report various risks identified during development. We hope\nthese insights will deepen understanding of current progress and risks in AI\nScientist development.",
      "url": "http://arxiv.org/abs/2511.04583v1",
      "published_time_eastern_timestamp": 1762450669.0
    },
    {
      "title": "Regular fat linear sets",
      "summary": "In this work, we introduce $(r,i)$-regular fat linear sets, which are defined\nas linear sets containing exactly $r$ points of weight $i$ and all other points\nof weight one. This notion generalizes and unifies existing constructions;\nscattered linear sets, clubs, and other previously studied families are special\ncases. We present new classes of regular fat linear sets in PG$(k-1,q^n)$ for\ncomposite $n$ and study their equivalence classes. Finally, we show that\nregular fat linear sets naturally yield three-weight rank-metric codes, which\nwe use to obtain bounds on their parameters.",
      "url": "http://arxiv.org/abs/2511.04581v1",
      "published_time_eastern_timestamp": 1762450630.0
    },
    {
      "title": "Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic\n  Alignment",
      "summary": "Vision-Language-Action (VLA) models have emerged as a powerful framework that\nunifies perception, language, and control, enabling robots to perform diverse\ntasks through multimodal understanding. However, current VLA models typically\ncontain massive parameters and rely heavily on large-scale robot data\npretraining, leading to high computational costs during training, as well as\nlimited deployability for real-time inference. Moreover, most training\nparadigms often degrade the perceptual representations of the vision-language\nbackbone, resulting in overfitting and poor generalization to downstream tasks.\nIn this work, we present Evo-1, a lightweight VLA model that reduces\ncomputation and improves deployment efficiency, while maintaining strong\nperformance without pretraining on robot data. Evo-1 builds on a native\nmultimodal Vision-Language model (VLM), incorporating a novel cross-modulated\ndiffusion transformer along with an optimized integration module, together\nforming an effective architecture. We further introduce a two-stage training\nparadigm that progressively aligns action with perception, preserving the\nrepresentations of the VLM. Notably, with only 0.77 billion parameters, Evo-1\nachieves state-of-the-art results on the Meta-World and RoboTwin suite,\nsurpassing the previous best models by 12.4% and 6.9%, respectively, and also\nattains a competitive result of 94.8% on LIBERO. In real-world evaluations,\nEvo-1 attains a 78% success rate with high inference frequency and low memory\noverhead, outperforming all baseline methods. We release code, data, and model\nweights to facilitate future research on lightweight and efficient VLA models.",
      "url": "http://arxiv.org/abs/2511.04555v1",
      "published_time_eastern_timestamp": 1762448869.0
    },
    {
      "title": "From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities\n  Reporting",
      "summary": "As the role of Large Language Models (LLM)-based coding assistants in\nsoftware development becomes more critical, so does the role of the bugs they\ngenerate in the overall cybersecurity landscape. While a number of LLM code\nsecurity benchmarks have been proposed alongside approaches to improve the\nsecurity of generated code, it remains unclear to what extent they have\nimpacted widely used coding LLMs. Here, we show that even the latest\nopen-weight models are vulnerable in the earliest reported vulnerability\nscenarios in a realistic use setting, suggesting that the safety-functionality\ntrade-off has until now prevented effective patching of vulnerabilities. To\nhelp address this issue, we introduce a new severity metric that reflects the\nrisk posed by an LLM-generated vulnerability, accounting for vulnerability\nseverity, generation chance, and the formulation of the prompt that induces\nvulnerable code generation - Prompt Exposure (PE). To encourage the mitigation\nof the most serious and prevalent vulnerabilities, we use PE to define the\nModel Exposure (ME) score, which indicates the severity and prevalence of\nvulnerabilities a model generates.",
      "url": "http://arxiv.org/abs/2511.04538v1",
      "published_time_eastern_timestamp": 1762447947.0
    },
    {
      "title": "SeismoStats: A Python Package for Statistical Seismology",
      "summary": "We introduce SeismoStats, a Python package that enables essential statistical\nseismology analyses, with a focus on well-established methods. The package\nprovides user-friendly tools to download and manipulate earthquake catalogs,\nbut also plotting functionalities to visualize them, as well as means to\nperform analyses such as estimating the a- and b-value of the Gutenberg-Richter\nlaw, or estimating the magnitude of completeness of any earthquake catalog.\nThis is the first well-tested, well-documented, and openly accessible Python\npackage with all these features. It is intended to serve as the nucleus of a\nlong-term community effort, continually expanding in functionality through\nshared contributions. We invite seismologists and developers to contribute\nideas and code to support and shape its future development.",
      "url": "http://arxiv.org/abs/2511.04521v1",
      "published_time_eastern_timestamp": 1762446857.0
    },
    {
      "title": "THEval. Evaluation Framework for Talking Head Video Generation",
      "summary": "Video generation has achieved remarkable progress, with generated videos\nincreasingly resembling real ones. However, the rapid advance in generation has\noutpaced the development of adequate evaluation metrics. Currently, the\nassessment of talking head generation primarily relies on limited metrics,\nevaluating general video quality, lip synchronization, and on conducting user\nstudies. Motivated by this, we propose a new evaluation framework comprising 8\nmetrics related to three dimensions (i) quality, (ii) naturalness, and (iii)\nsynchronization. In selecting the metrics, we place emphasis on efficiency, as\nwell as alignment with human preferences. Based on this considerations, we\nstreamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as\nwell as face quality. Our extensive experiments on 85,000 videos generated by\n17 state-of-the-art models suggest that while many algorithms excel in lip\nsynchronization, they face challenges with generating expressiveness and\nartifact-free details. These videos were generated based on a novel real\ndataset, that we have curated, in order to mitigate bias of training data. Our\nproposed benchmark framework is aimed at evaluating the improvement of\ngenerative methods. Original code, dataset and leaderboards will be publicly\nreleased and regularly updated with new methods, in order to reflect progress\nin the field.",
      "url": "http://arxiv.org/abs/2511.04520v1",
      "published_time_eastern_timestamp": 1762446850.0
    },
    {
      "title": "Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image\n  Classifiers",
      "summary": "The phenomenon of linear mode connectivity (LMC) links several aspects of\ndeep learning, including training stability under noisy stochastic gradients,\nthe smoothness and generalization of local minima (basins), the similarity and\nfunctional diversity of sampled models, and architectural effects on data\nprocessing. In this work, we experimentally study LMC under data shifts and\nidentify conditions that mitigate their impact. We interpret data shifts as an\nadditional source of stochastic gradient noise, which can be reduced through\nsmall learning rates and large batch sizes. These parameters influence whether\nmodels converge to the same local minimum or to regions of the loss landscape\nwith varying smoothness and generalization. Although models sampled via LMC\ntend to make similar errors more frequently than those converging to different\nbasins, the benefit of LMC lies in balancing training efficiency against the\ngains achieved from larger, more diverse ensembles. Code and supplementary\nmaterials will be made publicly available at https://github.com/DLR-KI/LMC in\ndue course.",
      "url": "http://arxiv.org/abs/2511.04514v1",
      "published_time_eastern_timestamp": 1762446656.0
    },
    {
      "title": "Decoding Emergent Big Five Traits in Large Language Models:\n  Temperature-Dependent Expression and Architectural Clustering",
      "summary": "As Large Language Models (LLMs) become integral to human-centered\napplications, understanding their personality-like behaviors is increasingly\nimportant for responsible development and deployment. This paper systematically\nevaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to\nassess trait expressions under varying sampling temperatures. We find\nsignificant differences across four of the five personality dimensions, with\nNeuroticism and Extraversion susceptible to temperature adjustments. Further,\nhierarchical clustering reveals distinct model clusters, suggesting that\narchitectural features may predispose certain models toward stable trait\nprofiles. Taken together, these results offer new insights into the emergence\nof personality-like patterns in LLMs and provide a new perspective on model\ntuning, selection, and the ethical governance of AI systems. We share the data\nand code for this analysis here:\nhttps://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1",
      "url": "http://arxiv.org/abs/2511.04499v1",
      "published_time_eastern_timestamp": 1762446052.0
    },
    {
      "title": "OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code\n  Generation",
      "summary": "This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task\n(Alva-Manchego et al., 2025), designed for readability-controlled text\nsimplification using LLM-prompting-based generation. Based on the analysis of\nprompt-based text simplification methods, we discovered an interesting finding\nthat text simplification performance is highly related to the gap between the\nsource CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by\nthis finding, we propose two multi-round simplification methods and generate\nthem via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based\nLLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams.\nLater improvements with MRS-Joint show that taking the LLM simplified\ncandidates as the starting point could further boost the multi-round\nsimplification performance.",
      "url": "http://arxiv.org/abs/2511.04495v1",
      "published_time_eastern_timestamp": 1762445792.0
    },
    {
      "title": "Scalable Domain-decomposed Monte Carlo Neutral Transport for Nuclear\n  Fusion",
      "summary": "EIRENE [1] is a Monte Carlo neutral transport solver heavily used in the\nfusion community. EIRENE does not implement domain decomposition, making it\nimpossible to use for simulations where the grid data does not fit on one\ncompute node (see e.g. [2]). This paper presents a domain-decomposed Monte\nCarlo (DDMC) algorithm implemented in a new open source Monte Carlo code,\nEiron. Two parallel algorithms currently used in EIRENE are also implemented in\nEiron, and the three algorithms are compared by running strong scaling tests,\nwith DDMC performing better than the other two algorithms in nearly all cases.\nOn the supercomputer Mahti [3], DDMC strong scaling is superlinear for grids\nthat do not fit into an L3 cache slice (4 MiB). The DDMC algorithm is also\nscaled up to 16384 cores in weak scaling tests, with a weak scaling efficiency\nof 45% in a high-collisional (heavier compute load) case, and 26% in a\nlow-collisional (lighter compute load) case. We conclude that implementing this\ndomain decomposition algorithm in EIRENE would improve performance and enable\nsimulations that are currently impossible due to memory constraints.",
      "url": "http://arxiv.org/abs/2511.04489v1",
      "published_time_eastern_timestamp": 1762445304.0
    },
    {
      "title": "EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed\n  Code Edits",
      "summary": "Instructed code editing, where LLMs directly modify a developer's existing\ncode based on a user instruction, is becoming a widely used interaction mode in\nAI coding assistants. However, few benchmarks directly evaluate this capability\nand current datasets often rely on artificial sources. We introduce EDIT-Bench,\na benchmark for evaluating LLM code editing capabilities grounded in real-world\nusage, i.e., user instructions and code contexts collected in the wild.\nEDIT-Bench comprises of 545 problems, multiple natural and programming\nlanguages, and a diverse set of real-world use cases, ranging from resolving\nerrors to adding features. EDIT-Bench introduces context-dependent problems\nthat require the model to understand code context, highlighted code, and cursor\nposition in addition to the user instruction. We evaluate 40 diverse LLMs and\nobserve that EDIT-Bench is a challenging set of problems where only 5 models\nscore over 60%. We find that model performance varies across different\ncategories of user instructions. Further, we find that varying levels of\ncontextual information greatly affect task success rate, with performance\nvarying up to 11%, indicating the importance of evaluating with realistic\ncontext.",
      "url": "http://arxiv.org/abs/2511.04486v1",
      "published_time_eastern_timestamp": 1762445128.0
    },
    {
      "title": "Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI\n  Tools",
      "summary": "Social news platforms have become key launch outlets for open-source\nprojects, especially Hacker News (HN), though quantifying their immediate\nimpact remains challenging. This paper presents a reproducible demonstration\nsystem that tracks how HN exposure translates into GitHub star growth for AI\nand LLM tools. Built entirely on public APIs, our pipeline analyzes 138\nrepository launches from 2024-2025 and reveals substantial launch effects:\nrepositories gain an average of 121 stars within 24 hours, 189 stars within 48\nhours, and 289 stars within a week of HN exposure. Through machine learning\nmodels (Elastic Net) and non-linear approaches (Gradient Boosting), we identify\nkey predictors of viral growth. Posting timing appears as key factor--launching\nat optimal hours can mean hundreds of additional stars--while the \"Show HN\" tag\nshows no statistical advantage after controlling for other factors. The\ndemonstration completes in under five minutes on standard hardware,\nautomatically collecting data, training models, and generating visualizations\nthrough single-file scripts. This makes our findings immediately reproducible\nand the framework easily be extended to other platforms, providing both\nresearchers and developers with actionable insights into launch dynamics.",
      "url": "http://arxiv.org/abs/2511.04453v1",
      "published_time_eastern_timestamp": 1762442630.0
    },
    {
      "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards",
      "summary": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly\ndesirable for adapting LLMs to become experts at specific tasks. But this\nsimplicity also makes it ill-specified as we seek to enhance RL training with\nricher, non-binary feedback. When using ordinal rewards to give partial credit,\nGRPO's simplicity starts to hurt, as its group-average baseline often assigns a\npositive advantage to failed trajectories and reinforces incorrect behavior.\n  We introduce Correctness Relative Policy Optimization (CoRPO), a new\nformulation that solves this flaw. CoRPO uses an adaptive baseline that\nenforces a minimum quality threshold, ensuring failed solutions are never\npositively reinforced. Once the policy consistently meets this threshold, the\nbaseline automatically transitions to a relative preference mode, pushing the\nmodel to find optimal solutions rather than just \"acceptable\" ones. We\nempirically validate CoRPO on a code verification task, where it demonstrates\nmore stable convergence and better out-of-domain generalization.\n  This work represents a critical step in our broader research program to\nenable LLMs to learn genuinely new capabilities through reinforcement learning.\nWe achieve this by enabling LLMs to learn from rich, multi-dimensional feedback\n- progressing from binary to ordinal rewards in this work, and onward to\ndenser, per-step supervision.",
      "url": "http://arxiv.org/abs/2511.04439v1",
      "published_time_eastern_timestamp": 1762441970.0
    }
  ]
}
{
  "last_updated": "2025-05-28T14:15:13.389913-04:00",
  "papers": [
    {
      "title": "AdInject: Real-World Black-Box Attacks on Web Agents via Advertising\n  Delivery",
      "summary": "Vision-Language Model (VLM) based Web Agents represent a significant step\ntowards automating complex tasks by simulating human-like interaction with\nwebsites. However, their deployment in uncontrolled web environments introduces\nsignificant security vulnerabilities. Existing research on adversarial\nenvironmental injection attacks often relies on unrealistic assumptions, such\nas direct HTML manipulation, knowledge of user intent, or access to agent model\nparameters, limiting their practical applicability. In this paper, we propose\nAdInject, a novel and real-world black-box attack method that leverages the\ninternet advertising delivery to inject malicious content into the Web Agent's\nenvironment. AdInject operates under a significantly more realistic threat\nmodel than prior work, assuming a black-box agent, static malicious content\nconstraints, and no specific knowledge of user intent. AdInject includes\nstrategies for designing malicious ad content aimed at misleading agents into\nclicking, and a VLM-based ad content optimization technique that infers\npotential user intents from the target website's context and integrates these\nintents into the ad content to make it appear more relevant or critical to the\nagent's task, thus enhancing attack effectiveness. Experimental evaluations\ndemonstrate the effectiveness of AdInject, attack success rates exceeding 60%\nin most scenarios and approaching 100% in certain cases. This strongly\ndemonstrates that prevalent advertising delivery constitutes a potent and\nreal-world vector for environment injection attacks against Web Agents. This\nwork highlights a critical vulnerability in Web Agent security arising from\nreal-world environment manipulation channels, underscoring the urgent need for\ndeveloping robust defense mechanisms against such threats. Our code is\navailable at https://github.com/NicerWang/AdInject.",
      "url": "http://arxiv.org/abs/2505.21499v1",
      "published_time_eastern_timestamp": 1748368745.0
    },
    {
      "title": "Paper2Poster: Towards Multimodal Poster Automation from Scientific\n  Papers",
      "summary": "Academic poster generation is a crucial yet challenging task in scientific\ncommunication, requiring the compression of long-context interleaved documents\ninto a single, visually coherent page. To address this challenge, we introduce\nthe first benchmark and metric suite for poster generation, which pairs recent\nconference papers with author-designed posters and evaluates outputs on\n(i)Visual Quality-semantic alignment with human posters, (ii)Textual\nCoherence-language fluency, (iii)Holistic Assessment-six fine-grained aesthetic\nand informational criteria scored by a VLM-as-judge, and notably\n(iv)PaperQuiz-the poster's ability to convey core paper content as measured by\nVLMs answering generated quizzes. Building on this benchmark, we propose\nPosterAgent, a top-down, visual-in-the-loop multi-agent pipeline: the (a)Parser\ndistills the paper into a structured asset library; the (b)Planner aligns\ntext-visual pairs into a binary-tree layout that preserves reading order and\nspatial balance; and the (c)Painter-Commenter loop refines each panel by\nexecuting rendering code and using VLM feedback to eliminate overflow and\nensure alignment. In our comprehensive evaluation, we find that GPT-4o\noutputs-though visually appealing at first glance-often exhibit noisy text and\npoor PaperQuiz scores, and we find that reader engagement is the primary\naesthetic bottleneck, as human-designed posters rely largely on visual\nsemantics to convey meaning. Our fully open-source variants (e.g. based on the\nQwen-2.5 series) outperform existing 4o-driven multi-agent systems across\nnearly all metrics, while using 87% fewer tokens. It transforms a 22-page paper\ninto a finalized yet editable .pptx poster - all for just $0.005. These\nfindings chart clear directions for the next generation of fully automated\nposter-generation models. The code and datasets are available at\nhttps://github.com/Paper2Poster/Paper2Poster.",
      "url": "http://arxiv.org/abs/2505.21497v1",
      "published_time_eastern_timestamp": 1748368729.0
    },
    {
      "title": "Adversarial Attacks against Closed-Source MLLMs via Feature Optimal\n  Alignment",
      "summary": "Multimodal large language models (MLLMs) remain vulnerable to transferable\nadversarial examples. While existing methods typically achieve targeted attacks\nby aligning global features-such as CLIP's [CLS] token-between adversarial and\ntarget samples, they often overlook the rich local information encoded in patch\ntokens. This leads to suboptimal alignment and limited transferability,\nparticularly for closed-source models. To address this limitation, we propose a\ntargeted transferable adversarial attack method based on feature optimal\nalignment, called FOA-Attack, to improve adversarial transfer capability.\nSpecifically, at the global level, we introduce a global feature loss based on\ncosine similarity to align the coarse-grained features of adversarial samples\nwith those of target samples. At the local level, given the rich local\nrepresentations within Transformers, we leverage clustering techniques to\nextract compact local patterns to alleviate redundant local features. We then\nformulate local feature alignment between adversarial and target samples as an\noptimal transport (OT) problem and propose a local clustering optimal transport\nloss to refine fine-grained feature alignment. Additionally, we propose a\ndynamic ensemble model weighting strategy to adaptively balance the influence\nof multiple models during adversarial example generation, thereby further\nimproving transferability. Extensive experiments across various models\ndemonstrate the superiority of the proposed method, outperforming\nstate-of-the-art methods, especially in transferring to closed-source MLLMs.\nThe code is released at https://github.com/jiaxiaojunQAQ/FOA-Attack.",
      "url": "http://arxiv.org/abs/2505.21494v1",
      "published_time_eastern_timestamp": 1748368617.0
    },
    {
      "title": "Reinforcing General Reasoning without Verifiers",
      "summary": "The recent paradigm shift towards training large language models (LLMs) using\nDeepSeek-R1-Zero-style reinforcement learning (RL) on verifiable rewards has\nled to impressive advancements in code and mathematical reasoning. However,\nthis methodology is limited to tasks where rule-based answer verification is\npossible and does not naturally extend to real-world domains such as chemistry,\nhealthcare, engineering, law, biology, business, and economics. Current\npractical workarounds use an additional LLM as a model-based verifier; however,\nthis introduces issues such as reliance on a strong verifier LLM,\nsusceptibility to reward hacking, and the practical burden of maintaining the\nverifier model in memory during training. To address this and extend\nDeepSeek-R1-Zero-style training to general reasoning domains, we propose a\nverifier-free method (VeriFree) that bypasses answer verification and instead\nuses RL to directly maximize the probability of generating the reference\nanswer. We compare VeriFree with verifier-based methods and demonstrate that,\nin addition to its significant practical benefits and reduced compute\nrequirements, VeriFree matches and even surpasses verifier-based methods on\nextensive evaluations across MMLU-Pro, GPQA, SuperGPQA, and math-related\nbenchmarks. Moreover, we provide insights into this method from multiple\nperspectives: as an elegant integration of training both the policy and\nimplicit verifier in a unified model, and as a variational optimization\napproach. Code is available at https://github.com/sail-sg/VeriFree.",
      "url": "http://arxiv.org/abs/2505.21493v1",
      "published_time_eastern_timestamp": 1748368587.0
    },
    {
      "title": "Are Language Models Consequentialist or Deontological Moral Reasoners?",
      "summary": "As AI systems increasingly navigate applications in healthcare, law, and\ngovernance, understanding how they handle ethically complex scenarios becomes\ncritical. Previous work has mainly examined the moral judgments in large\nlanguage models (LLMs), rather than their underlying moral reasoning process.\nIn contrast, we focus on a large-scale analysis of the moral reasoning traces\nprovided by LLMs. Furthermore, unlike prior work that attempted to draw\ninferences from only a handful of moral dilemmas, our study leverages over 600\ndistinct trolley problems as probes for revealing the reasoning patterns that\nemerge within different LLMs. We introduce and test a taxonomy of moral\nrationales to systematically classify reasoning traces according to two main\nnormative ethical theories: consequentialism and deontology. Our analysis\nreveals that LLM chains-of-thought tend to favor deontological principles based\non moral obligations, while post-hoc explanations shift notably toward\nconsequentialist rationales that emphasize utility. Our framework provides a\nfoundation for understanding how LLMs process and articulate ethical\nconsiderations, an important step toward safe and interpretable deployment of\nLLMs in high-stakes decision-making environments. Our code is available at\nhttps://github.com/keenansamway/moral-lens .",
      "url": "http://arxiv.org/abs/2505.21479v1",
      "published_time_eastern_timestamp": 1748368278.0
    },
    {
      "title": "Scaling External Knowledge Input Beyond Context Windows of LLMs via\n  Multi-Agent Collaboration",
      "summary": "With the rapid advancement of post-training techniques for reasoning and\ninformation seeking, large language models (LLMs) can incorporate a large\nquantity of retrieved knowledge to solve complex tasks. However, the limited\ncontext window of LLMs obstructs scaling the amount of external knowledge\ninput, prohibiting further improvement, especially for tasks requiring\nsignificant amount of external knowledge. Existing context window extension\nmethods inevitably cause information loss. LLM-based multi-agent methods emerge\nas a new paradigm to handle massive input in a distributional manner, where we\nidentify two core bottlenecks in existing knowledge synchronization and\nreasoning processes. In this work, we develop a multi-agent framework,\n$\\textbf{ExtAgents}$, to overcome the bottlenecks and enable better scalability\nin inference-time knowledge integration without longer-context training.\nBenchmarked with our enhanced multi-hop question answering test,\n$\\textbf{$\\boldsymbol{\\infty}$Bench+}$, and other public test sets including\nlong survey generation, ExtAgents significantly enhances the performance over\nexisting non-training methods with the same amount of external knowledge input,\nregardless of whether it falls $\\textit{within or exceeds the context window}$.\nMoreover, the method maintains high efficiency due to high parallelism. Further\nstudy in the coordination of LLM agents on increasing external knowledge input\ncould benefit real-world applications.",
      "url": "http://arxiv.org/abs/2505.21471v1",
      "published_time_eastern_timestamp": 1748367904.0
    },
    {
      "title": "ID-Align: RoPE-Conscious Position Remapping for Dynamic High-Resolution\n  Adaptation in Vision-Language Models",
      "summary": "Currently, a prevalent approach for enhancing Vision-Language Models (VLMs)\nperformance is to encode both the high-resolution version and the thumbnail of\nan image simultaneously. While effective, this method generates a large number\nof image tokens. When combined with the widely used Rotary Position Embedding\n(RoPE), its long-term decay property hinders the interaction between\nhigh-resolution tokens and thumbnail tokens, as well as between text and image.\nTo address these issues, we propose ID-Align, which alleviates these problems\nby reordering position IDs. In this method, high-resolution tokens inherit IDs\nfrom their corresponding thumbnail token while constraining the overexpansion\nof positional indices. Our experiments conducted within the LLaVA-Next\nframework demonstrate that ID-Align achieves significant improvements,\nincluding a 6.09% enhancement on MMBench's relation reasoning tasks and notable\ngains across multiple benchmarks. Our code is available at the following link:\nhttps://github.com/zooblastlbz/ID-Align.",
      "url": "http://arxiv.org/abs/2505.21465v1",
      "published_time_eastern_timestamp": 1748367383.0
    },
    {
      "title": "GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural\n  Code Generation",
      "summary": "With the widespread application of large language models in code generation,\nrecent studies demonstrate that employing additional Chain-of-Thought\ngeneration models can significantly enhance code generation performance by\nproviding explicit reasoning steps. However, as external components, CoT models\nare particularly vulnerable to backdoor attacks, which existing defense\nmechanisms often fail to detect effectively. To address this challenge, we\npropose GUARD, a novel dual-agent defense framework specifically designed to\ncounter CoT backdoor attacks in neural code generation. GUARD integrates two\ncore components: GUARD-Judge, which identifies suspicious CoT steps and\npotential triggers through comprehensive analysis, and GUARD-Repair, which\nemploys a retrieval-augmented generation approach to regenerate secure CoT\nsteps for identified anomalies. Experimental results show that GUARD\neffectively mitigates attacks while maintaining generation quality, advancing\nsecure code generation systems.",
      "url": "http://arxiv.org/abs/2505.21425v1",
      "published_time_eastern_timestamp": 1748364946.0
    },
    {
      "title": "RefTool: Enhancing Model Reasoning with Reference-Guided Tool Creation",
      "summary": "Tools enhance the reasoning capabilities of large language models (LLMs) in\ncomplex problem-solving tasks, but not all tasks have available tools. In the\nabsence of predefined tools, prior works have explored instructing LLMs to\ngenerate tools on their own. However, such approaches rely heavily on the\nmodels' internal knowledge and would fail in domains beyond the LLMs' knowledge\nscope. To address this limitation, we propose RefTool, a reference-guided\nframework for automatic tool creation that leverages structured external\nmaterials such as textbooks. RefTool consists of two modules: (1) tool\ncreation, where LLMs generate executable tools from reference content, validate\nthem using illustrative examples, and organize them hierarchically into a\ntoolbox; and (2) tool utilization, where LLMs navigate the toolbox structure to\nselect and apply the appropriate tools to solve problems. Experiments on\ncausality, physics, and chemistry benchmarks demonstrate that RefTool\noutperforms existing tool-creation and domain-specific reasoning methods by\n11.3% on average accuracy, while being cost-efficient and broadly\ngeneralizable. Analyses reveal that grounding tool creation in references\nproduces accurate and faithful tools, and that the hierarchical structure\nfacilitates effective tool selection. RefTool enables LLMs to overcome\nknowledge limitations, demonstrating the value of grounding tool creation in\nexternal references for enhanced and generalizable reasoning.",
      "url": "http://arxiv.org/abs/2505.21413v1",
      "published_time_eastern_timestamp": 1748364079.0
    },
    {
      "title": "DecisionFlow: Advancing Large Language Model as Principled Decision\n  Maker",
      "summary": "In high-stakes domains such as healthcare and finance, effective\ndecision-making demands not just accurate outcomes but transparent and\nexplainable reasoning. However, current language models often lack the\nstructured deliberation needed for such tasks, instead generating decisions and\njustifications in a disconnected, post-hoc manner. To address this, we propose\nDecisionFlow, a novel decision modeling framework that guides models to reason\nover structured representations of actions, attributes, and constraints. Rather\nthan predicting answers directly from prompts, DecisionFlow builds a\nsemantically grounded decision space and infers a latent utility function to\nevaluate trade-offs in a transparent, utility-driven manner. This process\nproduces decisions tightly coupled with interpretable rationales reflecting the\nmodel's reasoning. Empirical results on two high-stakes benchmarks show that\nDecisionFlow not only achieves up to 30% accuracy gains over strong prompting\nbaselines but also enhances alignment in outcomes. Our work is a critical step\ntoward integrating symbolic reasoning with LLMs, enabling more accountable,\nexplainable, and reliable LLM decision support systems. We release the data and\ncode at https://github.com/xiusic/DecisionFlow.",
      "url": "http://arxiv.org/abs/2505.21397v1",
      "published_time_eastern_timestamp": 1748363033.0
    },
    {
      "title": "Automatically Identify and Rectify: Robust Deep Contrastive Multi-view\n  Clustering in Noisy Scenarios",
      "summary": "Leveraging the powerful representation learning capabilities, deep multi-view\nclustering methods have demonstrated reliable performance by effectively\nintegrating multi-source information from diverse views in recent years. Most\nexisting methods rely on the assumption of clean views. However, noise is\npervasive in real-world scenarios, leading to a significant degradation in\nperformance. To tackle this problem, we propose a novel multi-view clustering\nframework for the automatic identification and rectification of noisy data,\ntermed AIRMVC. Specifically, we reformulate noisy identification as an anomaly\nidentification problem using GMM. We then design a hybrid rectification\nstrategy to mitigate the adverse effects of noisy data based on the\nidentification results. Furthermore, we introduce a noise-robust contrastive\nmechanism to generate reliable representations. Additionally, we provide a\ntheoretical proof demonstrating that these representations can discard noisy\ninformation, thereby improving the performance of downstream tasks. Extensive\nexperiments on six benchmark datasets demonstrate that AIRMVC outperforms\nstate-of-the-art algorithms in terms of robustness in noisy scenarios. The code\nof AIRMVC are available at https://github.com/xihongyang1999/AIRMVC on Github.",
      "url": "http://arxiv.org/abs/2505.21387v1",
      "published_time_eastern_timestamp": 1748362614.0
    },
    {
      "title": "ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding",
      "summary": "State Space models (SSMs) such as PointMamba enable efficient feature\nextraction for point cloud self-supervised learning with linear complexity,\noutperforming Transformers in computational efficiency. However, existing\nPointMamba-based methods depend on complex token ordering and random masking,\nwhich disrupt spatial continuity and local semantic correlations. We propose\nZigzagPointMamba to tackle these challenges. The core of our approach is a\nsimple zigzag scan path that globally sequences point cloud tokens, enhancing\nspatial continuity by preserving the proximity of spatially adjacent point\ntokens. Nevertheless, random masking undermines local semantic modeling in\nself-supervised learning. To address this, we introduce a Semantic-Siamese\nMasking Strategy (SMS), which masks semantically similar tokens to facilitate\nreconstruction by integrating local features of original and similar tokens.\nThis overcomes the dependence on isolated local features and enables robust\nglobal semantic modeling. Our pre-trained ZigzagPointMamba weights\nsignificantly improve downstream tasks, achieving a 1.59% mIoU gain on\nShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for\nclassification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for\nthe classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of\nScanObjectNN. The code is available at:\nhttps://anonymous.4open.science/r/ZigzagPointMamba-1800/",
      "url": "http://arxiv.org/abs/2505.21381v1",
      "published_time_eastern_timestamp": 1748362190.0
    },
    {
      "title": "PLANETALIGN: A Comprehensive Python Library for Benchmarking Network\n  Alignment",
      "summary": "Network alignment (NA) aims to identify node correspondence across different\nnetworks and serves as a critical cornerstone behind various downstream\nmulti-network learning tasks. Despite growing research in NA, there lacks a\ncomprehensive library that facilitates the systematic development and\nbenchmarking of NA methods. In this work, we introduce PLANETALIGN, a\ncomprehensive Python library for network alignment that features a rich\ncollection of built-in datasets, methods, and evaluation pipelines with\neasy-to-use APIs. Specifically, PLANETALIGN integrates 18 datasets and 14 NA\nmethods with extensible APIs for easy use and development of NA methods. Our\nstandardized evaluation pipeline encompasses a wide range of metrics, enabling\na systematic assessment of the effectiveness, scalability, and robustness of NA\nmethods. Through extensive comparative studies, we reveal practical insights\ninto the strengths and limitations of existing NA methods. We hope that\nPLANETALIGN can foster a deeper understanding of the NA problem and facilitate\nthe development and benchmarking of more effective, scalable, and robust\nmethods in the future. The source code of PLANETALIGN is available at\nhttps://github.com/yq-leo/PlanetAlign.",
      "url": "http://arxiv.org/abs/2505.21366v1",
      "published_time_eastern_timestamp": 1748361390.0
    },
    {
      "title": "Towards Interpretability Without Sacrifice: Faithful Dense Layer\n  Decomposition with Mixture of Decoders",
      "summary": "Multilayer perceptrons (MLPs) are an integral part of large language models,\nyet their dense representations render them difficult to understand, edit, and\nsteer. Recent methods learn interpretable approximations via neuron-level\nsparsity, yet fail to faithfully reconstruct the original\nmapping--significantly increasing model's next-token cross-entropy loss. In\nthis paper, we advocate for moving to layer-level sparsity to overcome the\naccuracy trade-off in sparse layer approximation. Under this paradigm, we\nintroduce Mixture of Decoders (MxDs). MxDs generalize MLPs and Gated Linear\nUnits, expanding pre-trained dense layers into tens of thousands of specialized\nsublayers. Through a flexible form of tensor factorization, each sparsely\nactivating MxD sublayer implements a linear transformation with full-rank\nweights--preserving the original decoders' expressive capacity even under heavy\nsparsity. Experimentally, we show that MxDs significantly outperform\nstate-of-the-art methods (e.g., Transcoders) on the sparsity-accuracy frontier\nin language models with up to 3B parameters. Further evaluations on sparse\nprobing and feature steering demonstrate that MxDs learn similarly specialized\nfeatures of natural language--opening up a promising new avenue for designing\ninterpretable yet faithful decompositions. Our code is included at:\nhttps://github.com/james-oldfield/MxD/.",
      "url": "http://arxiv.org/abs/2505.21364v1",
      "published_time_eastern_timestamp": 1748361355.0
    },
    {
      "title": "AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop\n  Mapping",
      "summary": "Accurate crop mapping fundamentally relies on modeling multi-scale\nspatiotemporal patterns, where spatial scales range from individual field\ntextures to landscape-level context, and temporal scales capture both\nshort-term phenological transitions and full growing-season dynamics.\nTransformer-based remote sensing foundation models (RSFMs) offer promising\npotential for crop mapping due to their innate ability for unified\nspatiotemporal processing. However, current RSFMs remain suboptimal for crop\nmapping: they either employ fixed spatiotemporal windows that ignore the\nmulti-scale nature of crop systems or completely disregard temporal information\nby focusing solely on spatial patterns. To bridge these gaps, we present\nAgriFM, a multi-source remote sensing foundation model specifically designed\nfor agricultural crop mapping. Our approach begins by establishing the\nnecessity of simultaneous hierarchical spatiotemporal feature extraction,\nleading to the development of a modified Video Swin Transformer architecture\nwhere temporal down-sampling is synchronized with spatial scaling operations.\nThis modified backbone enables efficient unified processing of long time-series\nsatellite inputs. AgriFM leverages temporally rich data streams from three\nsatellite sources including MODIS, Landsat-8/9 and Sentinel-2, and is\npre-trained on a global representative dataset comprising over 25 million image\nsamples supervised by land cover products. The resulting framework incorporates\na versatile decoder architecture that dynamically fuses these learned\nspatiotemporal representations, supporting diverse downstream tasks.\nComprehensive evaluations demonstrate AgriFM's superior performance over\nconventional deep learning approaches and state-of-the-art general-purpose\nRSFMs across all downstream tasks. Codes will be available at\nurlhttps://github.com/flyakon/AgriFM.",
      "url": "http://arxiv.org/abs/2505.21357v1",
      "published_time_eastern_timestamp": 1748361014.0
    },
    {
      "title": "PEDANTIC: A Dataset for the Automatic Examination of Definiteness in\n  Patent Claims",
      "summary": "Patent claims define the scope of protection for an invention. If there are\nambiguities in a claim, it is rejected by the patent office. In the US, this is\nreferred to as indefiniteness (35 U.S.C {\\S} 112(b)) and is among the most\nfrequent reasons for patent application rejection. The development of automatic\nmethods for patent definiteness examination has the potential to make patent\ndrafting and examination more efficient, but no annotated dataset has been\npublished to date.\n  We introduce PEDANTIC (\\underline{P}at\\underline{e}nt\n\\underline{D}efiniteness Ex\\underline{a}mi\\underline{n}a\\underline{ti}on\n\\underline{C}orpus), a novel dataset of 14k US patent claims from patent\napplications relating to Natural Language Processing (NLP), annotated with\nreasons for indefiniteness. We construct PEDANTIC using a fully automatic\npipeline that retrieves office action documents from the USPTO and uses Large\nLanguage Models (LLMs) to extract the reasons for indefiniteness. A human\nvalidation study confirms the pipeline's accuracy in generating high-quality\nannotations. To gain insight beyond binary classification metrics, we implement\nan LLM-as-Judge evaluation that compares the free-form reasoning of every\nmodel-cited reason with every examiner-cited reason. We show that LLM agents\nbased on Qwen 2.5 32B and 72B struggle to outperform logistic regression\nbaselines on definiteness prediction, even though they often correctly identify\nthe underlying reasons. PEDANTIC provides a valuable resource for patent AI\nresearchers, enabling the development of advanced examination models. We will\npublicly release the dataset and code.",
      "url": "http://arxiv.org/abs/2505.21342v1",
      "published_time_eastern_timestamp": 1748360079.0
    },
    {
      "title": "Beyond Chemical QA: Evaluating LLM's Chemical Reasoning with Modular\n  Chemical Operations",
      "summary": "While large language models (LLMs) with Chain-of-Thought (CoT) reasoning\nexcel in mathematics and coding, their potential for systematic reasoning in\nchemistry, a domain demanding rigorous structural analysis for real-world tasks\nlike drug design and reaction engineering, remains untapped. Current benchmarks\nfocus on simple knowledge retrieval, neglecting step-by-step reasoning required\nfor complex tasks such as molecular optimization and reaction prediction. To\naddress this, we introduce ChemCoTBench, a reasoning framework that bridges\nmolecular structure understanding with arithmetic-inspired operations,\nincluding addition, deletion, and substitution, to formalize chemical\nproblem-solving into transparent, step-by-step workflows. By treating molecular\ntransformations as modular \"chemical operations\", the framework enables\nslow-thinking reasoning, mirroring the logic of mathematical proofs while\ngrounding solutions in real-world chemical constraints. We evaluate models on\ntwo high-impact tasks: Molecular Property Optimization and Chemical Reaction\nPrediction. These tasks mirror real-world challenges while providing structured\nevaluability. By providing annotated datasets, a reasoning taxonomy, and\nbaseline evaluations, ChemCoTBench bridges the gap between abstract reasoning\nmethods and practical chemical discovery, establishing a foundation for\nadvancing LLMs as tools for AI-driven scientific innovation.",
      "url": "http://arxiv.org/abs/2505.21318v1",
      "published_time_eastern_timestamp": 1748358944.0
    },
    {
      "title": "Spectral Compression Transformer with Line Pose Graph for Monocular 3D\n  Human Pose Estimation",
      "summary": "Transformer-based 3D human pose estimation methods suffer from high\ncomputational costs due to the quadratic complexity of self-attention with\nrespect to sequence length. Additionally, pose sequences often contain\nsignificant redundancy between frames. However, recent methods typically fail\nto improve model capacity while effectively eliminating sequence redundancy. In\nthis work, we introduce the Spectral Compression Transformer (SCT) to reduce\nsequence length and accelerate computation. The SCT encoder treats hidden\nfeatures between blocks as Temporal Feature Signals (TFS) and applies the\nDiscrete Cosine Transform, a Fourier transform-based technique, to determine\nthe spectral components to be retained. By filtering out certain high-frequency\nnoise components, SCT compresses the sequence length and reduces redundancy. To\nfurther enrich the input sequence with prior structural information, we propose\nthe Line Pose Graph (LPG) based on line graph theory. The LPG generates\nskeletal position information that complements the input 2D joint positions,\nthereby improving the model's performance. Finally, we design a dual-stream\nnetwork architecture to effectively model spatial joint relationships and the\ncompressed motion trajectory within the pose sequence. Extensive experiments on\ntwo benchmark datasets (i.e., Human3.6M and MPI-INF-3DHP) demonstrate that our\nmodel achieves state-of-the-art performance with improved computational\nefficiency. For example, on the Human3.6M dataset, our method achieves an MPJPE\nof 37.7mm while maintaining a low computational cost. Furthermore, we perform\nablation studies on each module to assess its effectiveness. The code and\nmodels will be released.",
      "url": "http://arxiv.org/abs/2505.21309v1",
      "published_time_eastern_timestamp": 1748358483.0
    },
    {
      "title": "rStar-Coder: Scaling Competitive Code Reasoning with a Large-Scale\n  Verified Dataset",
      "summary": "Advancing code reasoning in large language models (LLMs) is fundamentally\nlimited by the scarcity of high-difficulty datasets, especially those with\nverifiable input-output test cases necessary for rigorous solution validation\nat scale. We introduce rStar-Coder, which significantly improves LLM code\nreasoning capabilities by constructing a large-scale, verified dataset of 418K\ncompetition-level code problems, 580K long-reasoning solutions along with rich\ntest cases of varying difficulty. This is achieved through three core\ncontributions: (1) we curate competitive programming code problems and oracle\nsolutions to synthesize new, solvable problems; (2) we introduce a reliable\ninput-output test case synthesis pipeline that decouples the generation into a\nthree-step input generation method and a mutual verification mechanism for\neffective output labeling; (3) we augment problems with high-quality,\ntest-case-verified long-reasoning solutions. Extensive experiments on Qwen\nmodels (1.5B-14B) across various code reasoning benchmarks demonstrate the\nsuperiority of rStar-Coder dataset, achieving leading performance comparable to\nfrontier reasoning LLMs with much smaller model sizes. On LiveCodeBench,\nrStar-Coder improves Qwen2.5-7B from 17.4% to an impressive 57.3%, and\nQwen2.5-14B from 23.3% to 62.5%, surpassing o3-mini (low) by3.1%. On the more\nchallenging USA Computing Olympiad, our 7B model achieves an average pass@1\naccuracy of 16.15%, outperforming the frontier-level QWQ-32B. Code and the\ndataset will be released at https://github.com/microsoft/rStar.",
      "url": "http://arxiv.org/abs/2505.21297v1",
      "published_time_eastern_timestamp": 1748358057.0
    },
    {
      "title": "RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with\n  Large Language Models",
      "summary": "Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existing\nsemantic-enhanced LJP models integrate judicial precedents and legal knowledge\nfor high performance. But they neglect legal reasoning logic, a critical\ncomponent of legal judgments requiring rigorous logical analysis. Although some\napproaches utilize legal reasoning logic for high-quality predictions, their\nlogic rigidity hinders adaptation to case-specific logical frameworks,\nparticularly in complex cases that are lengthy and detailed. This paper\nproposes a rule-enhanced legal judgment prediction framework based on\nfirst-order logic (FOL) formalism and comparative learning (CL) to develop an\nadaptive adjustment mechanism for legal judgment logic and further enhance\nperformance in LJP. Inspired by the process of human exam preparation, our\nmethod follows a three-stage approach: first, we initialize judgment rules\nusing the FOL formalism to capture complex reasoning logic accurately; next, we\npropose a Confusion-aware Contrastive Learning (CACL) to dynamically optimize\nthe judgment rules through a quiz consisting of confusable cases; finally, we\nutilize the optimized judgment rules to predict legal judgments. Experimental\nresults on two public datasets show superior performance across all metrics.\nThe code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}.",
      "url": "http://arxiv.org/abs/2505.21281v1",
      "published_time_eastern_timestamp": 1748357421.0
    }
  ]
}
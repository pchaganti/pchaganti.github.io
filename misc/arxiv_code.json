{
  "last_updated": "2025-09-21T23:34:14.267534-04:00",
  "papers": [
    {
      "title": "RPG: A Repository Planning Graph for Unified and Scalable Codebase\n  Generation",
      "summary": "Large language models excel at function- and file-level code generation, yet\ngenerating complete repositories from scratch remains a fundamental challenge.\nThis process demands coherent and reliable planning across proposal- and\nimplementation-level stages, while natural language, due to its ambiguity and\nverbosity, is ill-suited for faithfully representing complex software\nstructures. To address this, we introduce the Repository Planning Graph (RPG),\na persistent representation that unifies proposal- and implementation-level\nplanning by encoding capabilities, file structures, data flows, and functions\nin one graph. RPG replaces ambiguous natural language with an explicit\nblueprint, enabling long-horizon planning and scalable repository generation.\nBuilding on RPG, we develop ZeroRepo, a graph-driven framework for repository\ngeneration from scratch. It operates in three stages: proposal-level planning\nand implementation-level refinement to construct the graph, followed by\ngraph-guided code generation with test validation. To evaluate this setting, we\nconstruct RepoCraft, a benchmark of six real-world projects with 1,052 tasks.\nOn RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly\n3.9$\\times$ the strongest baseline (Claude Code) and about 64$\\times$ other\nbaselines. It attains 81.5% functional coverage and a 69.7% pass rate,\nexceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further\nanalysis shows that RPG models complex dependencies, enables progressively more\nsophisticated planning through near-linear scaling, and enhances LLM\nunderstanding of repositories, thereby accelerating agent localization.",
      "url": "http://arxiv.org/abs/2509.16198v1",
      "published_time_eastern_timestamp": 1758304694.0
    },
    {
      "title": "FocalCodec-Stream: Streaming Low-Bitrate Speech Coding via Causal\n  Distillation",
      "summary": "Neural audio codecs are a fundamental component of modern generative audio\npipelines. Although recent codecs achieve strong low-bitrate reconstruction and\nprovide powerful representations for downstream tasks, most are non-streamable,\nlimiting their use in real-time applications. We present FocalCodec-Stream, a\nhybrid codec based on focal modulation that compresses speech into a single\nbinary codebook at 0.55 - 0.80 kbps with a theoretical latency of 80 ms. Our\napproach combines multi-stage causal distillation of WavLM with targeted\narchitectural improvements, including a lightweight refiner module that\nenhances quality under latency constraints. Experiments show that\nFocalCodec-Stream outperforms existing streamable codecs at comparable\nbitrates, while preserving both semantic and acoustic information. The result\nis a favorable trade-off between reconstruction quality, downstream task\nperformance, latency, and efficiency. Code and checkpoints will be released at\nhttps://github.com/lucadellalib/focalcodec.",
      "url": "http://arxiv.org/abs/2509.16195v1",
      "published_time_eastern_timestamp": 1758304633.0
    },
    {
      "title": "CultureScope: A Dimensional Lens for Probing Cultural Understanding in\n  LLMs",
      "summary": "As large language models (LLMs) are increasingly deployed in diverse cultural\nenvironments, evaluating their cultural understanding capability has become\nessential for ensuring trustworthy and culturally aligned applications.\nHowever, most existing benchmarks lack comprehensiveness and are challenging to\nscale and adapt across different cultural contexts, because their frameworks\noften lack guidance from well-established cultural theories and tend to rely on\nexpert-driven manual annotations. To address these issues, we propose\nCultureScope, the most comprehensive evaluation framework to date for assessing\ncultural understanding in LLMs. Inspired by the cultural iceberg theory, we\ndesign a novel dimensional schema for cultural knowledge classification,\ncomprising 3 layers and 140 dimensions, which guides the automated construction\nof culture-specific knowledge bases and corresponding evaluation datasets for\nany given languages and cultures. Experimental results demonstrate that our\nmethod can effectively evaluate cultural understanding. They also reveal that\nexisting large language models lack comprehensive cultural competence, and\nmerely incorporating multilingual data does not necessarily enhance cultural\nunderstanding. All code and data files are available at\nhttps://github.com/HoganZinger/Culture",
      "url": "http://arxiv.org/abs/2509.16188v1",
      "published_time_eastern_timestamp": 1758304068.0
    },
    {
      "title": "MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code\n  Translation Validation and Repair",
      "summary": "Code translation transforms source code from one programming language (PL) to\nanother. Validating the functional equivalence of translation and repairing, if\nnecessary, are critical steps in code translation. Existing automated\nvalidation and repair approaches struggle to generalize to many PLs due to high\nengineering overhead, and they rely on existing and often inadequate test\nsuites, which results in false claims of equivalence and ineffective\ntranslation repair. We develop MatchFixAgent, a large language model\n(LLM)-based, PL-agnostic framework for equivalence validation and repair of\ntranslations. MatchFixAgent features a multi-agent architecture that divides\nequivalence validation into several sub-tasks to ensure thorough and consistent\nsemantic analysis of the translation. Then it feeds this analysis to test agent\nto write and execute tests. Upon observing a test failure, the repair agent\nattempts to fix the translation bug. The final (in)equivalence decision is made\nby the verdict agent, considering semantic analyses and test execution results.\n  We compare MatchFixAgent's validation and repair results with four\nrepository-level code translation techniques. We use 2,219 translation pairs\nfrom their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub\nprojects totaling over 900K lines of code. Our results demonstrate that\nMatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs,\nwith the same equivalence validation result as prior work on 72.8% of them.\nWhen MatchFixAgent's result disagrees with prior work, we find that 60.7% of\nthe time MatchFixAgent's result is actually correct. In addition, we show that\nMatchFixAgent can repair 50.6% of inequivalent translation, compared to prior\nwork's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to\nmany PL pairs than prior work, while producing highly accurate validation\nresults.",
      "url": "http://arxiv.org/abs/2509.16187v1",
      "published_time_eastern_timestamp": 1758303973.0
    },
    {
      "title": "UniMRSeg: Unified Modality-Relax Segmentation via Hierarchical\n  Self-Supervised Compensation",
      "summary": "Multi-modal image segmentation faces real-world deployment challenges from\nincomplete/corrupted modalities degrading performance. While existing methods\naddress training-inference modality gaps via specialized per-combination\nmodels, they introduce high deployment costs by requiring exhaustive model\nsubsets and model-modality matching. In this work, we propose a unified\nmodality-relax segmentation network (UniMRSeg) through hierarchical\nself-supervised compensation (HSSC). Our approach hierarchically bridges\nrepresentation gaps between complete and incomplete modalities across input,\nfeature and output levels. % First, we adopt modality reconstruction with the\nhybrid shuffled-masking augmentation, encouraging the model to learn the\nintrinsic modality characteristics and generate meaningful representations for\nmissing modalities through cross-modal fusion. % Next, modality-invariant\ncontrastive learning implicitly compensates the feature space distance among\nincomplete-complete modality pairs. Furthermore, the proposed lightweight\nreverse attention adapter explicitly compensates for the weak perceptual\nsemantics in the frozen encoder. Last, UniMRSeg is fine-tuned under the hybrid\nconsistency constraint to ensure stable prediction under all modality\ncombinations without large performance fluctuations. Without bells and\nwhistles, UniMRSeg significantly outperforms the state-of-the-art methods under\ndiverse missing modality scenarios on MRI-based brain tumor segmentation, RGB-D\nsemantic segmentation, RGB-D/T salient object segmentation. The code will be\nreleased at https://github.com/Xiaoqi-Zhao-DLUT/UniMRSeg.",
      "url": "http://arxiv.org/abs/2509.16170v1",
      "published_time_eastern_timestamp": 1758302965.0
    },
    {
      "title": "CAPOS: The bulge Cluster APOGEE Survey VI. Characterizing multiple\n  stellar populations and chemical abundances in the bulge globular cluster NGC\n  6569",
      "summary": "Context. The CAPOS project aims to obtain accurate mean abundances and radial\nvelocities for many elements, and it explores the multiple population (MP)\nphenomenon in Galactic bulge globular clusters (BGCs). NGC 6569 is one of the\nCAPOS targets. Aims. This study provides a detailed high-resolution\nspectroscopic analysis of NGC 6569 to derive precise abundances for elements of\ndifferent nucleosynthetic origins and to unveil its MPs by focusing on key\nspectral features. Methods. We analyzed APOGEE-2 near-infrared spectra of 11\ngiant members with the BACCHUS code, deriving abundances for 12 elements (C, N,\nO, Mg, Si, Ca, Ti, Fe, Ni, Al, Ce, Nd). Isochrone fitting with Gaia+2MASS\nphotometry was used to estimate atmospheric parameters, cluster distance, and\nextinction. Results. We obtained [Fe/H] = -0.91 $\\pm$ 0.06, consistent with\nAPOGEE pipeline values; the scatter lies within uncertainties. The cluster\nshows [$\\alpha$/Fe] = 0.36 $\\pm$ 0.06 dex, similar to other GCs. Al appears\nhomogeneous, while N is strongly enriched ([N/Fe] = 0.68 $\\pm$ 0.34) with a\nspread of 0.90 dex, yielding two populations anticorrelated in C. The n-capture\nelements Ce and Nd are overabundant compared to the Sun but consistent with GCs\nof similar metallicity, with $\\langle$[Ce/Nd]$\\rangle$ = -0.17 $\\pm$ 0.12. We\nalso measure RV = -49.75 $\\pm$ 3.68 km s$^{-1}$, consistent with previous\nworks, while d$_\\odot$ = 12.4 $\\pm$ 1.45 kpc and E(B-V) = 0.68 are both higher\nthan literature values. Conclusions. MPs in NGC 6569 are confirmed through a\nclear C-N anticorrelation. The cluster shows [$\\alpha$/Fe] enhancement from\nType II SNe and no Mg-Al-Si anticorrelation, suggesting rapid and homogeneous\nformation. The $\\langle$[Ce/Nd]$\\rangle$ ratio points to contributions from\nr-process events such as neutron star mergers, while overall Ce and Nd\nabundances are reported here for the first time in this cluster.",
      "url": "http://arxiv.org/abs/2509.16168v1",
      "published_time_eastern_timestamp": 1758302812.0
    },
    {
      "title": "Implicit Communication in Linear Quadratic Gaussian Control Systems",
      "summary": "This paper studies implicit communication in linear quadratic Gaussian\ncontrol systems. We show that the control system itself can serve as an\nimplicit communication channel, enabling the controller to transmit messages\nthrough its inputs to a receiver that observes the system state. This\ncommunication is considered implicit because (i) no explicit communication\nchannels are needed; and (ii) information is transmitted while simultaneously\nfulfilling the controller's primary objective--maintaining the control cost\nwithin a specified level. As a result, there exists an inherent trade-off\nbetween control and communication performance. This trade-off is formalized\nthrough the notion of implicit channel capacity, which characterizes the\nsupremum reliable communication rate subject to a constraint on control\nperformance. We characterize the implicit channel capacity in three settings.\nWhen both the controller and the receiver have noiseless observations of the\nsystem state, the channel capacity admits a closed-form expression. When only\nthe controller has noiseless observations, the channel capacity is given by the\nsolution of a convex optimization. When both the controller and the receiver\nhave noisy observations, we establish a lower bound on the implicit capacity.\nSurprisingly, when the controller has noiseless observations, the\ncapacity-achieving input policy adheres to a separation principle, allowing the\ncontrol and channel coding tasks to be addressed independently, without loss of\noptimality. Moreover, under this capacity-achieving input policy, the implicit\nchannel can be equivalently translated into a Gaussian MIMO channel, enabling\nthe use of existing channel codes to achieve implicit communication.",
      "url": "http://arxiv.org/abs/2509.16146v1",
      "published_time_eastern_timestamp": 1758300685.0
    },
    {
      "title": "Flare energetics, CME launch and heliospheric propagation for the May\n  2024 events, as derived from ensemble MHD modelling",
      "summary": "Many questions must be answered before understanding the relationship between\nthe emerging magnetic flux through the solar surface and the extreme\ngeoeffective events. The main ingredients for getting X-ray class flares and\nlarge interplanetary Coronal Mass Ejections (CMEs) are the build-up of electric\ncurrent in the corona, the existence of magnetic free energy, magnetic\nenergy/helicity ratio, twist, and magnetic stress in active regions (ARs). The\nupper limit of solar energy in the space research era, as well as the potential\nfor experiencing superflares and extreme solar events, can be predicted using\nMHD simulations of CMEs.\n  To address this problem, we consider the recent events of May 2024 and use\nthree MHD models: 1) OHM (\"Observationally driven High order scheme\nMagnetohydrodynamic code\") for investigating the magnetic evolutions at a\nsynthetic dipole structure. 2) TMF (time-dependent magneto-friction) for\nsetting up an initial non-potential magnetic field in the active region. A\nzero-beta MHD model for tracing the magnetic evolution of active regions. 3)\nEUHFORIA (''European heliospheric forecasting information asset'') for\ninterplanetary CME propagations.\n  For the eruptive flares with CMEs, magnetic solar energy is computed along\nwith data-constrained MHD simulations for the May 2024 events. We show the\nconsistency between the data-initiated realistic simulation of the May 2024 big\nevent and energy scalings from an idealised simulation of a bipolar eruption\nusing OHM. The estimated free magnetic energy did not surpass $5.2 \\times\n10^{32}\\;$erg. Good arrival time predictions ($<3$ hours) are achieved with the\nEUHFORIA simulation with the cone model. We note the interest in coupling all\nthe chains of codes from the Sun to the Earth and developing different\napproaches to test the results.",
      "url": "http://arxiv.org/abs/2509.16144v1",
      "published_time_eastern_timestamp": 1758300552.0
    },
    {
      "title": "Euclid preparation. Predicting star-forming galaxy scaling relations\n  with the spectral stacking code SpectraPyle",
      "summary": "We introduce SpectraPyle, a versatile spectral stacking pipeline developed\nfor the Euclid mission's NISP spectroscopic surveys, aimed at extracting faint\nemission lines and spectral features from large galaxy samples in the Wide and\nDeep Surveys. Designed for computational efficiency and flexible configuration,\nSpectraPyle supports the processing of extensive datasets critical to Euclid's\nnon-cosmological science goals. We validate the pipeline using simulated\nspectra processed to match Euclid's expected final data quality. Stacking\nenables robust recovery of key emission lines, including Halpha, Hbeta, [O\nIII], and [N II], below individual detection limits. However, the measurement\nof galaxy properties such as star formation rate, dust attenuation, and\ngas-phase metallicity are biased at stellar mass below log10(M*/Msol) ~ 9 due\nto the flux-limited nature of Euclid spectroscopic samples, which cannot be\novercome by stacking. The SFR-stellar mass relation of the parent sample is\nrecovered reliably only in the Deep survey for log10(M*/Msol) > 10, whereas the\nmetallicity-mass relation is recovered more accurately over a wider mass range.\nThese limitations are caused by the increased fraction of redshift measurement\nerrors at lower masses and fluxes. We examine the impact of residual redshift\ncontaminants that arises from misidentified emission lines and noise spikes, on\nstacked spectra. Even after stringent quality selections, low-level\ncontamination (< 6%) has minimal impact on line fluxes due to the\nsystematically weaker emission of contaminants. Percentile-based analysis of\nstacked spectra provides a sensitive diagnostic for detecting contamination via\ncoherent spurious features at characteristic wavelengths. While our simulations\ninclude most instrumental effects, real Euclid data will require further\nrefinement of contamination mitigation strategies.",
      "url": "http://arxiv.org/abs/2509.16120v1",
      "published_time_eastern_timestamp": 1758298447.0
    },
    {
      "title": "CodeRAG: Finding Relevant and Necessary Knowledge for\n  Retrieval-Augmented Repository-Level Code Completion",
      "summary": "Repository-level code completion automatically predicts the unfinished code\nbased on the broader information from the repository. Recent strides in Code\nLarge Language Models (code LLMs) have spurred the development of\nrepository-level code completion methods, yielding promising results.\nNevertheless, they suffer from issues such as inappropriate query construction,\nsingle-path code retrieval, and misalignment between code retriever and code\nLLM. To address these problems, we introduce CodeRAG, a framework tailored to\nidentify relevant and necessary knowledge for retrieval-augmented\nrepository-level code completion. Its core components include log probability\nguided query construction, multi-path code retrieval, and preference-aligned\nBestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval\ndemonstrate that CodeRAG significantly and consistently outperforms\nstate-of-the-art methods. The implementation of CodeRAG is available at\nhttps://github.com/KDEGroup/CodeRAG.",
      "url": "http://arxiv.org/abs/2509.16112v1",
      "published_time_eastern_timestamp": 1758297460.0
    },
    {
      "title": "Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising",
      "summary": "In this work, we present Blind-Spot Guided Diffusion, a novel self-supervised\nframework for real-world image denoising. Our approach addresses two major\nchallenges: the limitations of blind-spot networks (BSNs), which often\nsacrifice local detail and introduce pixel discontinuities due to spatial\nindependence assumptions, and the difficulty of adapting diffusion models to\nself-supervised denoising. We propose a dual-branch diffusion framework that\ncombines a BSN-based diffusion branch, generating semi-clean images, with a\nconventional diffusion branch that captures underlying noise distributions. To\nenable effective training without paired data, we use the BSN-based branch to\nguide the sampling process, capturing noise structure while preserving local\ndetails. Extensive experiments on the SIDD and DND datasets demonstrate\nstate-of-the-art performance, establishing our method as a highly effective\nself-supervised solution for real-world denoising. Code and pre-trained models\nare released at: https://github.com/Sumching/BSGD.",
      "url": "http://arxiv.org/abs/2509.16091v1",
      "published_time_eastern_timestamp": 1758296107.0
    },
    {
      "title": "Software Development Aspects of Integrating Linear Algebra Libraries",
      "summary": "Many scientific discoveries are made through, or aided by, the use of\nsimulation software. These sophisticated software applications are not built\nfrom the ground up, instead they rely on smaller parts for specific use cases,\nusually from domains unfamiliar to the application scientists. The software\nlibrary Ginkgo is one of these building blocks to handle sparse numerical\nlinear algebra on different platforms. By using Ginkgo, applications are able\nto ease the transition to modern systems, and speed up their simulations\nthrough faster numerical linear algebra routines. This paper discusses the\nchallenges and benefits for application software in adopting Ginkgo. It will\npresent examples from different domains, such as CFD, power grid simulation, as\nwell as electro-cardiophysiology. For these cases, the impact of the\nintegrations on the application code is discussed from a software engineering\nstandpoint, and in particular, the approaches taken by Ginkgo and the\napplications to enable sustainable software development are highlighted.",
      "url": "http://arxiv.org/abs/2509.16081v1",
      "published_time_eastern_timestamp": 1758295665.0
    },
    {
      "title": "Latent Conditioned Loco-Manipulation Using Motion Priors",
      "summary": "Although humanoid and quadruped robots provide a wide range of capabilities,\ncurrent control methods, such as Deep Reinforcement Learning, focus mainly on\nsingle skills. This approach is inefficient for solving more complicated tasks\nwhere high-level goals, physical robot limitations and desired motion style\nmight all need to be taken into account. A more effective approach is to first\ntrain a multipurpose motion policy that acquires low-level skills through\nimitation, while providing latent space control over skill execution. Then,\nthis policy can be used to efficiently solve downstream tasks. This method has\nalready been successful for controlling characters in computer graphics. In\nthis work, we apply the approach to humanoid and quadrupedal loco-manipulation\nby imitating either simple synthetic motions or kinematically retargeted dog\nmotions. We extend the original formulation to handle constraints, ensuring\ndeployment safety, and use a diffusion discriminator for better imitation\nquality. We verify our methods by performing loco-manipulation in simulation\nfor the H1 humanoid and Solo12 quadruped, as well as deploying policies on\nSolo12 hardware. Videos and code are available at\nhttps://gepetto.github.io/LaCoLoco/",
      "url": "http://arxiv.org/abs/2509.16061v1",
      "published_time_eastern_timestamp": 1758294633.0
    },
    {
      "title": "SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer\n  Residual Connection",
      "summary": "Large Language Models (LLMs) with safe-alignment training are powerful\ninstruments with robust language comprehension capabilities. These models\ntypically undergo meticulous alignment procedures involving human feedback to\nensure the acceptance of safe inputs while rejecting harmful or unsafe ones.\nHowever, despite their massive scale and alignment efforts, LLMs remain\nvulnerable to jailbreak attacks, where malicious users manipulate the model to\nproduce harmful outputs that it was explicitly trained to avoid. In this study,\nwe find that the safety mechanisms in LLMs are predominantly embedded in the\nmiddle-to-late layers. Building on this insight, we introduce a novel white-box\njailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which\nconnects two intermediate layers $s$ and $e$ such that $s < e$, through a\nresidual connection. Our approach achieves a 51% improvement over the\nbest-performing baseline on the HarmBench test set. Furthermore, SABER induces\nonly a marginal shift in perplexity when evaluated on the HarmBench validation\nset. The source code is publicly available at\nhttps://github.com/PalGitts/SABER.",
      "url": "http://arxiv.org/abs/2509.16060v1",
      "published_time_eastern_timestamp": 1758294619.0
    },
    {
      "title": "Think, Verbalize, then Speak: Bridging Complex Thoughts and\n  Comprehensible Speech",
      "summary": "Spoken dialogue systems increasingly employ large language models (LLMs) to\nleverage their advanced reasoning capabilities. However, direct application of\nLLMs in spoken communication often yield suboptimal results due to mismatches\nbetween optimal textual and verbal delivery. While existing approaches adapt\nLLMs to produce speech-friendly outputs, their impact on reasoning performance\nremains underexplored. In this work, we propose Think-Verbalize-Speak, a\nframework that decouples reasoning from spoken delivery to preserve the full\nreasoning capacity of LLMs. Central to our method is verbalizing, an\nintermediate step that translates thoughts into natural, speech-ready text. We\nalso introduce ReVerT, a latency-efficient verbalizer based on incremental and\nasynchronous summarization. Experiments across multiple benchmarks show that\nour method enhances speech naturalness and conciseness with minimal impact on\nreasoning. The project page with the dataset and the source code is available\nat https://yhytoto12.github.io/TVS-ReVerT",
      "url": "http://arxiv.org/abs/2509.16028v1",
      "published_time_eastern_timestamp": 1758292462.0
    },
    {
      "title": "SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality\n  Synthesis in MRI",
      "summary": "Brain MRI scans are often found in four modalities, consisting of T1-weighted\nwith and without contrast enhancement (T1ce and T1w), T2-weighted imaging\n(T2w), and Flair. Leveraging complementary information from these different\nmodalities enables models to learn richer, more discriminative features for\nunderstanding brain anatomy, which could be used in downstream tasks such as\nanomaly detection. However, in clinical practice, not all MRI modalities are\nalways available due to various reasons. This makes missing modality generation\na critical challenge in medical image analysis. In this paper, we propose\nSLaM-DiMM, a novel missing modality generation framework that harnesses the\npower of diffusion models to synthesize any of the four target MRI modalities\nfrom other available modalities. Our approach not only generates high-fidelity\nimages but also ensures structural coherence across the depth of the volume\nthrough a dedicated coherence enhancement mechanism. Qualitative and\nquantitative evaluations on the BraTS-Lighthouse-2025 Challenge dataset\ndemonstrate the effectiveness of the proposed approach in synthesizing\nanatomically plausible and structurally consistent results. Code is available\nat https://github.com/BheeshmSharma/SLaM-DiMM-MICCAI-BraTS-Challenge-2025.",
      "url": "http://arxiv.org/abs/2509.16019v1",
      "published_time_eastern_timestamp": 1758292055.0
    },
    {
      "title": "Uncertainty-Based Smooth Policy Regularisation for Reinforcement\n  Learning with Few Demonstrations",
      "summary": "In reinforcement learning with sparse rewards, demonstrations can accelerate\nlearning, but determining when to imitate them remains challenging. We propose\nSmooth Policy Regularisation from Demonstrations (SPReD), a framework that\naddresses the fundamental question: when should an agent imitate a\ndemonstration versus follow its own policy? SPReD uses ensemble methods to\nexplicitly model Q-value distributions for both demonstration and policy\nactions, quantifying uncertainty for comparisons. We develop two complementary\nuncertainty-aware methods: a probabilistic approach estimating the likelihood\nof demonstration superiority, and an advantage-based approach scaling imitation\nby statistical significance. Unlike prevailing methods (e.g. Q-filter) that\nmake binary imitation decisions, SPReD applies continuous,\nuncertainty-proportional regularisation weights, reducing gradient variance\nduring training. Despite its computational simplicity, SPReD achieves\nremarkable gains in experiments across eight robotics tasks, outperforming\nexisting approaches by up to a factor of 14 in complex tasks while maintaining\nrobustness to demonstration quality and quantity. Our code is available at\nhttps://github.com/YujieZhu7/SPReD.",
      "url": "http://arxiv.org/abs/2509.15981v1",
      "published_time_eastern_timestamp": 1758289640.0
    },
    {
      "title": "LeakageDetector 2.0: Analyzing Data Leakage in Jupyter-Driven Machine\n  Learning Pipelines",
      "summary": "In software development environments, code quality is crucial. This study\naims to assist Machine Learning (ML) engineers in enhancing their code by\nidentifying and correcting Data Leakage issues within their models. Data\nLeakage occurs when information from the test dataset is inadvertently included\nin the training data when preparing a data science model, resulting in\nmisleading performance evaluations. ML developers must carefully separate their\ndata into training, evaluation, and test sets to avoid introducing Data Leakage\ninto their code. In this paper, we develop a new Visual Studio Code (VS Code)\nextension, called LeakageDetector, that detects Data Leakage, mainly Overlap,\nPreprocessing and Multi-test leakage, from Jupyter Notebook files. Beyond\ndetection, we included two correction mechanisms: a conventional approach,\nknown as a quick fix, which manually fixes the leakage, and an LLM-driven\napproach that guides ML developers toward best practices for building ML\npipelines.",
      "url": "http://arxiv.org/abs/2509.15971v1",
      "published_time_eastern_timestamp": 1758288447.0
    },
    {
      "title": "VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency",
      "summary": "We present VoXtream, a fully autoregressive, zero-shot streaming\ntext-to-speech (TTS) system for real-time use that begins speaking from the\nfirst word. VoXtream directly maps incoming phonemes to audio tokens using a\nmonotonic alignment scheme and a dynamic look-ahead that does not delay onset.\nBuilt around an incremental phoneme transformer, a temporal transformer\npredicting semantic and duration tokens, and a depth transformer producing\nacoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay\namong publicly available streaming TTS: 102 ms on GPU. Despite being trained on\na mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several\nmetrics, while delivering competitive quality in both output- and\nfull-streaming settings. Demo and code are available at\nhttps://herimor.github.io/voxtream.",
      "url": "http://arxiv.org/abs/2509.15969v1",
      "published_time_eastern_timestamp": 1758288406.0
    },
    {
      "title": "Explainable AI for Maritime Autonomous Surface Ships (MASS): Adaptive\n  Interfaces and Trustworthy Human-AI Collaboration",
      "summary": "Autonomous navigation in maritime domains is accelerating alongside advances\nin artificial intelligence, sensing, and connectivity. Opaque decision-making\nand poorly calibrated human-automation interaction remain key barriers to safe\nadoption. This article synthesizes 100 studies on automation transparency for\nMaritime Autonomous Surface Ships (MASS) spanning situation awareness (SA),\nhuman factors, interface design, and regulation. We (i) map the\nGuidance-Navigation-Control stack to shore-based operational modes -- remote\nsupervision (RSM) and remote control (RCM) -- and identify where human unsafe\ncontrol actions (Human-UCAs) concentrate in handover and emergency loops; (ii)\nsummarize evidence that transparency features (decision rationales,\nalternatives, confidence/uncertainty, and rule-compliance indicators) improve\nunderstanding and support trust calibration, though reliability and\npredictability often dominate trust; (iii) distill design strategies for\ntransparency at three layers: sensor/SA acquisition and fusion, HMI/eHMI\npresentation (textual/graphical overlays, color coding, conversational and\nimmersive UIs), and engineer-facing processes (resilient interaction design,\nvalidation, and standardization). We integrate methods for Human-UCA\nidentification (STPA-Cog + IDAC), quantitative trust/SA assessment, and\noperator workload monitoring, and outline regulatory and rule-based\nimplications including COLREGs formalization and route exchange. We conclude\nwith an adaptive transparency framework that couples operator state estimation\nwith explainable decision support to reduce cognitive overload and improve\ntakeover timeliness. The review highlights actionable figure-of-merit displays\n(e.g., CPA/TCPA risk bars, robustness heatmaps), transparent model outputs\n(rule traceability, confidence), and training pipelines (HIL/MIL, simulation)\nas near-term levers for safer MASS operations.",
      "url": "http://arxiv.org/abs/2509.15959v1",
      "published_time_eastern_timestamp": 1758287934.0
    }
  ]
}
{
  "last_updated": "2025-07-13T02:17:37.545458-04:00",
  "papers": [
    {
      "title": "Impact of Pretraining Word Co-occurrence on Compositional Generalization\n  in Multimodal Models",
      "summary": "CLIP and large multimodal models (LMMs) have better accuracy on examples\ninvolving concepts that are highly represented in the training data. However,\nthe role of concept combinations in the training data on compositional\ngeneralization is largely unclear -- for instance, how does accuracy vary when\na common object appears in an uncommon pairing with another object? In this\npaper, we investigate how word co-occurrence statistics in the pretraining\ndataset (a proxy for co-occurrence of visual concepts) impacts CLIP/LMM\nperformance. To disentangle the effects of word co-occurrence frequencies from\nsingle-word frequencies, we measure co-occurrence with pointwise mutual\ninformation (PMI), which normalizes the joint probability of two words\nco-occurring by the probability of co-occurring independently. Using\nsynthetically generated images with a variety of concept pairs, we show a\nstrong correlation between PMI in the CLIP pretraining data and zero-shot\naccuracy in CLIP models trained on LAION-400M (r=0.97 and 14% accuracy gap\nbetween images in the top and bottom 5% of PMI values), demonstrating that even\naccuracy on common concepts is affected by the combination of concepts in the\nimage. Leveraging this finding, we reproduce this effect in natural images by\nediting them to contain pairs with varying PMI, resulting in a correlation of\nr=0.75. Finally, we demonstrate that this behavior in CLIP transfers to LMMs\nbuilt on top of CLIP (r=0.70 for TextVQA, r=0.62 for VQAv2). Our findings\nhighlight the need for algorithms and architectures that improve compositional\ngeneralization in multimodal models without scaling the training data\ncombinatorially. Our code is available at\nhttps://github.com/helenqu/multimodal-pretraining-pmi.",
      "url": "http://arxiv.org/abs/2507.08000v1",
      "published_time_eastern_timestamp": 1752170399.0
    },
    {
      "title": "Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and\n  Methodology",
      "summary": "Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically\nreferencing visual regions, just like human \"thinking with images\". However, no\nbenchmark exists to evaluate these capabilities holistically. To bridge this\ngap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a\ndiagnostic benchmark built on three principles: (1) focused visual perception\nof subtle targets in complex scenes, (2) traceable evidence via bounding box\nevaluation, and (3) second-order reasoning to test object interactions and\nspatial hierarchies beyond simple object localization. Prioritizing images with\ndense objects, we initially sample 1K high-quality images from SA-1B, and\nincorporate eight LMM experts to manually annotate questions, candidate\noptions, and answers for each image. After three stages of quality control,\nTreeBench consists of 405 challenging visual question-answering pairs, even the\nmost advanced models struggle with this benchmark, where none of them reach 60%\naccuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR\n(Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to\nsupervise localization and reasoning jointly with reinforcement learning,\nenabling accurate localizations and explainable reasoning pathways. Initialized\nfrom Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and\nTreeBench (+13.4), proving traceability is key to advancing vision-grounded\nreasoning. The code is available at https://github.com/Haochen-Wang409/TreeVGR.",
      "url": "http://arxiv.org/abs/2507.07999v1",
      "published_time_eastern_timestamp": 1752170398.0
    },
    {
      "title": "MGVQ: Could VQ-VAE Beat VAE? A Generalizable Tokenizer with Multi-group\n  Quantization",
      "summary": "Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental models\nthat compress continuous visual data into discrete tokens. Existing methods\nhave tried to improve the quantization strategy for better reconstruction\nquality, however, there still exists a large gap between VQ-VAEs and VAEs. To\nnarrow this gap, we propose \\NickName, a novel method to augment the\nrepresentation capability of discrete codebooks, facilitating easier\noptimization for codebooks and minimizing information loss, thereby enhancing\nreconstruction quality. Specifically, we propose to retain the latent dimension\nto preserve encoded features and incorporate a set of sub-codebooks for\nquantization. Furthermore, we construct comprehensive zero-shot benchmarks\nfeaturing resolutions of 512p and 2k to evaluate the reconstruction performance\nof existing methods rigorously. \\NickName~achieves the \\textbf{state-of-the-art\nperformance on both ImageNet and $8$ zero-shot benchmarks} across all VQ-VAEs.\nNotably, compared with SD-VAE, we outperform them on ImageNet significantly,\nwith rFID $\\textbf{0.49}$ v.s. $\\textbf{0.91}$, and achieve superior PSNR on\nall zero-shot benchmarks. These results highlight the superiority of\n\\NickName~in reconstruction and pave the way for preserving fidelity in HD\nimage processing tasks. Code will be publicly available at\nhttps://github.com/MKJia/MGVQ.",
      "url": "http://arxiv.org/abs/2507.07997v1",
      "published_time_eastern_timestamp": 1752170394.0
    },
    {
      "title": "Single-pass Adaptive Image Tokenization for Minimum Program Search",
      "summary": "According to Algorithmic Information Theory (AIT) -- Intelligent\nrepresentations compress data into the shortest possible program that can\nreconstruct its content, exhibiting low Kolmogorov Complexity (KC). In\ncontrast, most visual representation learning systems use fixed-length\nrepresentations for all inputs, ignoring variations in complexity or\nfamiliarity. Recent adaptive tokenization methods address this by allocating\nvariable-length representations but typically require test-time search over\nmultiple encodings to find the most predictive one. Inspired by Kolmogorov\nComplexity principles, we propose a single-pass adaptive tokenizer, KARL, which\npredicts the appropriate number of tokens for an image in a single forward\npass, halting once its approximate KC is reached. The token count serves as a\nproxy for the minimum description length. KARL's training procedure closely\nresembles the Upside-Down Reinforcement Learning paradigm, as it learns to\nconditionally predict token halting based on a desired reconstruction quality.\nKARL matches the performance of recent adaptive tokenizers while operating in a\nsingle pass. We present scaling laws for KARL, analyzing the role of\nencoder/decoder size, continuous vs. discrete tokenization and more.\nAdditionally, we offer a conceptual study drawing an analogy between Adaptive\nImage Tokenization and Algorithmic Information Theory, examining the predicted\nimage complexity (KC) across axes such as structure vs. noise and in- vs.\nout-of-distribution familiarity -- revealing alignment with human intuition.",
      "url": "http://arxiv.org/abs/2507.07995v1",
      "published_time_eastern_timestamp": 1752170393.0
    },
    {
      "title": "OST-Bench: Evaluating the Capabilities of MLLMs in Online\n  Spatio-temporal Scene Understanding",
      "summary": "Recent advances in multimodal large language models (MLLMs) have shown\nremarkable capabilities in integrating vision and language for complex\nreasoning. While most existing benchmarks evaluate models under offline\nsettings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a\nbenchmark designed to evaluate Online Spatio-Temporal understanding from the\nperspective of an agent actively exploring a scene. The Online aspect\nemphasizes the need to process and reason over incrementally acquired\nobservations, while the Spatio-Temporal component requires integrating current\nvisual inputs with historical memory to support dynamic spatial reasoning.\nOST-Bench better reflects the challenges of real-world embodied perception.\nBuilt on an efficient data collection pipeline, OST-Bench consists of 1.4k\nscenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and\nARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that\nthey fall short on tasks requiring complex spatio-temporal reasoning. Under the\nonline setting, their accuracy declines as the exploration horizon extends and\nthe memory grows. Through further experimental analysis, we identify common\nerror patterns across models and find that both complex clue-based spatial\nreasoning demands and long-term memory retrieval requirements significantly\ndrop model performance along two separate axes, highlighting the core\nchallenges that must be addressed to improve online embodied reasoning. To\nfoster further research and development in the field, our codes, dataset, and\nbenchmark are available. Our project page is:\nhttps://rbler1234.github.io/OSTBench.github.io/",
      "url": "http://arxiv.org/abs/2507.07984v1",
      "published_time_eastern_timestamp": 1752170167.0
    },
    {
      "title": "Defending Against Prompt Injection With a Few DefensiveTokens",
      "summary": "When large language model (LLM) systems interact with external data to\nperform complex tasks, a new attack, namely prompt injection, becomes a\nsignificant threat. By injecting instructions into the data accessed by the\nsystem, the attacker is able to override the initial user task with an\narbitrary task directed by the attacker. To secure the system, test-time\ndefenses, e.g., defensive prompting, have been proposed for system developers\nto attain security only when needed in a flexible manner. However, they are\nmuch less effective than training-time defenses that change the model\nparameters. Motivated by this, we propose DefensiveToken, a test-time defense\nwith prompt injection robustness comparable to training-time alternatives.\nDefensiveTokens are newly inserted as special tokens, whose embeddings are\noptimized for security. In security-sensitive cases, system developers can\nappend a few DefensiveTokens before the LLM input to achieve security with a\nminimal utility drop. In scenarios where security is less of a concern,\ndevelopers can simply skip DefensiveTokens; the LLM system remains the same as\nthere is no defense, generating high-quality responses. Thus, DefensiveTokens,\nif released alongside the model, allow a flexible switch between the\nstate-of-the-art (SOTA) utility and almost-SOTA security at test time. The code\nis available at https://github.com/Sizhe-Chen/DefensiveToken.",
      "url": "http://arxiv.org/abs/2507.07974v1",
      "published_time_eastern_timestamp": 1752169865.0
    },
    {
      "title": "Scaling RL to Long Videos",
      "summary": "We introduce a full-stack framework that scales up reasoning in\nvision-language models (VLMs) to long videos, leveraging reinforcement\nlearning. We address the unique challenges of long video reasoning by\nintegrating three critical components: (1) a large-scale dataset,\nLongVideo-Reason, comprising 52K long video QA pairs with high-quality\nreasoning annotations across diverse domains such as sports, games, and vlogs;\n(2) a two-stage training pipeline that extends VLMs with chain-of-thought\nsupervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a\ntraining infrastructure for long video RL, named Multi-modal Reinforcement\nSequence Parallelism (MR-SP), which incorporates sequence parallelism and a\nvLLM-based engine tailored for long video, using cached video embeddings for\nefficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves\nstrong performance on long video QA benchmarks such as VideoMME. It also\noutperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal\nreasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on\nour LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to\n2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent\nperformance gains as the number of input video frames scales. LongVILA-R1 marks\na firm step towards long video reasoning in VLMs. In addition, we release our\ntraining system for public availability that supports RL training on various\nmodalities (video, text, and audio), various models (VILA and Qwen series), and\neven image and video generation models. On a single A100 node (8 GPUs), it\nsupports RL training on hour-long videos (e.g., 3,600 frames / around 256k\ntokens).",
      "url": "http://arxiv.org/abs/2507.07966v1",
      "published_time_eastern_timestamp": 1752169660.0
    },
    {
      "title": "Synthesizing Sun-as-a-star flare spectra from high-resolution solar\n  observations",
      "summary": "Spatially resolved observations of the Sun and the astronomical sample size\nof stellar bodies are the respective key strengths of solar and stellar\nobservations. However, the large difference in object brightness between the\nSun and other stars has led to distinctly different instrumentation and\nmethodologies between the two fields. We produce and analyze synthetic\nfull-disk spectra derived from 19 small area field-of-view optical observations\nof solar flares acquired by the Swedish 1-m Solar Telescope (SST) between 2011\nand 2024. These are used to investigate what can and cannot be inferred about\nphysical processes on the Sun from Sun-as-a-star observations. The recently\nreleased Numerical Empirical Sun-as-a-Star Integrator (NESSI) code provides\nsynthetic full-disk integrated spectral line emission based on smaller\nfield-of-view input, accounting for center-to-limb variations and differential\nrotation. We use this code to generate pseudo-Sun-as-a-star spectra from the\nSST observations. ...",
      "url": "http://arxiv.org/abs/2507.07967v1",
      "published_time_eastern_timestamp": 1752169660.0
    },
    {
      "title": "Prospective Learning in Retrospect",
      "summary": "In most real-world applications of artificial intelligence, the distributions\nof the data and the goals of the learners tend to change over time. The\nProbably Approximately Correct (PAC) learning framework, which underpins most\nmachine learning algorithms, fails to account for dynamic data distributions\nand evolving objectives, often resulting in suboptimal performance. Prospective\nlearning is a recently introduced mathematical framework that overcomes some of\nthese limitations. We build on this framework to present preliminary results\nthat improve the algorithm and numerical results, and extend prospective\nlearning to sequential decision-making scenarios, specifically foraging. Code\nis available at: https://github.com/neurodata/prolearn2.",
      "url": "http://arxiv.org/abs/2507.07965v1",
      "published_time_eastern_timestamp": 1752169515.0
    },
    {
      "title": "Gravitational lensing rarely produces high-mass outliers to the compact\n  binary population",
      "summary": "All gravitational-wave signals are inevitably gravitationally lensed by\nintervening matter as they propagate through the Universe. When a\ngravitational-wave signal is magnified, it appears to have originated from a\ncloser, more massive system. Thus, high-mass outliers to the gravitational-wave\nsource population are often proposed as natural candidates for strongly lensed\nevents. However, when using a data-driven method for identifying population\noutliers, we find that high-mass outliers are not necessarily strongly lensed,\nnor will the majority of strongly-lensed signals appear as high-mass outliers.\nThis is both because statistical fluctuations produce a larger effect on\nobserved binary parameters than does lensing magnification, and because\nlensing-induced outliers must originate from intrinsically high-mass sources,\nwhich are rare. Thus, the appearance of a single lensing-induced outlier\nimplies the existence of many other lensed events within the catalog. We\nadditionally show that it is possible to constrain the strong lensing optical\ndepth, which is a fundamental quantity of our Universe, with the detection or\nabsence of high-mass outliers. However, constraints using the latest\ngravitational-wave catalog are weak$\\unicode{x2014}$we obtain an upper limit on\nthe optical depth of sources at redshift $1$ magnified by a factor of $5$ or\nmore of $\\tau(\\mu\\geq5,z=1)\\leq 0.035 \\unicode{x2014}$and future observing runs\nwill not make an outlier-based method competitive with other probes of the\noptical depth. Future work will investigate the ability of the full inferred\npopulation of compact binaries to inform the distribution of lenses in the\nUniverse, opening a unique opportunity to access the high-redshift Universe and\nconstrain cosmic structures.",
      "url": "http://arxiv.org/abs/2507.07964v1",
      "published_time_eastern_timestamp": 1752169467.0
    },
    {
      "title": "Dynamic Chunking for End-to-End Hierarchical Sequence Modeling",
      "summary": "Despite incredible progress in language models (LMs) in recent years, largely\nresulting from moving away from specialized models designed for specific tasks\nto general models based on powerful architectures (e.g. the Transformer) that\nlearn everything from raw data, pre-processing steps such as tokenization\nremain a barrier to true end-to-end foundation models. We introduce a\ncollection of new techniques that enable a dynamic chunking mechanism which\nautomatically learns content -- and context -- dependent segmentation\nstrategies learned jointly with the rest of the model. Incorporating this into\nan explicit hierarchical network (H-Net) allows replacing the (implicitly\nhierarchical) tokenization-LM-detokenization pipeline with a single model\nlearned fully end-to-end. When compute- and data- matched, an H-Net with one\nstage of hierarchy operating at the byte level outperforms a strong Transformer\nlanguage model operating over BPE tokens. Iterating the hierarchy to multiple\nstages further increases its performance by modeling multiple levels of\nabstraction, demonstrating significantly better scaling with data and matching\na token-based Transformer of twice its size. H-Nets pretrained on English show\nsignificantly increased character-level robustness, and qualitatively learn\nmeaningful data-dependent chunking strategies without any heuristics or\nexplicit supervision. Finally, the H-Net's improvement over tokenized pipelines\nis further increased in languages and modalities with weaker tokenization\nheuristics, such as Chinese and code, or DNA sequences (nearly 4x improvement\nin data efficiency over baselines), showing the potential of true end-to-end\nmodels that learn and scale better from unprocessed data.",
      "url": "http://arxiv.org/abs/2507.07955v1",
      "published_time_eastern_timestamp": 1752169177.0
    },
    {
      "title": "SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement\n  and Entropy-aware Alignment",
      "summary": "While Vision-Language Models (VLMs) have shown promising progress in general\nmultimodal tasks, they often struggle in industrial anomaly detection and\nreasoning, particularly in delivering interpretable explanations and\ngeneralizing to unseen categories. This limitation stems from the inherently\ndomain-specific nature of anomaly detection, which hinders the applicability of\nexisting VLMs in industrial scenarios that require precise, structured, and\ncontext-aware analysis. To address these challenges, we propose SAGE, a\nVLM-based framework that enhances anomaly reasoning through Self-Guided Fact\nEnhancement (SFE) and Entropy-aware Direct Preference Optimization (E-DPO). SFE\nintegrates domain-specific knowledge into visual reasoning via fact extraction\nand fusion, while E-DPO aligns model outputs with expert preferences using\nentropy-aware optimization. Additionally, we introduce AD-PL, a\npreference-optimized dataset tailored for industrial anomaly reasoning,\nconsisting of 28,415 question-answering instances with expert-ranked responses.\nTo evaluate anomaly reasoning models, we develop Multiscale Logical Evaluation\n(MLE), a quantitative framework analyzing model logic and consistency. SAGE\ndemonstrates superior performance on industrial anomaly datasets under\nzero-shot and one-shot settings. The code, model and dataset are available at\nhttps://github.com/amoreZgx1n/SAGE.",
      "url": "http://arxiv.org/abs/2507.07939v1",
      "published_time_eastern_timestamp": 1752168222.0
    },
    {
      "title": "DTECT: Dynamic Topic Explorer & Context Tracker",
      "summary": "The explosive growth of textual data over time presents a significant\nchallenge in uncovering evolving themes and trends. Existing dynamic topic\nmodeling techniques, while powerful, often exist in fragmented pipelines that\nlack robust support for interpretation and user-friendly exploration. We\nintroduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end\nsystem that bridges the gap between raw textual data and meaningful temporal\ninsights. DTECT provides a unified workflow that supports data preprocessing,\nmultiple model architectures, and dedicated evaluation metrics to analyze the\ntopic quality of temporal topic models. It significantly enhances\ninterpretability by introducing LLM-driven automatic topic labeling, trend\nanalysis via temporally salient words, interactive visualizations with\ndocument-level summarization, and a natural language chat interface for\nintuitive data querying. By integrating these features into a single, cohesive\nplatform, DTECT empowers users to more effectively track and understand\nthematic dynamics. DTECT is open-source and available at\nhttps://github.com/AdhyaSuman/DTECT.",
      "url": "http://arxiv.org/abs/2507.07910v1",
      "published_time_eastern_timestamp": 1752165873.0
    },
    {
      "title": "Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal\n  Inconsistency for Remote Physiological Measurement",
      "summary": "Remote photoplethysmography (rPPG) has emerged as a promising non-invasive\nmethod for monitoring physiological signals using the camera. Although various\ndomain adaptation and generalization methods were proposed to promote the\nadaptability of deep-based rPPG models in unseen deployment environments,\nconsiderations in aspects like privacy concerns and real-time adaptation\nrestrict their application in real-world deployment. Thus, we aim to propose a\nnovel fully Test-Time Adaptation (TTA) strategy tailored for rPPG tasks in this\nwork. Specifically, based on prior knowledge in physiology and our\nobservations, we noticed not only there is spatio-temporal consistency in the\nfrequency domain of rPPG signals, but also that inconsistency in the time\ndomain was significant. Given this, by leveraging both consistency and\ninconsistency priors, we introduce an innovative expert knowledge-based\nself-supervised\n\\textbf{C}onsistency-\\textbf{i}n\\textbf{C}onsistency-\\textbf{i}ntegration\n(\\textbf{CiCi}) framework to enhances model adaptation during inference.\nBesides, our approach further incorporates a gradient dynamic control mechanism\nto mitigate potential conflicts between priors, ensuring stable adaptation\nacross instances. Through extensive experiments on five diverse datasets under\nthe TTA protocol, our method consistently outperforms existing techniques,\npresenting state-of-the-art performance in real-time self-supervised adaptation\nwithout accessing source data. The code will be released later.",
      "url": "http://arxiv.org/abs/2507.07908v1",
      "published_time_eastern_timestamp": 1752165589.0
    },
    {
      "title": "MIRA: A Novel Framework for Fusing Modalities in Medical RAG",
      "summary": "Multimodal Large Language Models (MLLMs) have significantly advanced\nAI-assisted medical diagnosis, but they often generate factually inconsistent\nresponses that deviate from established medical knowledge. Retrieval-Augmented\nGeneration (RAG) enhances factual accuracy by integrating external sources, but\nit presents two key challenges. First, insufficient retrieval can miss critical\ninformation, whereas excessive retrieval can introduce irrelevant or misleading\ncontent, disrupting model output. Second, even when the model initially\nprovides correct answers, over-reliance on retrieved data can lead to factual\nerrors. To address these issues, we introduce the Multimodal Intelligent\nRetrieval and Augmentation (MIRA) framework, designed to optimize factual\naccuracy in MLLM. MIRA consists of two key components: (1) a calibrated\nRethinking and Rearrangement module that dynamically adjusts the number of\nretrieved contexts to manage factual risk, and (2) A medical RAG framework\nintegrating image embeddings and a medical knowledge base with a query-rewrite\nmodule for efficient multimodal reasoning. This enables the model to\neffectively integrate both its inherent knowledge and external references. Our\nevaluation of publicly available medical VQA and report generation benchmarks\ndemonstrates that MIRA substantially enhances factual accuracy and overall\nperformance, achieving new state-of-the-art results. Code is released at\nhttps://github.com/mbzuai-oryx/MIRA.",
      "url": "http://arxiv.org/abs/2507.07902v1",
      "published_time_eastern_timestamp": 1752165230.0
    },
    {
      "title": "The Trust Fabric: Decentralized Interoperability and Economic\n  Coordination for the Agentic Web",
      "summary": "The fragmentation of AI agent ecosystems has created urgent demands for\ninteroperability, trust, and economic coordination that current protocols --\nincluding MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al.,\n2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present\nthe Nanda Unified Architecture, a decentralized framework built around three\ncore innovations: fast DID-based agent discovery through distributed\nregistries, semantic agent cards with verifiable credentials and composability\nprofiles, and a dynamic trust layer that integrates behavioral attestations\nwith policy compliance. The system introduces X42/H42 micropayments for\neconomic coordination and MAESTRO, a security framework incorporating\nSynergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure\ncontainerization. Real-world deployments demonstrate 99.9 percent compliance in\nhealthcare applications and substantial monthly transaction volumes with strong\nprivacy guarantees. By unifying MIT's trust research with production\ndeployments from Cisco and Synergetics, we show how cryptographic proofs and\npolicy-as-code transform agents into trust-anchored participants in a\ndecentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a\nglobally interoperable Internet of Agents where trust becomes the native\ncurrency of collaboration across both enterprise and Web3 ecosystems.",
      "url": "http://arxiv.org/abs/2507.07901v1",
      "published_time_eastern_timestamp": 1752165186.0
    },
    {
      "title": "An Integrated Framework of Prompt Engineering and Multidimensional\n  Knowledge Graphs for Legal Dispute Analysis",
      "summary": "The rapid development of artificial intelligence has positioned large\nlanguage models as fundamental components of intelligent legal systems.\nHowever, these models face significant limitations in legal dispute analysis,\nincluding insufficient legal knowledge representation, limited concept\nunderstanding, and reasoning deficiencies. This research proposes an enhanced\nframework integrating prompt engineering with multidimensional knowledge\ngraphs. The framework introduces a three-stage hierarchical prompt structure\ncomprising task definition, knowledge background, and reasoning guidance,\nsupplemented by legal-specific reasoning templates and dynamic optimization\nmechanisms. A three-layer knowledge graph architecture is constructed with\nlegal classification ontology, representation, and instance layers. Four\ncomplementary methods enable precise legal concept retrieval: direct legal norm\ncode matching, domain-specific semantic vector similarity, ontology-based path\nreasoning, and specialized lexical segmentation. These components integrate\nwith web search technology to establish a knowledge-enhanced framework for\nlegal decision-making. Experimental results demonstrate significant performance\nimprovements in legal dispute analysis, enabling accurate legal application\nanalysis for complex cases while exhibiting nuanced understanding of judicial\ndecision-making logic, providing a novel technical approach for implementing\nintelligent legal assistance systems.",
      "url": "http://arxiv.org/abs/2507.07893v1",
      "published_time_eastern_timestamp": 1752164561.0
    },
    {
      "title": "Automating MD simulations for Proteins using Large language Models:\n  NAMD-Agent",
      "summary": "Molecular dynamics simulations are an essential tool in understanding protein\nstructure, dynamics, and function at the atomic level. However, preparing high\nquality input files for MD simulations can be a time consuming and error prone\nprocess. In this work, we introduce an automated pipeline that leverages Large\nLanguage Models (LLMs), specifically Gemini 2.0 Flash, in conjunction with\npython scripting and Selenium based web automation to streamline the generation\nof MD input files. The pipeline exploits CHARMM GUI's comprehensive web-based\ninterface for preparing simulation-ready inputs for NAMD. By integrating\nGemini's code generation and iterative refinement capabilities, simulation\nscripts are automatically written, executed, and revised to navigate CHARMM\nGUI, extract appropriate parameters, and produce the required NAMD input files.\nPost processing is performed using additional software to further refine the\nsimulation outputs, thereby enabling a complete and largely hands free\nworkflow. Our results demonstrate that this approach reduces setup time,\nminimizes manual errors, and offers a scalable solution for handling multiple\nprotein systems in parallel. This automated framework paves the way for broader\napplication of LLMs in computational structural biology, offering a robust and\nadaptable platform for future developments in simulation automation.",
      "url": "http://arxiv.org/abs/2507.07887v1",
      "published_time_eastern_timestamp": 1752164260.0
    },
    {
      "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization\n  with Joint Global-Local Perturbation",
      "summary": "Multi-task learning (MTL) enables a joint model to capture commonalities\nacross multiple tasks, reducing computation costs and improving data\nefficiency. However, a major challenge in MTL optimization is task conflicts,\nwhere the task gradients differ in direction or magnitude, limiting model\nperformance compared to single-task counterparts. Sharpness-aware minimization\n(SAM) minimizes task loss while simultaneously reducing the sharpness of the\nloss landscape. Our empirical observations show that SAM effectively mitigates\ntask conflicts in MTL. Motivated by these findings, we explore integrating SAM\ninto MTL but face two key challenges. While both the average loss gradient and\nindividual task gradients-referred to as global and local\ninformation-contribute to SAM, how to combine them remains unclear. Moreover,\ndirectly computing each task gradient introduces significant computational and\nmemory overheads. To address these challenges, we propose SAMO, a lightweight\n\\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization\napproach, that leverages a joint global-local perturbation. The local\nperturbations are approximated using only forward passes and are layerwise\nnormalized to improve efficiency. Extensive experiments on a suite of\nmulti-task benchmarks demonstrate both the effectiveness and efficiency of our\nmethod. Code is available at https://github.com/OptMN-Lab/SAMO.",
      "url": "http://arxiv.org/abs/2507.07883v1",
      "published_time_eastern_timestamp": 1752163562.0
    },
    {
      "title": "Homeostatic Adaptation of Optimal Population Codes under Metabolic\n  Stress",
      "summary": "Information processing in neural populations is inherently constrained by\nmetabolic resource limits and noise properties, with dynamics that are not\naccurately described by existing mathematical models. Recent data, for example,\nshows that neurons in mouse visual cortex go into a \"low power mode\" in which\nthey maintain firing rate homeostasis while expending less energy. This\nadaptation leads to increased neuronal noise and tuning curve flattening in\nresponse to metabolic stress. We have developed a theoretical population coding\nframework that captures this behavior using two novel, surprisingly simple\nconstraints: an approximation of firing rate homeostasis and an energy limit\ntied to noise levels via biophysical simulation. A key feature of our\ncontribution is an energy budget model directly connecting adenosine\ntriphosphate (ATP) use in cells to a fully explainable mathematical framework\nthat generalizes existing optimal population codes. Specifically, our\nsimulation provides an energy-dependent dispersed Poisson noise model, based on\nthe assumption that the cell will follow an optimal decay path to produce the\nleast-noisy spike rate that is possible at a given cellular energy budget. Each\nstate along this optimal path is associated with properties (resting potential\nand leak conductance) which can be measured in electrophysiology experiments\nand have been shown to change under prolonged caloric deprivation. We\nanalytically derive the optimal coding strategy for neurons under varying\nenergy budgets and coding goals, and show how our method uniquely captures how\npopulations of tuning curves adapt while maintaining homeostasis, as has been\nobserved empirically.",
      "url": "http://arxiv.org/abs/2507.07874v1",
      "published_time_eastern_timestamp": 1752163137.0
    }
  ]
}
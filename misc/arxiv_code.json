{
  "last_updated": "2025-10-06T17:10:00.241605-04:00",
  "papers": [
    {
      "title": "MIXER: Mixed Hyperspherical Random Embedding Neural Network for Texture\n  Recognition",
      "summary": "Randomized neural networks for representation learning have consistently\nachieved prominent results in texture recognition tasks, effectively combining\nthe advantages of both traditional techniques and learning-based approaches.\nHowever, existing approaches have so far focused mainly on improving\ncross-information prediction, without introducing significant advancements to\nthe overall randomized network architecture. In this paper, we propose Mixer, a\nnovel randomized neural network for texture representation learning. At its\ncore, the method leverages hyperspherical random embeddings coupled with a\ndual-branch learning module to capture both intra- and inter-channel\nrelationships, further enhanced by a newly formulated optimization problem for\nbuilding rich texture representations. Experimental results have shown the\ninteresting results of the proposed approach across several pure texture\nbenchmarks, each with distinct characteristics and challenges. The source code\nwill be available upon publication.",
      "url": "http://arxiv.org/abs/2510.03228v1",
      "published_time_eastern_timestamp": 1759514284.0
    },
    {
      "title": "Low-probability Tokens Sustain Exploration in Reinforcement Learning\n  with Verifiable Reward",
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has propelled Large\nLanguage Models in complex reasoning, yet its scalability is often hindered by\na training bottleneck where performance plateaus as policy entropy collapses,\nsignaling a loss of exploration. Previous methods typically address this by\nmaintaining high policy entropy, yet the precise mechanisms that govern\nmeaningful exploration have remained underexplored. Our analysis suggests that\nan unselective focus on entropy risks amplifying irrelevant tokens and\ndestabilizing training. This paper investigates the exploration dynamics within\nRLVR and identifies a key issue: the gradual elimination of valuable\nlow-probability exploratory tokens, which we term \\textbf{\\textit{reasoning\nsparks}}. We find that while abundant in pre-trained models, these sparks are\nsystematically extinguished during RLVR due to over-penalization, leading to a\ndegeneracy in exploration. To address this, we introduce Low-probability\nRegularization (Lp-Reg). Its core mechanism regularizes the policy towards a\nheuristic proxy distribution. This proxy is constructed by filtering out\npresumed noise tokens and re-normalizing the distribution over the remaining\ncandidates. The result is a less-noisy proxy where the probability of\n\\textit{reasoning sparks} is amplified, which then serves as a soft\nregularization target to shield these valuable tokens from elimination via KL\ndivergence. Experiments show that Lp-Reg enables stable on-policy training for\naround 1,000 steps, a regime where baseline entropy-control methods collapse.\nThis sustained exploration leads to state-of-the-art performance, achieving a\n$60.17\\%$ average accuracy on five math benchmarks, an improvement of $2.66\\%$\nover prior methods. Code is available at https://github.com/CarlanLark/Lp-Reg.",
      "url": "http://arxiv.org/abs/2510.03222v1",
      "published_time_eastern_timestamp": 1759514173.0
    },
    {
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "url": "http://arxiv.org/abs/2510.03217v1",
      "published_time_eastern_timestamp": 1759514008.0
    },
    {
      "title": "Wave-GMS: Lightweight Multi-Scale Generative Model for Medical Image\n  Segmentation",
      "summary": "For equitable deployment of AI tools in hospitals and healthcare facilities,\nwe need Deep Segmentation Networks that offer high performance and can be\ntrained on cost-effective GPUs with limited memory and large batch sizes. In\nthis work, we propose Wave-GMS, a lightweight and efficient multi-scale\ngenerative model for medical image segmentation. Wave-GMS has a substantially\nsmaller number of trainable parameters, does not require loading\nmemory-intensive pretrained vision foundation models, and supports training\nwith large batch sizes on GPUs with limited memory. We conducted extensive\nexperiments on four publicly available datasets (BUS, BUSI, Kvasir-Instrument,\nand HAM10000), demonstrating that Wave-GMS achieves state-of-the-art\nsegmentation performance with superior cross-domain generalizability, while\nrequiring only ~2.6M trainable parameters. Code is available at\nhttps://github.com/ATPLab-LUMS/Wave-GMS.",
      "url": "http://arxiv.org/abs/2510.03216v1",
      "published_time_eastern_timestamp": 1759513996.0
    },
    {
      "title": "Cache-to-Cache: Direct Semantic Communication Between Large Language\n  Models",
      "summary": "Multi-LLM systems harness the complementary strengths of diverse Large\nLanguage Models, achieving performance and efficiency gains unattainable by a\nsingle model. In existing designs, LLMs communicate through text, forcing\ninternal representations to be transformed into output token sequences. This\nprocess both loses rich semantic information and incurs token-by-token\ngeneration latency. Motivated by these limitations, we ask: Can LLMs\ncommunicate beyond text? Oracle experiments show that enriching the KV-Cache\nsemantics can improve response quality without increasing cache size,\nsupporting KV-Cache as an effective medium for inter-model communication. Thus,\nwe propose Cache-to-Cache (C2C), a new paradigm for direct semantic\ncommunication between LLMs. C2C uses a neural network to project and fuse the\nsource model's KV-cache with that of the target model to enable direct semantic\ntransfer. A learnable gating mechanism selects the target layers that benefit\nfrom cache communication. Compared with text communication, C2C utilizes the\ndeep, specialized semantics from both models, while avoiding explicit\nintermediate text generation. Experiments show that C2C achieves 8.5-10.5%\nhigher average accuracy than individual models. It further outperforms the text\ncommunication paradigm by approximately 3.0-5.0%, while delivering an average\n2.0x speedup in latency. Our code is available at\nhttps://github.com/thu-nics/C2C.",
      "url": "http://arxiv.org/abs/2510.03215v1",
      "published_time_eastern_timestamp": 1759513952.0
    },
    {
      "title": "OpenZL: A Graph-Based Model for Compression",
      "summary": "Research in general-purpose lossless compression over the last decade has\nlargely found improvements in compression ratio that come at great cost to\nresource utilization and processing throughput. However, most production\nworkloads require high throughput and low resource utilization, so most\nresearch systems have seen little adoption. Instead, real world improvements in\ncompression are increasingly often realized by building application-specific\ncompressors which can exploit knowledge about the structure and semantics of\nthe data being compressed. These systems easily outperform even the best\ngeneric compressors, but application-specific compression schemes are not\nwithout drawbacks. They are inherently limited in applicability and are\ndifficult to maintain and deploy.\n  We show that these challenges can be overcome with a new way of thinking\nabout compression. We propose the ``graph model'' of compression, a new\ntheoretical framework for representing compression as a directed acyclic graph\nof modular codecs. This motivates OpenZL, an implementation of this model that\ncompresses data into a self-describing wire format, any configuration of which\ncan be decompressed by a universal decoder. OpenZL's design enables rapid\ndevelopment of tailored compressors with minimal code, its universal decoder\neliminates deployment lag, and its investment in a well-vetted standard\ncomponent library minimizes security risks. Experimental results demonstrate\nthat OpenZL achieves superior compression ratios and speeds compared to\nstate-of-the-art general-purpose compressors on a variety of real-world\ndatasets. Internal deployments at Meta have also shown consistent improvements\nin size and/or speed, with development timelines reduced from months to days.\nOpenZL thus represents an advance in practical, scalable, and maintainable data\ncompression for modern data-intensive applications.",
      "url": "http://arxiv.org/abs/2510.03203v1",
      "published_time_eastern_timestamp": 1759513229.0
    },
    {
      "title": "MonSTeR: a Unified Model for Motion, Scene, Text Retrieval",
      "summary": "Intention drives human movement in complex environments, but such movement\ncan only happen if the surrounding context supports it. Despite the intuitive\nnature of this mechanism, existing research has not yet provided tools to\nevaluate the alignment between skeletal movement (motion), intention (text),\nand the surrounding context (scene). In this work, we introduce MonSTeR, the\nfirst MOtioN-Scene-TExt Retrieval model. Inspired by the modeling of\nhigher-order relations, MonSTeR constructs a unified latent space by leveraging\nunimodal and cross-modal representations. This allows MonSTeR to capture the\nintricate dependencies between modalities, enabling flexible but robust\nretrieval across various tasks. Our results show that MonSTeR outperforms\ntrimodal models that rely solely on unimodal representations. Furthermore, we\nvalidate the alignment of our retrieval scores with human preferences through a\ndedicated user study. We demonstrate the versatility of MonSTeR's latent space\non zero-shot in-Scene Object Placement and Motion Captioning. Code and\npre-trained models are available at github.com/colloroneluca/MonSTeR.",
      "url": "http://arxiv.org/abs/2510.03200v1",
      "published_time_eastern_timestamp": 1759513070.0
    },
    {
      "title": "CoDA: Agentic Systems for Collaborative Data Visualization",
      "summary": "Deep research has revolutionized data analysis, yet data scientists still\ndevote substantial time to manually crafting visualizations, highlighting the\nneed for robust automation from natural language queries. However, current\nsystems struggle with complex datasets containing multiple files and iterative\nrefinement. Existing approaches, including simple single- or multi-agent\nsystems, often oversimplify the task, focusing on initial query parsing while\nfailing to robustly manage data complexity, code errors, or final visualization\nquality. In this paper, we reframe this challenge as a collaborative\nmulti-agent problem. We introduce CoDA, a multi-agent system that employs\nspecialized LLM agents for metadata analysis, task planning, code generation,\nand self-reflection. We formalize this pipeline, demonstrating how\nmetadata-focused analysis bypasses token limits and quality-driven refinement\nensures robustness. Extensive evaluations show CoDA achieves substantial gains\nin the overall score, outperforming competitive baselines by up to 41.5%. This\nwork demonstrates that the future of visualization automation lies not in\nisolated code generation but in integrated, collaborative agentic workflows.",
      "url": "http://arxiv.org/abs/2510.03194v1",
      "published_time_eastern_timestamp": 1759512616.0
    },
    {
      "title": "Superposition disentanglement of neural representations reveals hidden\n  alignment",
      "summary": "The superposition hypothesis states that a single neuron within a population\nmay participate in the representation of multiple features in order for the\npopulation to represent more features than the number of neurons. In\nneuroscience and AI, representational alignment metrics measure the extent to\nwhich different deep neural networks (DNNs) or brains represent similar\ninformation. In this work, we explore a critical question: \\textit{does\nsuperposition interact with alignment metrics in any undesirable way?} We\nhypothesize that models which represent the same features in \\textit{different\nsuperposition arrangements}, i.e., their neurons have different linear\ncombinations of the features, will interfere with predictive mapping metrics\n(semi-matching, soft-matching, linear regression), producing lower alignment\nthan expected. We first develop a theory for how the strict permutation metrics\nare dependent on superposition arrangements. This is tested by training sparse\nautoencoders (SAEs) to disentangle superposition in toy models, where alignment\nscores are shown to typically increase when a model's base neurons are replaced\nwith its sparse overcomplete latent codes. We find similar increases for\nDNN\\(\\rightarrow\\)DNN and DNN\\(\\rightarrow\\)brain linear regression alignment\nin the visual domain. Our results suggest that superposition disentanglement is\nnecessary for mapping metrics to uncover the true representational alignment\nbetween neural codes.",
      "url": "http://arxiv.org/abs/2510.03186v1",
      "published_time_eastern_timestamp": 1759511560.0
    },
    {
      "title": "On the Hardness of the One-Sided Code Sparsifier Problem",
      "summary": "The notion of code sparsification was introduced by Khanna, Putterman and\nSudan (arxiv.2311.00788), as an analogue to the the more established notion of\ncut sparsification in graphs and hypergraphs. In particular, for $\\alpha\\in\n(0,1)$ an (unweighted) one-sided $\\alpha$-sparsifier for a linear code\n$\\mathcal{C} \\subseteq \\mathbb{F}_2^n$ is a subset $S\\subseteq [n]$ such that\nthe weight of each codeword projected onto the coordinates in $S$ is preserved\nup to an $\\alpha$ fraction. Recently, Gharan and Sahami (arxiv.2502.02799) show\nthe existence of one-sided 1/2-sparsifiers of size $n/2+O(\\sqrt{kn})$ for any\nlinear code, where $k$ is the dimension of $\\mathcal{C}$. In this paper, we\nconsider the computational problem of finding a one-sided 1/2-sparsifier of\nminimal size, and show that it is NP-hard, via a reduction from the classical\nnearest codeword problem. We also show hardness of approximation results.",
      "url": "http://arxiv.org/abs/2510.03184v1",
      "published_time_eastern_timestamp": 1759511046.0
    },
    {
      "title": "When Names Disappear: Revealing What LLMs Actually Understand About Code",
      "summary": "Large Language Models (LLMs) achieve strong results on code tasks, but how\nthey derive program meaning remains unclear. We argue that code communicates\nthrough two channels: structural semantics, which define formal behavior, and\nhuman-interpretable naming, which conveys intent. Removing the naming channel\nseverely degrades intent-level tasks such as summarization, where models\nregress to line-by-line descriptions. Surprisingly, we also observe consistent\nreductions on execution tasks that should depend only on structure, revealing\nthat current benchmarks reward memorization of naming patterns rather than\ngenuine semantic reasoning. To disentangle these effects, we introduce a suite\nof semantics-preserving obfuscations and show that they expose identifier\nleakage across both summarization and execution. Building on these insights, we\nrelease ClassEval-Obf, an obfuscation-enhanced benchmark that systematically\nsuppresses naming cues while preserving behavior. Our results demonstrate that\nClassEval-Obf reduces inflated performance gaps, weakens memorization\nshortcuts, and provides a more reliable basis for assessing LLMs' code\nunderstanding and generalization.",
      "url": "http://arxiv.org/abs/2510.03178v1",
      "published_time_eastern_timestamp": 1759510393.0
    },
    {
      "title": "Beyond Cons: Purely Relational Data Structures",
      "summary": "We present {Kanren} (read: set-Kanren), an extension to miniKanren with\nconstraints for reasoning about sets and association lists. {Kanren} includes\nfirst-class set objects, a functionally complete family of set-theoretic\nconstraints (including membership, union, and disjointedness), and new\nconstraints for reasoning about association lists with shadowing and scoped\nlookup. These additions allow programmers to describe collections declaratively\nand lazily, without relying on structural encodings and eager search over\nrepresentation spaces. The result is improved expressiveness and operational\nbehavior in programs that manipulate abstract data -- particularly interpreters\n-- by supporting set equality based on contents, enabling finite failure. We\ndescribe the design and implementation of {Kanren} in a constraint-enabled\nminiKanren system and illustrate its use in representative examples.",
      "url": "http://arxiv.org/abs/2510.03170v1",
      "published_time_eastern_timestamp": 1759509843.0
    },
    {
      "title": "Application of the holographic equations of state for modeling\n  experiments on heavy ion collisions",
      "summary": "In this paper, we propose a method for numerical modeling of the nuclear\nmatter properties within the framework of relativistic heavy-ion collisions\nusing a holographic equation of state. Machine learning methods were applied to\naddress the regression and optimization issues during the calibration of the\nrelevant parameters using the LQCD results for quark masses that approximate\nthe physical values. Numerical simulations are performed using the iEBE-MUSIC\nand vHLLE-SMASH frameworks, which incorporate certain relativistic\nhydrodynamics solvers. We modify the code by implementing a tabulated\nholographic equation of state, enabling simulations of quark-gluon plasma\nevolution with dynamically generated initial conditions via the 3D Monte Carlo\nGlauber Model and SMASH. Finally, the spectra of produced hadrons are computed\nusing a hybrid iSS+UrQMD and Hadron Sampler+SMASH approaches at the freeze-out\nstage.12 p",
      "url": "http://arxiv.org/abs/2510.03157v1",
      "published_time_eastern_timestamp": 1759508988.0
    },
    {
      "title": "Stimulus-Voltage-Based Prediction of Action Potential Onset Timing:\n  Classical vs. Quantum-Inspired Approaches",
      "summary": "Accurate modeling of neuronal action potential (AP) onset timing is crucial\nfor understanding neural coding of danger signals. Traditional leaky\nintegrate-and-fire (LIF) models, while widely used, exhibit high relative error\nin predicting AP onset latency, especially under strong or rapidly changing\nstimuli. Inspired by recent experimental findings and quantum theory, we\npresent a quantum-inspired leaky integrate-and-fire (QI-LIF) model that treats\nAP onset as a probabilistic event, represented by a Gaussian wave packet in\ntime. This approach captures the biological variability and uncertainty\ninherent in neuronal firing. We systematically compare the relative error of AP\nonset predictions between the classical LIF and QI-LIF models using synthetic\ndata from hippocampal and sensory neurons subjected to varying stimulus\namplitudes. Our results demonstrate that the QI-LIF model significantly reduces\nprediction error, particularly for high-intensity stimuli, aligning closely\nwith observed biological responses. This work highlights the potential of\nquantum-inspired computational frameworks in advancing the accuracy of neural\nmodeling and has implications for quantum engineering approaches to\nbrain-inspired computing.",
      "url": "http://arxiv.org/abs/2510.03155v1",
      "published_time_eastern_timestamp": 1759508882.0
    },
    {
      "title": "Optimising the MeerKAT Pulsar Timing Array and towards precision pulsar\n  timing with SKA-mid",
      "summary": "Pulsar timing arrays (PTAs) are Galactic-scale nanohertz-frequency\ngravitational wave (GW) detectors. Recently, several PTAs have found evidence\nfor the presence of GWs in their datasets, but none of them have achieved a\ncommunity-defined definitive (> 5$\\sigma$) detection. Here, we identify\nlimiting noise sources for PTAs and quantify their impact on sensitivity to GWs\nunder different observing and noise modelling strategies. First, we search for\nintrinsic pulse jitter in a sample of 89 MSPs observed by the MeerKAT Pulsar\nTiming Array and obtain new jitter measurements for 20 MSPs. We then forecast\njitter noise in pulsars for the future SKA-Mid telescope, finding that the\ntiming precision of many of the best-timed MSPs would be dominated by jitter\nnoise. We then consider dispersion measure variations from the interstellar\nmedium and find that their effects are best mitigated by modelling them as a\nstationary Gaussian process with a power-law spectrum. Improving upon the\nestablished hasasia code for PTA sensitivity analysis, we assess the timing\npotential of the lower frequency UHF-band (544$-$1088\\,MHz) of MeerKAT and find\na potential increase in GW background sensitivity by $\\approx 8$\\%, relative to\nobserving at L-band. We show that this improvement relies on assumptions on the\npropagation through the interstellar medium, and highlight that if observing\nfrequency-dependent propagation effects, such as scattering noise, are present,\nwhere noise is not completely correlated across observing frequency, then the\nimprovement is significantly diminished. Using the multi-frequency receivers\nand sub-arraying flexibility of MeerKAT, we find that focussed, high-cadence\nobservations of the best MSPs can enhance the sensitivity of the array for both\nthe continuous GWs and stochastic GWB. These results highlight the role of\nMeerKAT and the MPTA in the context of international GW search efforts.",
      "url": "http://arxiv.org/abs/2510.03139v1",
      "published_time_eastern_timestamp": 1759507815.0
    },
    {
      "title": "Signature-Informed Transformer for Asset Allocation",
      "summary": "Robust asset allocation is a key challenge in quantitative finance, where\ndeep-learning forecasters often fail due to objective mismatch and error\namplification. We introduce the Signature-Informed Transformer (SIT), a novel\nframework that learns end-to-end allocation policies by directly optimizing a\nrisk-aware financial objective. SIT's core innovations include path signatures\nfor a rich geometric representation of asset dynamics and a signature-augmented\nattention mechanism embedding financial inductive biases, like lead-lag\neffects, into the model. Evaluated on daily S\\&P 100 equity data, SIT\ndecisively outperforms traditional and deep-learning baselines, especially when\ncompared to predict-then-optimize models. These results indicate that\nportfolio-aware objectives and geometry-aware inductive biases are essential\nfor risk-aware capital allocation in machine-learning systems. The code is\navailable at:\nhttps://github.com/Yoontae6719/Signature-Informed-Transformer-For-Asset-Allocation",
      "url": "http://arxiv.org/abs/2510.03129v1",
      "published_time_eastern_timestamp": 1759507101.0
    },
    {
      "title": "Taming Text-to-Sounding Video Generation via Advanced Modality Condition\n  and Interaction",
      "summary": "This study focuses on a challenging yet promising task,\nText-to-Sounding-Video (T2SV) generation, which aims to generate a video with\nsynchronized audio from text conditions, meanwhile ensuring both modalities are\naligned with text. Despite progress in joint audio-video training, two critical\nchallenges still remain unaddressed: (1) a single, shared text caption where\nthe text for video is equal to the text for audio often creates modal\ninterference, confusing the pretrained backbones, and (2) the optimal mechanism\nfor cross-modal feature interaction remains unclear. To address these\nchallenges, we first propose the Hierarchical Visual-Grounded Captioning (HVGC)\nframework that generates pairs of disentangled captions, a video caption, and\nan audio caption, eliminating interference at the conditioning stage. Based on\nHVGC, we further introduce BridgeDiT, a novel dual-tower diffusion transformer,\nwhich employs a Dual CrossAttention (DCA) mechanism that acts as a robust\n``bridge\" to enable a symmetric, bidirectional exchange of information,\nachieving both semantic and temporal synchronization. Extensive experiments on\nthree benchmark datasets, supported by human evaluations, demonstrate that our\nmethod achieves state-of-the-art results on most metrics. Comprehensive\nablation studies further validate the effectiveness of our contributions,\noffering key insights for the future T2SV task. All the codes and checkpoints\nwill be publicly released.",
      "url": "http://arxiv.org/abs/2510.03117v1",
      "published_time_eastern_timestamp": 1759506236.0
    },
    {
      "title": "Semantic Similarity in Radiology Reports via LLMs and NER",
      "summary": "Radiology report evaluation is a crucial part of radiologists' training and\nplays a key role in ensuring diagnostic accuracy. As part of the standard\nreporting workflow, a junior radiologist typically prepares a preliminary\nreport, which is then reviewed and edited by a senior radiologist to produce\nthe final report. Identifying semantic differences between preliminary and\nfinal reports is essential for junior doctors, both as a training tool and to\nhelp uncover gaps in clinical knowledge. While AI in radiology is a rapidly\ngrowing field, the application of large language models (LLMs) remains\nchallenging due to the need for specialised domain knowledge. In this paper, we\nexplore the ability of LLMs to provide explainable and accurate comparisons of\nreports in the radiology domain. We begin by comparing the performance of\nseveral LLMs in comparing radiology reports. We then assess a more traditional\napproach based on Named-Entity-Recognition (NER). However, both approaches\nexhibit limitations in delivering accurate feedback on semantic similarity. To\naddress this, we propose Llama-EntScore, a semantic similarity scoring method\nusing a combination of Llama 3.1 and NER with tunable weights to emphasise or\nde-emphasise specific types of differences. Our approach generates a\nquantitative similarity score for tracking progress and also gives an\ninterpretation of the score that aims to offer valuable guidance in reviewing\nand refining their reporting. We find our method achieves 67% exact-match\naccuracy and 93% accuracy within +/- 1 when compared to radiologist-provided\nground truth scores - outperforming both LLMs and NER used independently. Code\nis available at:\n\\href{https://github.com/otmive/llama_reports}{github.com/otmive/llama\\_reports}",
      "url": "http://arxiv.org/abs/2510.03102v1",
      "published_time_eastern_timestamp": 1759505471.0
    },
    {
      "title": "Modified logarithmic Sobolev inequalities for CSS codes",
      "summary": "We consider the class of Davies quantum semigroups modelling thermalization\nfor translation-invariant Calderbank-Shor-Steane (CSS) codes in D dimensions.\nWe prove that conditions of Dobrushin-Shlosman-type on the quantum Gibbs state\nimply a modified logarithmic Sobolev inequality with a constant that is uniform\nin the system's size. This is accomplished by generalizing parts of the\nclassical results on thermalization by Stroock, Zegarlinski, Martinelli, and\nOlivieri to the CSS quantum setting. The results in particular imply the rapid\nthermalization at any positive temperature of the toric code in 2D and the star\npart of the toric code in 3D, implying a rapid loss of stored quantum\ninformation for these models.",
      "url": "http://arxiv.org/abs/2510.03090v1",
      "published_time_eastern_timestamp": 1759504810.0
    },
    {
      "title": "A Study of Neural Polar Decoders for Communication",
      "summary": "In this paper, we adapt and analyze Neural Polar Decoders (NPDs) for\nend-to-end communication systems. While prior work demonstrated the\neffectiveness of NPDs on synthetic channels, this study extends the NPD to\nreal-world communication systems. The NPD was adapted to complete OFDM and\nsingle-carrier communication systems. To satisfy practical system requirements,\nthe NPD is extended to support any code length via rate matching, higher-order\nmodulations, and robustness across diverse channel conditions. The NPD operates\ndirectly on channels with memory, exploiting their structure to achieve higher\ndata rates without requiring pilots and a cyclic prefix. Although NPD entails\nhigher computational complexity than the standard 5G polar decoder, its neural\nnetwork architecture enables an efficient representation of channel statistics,\nresulting in manageable complexity suitable for practical systems. Experimental\nresults over 5G channels demonstrate that the NPD consistently outperforms the\n5G polar decoder in terms of BER, BLER, and throughput. These improvements are\nparticularly significant for low-rate and short-block configurations, which are\nprevalent in 5G control channels. Furthermore, NPDs applied to single-carrier\nsystems offer performance comparable to OFDM with lower PAPR, enabling\neffective single-carrier transmission over 5G channels. These results position\nthe NPD as a high-performance, pilotless, and robust decoding solution.",
      "url": "http://arxiv.org/abs/2510.03069v1",
      "published_time_eastern_timestamp": 1759503318.0
    }
  ]
}
{
  "last_updated": "2025-06-28T05:11:29.857585-04:00",
  "papers": [
    {
      "title": "Where to find Grokking in LLM Pretraining? Monitor\n  Memorization-to-Generalization without Test",
      "summary": "Grokking, i.e., test performance keeps improving long after training loss\nconverged, has been recently witnessed in neural network training, making the\nmechanism of generalization and other emerging capabilities such as reasoning\nmysterious. While prior studies usually train small models on a few toy or\nhighly-specific tasks for thousands of epochs, we conduct the first study of\ngrokking on checkpoints during one-pass pretraining of a 7B large language\nmodel (LLM), i.e., OLMoE. We compute the training loss and evaluate\ngeneralization on diverse benchmark tasks, including math reasoning, code\ngeneration, and commonsense/domain-specific knowledge retrieval tasks.\n  Our study, for the first time, verifies that grokking still happens in the\npretraining of large-scale foundation models, though different data may enter\ngrokking stages asynchronously. We further demystify grokking's \"emergence of\ngeneralization\" by investigating LLM internal dynamics. Specifically, we find\nthat training samples' pathways (i.e., expert choices across layers) evolve\nfrom random, instance-specific to more structured and shareable between samples\nduring grokking. Also, the complexity of a sample's pathway reduces despite the\nconverged loss. These indicate a memorization-to-generalization conversion,\nproviding a mechanistic explanation of delayed generalization. In the study, we\ndevelop two novel metrics to quantify pathway distance and the complexity of a\nsingle pathway. We show their ability to predict the generalization improvement\non diverse downstream tasks. They are efficient, simple to compute and solely\ndependent on training data. Hence, they have practical value for pretraining,\nenabling us to monitor the generalization performance without finetuning and\ntest. Theoretically, we show that more structured pathways reduce model\ncomplexity and improve the generalization bound.",
      "url": "http://arxiv.org/abs/2506.21551v1",
      "published_time_eastern_timestamp": 1750960798.0
    },
    {
      "title": "DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised\n  Multi-View Diffusion",
      "summary": "Reconstructing 3D objects from a single image is a long-standing challenge,\nespecially under real-world occlusions. While recent diffusion-based view\nsynthesis models can generate consistent novel views from a single RGB image,\nthey generally assume fully visible inputs and fail when parts of the object\nare occluded. This leads to inconsistent views and degraded 3D reconstruction\nquality. To overcome this limitation, we propose an end-to-end framework for\nocclusion-aware multi-view generation. Our method directly synthesizes six\nstructurally consistent novel views from a single partially occluded image,\nenabling downstream 3D reconstruction without requiring prior inpainting or\nmanual annotations. We construct a self-supervised training pipeline using the\nPix2Gestalt dataset, leveraging occluded-unoccluded image pairs and\npseudo-ground-truth views to teach the model structure-aware completion and\nview consistency. Without modifying the original architecture, we fully\nfine-tune the view synthesis model to jointly learn completion and multi-view\ngeneration. Additionally, we introduce the first benchmark for occlusion-aware\nreconstruction, encompassing diverse occlusion levels, object categories, and\nmask patterns. This benchmark provides a standardized protocol for evaluating\nfuture methods under partial occlusions. Our code is available at\nhttps://github.com/Quyans/DeOcc123.",
      "url": "http://arxiv.org/abs/2506.21544v1",
      "published_time_eastern_timestamp": 1750960706.0
    },
    {
      "title": "WorldVLA: Towards Autoregressive Action World Model",
      "summary": "We present WorldVLA, an autoregressive action world model that unifies action\nand image understanding and generation. Our WorldVLA intergrates\nVision-Language-Action (VLA) model and world model in one single framework. The\nworld model predicts future images by leveraging both action and image\nunderstanding, with the purpose of learning the underlying physics of the\nenvironment to improve action generation. Meanwhile, the action model generates\nthe subsequent actions based on image observations, aiding in visual\nunderstanding and in turn helps visual generation of the world model. We\ndemonstrate that WorldVLA outperforms standalone action and world models,\nhighlighting the mutual enhancement between the world model and the action\nmodel. In addition, we find that the performance of the action model\ndeteriorates when generating sequences of actions in an autoregressive manner.\nThis phenomenon can be attributed to the model's limited generalization\ncapability for action prediction, leading to the propagation of errors from\nearlier actions to subsequent ones. To address this issue, we propose an\nattention mask strategy that selectively masks prior actions during the\ngeneration of the current action, which shows significant performance\nimprovement in the action chunk generation task.",
      "url": "http://arxiv.org/abs/2506.21539v1",
      "published_time_eastern_timestamp": 1750960540.0
    },
    {
      "title": "Exploring the Design Space of 3D MLLMs for CT Report Generation",
      "summary": "Multimodal Large Language Models (MLLMs) have emerged as a promising way to\nautomate Radiology Report Generation (RRG). In this work, we systematically\ninvestigate the design space of 3D MLLMs, including visual input\nrepresentation, projectors, Large Language Models (LLMs), and fine-tuning\ntechniques for 3D CT report generation. We also introduce two knowledge-based\nreport augmentation methods that improve performance on the GREEN score by up\nto 10\\%, achieving the 2nd place on the MICCAI 2024 AMOS-MM challenge. Our\nresults on the 1,687 cases from the AMOS-MM dataset show that RRG is largely\nindependent of the size of LLM under the same training protocol. We also show\nthat larger volume size does not always improve performance if the original ViT\nwas pre-trained on a smaller volume size. Lastly, we show that using a\nsegmentation mask along with the CT volume improves performance. The code is\npublicly available at https://github.com/bowang-lab/AMOS-MM-Solution",
      "url": "http://arxiv.org/abs/2506.21535v1",
      "published_time_eastern_timestamp": 1750960460.0
    },
    {
      "title": "\"What's Up, Doc?\": Analyzing How Users Seek Health Information in\n  Large-Scale Conversational AI Datasets",
      "summary": "People are increasingly seeking healthcare information from large language\nmodels (LLMs) via interactive chatbots, yet the nature and inherent risks of\nthese conversations remain largely unexplored. In this paper, we filter\nlarge-scale conversational AI datasets to achieve HealthChat-11K, a curated\ndataset of 11K real-world conversations composed of 25K user messages. We use\nHealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs\nwhen seeking healthcare information in order to systematically study user\ninteractions across 21 distinct health specialties. Our analysis reveals\ninsights into the nature of how and why users seek health information, such as\ncommon interactions, instances of incomplete context, affective behaviors, and\ninteractions (e.g., leading questions) that can induce sycophancy, underscoring\nthe need for improvements in the healthcare support capabilities of LLMs\ndeployed as conversational AI. Code and artifacts to retrieve our analyses and\ncombine them into a curated dataset can be found here:\nhttps://github.com/yahskapar/HealthChat",
      "url": "http://arxiv.org/abs/2506.21532v1",
      "published_time_eastern_timestamp": 1750960338.0
    },
    {
      "title": "Detectability and Parameter Estimation for Einstein Telescope\n  Configurations with GWJulia",
      "summary": "Future gravitational-wave (GW) detectors are expected to detect tens of\nthousands of compact binary coalescences (CBC) per year, depending also on the\nfinal detectors layout. For this reason, it is essential to have a fast,\nreliable tool for forecasting how different detector layouts will affect\nparameter estimation for these events. The Fisher Information Matrix (FIM) is a\ncommon tool for tackling this problem. In this paper, we present a new open\nsource code GWJulia to perform FIM analysis of CBC parameters, i.e., stellar\nblack-hole binaries (BBH), neutron star binaries (BNS), and neutron star-black\nhole binaries (NSBH). The code is purely written in Julia, making it fast while\nmaintaining a high level of accuracy. We consider a set of case studies to\ncompare different Einstein Telescope (ET) designs. We compare a 10km triangular\nconfiguration with two 15km L-shaped detectors with different orientations and\ntemperatures. We discuss also the accuracy of combinations of parameters, which\nis very informative for cosmology or population studies. Finally, we focus on\nthe detection of golden events and explore how the FIM can guide posterior\nsampling of GW signals using a novel Hamiltonian Monte Carlo (HMC) sampler. The\ncode is publicly available at https://github.com/andrea-begnoni/GW.jl",
      "url": "http://arxiv.org/abs/2506.21530v1",
      "published_time_eastern_timestamp": 1750960219.0
    },
    {
      "title": "WAFT: Warping-Alone Field Transforms for Optical Flow",
      "summary": "We introduce Warping-Alone Field Transforms (WAFT), a simple and effective\nmethod for optical flow. WAFT is similar to RAFT but replaces cost volume with\nhigh-resolution warping, achieving better accuracy with lower memory cost. This\ndesign challenges the conventional wisdom that constructing cost volumes is\nnecessary for strong performance. WAFT is a simple and flexible\nmeta-architecture with minimal inductive biases and reliance on custom designs.\nCompared with existing methods, WAFT ranks 1st on Spring and KITTI benchmarks,\nachieves the best zero-shot generalization on KITTI, while being up to 4.1x\nfaster than methods with similar performance. Code and model weights are\navailable at https://github.com/princeton-vl/WAFT.",
      "url": "http://arxiv.org/abs/2506.21526v1",
      "published_time_eastern_timestamp": 1750960079.0
    },
    {
      "title": "Benchmarking and Parallelization of Electrostatic Particle-In-Cell for\n  low-temperature Plasma Simulation by particle-thread Binding",
      "summary": "The Particle-In-Cell (PIC) method for plasma simulation tracks particle phase\nspace information using particle and grid data structures. High computational\ncosts in 2D and 3D device-scale PIC simulations necessitate parallelization,\nwith the Charge Deposition (CD) subroutine often becoming a bottleneck due to\nfrequent particle-grid interactions. Conventional methods mitigate dependencies\nby generating private grids for each core, but this approach faces scalability\nissues. We propose a novel approach based on a particle-thread binding strategy\nthat requires only four private grids per node in distributed memory systems or\nfour private grids in shared memory systems, enhancing CD scalability and\nperformance while maintaining conventional data structures and requiring\nminimal changes to existing PIC codes. This method ensures complete\naccessibility of grid data structure for concurrent threads and avoids\nsimultaneous access to particles within the same cell using additional\nfunctions and flags. Performance evaluations using a PIC benchmark for\nlow-temperature partially magnetized E x B discharge simulation on a shared\nmemory as well as a distributed memory system (1000 cores) demonstrate the\nmethod's scalability, and additionally, we show the method has little hardware\ndependency.",
      "url": "http://arxiv.org/abs/2506.21524v1",
      "published_time_eastern_timestamp": 1750959853.0
    },
    {
      "title": "G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation",
      "summary": "Multimodal learning aims to leverage information from diverse data modalities\nto achieve more comprehensive performance. However, conventional multimodal\nmodels often suffer from modality imbalance, where one or a few modalities\ndominate model optimization, leading to suboptimal feature representation and\nunderutilization of weak modalities. To address this challenge, we introduce\nGradient-Guided Distillation (G$^{2}$D), a knowledge distillation framework\nthat optimizes the multimodal model with a custom-built loss function that\nfuses both unimodal and multimodal objectives. G$^{2}$D further incorporates a\ndynamic sequential modality prioritization (SMP) technique in the learning\nprocess to ensure each modality leads the learning process, avoiding the\npitfall of stronger modalities overshadowing weaker ones. We validate G$^{2}$D\non multiple real-world datasets and show that G$^{2}$D amplifies the\nsignificance of weak modalities while training and outperforms state-of-the-art\nmethods in classification and regression tasks. Our code is available at\nhttps://github.com/rAIson-Lab/G2D.",
      "url": "http://arxiv.org/abs/2506.21514v1",
      "published_time_eastern_timestamp": 1750959456.0
    },
    {
      "title": "Mitigating Hallucination of Large Vision-Language Models via Dynamic\n  Logits Calibration",
      "summary": "Large Vision-Language Models (LVLMs) have demonstrated significant\nadvancements in multimodal understanding, yet they are frequently hampered by\nhallucination-the generation of text that contradicts visual input. Existing\ntraining-free decoding strategies exhibit critical limitations, including the\nuse of static constraints that do not adapt to semantic drift during\ngeneration, inefficiency stemming from the need for multiple forward passes,\nand degradation of detail due to overly rigid intervention rules. To overcome\nthese challenges, this paper introduces Dynamic Logits Calibration (DLC), a\nnovel training-free decoding framework designed to dynamically align text\ngeneration with visual evidence at inference time. At the decoding phase, DLC\nstep-wise employs CLIP to assess the semantic alignment between the input image\nand the generated text sequence. Then, the Relative Visual Advantage (RVA) of\ncandidate tokens is evaluated against a dynamically updated contextual\nbaseline, adaptively adjusting output logits to favor tokens that are visually\ngrounded. Furthermore, an adaptive weighting mechanism, informed by a real-time\ncontext alignment score, carefully balances the visual guidance while ensuring\nthe overall quality of the textual output. Extensive experiments conducted\nacross diverse benchmarks and various LVLM architectures (such as LLaVA,\nInstructBLIP, and MiniGPT-4) demonstrate that DLC significantly reduces\nhallucinations, outperforming current methods while maintaining high inference\nefficiency by avoiding multiple forward passes. Overall, we present an\neffective and efficient decoding-time solution to mitigate hallucinations,\nthereby enhancing the reliability of LVLMs for more practices. Code will be\nreleased on Github.",
      "url": "http://arxiv.org/abs/2506.21509v1",
      "published_time_eastern_timestamp": 1750959340.0
    },
    {
      "title": "Ad-Hoc Human-AI Coordination Challenge",
      "summary": "Achieving seamless coordination between AI agents and humans is crucial for\nreal-world applications, yet it remains a significant open challenge. Hanabi is\na cooperative card game featuring imperfect information, constrained\ncommunication, theory of mind requirements, and coordinated action -- making it\nan ideal testbed for human-AI coordination. However, its use for human-AI\ninteraction has been limited by the challenges of human evaluation. In this\nwork, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to\novercome the constraints of costly and difficult-to-reproduce human\nevaluations. We develop \\textit{human proxy agents} on a large-scale human\ndataset that serve as robust, cheap, and reproducible human-like evaluation\npartners in AH2AC2. To encourage the development of data-efficient methods, we\nopen-source a dataset of 3,079 games, deliberately limiting the amount of\navailable human gameplay data. We present baseline results for both two- and\nthree- player Hanabi scenarios. To ensure fair evaluation, we host the proxy\nagents through a controlled evaluation system rather than releasing them\npublicly. The code is available at\n\\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.",
      "url": "http://arxiv.org/abs/2506.21490v1",
      "published_time_eastern_timestamp": 1750958392.0
    },
    {
      "title": "Quasar cosmology II: joint analyses with Cosmic Microwave Background",
      "summary": "Currently, the increasing availability of accurate cosmological probes leads\nto the emergence of tensions between data on the one hand and between\ntheoretical predictions and direct observations on the other. Moreover, after\n25 years since the discovery of the accelerated expansion of the Universe has\nelected the $\\Lambda$CDM model as the reference model, resolving shortcomings\nof the standard cosmological model seems to be an unpostponed priority. Hence,\nit is key to test alternative models and investigate new cosmological probes at\ndistances that range from the late to the early Universe, namely between the\ncosmic microwave background (CMB) and type Ia supernovae and baryonic acoustic\noscillations (BAO) data. Bargiacchi et al. (2022) for the first time analysed\ndark energy (DE) models using quasars (QSOs) while also testing their\nconsistency with BAO. Here, we carry on by exploring the compatibility of QSOs\nwith both CMB data and dark energy survey measurements against the standard\ncosmological model and some DE extensions, such as the $w$CDM and\nChevallier-Polarski-Linder parameterisations. We also consider an interacting\ndark matter and vacuum energy scenario, where vacuum energy perturbations\naffect the evolution of the matter growth rate in a decomposed Chaplygin gas\nmodel. We implement the QSO probe in Cobaya Markov chain Monte Carlo algorithm,\nusing Botzmann solver codes as Cosmic Linear Anisotropy Solving System (CLASS)\nfor the theory predictions. Our work shows that simple DE deviations from\n$\\Lambda$CDM model do not reconcile the data and that only more complex models\nof interaction in the dark sector can succeed in solving the discrepancies of\nprobes at all scales.",
      "url": "http://arxiv.org/abs/2506.21477v1",
      "published_time_eastern_timestamp": 1750957640.0
    },
    {
      "title": "Global and Local Entailment Learning for Natural World Imagery",
      "summary": "Learning the hierarchical structure of data in vision-language models is a\nsignificant challenge. Previous works have attempted to address this challenge\nby employing entailment learning. However, these approaches fail to model the\ntransitive nature of entailment explicitly, which establishes the relationship\nbetween order and semantics within a representation space. In this work, we\nintroduce Radial Cross-Modal Embeddings (RCME), a framework that enables the\nexplicit modeling of transitivity-enforced entailment. Our proposed framework\noptimizes for the partial order of concepts within vision-language models. By\nleveraging our framework, we develop a hierarchical vision-language foundation\nmodel capable of representing the hierarchy in the Tree of Life. Our\nexperiments on hierarchical species classification and hierarchical retrieval\ntasks demonstrate the enhanced performance of our models compared to the\nexisting state-of-the-art models. Our code and models are open-sourced at\nhttps://vishu26.github.io/RCME/index.html.",
      "url": "http://arxiv.org/abs/2506.21476v1",
      "published_time_eastern_timestamp": 1750957506.0
    },
    {
      "title": "Benchmarking Deep Learning and Vision Foundation Models for Atypical vs.\n  Normal Mitosis Classification with Cross-Dataset Evaluation",
      "summary": "Atypical mitoses mark a deviation in the cell division process that can be an\nindependent prognostically relevant marker for tumor malignancy. However, their\nidentification remains challenging due to low prevalence, at times subtle\nmorphological differences from normal mitoses, low inter-rater agreement among\npathologists, and class imbalance in datasets. Building on the Atypical Mitosis\ndataset for Breast Cancer (AMi-Br), this study presents a comprehensive\nbenchmark comparing deep learning approaches for automated atypical mitotic\nfigure (AMF) classification, including baseline models, foundation models with\nlinear probing, and foundation models fine-tuned with low-rank adaptation\n(LoRA). For rigorous evaluation, we further introduce two new hold-out AMF\ndatasets - AtNorM-Br, a dataset of mitoses from the The TCGA breast cancer\ncohort, and AtNorM-MD, a multi-domain dataset of mitoses from the MIDOG++\ntraining set. We found average balanced accuracy values of up to 0.8135,\n0.7696, and 0.7705 on the in-domain AMi-Br and the out-of-domain AtNorm-Br and\nAtNorM-MD datasets, respectively, with the results being particularly good for\nLoRA-based adaptation of the Virchow-line of foundation models. Our work shows\nthat atypical mitosis classification, while being a challenging problem, can be\neffectively addressed through the use of recent advances in transfer learning\nand model fine-tuning techniques. We make available all code and data used in\nthis paper in this github repository:\nhttps://github.com/DeepMicroscopy/AMi-Br_Benchmark.",
      "url": "http://arxiv.org/abs/2506.21444v1",
      "published_time_eastern_timestamp": 1750955442.0
    },
    {
      "title": "HyperSORT: Self-Organising Robust Training with hyper-networks",
      "summary": "Medical imaging datasets often contain heterogeneous biases ranging from\nerroneous labels to inconsistent labeling styles. Such biases can negatively\nimpact deep segmentation networks performance. Yet, the identification and\ncharacterization of such biases is a particularly tedious and challenging task.\nIn this paper, we introduce HyperSORT, a framework using a hyper-network\npredicting UNets' parameters from latent vectors representing both the image\nand annotation variability. The hyper-network parameters and the latent vector\ncollection corresponding to each data sample from the training set are jointly\nlearned. Hence, instead of optimizing a single neural network to fit a dataset,\nHyperSORT learns a complex distribution of UNet parameters where low density\nareas can capture noise-specific patterns while larger modes robustly segment\norgans in differentiated but meaningful manners. We validate our method on two\n3D abdominal CT public datasets: first a synthetically perturbed version of the\nAMOS dataset, and TotalSegmentator, a large scale dataset containing real\nunknown biases and errors. Our experiments show that HyperSORT creates a\nstructured mapping of the dataset allowing the identification of relevant\nsystematic biases and erroneous samples. Latent space clusters yield UNet\nparameters performing the segmentation task in accordance with the underlying\nlearned systematic bias. The code and our analysis of the TotalSegmentator\ndataset are made available: https://github.com/ImFusionGmbH/HyperSORT",
      "url": "http://arxiv.org/abs/2506.21430v1",
      "published_time_eastern_timestamp": 1750954354.0
    },
    {
      "title": "EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian\n  Splatting",
      "summary": "Efficient three-dimensional reconstruction and real-time visualization are\ncritical in surgical scenarios such as endoscopy. In recent years, 3D Gaussian\nSplatting (3DGS) has demonstrated remarkable performance in efficient 3D\nreconstruction and rendering. Most 3DGS-based Simultaneous Localization and\nMapping (SLAM) methods only rely on the appearance constraints for optimizing\nboth 3DGS and camera poses. However, in endoscopic scenarios, the challenges\ninclude photometric inconsistencies caused by non-Lambertian surfaces and\ndynamic motion from breathing affects the performance of SLAM systems. To\naddress these issues, we additionally introduce optical flow loss as a\ngeometric constraint, which effectively constrains both the 3D structure of the\nscene and the camera motion. Furthermore, we propose a depth regularisation\nstrategy to mitigate the problem of photometric inconsistencies and ensure the\nvalidity of 3DGS depth rendering in endoscopic scenes. In addition, to improve\nscene representation in the SLAM system, we improve the 3DGS refinement\nstrategy by focusing on viewpoints corresponding to Keyframes with suboptimal\nrendering quality frames, achieving better rendering results. Extensive\nexperiments on the C3VD static dataset and the StereoMIS dynamic dataset\ndemonstrate that our method outperforms existing state-of-the-art methods in\nnovel view synthesis and pose estimation, exhibiting high performance in both\nstatic and dynamic surgical scenes. The source code will be publicly available\nupon paper acceptance.",
      "url": "http://arxiv.org/abs/2506.21420v1",
      "published_time_eastern_timestamp": 1750954006.0
    },
    {
      "title": "Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction",
      "summary": "This paper presents an end-to-end framework for reconstructing 3D parametric\ncurves directly from multi-view edge maps. Contrasting with existing two-stage\nmethods that follow a sequential ``edge point cloud reconstruction and\nparametric curve fitting'' pipeline, our one-stage approach optimizes 3D\nparametric curves directly from 2D edge maps, eliminating error accumulation\ncaused by the inherent optimization gap between disconnected stages. However,\nparametric curves inherently lack suitability for rendering-based multi-view\noptimization, necessitating a complementary representation that preserves their\ngeometric properties while enabling differentiable rendering. We propose a\nnovel bi-directional coupling mechanism between parametric curves and\nedge-oriented Gaussian components. This tight correspondence formulates a\ncurve-aware Gaussian representation, \\textbf{CurveGaussian}, that enables\ndifferentiable rendering of 3D curves, allowing direct optimization guided by\nmulti-view evidence. Furthermore, we introduce a dynamically adaptive topology\noptimization framework during training to refine curve structures through\nlinearization, merging, splitting, and pruning operations. Comprehensive\nevaluations on the ABC dataset and real-world benchmarks demonstrate our\none-stage method's superiority over two-stage alternatives, particularly in\nproducing cleaner and more robust reconstructions. Additionally, by directly\noptimizing parametric curves, our method significantly reduces the parameter\ncount during training, achieving both higher efficiency and superior\nperformance compared to existing approaches.",
      "url": "http://arxiv.org/abs/2506.21401v1",
      "published_time_eastern_timestamp": 1750952888.0
    },
    {
      "title": "TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in\n  Multimodal Table Understanding",
      "summary": "Multimodal understanding of tables in real-world contexts is challenging due\nto the complexity of structure, symbolic density, and visual degradation (blur,\nskew, watermarking, incomplete structures or fonts, multi-span or\nhierarchically nested layouts). Existing multimodal large language models\n(MLLMs) struggle with such WildStruct conditions, resulting in limited\nperformance and poor generalization. To address these challenges, we propose\nTableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture\nspecifically designed for robust, structured reasoning over multimodal table\ndata. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which\npredicts latent semantic token roles (e.g., header, data cell, axis, formula)\nand dynamically routes table elements to specialized experts (Table-to-HTML,\nTable-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed\nby symbolic reasoning graphs. To facilitate effective alignment-driven\npretraining, we introduce the large-scale TableMoE-Align dataset, consisting of\n1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and\nindustry, utilized exclusively for model pretraining. For evaluation, we curate\nand release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,\nWMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models\nunder real-world multimodal degradation and structural complexity. Experimental\nresults demonstrate that TableMoE significantly surpasses existing\nstate-of-the-art models. Extensive ablation studies validate each core\ncomponent, emphasizing the critical role of Neuro-Symbolic Routing and\nstructured expert alignment. Through qualitative analyses, we further showcase\nTableMoE's interpretability and enhanced robustness, underscoring the\neffectiveness of integrating neuro-symbolic reasoning for multimodal table\nunderstanding.",
      "url": "http://arxiv.org/abs/2506.21393v1",
      "published_time_eastern_timestamp": 1750952494.0
    },
    {
      "title": "ShotBench: Expert-Level Cinematic Understanding in Vision-Language\n  Models",
      "summary": "Cinematography, the fundamental visual language of film, is essential for\nconveying narrative, emotion, and aesthetic quality. While recent\nVision-Language Models (VLMs) demonstrate strong general visual understanding,\ntheir proficiency in comprehending the nuanced cinematic grammar embedded\nwithin individual shots remains largely unexplored and lacks robust evaluation.\nThis critical gap limits both fine-grained visual comprehension and the\nprecision of AI-assisted video generation. To address this, we introduce\n\\textbf{ShotBench}, a comprehensive benchmark specifically designed for\ncinematic language understanding. It features over 3.5k expert-annotated QA\npairs from images and video clips, meticulously curated from over 200 acclaimed\n(predominantly Oscar-nominated) films and spanning eight key cinematography\ndimensions. Our evaluation of 24 leading VLMs on ShotBench reveals their\nsubstantial limitations: even the top-performing model achieves less than 60\\%\naverage accuracy, particularly struggling with fine-grained visual cues and\ncomplex spatial reasoning. To catalyze advancement in this domain, we construct\n\\textbf{ShotQA}, a large-scale multimodal dataset comprising approximately 70k\ncinematic QA pairs. Leveraging ShotQA, we develop \\textbf{ShotVL} through\nsupervised fine-tuning and Group Relative Policy Optimization. ShotVL\nsignificantly outperforms all existing open-source and proprietary models on\nShotBench, establishing new \\textbf{state-of-the-art} performance. We\nopen-source our models, data, and code to foster rapid progress in this crucial\narea of AI-driven cinematic understanding and generation.",
      "url": "http://arxiv.org/abs/2506.21356v1",
      "published_time_eastern_timestamp": 1750950561.0
    },
    {
      "title": "Bayesian Modeling for Aggregated Relational Data: A Unified Perspective",
      "summary": "Aggregated relational data is widely collected to study social network\ntheory. It has been used to address a variety of key problems in fields such as\nsociology, public health and economics. ARD models enable researchers to\nestimate the size of hidden populations, estimate personal network sizes,\nunderstand global network structures and fit complex latent variable models to\nmassive network data. Many of the successes of ARD models have been driven by\nthe utilisation of Bayesian modeling, which provides a principled and flexible\nway to fit and interpret these models for real data. In this work we create a\ncoherent collection of Bayesian implementations of existing models for ARD,\nwithin the state of the art Bayesian sampling language, Stan. Our\nimplementations incorporate within-iteration rescaling procedures by default,\neliminating the typical post-processing step and improving algorithm run time\nand convergence diagnostics. Bayesian modelling permits natural tools for model\ncriticism and comparison, which is largely unexplored in the ARD setting. Using\nsynthetic data, we demonstrate how well competing models recover true personal\nnetwork sizes and subpopulation sizes and how well existing posterior\npredictive checks compare across a range of Bayesian ARD models. We implement\nand provide code to leverage Stan's modelling framework for leave-one-out\ncross-validation, which has not previously been examined for ARD models.",
      "url": "http://arxiv.org/abs/2506.21353v1",
      "published_time_eastern_timestamp": 1750950475.0
    }
  ]
}
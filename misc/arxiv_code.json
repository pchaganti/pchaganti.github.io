{
  "last_updated": "2025-10-12T05:11:00.821068-04:00",
  "papers": [
    {
      "title": "BLAZER: Bootstrapping LLM-based Manipulation Agents with Zero-Shot Data\n  Generation",
      "summary": "Scaling data and models has played a pivotal role in the remarkable progress\nof computer vision and language. Inspired by these domains, recent efforts in\nrobotics have similarly focused on scaling both data and model size to develop\nmore generalizable and robust policies. However, unlike vision and language,\nrobotics lacks access to internet-scale demonstrations across diverse robotic\ntasks and environments. As a result, the scale of existing datasets typically\nsuffers from the need for manual data collection and curation. To address this\nproblem, here we propose BLAZER, a framework that learns manipulation policies\nfrom automatically generated training data. We build on the zero-shot\ncapabilities of LLM planners and automatically generate demonstrations for\ndiverse manipulation tasks in simulation. Successful examples are then used to\nfinetune an LLM and to improve its planning capabilities without human\nsupervision. Notably, while BLAZER training requires access to the simulator's\nstate, we demonstrate direct transfer of acquired skills to sensor-based\nmanipulation. Through extensive experiments, we show BLAZER to significantly\nimprove zero-shot manipulation in both simulated and real environments.\nMoreover, BLAZER improves on tasks outside of its training pool and enables\ndownscaling of LLM models. Our code and data will be made publicly available on\nthe project page.",
      "url": "http://arxiv.org/abs/2510.08572v1",
      "published_time_eastern_timestamp": 1760032798.0
    },
    {
      "title": "MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning",
      "summary": "Vision language models (VLMs) are increasingly deployed as controllers with\naccess to external tools for complex reasoning and decision-making, yet their\neffectiveness remains limited by the scarcity of high-quality multimodal\ntrajectories and the cost of manual annotation. We address this challenge with\na vision-centric agent tuning framework that automatically synthesizes\nmultimodal trajectories, generates step-wise preference pairs, and trains a VLM\ncontroller for robust tool-use reasoning. Our pipeline first constructs\nM-TRACE, a large-scale dataset of 28.5K multimodal tasks with 177K verified\ntrajectories, enabling imitation-based trajectory tuning. Building on this, we\ndevelop MATRIX Agent, a controller finetuned on M-TRACE for step-wise tool\nreasoning. To achieve finer alignment, we further introduce Pref-X, a set of\n11K automatically generated preference pairs, and optimize MATRIX on it via\nstep-wise preference learning. Across three benchmarks, Agent-X, GTA, and GAIA,\nMATRIX consistently surpasses both open- and closed-source VLMs, demonstrating\nscalable and effective multimodal tool use. Our data and code is avaliable at\nhttps://github.com/mbzuai-oryx/MATRIX.",
      "url": "http://arxiv.org/abs/2510.08567v1",
      "published_time_eastern_timestamp": 1760032794.0
    },
    {
      "title": "How to Teach Large Multimodal Models New Skills",
      "summary": "How can we teach large multimodal models (LMMs) new skills without erasing\nprior abilities? We study sequential fine-tuning on five target skills while\nmonitoring general ability on eight held-out benchmarks across three model\nfamilies. We observe that apparent \"forgetting\" on held-out tasks after narrow\nfine-tuning can partly recover at later stages. We trace this behavior to a\nmeasurable shift in the output token distribution, manifested through a simple\ncounting-bias probe that co-varies with forgetting. Guided by this picture, we\nidentify two simple, robust tuning recipes that learn strongly while limiting\ndrift: (i) updating only the self-attention projection layers, and (ii)\nupdating only the MLP Gate&Up while freezing the Down projection. Across models\nand tasks, these choices deliver strong target gains while largely preserving\nheld-out performance. Code is available at\nhttps://github.com/jessemelpolio/LMM_CL",
      "url": "http://arxiv.org/abs/2510.08564v1",
      "published_time_eastern_timestamp": 1760032777.0
    },
    {
      "title": "ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous\n  Driving",
      "summary": "End-to-end autonomous driving (E2EAD) systems, which learn to predict future\ntrajectories directly from sensor data, are fundamentally challenged by the\ninherent spatio-temporal imbalance of trajectory data. This imbalance creates a\nsignificant optimization burden, causing models to learn spurious correlations\ninstead of causal inference, while also prioritizing uncertain, distant\npredictions, thereby compromising immediate safety. To address these issues, we\npropose ResAD, a novel Normalized Residual Trajectory Modeling framework.\nInstead of predicting the future trajectory directly, our approach reframes the\nlearning task to predict the residual deviation from a deterministic inertial\nreference. The inertial reference serves as a counterfactual, forcing the model\nto move beyond simple pattern recognition and instead identify the underlying\ncausal factors (e.g., traffic rules, obstacles) that necessitate deviations\nfrom a default, inertially-guided path. To deal with the optimization imbalance\ncaused by uncertain, long-term horizons, ResAD further incorporates Point-wise\nNormalization of the predicted residual. It re-weights the optimization\nobjective, preventing large-magnitude errors associated with distant, uncertain\nwaypoints from dominating the learning signal. Extensive experiments validate\nthe effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a\nstate-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two\ndenoising steps, demonstrating that our approach significantly simplifies the\nlearning task and improves model performance. The code will be released to\nfacilitate further research.",
      "url": "http://arxiv.org/abs/2510.08562v1",
      "published_time_eastern_timestamp": 1760032776.0
    },
    {
      "title": "Improving Reasoning for Diffusion Language Models via Group Diffusion\n  Policy Optimization",
      "summary": "Diffusion language models (DLMs) enable parallel, order-agnostic generation\nwith iterative refinement, offering a flexible alternative to autoregressive\nlarge language models (LLMs). However, adapting reinforcement learning (RL)\nfine-tuning to DLMs remains an open challenge because of the intractable\nlikelihood. Pioneering work such as diffu-GRPO estimated token-level\nlikelihoods via one-step unmasking. While computationally efficient, this\napproach is severely biased. A more principled foundation lies in\nsequence-level likelihoods, where the evidence lower bound (ELBO) serves as a\nsurrogate. Yet, despite this clean mathematical connection, ELBO-based methods\nhave seen limited adoption due to the prohibitive cost of likelihood\nevaluation. In this work, we revisit ELBO estimation and disentangle its\nsources of variance. This decomposition motivates reducing variance through\nfast, deterministic integral approximations along a few pivotal dimensions.\nBuilding on this insight, we introduce \\textbf{Group Diffusion Policy\nOptimization (GDPO)}, a new RL algorithm tailored for DLMs. GDPO leverages\nsimple yet effective Semi-deterministic Monte Carlo schemes to mitigate the\nvariance explosion of ELBO estimators under vanilla double Monte Carlo\nsampling, yielding a provably lower-variance estimator under tight evaluation\nbudgets. Empirically, GDPO achieves consistent gains over pretrained\ncheckpoints and outperforms diffu-GRPO, one of the state-of-the-art baselines,\non the majority of math, reasoning, and coding benchmarks.",
      "url": "http://arxiv.org/abs/2510.08554v1",
      "published_time_eastern_timestamp": 1760032687.0
    },
    {
      "title": "Dream to Recall: Imagination-Guided Experience Retrieval for\n  Memory-Persistent Vision-and-Language Navigation",
      "summary": "Vision-and-Language Navigation (VLN) requires agents to follow natural\nlanguage instructions through environments, with memory-persistent variants\ndemanding progressive improvement through accumulated experience. Existing\napproaches for memory-persistent VLN face critical limitations: they lack\neffective memory access mechanisms, instead relying on entire memory\nincorporation or fixed-horizon lookup, and predominantly store only\nenvironmental observations while neglecting navigation behavioral patterns that\nencode valuable decision-making strategies. We present Memoir, which employs\nimagination as a retrieval mechanism grounded by explicit memory: a world model\nimagines future navigation states as queries to selectively retrieve relevant\nenvironmental observations and behavioral histories. The approach comprises: 1)\na language-conditioned world model that imagines future states serving dual\npurposes: encoding experiences for storage and generating retrieval queries; 2)\nHybrid Viewpoint-Level Memory that anchors both observations and behavioral\npatterns to viewpoints, enabling hybrid retrieval; and 3) an\nexperience-augmented navigation model that integrates retrieved knowledge\nthrough specialized encoders. Extensive evaluation across diverse\nmemory-persistent VLN benchmarks with 10 distinctive testing scenarios\ndemonstrates Memoir's effectiveness: significant improvements across all\nscenarios, with 5.4% SPL gains on IR2R over the best memory-persistent\nbaseline, accompanied by 8.3x training speedup and 74% inference memory\nreduction. The results validate that predictive retrieval of both environmental\nand behavioral memories enables more effective navigation, with analysis\nindicating substantial headroom (73.3% vs 93.4% upper bound) for this\nimagination-guided paradigm. Code at https://github.com/xyz9911/Memoir.",
      "url": "http://arxiv.org/abs/2510.08553v1",
      "published_time_eastern_timestamp": 1760032681.0
    },
    {
      "title": "Single-Shot Universality in Quantum LDPC Codes via Code-Switching",
      "summary": "Code-switching is a powerful technique in quantum error correction that\nallows one to leverage the complementary strengths of different codes to\nachieve fault-tolerant universal quantum computation. However, existing\ncode-switching protocols that encapsulate recent generalized lattice surgery\napproaches often either require many rounds of measurements to ensure\nfault-tolerance or suffer from low code rates. We present a single-shot,\nuniversal protocol that uses code-switching between high-rate quantum codes to\nperform fault-tolerant quantum computation. To our best knowledge, our work\ncontains the first universal fault-tolerant quantum computation protocol that\nachieves what we term single-shot universality on high-rate codes that is\ncharacterized by (i) single-shot error correction, (ii) single-shot state\npreparation, as well as (iii) universal logical gates and logical measurements\nwith constant depth circuits. We achieve this feat with single-shot\ncode-switching between constant-rate 2D hypergraph product (HGP) codes and\nhigh-rate 3D HGP codes that can be viewed as a generalization of Bombin's\ndimensional jump for color codes and Hillmann et al.'s single-shot lattice\nsurgery for higher-dimensional topological codes. In addition, we prove the\nfault-tolerance of our code-switching protocol under both the adversarial and\nlocal-stochastic noise models. We introduce a vastly simpler recipe to\nconstruct high-rate 3D HGP codes with transversal CCZ gates that grants immense\nflexibility in the choice of expander graphs and local codes, allowing us to\nexpand the search space for codes with good parameters and interesting logical\ngates. Our work opens an alternative path towards universal fault-tolerant\nquantum computation with low space-time overhead by circumventing the need for\nmagic state distillation.",
      "url": "http://arxiv.org/abs/2510.08552v1",
      "published_time_eastern_timestamp": 1760032666.0
    },
    {
      "title": "SpatialLadder: Progressive Training for Spatial Reasoning in\n  Vision-Language Models",
      "summary": "Spatial reasoning remains a fundamental challenge for Vision-Language Models\n(VLMs), with current approaches struggling to achieve robust performance\ndespite recent advances. We identify that this limitation stems from a critical\ngap: existing methods attempt to learn spatial reasoning directly without\nestablishing the hierarchical foundations of perception and understanding. To\naddress this challenge, we present a comprehensive methodology for building\nspatial intelligence progressively. We introduce SpatialLadder-26k, a\nmultimodal dataset containing 26,610 samples spanning object localization,\nsingle image, multi-view, and video spatial reasoning tasks, constructed\nthrough a standardized pipeline that ensures systematic coverage across\nmodalities. Building on this dataset, we design a three-stage progressive\ntraining framework that (1) establishes spatial perception through object\nlocalization, (2) develops spatial understanding through multi-dimensional\nspatial tasks, and (3) strengthens complex reasoning via reinforcement learning\nwith verifiable rewards. This approach yields SpatialLadder, a 3B-parameter\nmodel that achieves state-of-the-art performance on spatial reasoning\nbenchmarks, with 23.4% average improvement over the base model, surpassing\nGPT-4o by 20.8% and Gemini-2.0-Flash by 10.1%. Notably, SpatialLadder maintains\nstrong generalization with 7.2% improvement on out-of-domain benchmarks,\ndemonstrating that progressive training from perception to reasoning is\nessential for robust spatial intelligence.",
      "url": "http://arxiv.org/abs/2510.08531v1",
      "published_time_eastern_timestamp": 1760032254.0
    },
    {
      "title": "X2Video: Adapting Diffusion Models for Multimodal Controllable Neural\n  Video Rendering",
      "summary": "We present X2Video, the first diffusion model for rendering photorealistic\nvideos guided by intrinsic channels including albedo, normal, roughness,\nmetallicity, and irradiance, while supporting intuitive multi-modal controls\nwith reference images and text prompts for both global and local regions. The\nintrinsic guidance allows accurate manipulation of color, material, geometry,\nand lighting, while reference images and text prompts provide intuitive\nadjustments in the absence of intrinsic information. To enable these\nfunctionalities, we extend the intrinsic-guided image generation model XRGB to\nvideo generation by employing a novel and efficient Hybrid Self-Attention,\nwhich ensures temporal consistency across video frames and also enhances\nfidelity to reference images. We further develop a Masked Cross-Attention to\ndisentangle global and local text prompts, applying them effectively onto\nrespective local and global regions. For generating long videos, our novel\nRecursive Sampling method incorporates progressive frame sampling, combining\nkeyframe prediction and frame interpolation to maintain long-range temporal\nconsistency while preventing error accumulation. To support the training of\nX2Video, we assembled a video dataset named InteriorVideo, featuring 1,154\nrooms from 295 interior scenes, complete with reliable ground-truth intrinsic\nchannel sequences and smooth camera trajectories. Both qualitative and\nquantitative evaluations demonstrate that X2Video can produce long, temporally\nconsistent, and photorealistic videos guided by intrinsic conditions.\nAdditionally, X2Video effectively accommodates multi-modal controls with\nreference images, global and local text prompts, and simultaneously supports\nediting on color, material, geometry, and lighting through parametric tuning.\nProject page: https://luckyhzt.github.io/x2video",
      "url": "http://arxiv.org/abs/2510.08530v1",
      "published_time_eastern_timestamp": 1760032231.0
    },
    {
      "title": "High-Rate Surgery: towards constant-overhead logical operations",
      "summary": "Scalable quantum computation requires not only quantum codes with low memory\noverhead but also encoded operations with low space-time overhead. High rate\nquantum low-density parity-check (qLDPC) codes address the former by achieving\na high information-encoding rate, yet existing methods for implementing logical\noperations often suffer from a low information-processing rate, leading to\nsubstantial space-time costs. Here, we introduce high-rate surgery, a general\nscheme that can perform extensive, addressable logical Pauli-product\nmeasurements in parallel on arbitrary qLDPC codes using a shared ancilla\nsystem, attaining nearly constant space-time overhead. We develop both\nalgebraic and randomized ancilla constructions and demonstrate, using the\n$[[144, 12, 12]]$ Gross code and new instances of qLDPC codes (e.g., $[[1125,\n245, \\leq 10]]$) with encoding rate up to $25\\%$, that up to hundreds of\nrandomly sampled logical measurements can be executed simultaneously with a\ntotal space-time overhead around a factor of two of that of memory experiments.\nOur results address a major bottleneck for performing complex, addressable\nlogical operations on qLDPC codes in practice, advancing the prospect of\nscalable, constant-overhead fault-tolerant quantum computation.",
      "url": "http://arxiv.org/abs/2510.08523v1",
      "published_time_eastern_timestamp": 1760032179.0
    },
    {
      "title": "FlowSearch: Advancing deep research with dynamic structured knowledge\n  flow",
      "summary": "Deep research is an inherently challenging task that demands both breadth and\ndepth of thinking. It involves navigating diverse knowledge spaces and\nreasoning over complex, multi-step dependencies, which presents substantial\nchallenges for agentic systems. To address this, we propose FlowSearch, a\nmulti-agent framework that actively constructs and evolves a dynamic structured\nknowledge flow to drive subtask execution and reasoning. FlowSearch is capable\nof strategically planning and expanding the knowledge flow to enable parallel\nexploration and hierarchical task decomposition, while also adjusting the\nknowledge flow in real time based on feedback from intermediate reasoning\noutcomes and insights. FlowSearch achieves state-of-the-art performance on both\ngeneral and scientific benchmarks, including GAIA, HLE, GPQA and TRQA,\ndemonstrating its effectiveness in multi-disciplinary research scenarios and\nits potential to advance scientific discovery. The code is available at\nhttps://github.com/Alpha-Innovator/InternAgent.",
      "url": "http://arxiv.org/abs/2510.08521v1",
      "published_time_eastern_timestamp": 1760032092.0
    },
    {
      "title": "Tripartite entanglement in the HaPPY code is not holographic",
      "summary": "Holographic states satisfy several entropic inequalities owing to the\nRyu-Takayangi formula. A drawback of these inequalities is that they only use\nbipartite entanglement in their formulation. We investigate a recently proposed\n\"GHZ-forbidding\" inequality, built out of the reflected entropy and the\ntripartite multi-entropy, that holds for holographic states. We show that the\ninequality is either violated or saturated, but never strictly satisfied, by\nstabilizer states, thereby showing that stabilizer states are not holographic.\nAs a consequence, we show that tripartite entanglement in the HaPPY code is not\nholographic.",
      "url": "http://arxiv.org/abs/2510.08520v1",
      "published_time_eastern_timestamp": 1760032088.0
    },
    {
      "title": "AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents",
      "summary": "Large language models (LLMs) have shown impressive performance in general\nprogramming tasks. However, in Machine Learning Engineering (MLE) scenarios\nsuch as AutoML and Kaggle competitions, achieving high performance depends\nheavily on expert intervention and repeated adjustments rather than simply\ngenerating correct code. When applied directly to these tasks, LLMs often lack\nfine-grained domain priors, and existing MLE approaches that use linear or\ntree-structured searches limit knowledge transfer to adjacent hierarchical\nlinks. As a result, they cannot leverage past full trajectories or share\ninformation across branches, limiting self-evolving ability and search space\ndiversity. To address these limitations, we introduce AutoMLGen, an LLM-based\ncoding agent that integrates a domain knowledge base for high-quality prior\nguidance and Monte Carlo Graph Search (MCGS) for efficient exploration. MCGS\nretains the tree-guided exploration of MCTS while embedding a graph structure\ninto the expansion stage to enable dynamic path reorganization, historical\ntrajectory reuse, and multi-solution fusion to support both self-evolution and\ncollaborative learning. Combined with fine-grained operator sets, this design\nimproves stability and accelerates convergence. Evaluation on the MLE-Bench\nshows that AutoMLGen achieves state-of-the-art performance in numerous\ndimensions, such as the average medal rate and the valid submission rate, under\na 12-hour budget (half the standard runtime). The code is available at\nhttps://github.com/Alpha-Innovator/InternAgent.",
      "url": "http://arxiv.org/abs/2510.08511v1",
      "published_time_eastern_timestamp": 1760031905.0
    },
    {
      "title": "DeepPrune: Parallel Scaling without Inter-trace Redundancy",
      "summary": "Parallel scaling has emerged as a powerful paradigm to enhance reasoning\ncapabilities in large language models (LLMs) by generating multiple\nChain-of-Thought (CoT) traces simultaneously. However, this approach introduces\nsignificant computational inefficiency due to inter-trace redundancy -- our\nanalysis reveals that over 80% of parallel reasoning traces yield identical\nfinal answers, representing substantial wasted computation. To address this\ncritical efficiency bottleneck, we propose DeepPrune, a novel framework that\nenables efficient parallel scaling through dynamic pruning. Our method features\na specialized judge model trained with focal loss and oversampling techniques\nto accurately predict answer equivalence from partial reasoning traces which\nrealizes 0.87 AUROC on equivalence prediction, combined with an online greedy\nclustering algorithm that dynamically prunes redundant paths while preserving\nanswer diversity. Comprehensive evaluations across three challenging benchmarks\n(AIME 2024, AIME 2025, and GPQA) and multiple reasoning models demonstrate that\nDeepPrune achieves remarkable token reduction by over 80% compared to\nconventional consensus sampling on most cases, while maintaining competitive\naccuracy within 3 percentage points. Our work establishes a new standard for\nefficient parallel reasoning, making high-performance reasoning more efficient.\nOur code and data are here: https://deepprune.github.io/",
      "url": "http://arxiv.org/abs/2510.08483v1",
      "published_time_eastern_timestamp": 1760030694.0
    },
    {
      "title": "In-Context Clustering with Large Language Models",
      "summary": "We propose In-Context Clustering (ICC), a flexible LLM-based procedure for\nclustering data from diverse distributions. Unlike traditional clustering\nalgorithms constrained by predefined similarity measures, ICC flexibly captures\ncomplex relationships among inputs through an attention mechanism. We show that\npretrained LLMs exhibit impressive zero-shot clustering capabilities on\ntext-encoded numeric data, with attention matrices showing salient cluster\npatterns. Spectral clustering using attention matrices offers surprisingly\ncompetitive performance. We further enhance the clustering capabilities of LLMs\non numeric and image data through fine-tuning using the Next Token Prediction\n(NTP) loss. Moreover, the flexibility of LLM prompting enables text-conditioned\nimage clustering, a capability that classical clustering methods lack. Our work\nextends in-context learning to an unsupervised setting, showcasing the\neffectiveness and flexibility of LLMs for clustering. Our code is available at\nhttps://agenticlearning.ai/icc.",
      "url": "http://arxiv.org/abs/2510.08466v1",
      "published_time_eastern_timestamp": 1760029675.0
    },
    {
      "title": "Accelerated Aggregated D-Optimal Designs for Estimating Main Effects in\n  Black-Box Models",
      "summary": "Recent advances in supervised learning have driven growing interest in\nexplaining black-box models, particularly by estimating the effects of input\nvariables on model predictions. However, existing approaches often face key\nlimitations, including poor scalability, sensitivity to out-of-distribution\nsampling, and instability under correlated features. To address these issues,\nwe propose A2D2E, an $\\textbf{E}$stimator based on $\\textbf{A}$ccelerated\n$\\textbf{A}$ggregated $\\textbf{D}$-Optimal $\\textbf{D}$esigns. Our method\nleverages principled experimental design to improve efficiency and robustness\nin main effect estimation. We establish theoretical guarantees, including\nconvergence and variance reduction, and validate A2D2E through extensive\nsimulations. We further provide the potential of the proposed method with a\ncase study on real data and applications in language models. The code to\nreproduce the results can be found at https://github.com/cchihyu/A2D2E.",
      "url": "http://arxiv.org/abs/2510.08465v1",
      "published_time_eastern_timestamp": 1760029656.0
    },
    {
      "title": "Code Swendsen-Wang Dynamics",
      "summary": "An important open question about Markov chains for preparing quantum Gibbs\nstates is proving rapid mixing. However, rapid mixing at low temperatures has\nonly been proven for Gibbs states with no thermally stable phases, e.g., the 2D\ntoric code. Inspired by Swendsen-Wang dynamics, in this work we give a simple\nMarkov chain, Code Swendsen-Wang dynamics, for preparing Gibbs states of\ncommuting Hamiltonians. We prove rapid mixing of this chain for classes of\nquantum and classical Hamiltonians with thermally stable phases, including the\n4D toric code, at any temperature. We conjecture its efficiency for all code\nHamiltonians away from first-order phase transition points.",
      "url": "http://arxiv.org/abs/2510.08446v1",
      "published_time_eastern_timestamp": 1760028879.0
    },
    {
      "title": "Synthetic Series-Symbol Data Generation for Time Series Foundation\n  Models",
      "summary": "Foundation models for time series analysis (TSA) have attracted significant\nattention. However, challenges such as training data scarcity and imbalance\ncontinue to hinder their development. Inspired by complex dynamic system\ntheories, we design a series-symbol data generation mechanism, enabling the\nunrestricted creation of high-quality time series data paired with\ncorresponding symbolic expressions. To leverage series-symbol data pairs with\nstrong correlations, we develop \\texttt{SymTime}, a pre-trained foundation\nmodel for enhancing time series representation using symbolic information.\n\\texttt{SymTime} demonstrates competitive performance across five major TSA\ntasks when fine-tunes with downstream tasks, rivaling foundation models\npre-trained on real-world datasets. This approach underscores the potential of\nseries-symbol data generation and pretraining mechanisms in overcoming data\nscarcity and enhancing task performance. The code is available at\nhttps://github.com/wwhenxuan/SymTime.",
      "url": "http://arxiv.org/abs/2510.08445v1",
      "published_time_eastern_timestamp": 1760028858.0
    },
    {
      "title": "Reinforcing Diffusion Models by Direct Group Preference Optimization",
      "summary": "While reinforcement learning methods such as Group Relative Preference\nOptimization (GRPO) have significantly enhanced Large Language Models, adapting\nthem to diffusion models remains challenging. In particular, GRPO demands a\nstochastic policy, yet the most cost-effective diffusion samplers are based on\ndeterministic ODEs. Recent work addresses this issue by using inefficient\nSDE-based samplers to induce stochasticity, but this reliance on model-agnostic\nGaussian noise leads to slow convergence. To resolve this conflict, we propose\nDirect Group Preference Optimization (DGPO), a new online RL algorithm that\ndispenses with the policy-gradient framework entirely. DGPO learns directly\nfrom group-level preferences, which utilize relative information of samples\nwithin groups. This design eliminates the need for inefficient stochastic\npolicies, unlocking the use of efficient deterministic ODE samplers and faster\ntraining. Extensive results show that DGPO trains around 20 times faster than\nexisting state-of-the-art methods and achieves superior performance on both\nin-domain and out-of-domain reward metrics. Code is available at\nhttps://github.com/Luo-Yihong/DGPO.",
      "url": "http://arxiv.org/abs/2510.08425v1",
      "published_time_eastern_timestamp": 1760028043.0
    },
    {
      "title": "Trajectory-Dependent Electronic Energy Losses in Ion Range Simulations",
      "summary": "The energy losses of energetic ions in materials depend on both nuclear and\nelectronic interactions. In channeling geometries, the stopping effect of these\ninteractions can be highly reduced, resulting in deeper ion penetration.\nComprehensive, trajectory-dependent models for ion-material interactions are\ntherefore crucial for the accurate prediction of ion range profiles. We present\nthe implementation of a recent electron density-dependent energy-loss model in\nthe efficient molecular dynamics-based MDRANGE code. The model captures\n\\textit{ab initio} electron dynamics using a parametrized ion energy loss\nfunction, based on calculations for explicit trajectories using real-time\ntime-dependent density functional theory. We demonstrate the efficient\nsimulation of trajectory-dependent ion range profiles with this comprehensive\nmodel for electronic energy losses. Our results indicate that accurate\ntrajectory-dependent ion range profiles can be simulated using well-fitted\nparametrizations of this model. This method offers a unique tool for validation\nof the fitted energy-loss functions using energetic ion ranges, which can be\nmeasured experimentally but are beyond the capability of full MD simulations\ndue to the computational expense.",
      "url": "http://arxiv.org/abs/2510.08422v1",
      "published_time_eastern_timestamp": 1760027925.0
    }
  ]
}
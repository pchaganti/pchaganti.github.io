{
  "last_updated": "2025-09-08T23:28:49.212083-04:00",
  "papers": [
    {
      "title": "H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose\n  Transformers",
      "summary": "Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a hierarchical plug-and-play pruning-and-recovering\nframework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient\ntransformer-based 3D human pose estimation from videos. H$_{2}$OT begins with\nprogressively pruning pose tokens of redundant frames and ends with recovering\nfull-length sequences, resulting in a few pose tokens in the intermediate\ntransformer blocks and thus improving the model efficiency. It works with two\nkey modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module\n(TRM). TPM dynamically selects a few representative tokens to eliminate the\nredundancy of video frames, while TRM restores the detailed spatio-temporal\ninformation based on the selected tokens, thereby expanding the network output\nto the original full-length temporal resolution for fast inference. Our method\nis general-purpose: it can be easily incorporated into common VPT models on\nboth seq2seq and seq2frame pipelines while effectively accommodating different\ntoken pruning and recovery strategies. In addition, our H$_{2}$OT reveals that\nmaintaining the full pose sequence is unnecessary, and a few pose tokens of\nrepresentative frames can achieve both high efficiency and estimation accuracy.\nExtensive experiments on multiple benchmark datasets demonstrate both the\neffectiveness and efficiency of the proposed method. Code and models are\navailable at https://github.com/NationalGAILab/HoT.",
      "url": "http://arxiv.org/abs/2509.06956v1",
      "published_time_eastern_timestamp": 1757354399.0
    },
    {
      "title": "Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for\n  Dynamic Environments",
      "summary": "Generating collision-free motion in dynamic, partially observable\nenvironments is a fundamental challenge for robotic manipulators. Classical\nmotion planners can compute globally optimal trajectories but require full\nenvironment knowledge and are typically too slow for dynamic scenes. Neural\nmotion policies offer a promising alternative by operating in closed-loop\ndirectly on raw sensory inputs but often struggle to generalize in complex or\ndynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural\nmotion policy designed for reactive motion generation in diverse dynamic\nenvironments, operating directly on point cloud sensory input. At its core is\nIMPACT, a transformer-based neural motion policy pretrained on 10 million\ngenerated expert trajectories across diverse simulation scenarios. We further\nimprove IMPACT's static obstacle avoidance through iterative student-teacher\nfinetuning. We additionally enhance the policy's dynamic obstacle avoidance at\ninference time using DCP-RMP, a locally reactive goal-proposal module. We\nevaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving\nobstacles, and goal obstructions. DRP achieves strong generalization,\noutperforming prior classical and neural methods in success rate across both\nsimulated and real-world settings. Video results and code available at\nhttps://deep-reactive-policy.com",
      "url": "http://arxiv.org/abs/2509.06953v1",
      "published_time_eastern_timestamp": 1757354375.0
    },
    {
      "title": "Revolutionizing Reinforcement Learning Framework for Diffusion Large\n  Language Models",
      "summary": "We propose TraceRL, a trajectory-aware reinforcement learning framework for\ndiffusion language models (DLMs) that incorporates preferred inference\ntrajectory into post-training, and is applicable across different\narchitectures. Equipped with a diffusion-based value model that enhances\ntraining stability, we demonstrate improved reasoning performance on complex\nmath and coding tasks. Besides, it can also be applied to adapt block-specific\nmodels to larger blocks, which improves sampling flexibility. Employing\nTraceRL, we derive a series of state-of-the-art diffusion language models,\nnamely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still\nconsistently outperforms them across complex math reasoning tasks.\nTraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over\nQwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical\nreasoning benchmarks. Through curriculum learning, we also derive the first\nlong-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%\nrelative accuracy gain. To facilitate reproducible research and practical\napplications, we release a comprehensive open-source framework for building,\ntraining, and deploying diffusion LLMs across diverse architectures. The\nframework integrates accelerated KV-cache techniques and inference engines for\nboth inference and reinforcement learning, and includes implementations of\nvarious supervised fine-tuning and RL methods for mathematics, coding, and\ngeneral tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL",
      "url": "http://arxiv.org/abs/2509.06949v1",
      "published_time_eastern_timestamp": 1757354286.0
    },
    {
      "title": "Interleaving Reasoning for Better Text-to-Image Generation",
      "summary": "Unified multimodal understanding and generation models recently have achieve\nsignificant improvement in image generation capability, yet a large gap remains\nin instruction following and detail preservation compared to systems that\ntightly couple comprehension with generation such as GPT-4o. Motivated by\nrecent advances in interleaving reasoning, we explore whether such reasoning\ncan further improve Text-to-Image (T2I) generation. We introduce Interleaving\nReasoning Generation (IRG), a framework that alternates between text-based\nthinking and image synthesis: the model first produces a text-based thinking to\nguide an initial image, then reflects on the result to refine fine-grained\ndetails, visual quality, and aesthetics while preserving semantics. To train\nIRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL),\nwhich targets two sub-goals: (1) strengthening the initial think-and-generate\nstage to establish core content and base quality, and (2) enabling high-quality\ntextual reflection and faithful implementation of those refinements in a\nsubsequent image. We curate IRGL-300K, a dataset organized into six decomposed\nlearning modes that jointly cover learning text-based thinking, and full\nthinking-image trajectories. Starting from a unified foundation model that\nnatively emits interleaved text-image outputs, our two-stage training first\nbuilds robust thinking and reflection, then efficiently tunes the IRG pipeline\nin the full thinking-image trajectory data. Extensive experiments show SoTA\nperformance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF,\nGenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality\nand fine-grained fidelity. The code, model weights and datasets will be\nreleased in: https://github.com/Osilly/Interleaving-Reasoning-Generation .",
      "url": "http://arxiv.org/abs/2509.06945v1",
      "published_time_eastern_timestamp": 1757354183.0
    },
    {
      "title": "Row-Column Twisted Reed-Solomon codes",
      "summary": "In this article, we present a new class of codes known as row-column twisted\nReed-Solomon codes (abbreviated as RCTRS), motivated by the works of\n\\cite{beelen2017twisted} and \\cite{liu2025column}. We explicitly provide\nconditions for such codes to be MDS and also ensure their existence. By\ndetermining the dimensions of their Schur squares, we prove that these MDS\ncodes are not equivalent to Reed-Solomon codes, thus presenting a new family of\nnon-RS MDS codes. Additionally, we prove that these MDS codes are also not\nequivalent to column twisted Reed-Solomon codes described in\n\\cite{liu2025column}, showing the novelty of our construction.",
      "url": "http://arxiv.org/abs/2509.06919v1",
      "published_time_eastern_timestamp": 1757352603.0
    },
    {
      "title": "Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI\n  Agents",
      "summary": "We introduce Paper2Agent, an automated framework that converts research\npapers into AI agents. Paper2Agent transforms research output from passive\nartifacts into active systems that can accelerate downstream use, adoption, and\ndiscovery. Conventional research papers require readers to invest substantial\neffort to understand and adapt a paper's code, data, and methods to their own\nwork, creating barriers to dissemination and reuse. Paper2Agent addresses this\nchallenge by automatically converting a paper into an AI agent that acts as a\nknowledgeable research assistant. It systematically analyzes the paper and the\nassociated codebase using multiple agents to construct a Model Context Protocol\n(MCP) server, then iteratively generates and runs tests to refine and robustify\nthe resulting MCP. These paper MCPs can then be flexibly connected to a chat\nagent (e.g. Claude Code) to carry out complex scientific queries through\nnatural language while invoking tools and workflows from the original paper. We\ndemonstrate Paper2Agent's effectiveness in creating reliable and capable paper\nagents through in-depth case studies. Paper2Agent created an agent that\nleverages AlphaGenome to interpret genomic variants and agents based on ScanPy\nand TISSUE to carry out single-cell and spatial transcriptomics analyses. We\nvalidate that these paper agents can reproduce the original paper's results and\ncan correctly carry out novel user queries. By turning static papers into\ndynamic, interactive AI agents, Paper2Agent introduces a new paradigm for\nknowledge dissemination and a foundation for the collaborative ecosystem of AI\nco-scientists.",
      "url": "http://arxiv.org/abs/2509.06917v1",
      "published_time_eastern_timestamp": 1757352522.0
    },
    {
      "title": "Rate-Optimal Streaming Codes over Three-Node Relay Networks with Burst\n  Erasures",
      "summary": "This paper investigates streaming codes over three-node relay networks under\nburst packet erasures with a delay constraint $T$. In any sliding window of\n$T+1$ consecutive packets, the source-to-relay and relay-to-destination\nchannels may introduce burst erasures of lengths at most $b_1$ and $b_2$,\nrespectively. Singhvi et al. proposed a construction achieving the optimal code\nrate when $\\max\\{b_1,b_2\\}\\mid (T-b_1-b_2)$. We construct streaming codes with\nthe optimal rate under the condition\n  $T\\geq b_1+b_2+\\frac{b_1b_2}{|b_1-b_2|}$, thereby enriching the family of\nrate-optimal streaming codes for three-node relay networks.",
      "url": "http://arxiv.org/abs/2509.06912v1",
      "published_time_eastern_timestamp": 1757352337.0
    },
    {
      "title": "Barlow-Swin: Toward a novel siamese-based segmentation architecture\n  using Swin-Transformers",
      "summary": "Medical image segmentation is a critical task in clinical workflows,\nparticularly for the detection and delineation of pathological regions. While\nconvolutional architectures like U-Net have become standard for such tasks,\ntheir limited receptive field restricts global context modeling. Recent efforts\nintegrating transformers have addressed this, but often result in deep,\ncomputationally expensive models unsuitable for real-time use. In this work, we\npresent a novel end-to-end lightweight architecture designed specifically for\nreal-time binary medical image segmentation. Our model combines a Swin\nTransformer-like encoder with a U-Net-like decoder, connected via skip pathways\nto preserve spatial detail while capturing contextual information. Unlike\nexisting designs such as Swin Transformer or U-Net, our architecture is\nsignificantly shallower and competitively efficient. To improve the encoder's\nability to learn meaningful features without relying on large amounts of\nlabeled data, we first train it using Barlow Twins, a self-supervised learning\nmethod that helps the model focus on important patterns by reducing unnecessary\nrepetition in the learned features. After this pretraining, we fine-tune the\nentire model for our specific task. Experiments on benchmark binary\nsegmentation tasks demonstrate that our model achieves competitive accuracy\nwith substantially reduced parameter count and faster inference, positioning it\nas a practical alternative for deployment in real-time and resource-limited\nclinical environments. The code for our method is available at Github\nrepository: https://github.com/mkianih/Barlow-Swin.",
      "url": "http://arxiv.org/abs/2509.06885v1",
      "published_time_eastern_timestamp": 1757351153.0
    },
    {
      "title": "A Class of Cyclic Quantum Codes",
      "summary": "We introduce a class of cyclic quantum codes, basing the construction not on\nthe simplicity of the stabilizers, but rather on the simplicity of preparation\nof a code state (at least in the absence of noise). We show how certain known\ncodes, such as a certain family of rotated two-dimensional toric codes, fall\ninto this class, and we also give certain other examples at small sizes found\nby computer search. We finally discuss fault tolerant preparation of these\ncodes.",
      "url": "http://arxiv.org/abs/2509.06865v1",
      "published_time_eastern_timestamp": 1757349217.0
    },
    {
      "title": "Test-Time Scaling in Reasoning Models Is Not Effective for\n  Knowledge-Intensive Tasks Yet",
      "summary": "Test-time scaling increases inference-time computation by allowing models to\ngenerate long reasoning chains, and has shown strong performance across many\ndomains. However, in this work, we show that this approach is not yet effective\nfor knowledge-intensive tasks, where high factual accuracy and low\nhallucination rates are essential. We conduct a comprehensive evaluation of\ntest-time scaling using 12 reasoning models on two knowledge-intensive\nbenchmarks. Our results reveal that increasing test-time computation does not\nconsistently improve accuracy and, in many cases, it even leads to more\nhallucinations. We then analyze how extended reasoning affects hallucination\nbehavior. We find that reduced hallucinations often result from the model\nchoosing to abstain after thinking more, rather than from improved factual\nrecall. Conversely, for some models, longer reasoning encourages attempts on\npreviously unanswered questions, many of which result in hallucinations. Case\nstudies show that extended reasoning can induce confirmation bias, leading to\noverconfident hallucinations. Despite these limitations, we observe that\ncompared to non-thinking, enabling thinking remains beneficial. Code and data\nare available at https://github.com/XuZhao0/tts-knowledge",
      "url": "http://arxiv.org/abs/2509.06861v1",
      "published_time_eastern_timestamp": 1757348905.0
    },
    {
      "title": "MIO: Multiverse Debugging in the Face of Input/Output -- Extended\n  Version with Additional Appendices",
      "summary": "Debugging non-deterministic programs on microcontrollers is notoriously\nchallenging, especially when bugs manifest in unpredictable, input-dependent\nexecution paths. A recent approach, called multiverse debugging, makes it\neasier to debug non-deterministic programs by allowing programmers to explore\nall potential execution paths. Current multiverse debuggers enable both forward\nand backward traversal of program paths, and some facilitate jumping to any\npreviously visited states, potentially branching into alternative execution\npaths within the state space.\n  Unfortunately, debugging programs that involve input/output operations using\nexisting multiverse debuggers can reveal inaccessible program states, i.e.\nstates which are not encountered during regular execution. This can\nsignificantly hinder the debugging process, as the programmer may spend\nsubstantial time exploring and examining inaccessible program states, or worse,\nmay mistakenly assume a bug is present in the code, when in fact, the issue is\ncaused by the debugger.\n  This paper presents a novel approach to multiverse debugging, which can\naccommodate a broad spectrum of input/output operations. We provide the\nsemantics of our approach and prove the correctness of our debugger, ensuring\nthat despite having support for a wide range of input/output operations the\ndebugger will only explore those program states which can be reached during\nregular execution.\n  We have developed a prototype, called MIO, leveraging the WARDuino\nWebAssembly virtual machine to demonstrate the feasibility and efficiency of\nour techniques. As a demonstration of the approach we highlight a color dial\nbuilt with a Lego Mindstorms motor, and color sensor, providing a tangible\nexample of how our approach enables multiverse debugging for programs running\non an STM32 microcontroller.",
      "url": "http://arxiv.org/abs/2509.06845v1",
      "published_time_eastern_timestamp": 1757348118.0
    },
    {
      "title": "ToonOut: Fine-tuned Background-Removal for Anime Characters",
      "summary": "While state-of-the-art background removal models excel at realistic imagery,\nthey frequently underperform in specialized domains such as anime-style\ncontent, where complex features like hair and transparency present unique\nchallenges. To address this limitation, we collected and annotated a custom\ndataset of 1,228 high-quality anime images of characters and objects, and\nfine-tuned the open-sourced BiRefNet model on this dataset. This resulted in\nmarked improvements in background removal accuracy for anime-style images,\nincreasing from 95.3% to 99.5% for our newly introduced Pixel Accuracy metric.\nWe are open-sourcing the code, the fine-tuned model weights, as well as the\ndataset at: https://github.com/MatteoKartoon/BiRefNet.",
      "url": "http://arxiv.org/abs/2509.06839v1",
      "published_time_eastern_timestamp": 1757347736.0
    },
    {
      "title": "COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens",
      "summary": "Making LLMs more efficient in memory, latency, and serving cost is crucial\nfor edge deployment, interactive applications, and sustainable inference at\nscale. Pruning is a key technique toward this goal. However, prior pruning\nmethods are limited: width pruning often breaks the standard transformer layout\nor requires custom inference code, while depth pruning removes entire layers\nand can cause abrupt accuracy drops. In this work, we propose COMPACT, which\njointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii)\nprunes FFN intermediate channels using common-token-weighted activations,\naligning importance with the post-pruning token distribution. COMPACT enjoys\nmerits of both depth and width pruning, such as: deployment-friendliness (keeps\na standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN\npruning), training-free operation with competitive pruning time, and strong\nmemory savings alongside throughput gains. Experiments across Qwen, LLaMA, and\nGemma families (0.5B-70B) show state-of-the-art downstream task performance at\nsimilar or higher pruning ratios, with substantial reductions in parameters,\nGPU memory, and end-to-end latency.",
      "url": "http://arxiv.org/abs/2509.06836v1",
      "published_time_eastern_timestamp": 1757347626.0
    },
    {
      "title": "Leveraging Generic Foundation Models for Multimodal Surgical Data\n  Analysis",
      "summary": "We investigate how both the adaptation of a generic foundation model via\ntransfer learning and the integration of complementary modalities from the\noperating room (OR) can support surgical data science. To this end, we use\nV-JEPA as the single-modality foundation of a multimodal model for minimally\ninvasive surgery support. We analyze how the model's downstream performance can\nbenefit (a) from finetuning on unlabeled surgical video data and (b) from\nproviding additional time-resolved data streams from the OR in a multimodal\nsetup.\n  In an in-house dataset of liver surgery videos, we analyze the tasks of\npredicting hospital length of stay and postoperative complications. In videos\nof the public HeiCo dataset, we analyze the task of surgical phase recognition.\nAs a baseline, we apply pretrained V-JEPA to all tasks. We then finetune it on\nunlabeled, held-out videos to investigate its change in performance after\ndomain adaptation. Following the idea of modular decision support networks, we\nintegrate additional data streams from the OR by training a separate encoder to\nform a shared representation space with V-JEPA's embeddings.\n  Our experiments show that finetuning on domain-specific data increases model\nperformance. On the in-house data, integrating additional time-resolved data\nlikewise benefits the model. On the HeiCo data, accuracy of the pretrained\nvideo-only, single-modality baseline setup is on par with the top-performing\nsubmissions of the EndoVis2017 challenge, while finetuning on domain-specific\ndata increases accuracy further. Our results thus demonstrate how surgical data\nscience can leverage public, generic foundation models. Likewise, they indicate\nthe potential of domain adaptation and of integrating suitable complementary\ndata streams from the OR. To support further research, we release our code and\nmodel weights at https://github.com/DigitalSurgeryLab-Basel/ML-CDS-2025.",
      "url": "http://arxiv.org/abs/2509.06831v1",
      "published_time_eastern_timestamp": 1757347459.0
    },
    {
      "title": "UMO: Scaling Multi-Identity Consistency for Image Customization via\n  Matching Reward",
      "summary": "Recent advancements in image customization exhibit a wide range of\napplication prospects due to stronger customization capabilities. However,\nsince we humans are more sensitive to faces, a significant challenge remains in\npreserving consistent identity while avoiding identity confusion with\nmulti-reference images, limiting the identity scalability of customization\nmodels. To address this, we present UMO, a Unified Multi-identity Optimization\nframework, designed to maintain high-fidelity identity preservation and\nalleviate identity confusion with scalability. With \"multi-to-multi matching\"\nparadigm, UMO reformulates multi-identity generation as a global assignment\noptimization problem and unleashes multi-identity consistency for existing\nimage customization methods generally through reinforcement learning on\ndiffusion models. To facilitate the training of UMO, we develop a scalable\ncustomization dataset with multi-reference images, consisting of both\nsynthesised and real parts. Additionally, we propose a new metric to measure\nidentity confusion. Extensive experiments demonstrate that UMO not only\nimproves identity consistency significantly, but also reduces identity\nconfusion on several image customization methods, setting a new\nstate-of-the-art among open-source methods along the dimension of identity\npreserving. Code and model: https://github.com/bytedance/UMO",
      "url": "http://arxiv.org/abs/2509.06818v1",
      "published_time_eastern_timestamp": 1757346895.0
    },
    {
      "title": "Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in\n  the TPTP Ecosystem",
      "summary": "The scarcity of high-quality, logically sound data is a critical bottleneck\nfor advancing the mathematical reasoning of Large Language Models (LLMs). Our\nwork confronts this challenge by turning decades of automated theorem proving\nresearch into a scalable data engine. Rather than relying on error-prone LLMs\nor complex proof-assistant syntax like Lean and Isabelle, our framework\nleverages E-prover's saturation capabilities on the vast TPTP axiom library to\nderive a massive, guaranteed-valid corpus of theorems. Our pipeline is\nprincipled and simple: saturate axioms, filter for \"interesting\" theorems, and\ngenerate tasks. With no LLMs in the loop, we eliminate factual errors by\nconstruction. This purely symbolic data is then transformed into three\ndifficulty-controlled challenges: entailment verification, premise selection,\nand proof reconstruction. Our zero-shot experiments on frontier models reveal a\nclear weakness: performance collapses on tasks requiring deep, structural\nreasoning. Our framework provides both the diagnostic tool to measure this gap\nand a scalable source of symbolic training data to address it. We make the code\nand data publicly available.\n  https://github.com/sileod/reasoning_core\nhttps://hf.co/datasets/reasoning-core/rc1",
      "url": "http://arxiv.org/abs/2509.06809v1",
      "published_time_eastern_timestamp": 1757346209.0
    },
    {
      "title": "Large eddy simulations in astrophysics",
      "summary": "In this review, the methodology of large eddy simulations (LES) is introduced\nand applications in astrophysics are discussed. As theoretical framework, the\nscale decomposition of the dynamical equations for compressible neutral fluids\nby means of spatial filtering is explained. For cosmological applications, the\nfiltered equations in co-moving coordinates are formulated. Moreover, the\ndecomposition is extended to magnetohydrodynamics (MHD). While energy is\ndissipated through numerical diffusivities in implicit large eddy simulations\n(ILES), explicit subgrid-scale (SGS) models are applied in LES to compute\nenergy dissipation, mixing, and dynamo action due to numerically unresolved\nturbulent eddies. The most commonly used models in astrophysics are the\nSmagorinsky model, the hydrodynamical SGS turbulence energy equation model, and\nthe non-linear structural model for both non-relativistic and relativistic MHD.\nModel validation is carried out a priori by testing correlations between model\nand data for specific terms or a posteriori by comparing turbulence statistics\nin LES and ILES. Since most solvers in astrophysical simulation codes have\nsignificant numerical diffusion, the additional effect of SGS models is\ngenerally small. However, convergence with resolution increases in some cases.\nA recent example is magnetic field amplification in binary neutron star\nmergers. For mesh-free codes, it has been shown that explicit modelling of\nturbulent diffusion of metals has a significant impact. Moreover, SGS models\ncan help to compute the turbulent velocity dispersion consistently and to\nparameterize sub-resolution processes that are influenced by turbulence, such\nas the star formation efficiency in galaxy simulations.",
      "url": "http://arxiv.org/abs/2509.06801v1",
      "published_time_eastern_timestamp": 1757345605.0
    },
    {
      "title": "Imitative Membership Inference Attack",
      "summary": "A Membership Inference Attack (MIA) assesses how much a target machine\nlearning model reveals about its training data by determining whether specific\nquery instances were part of the training set. State-of-the-art MIAs rely on\ntraining hundreds of shadow models that are independent of the target model,\nleading to significant computational overhead. In this paper, we introduce\nImitative Membership Inference Attack (IMIA), which employs a novel imitative\ntraining technique to strategically construct a small number of target-informed\nimitative models that closely replicate the target model's behavior for\ninference. Extensive experimental results demonstrate that IMIA substantially\noutperforms existing MIAs in various attack settings while only requiring less\nthan 5% of the computational cost of state-of-the-art approaches.",
      "url": "http://arxiv.org/abs/2509.06796v1",
      "published_time_eastern_timestamp": 1757345255.0
    },
    {
      "title": "Dato: A Task-Based Programming Model for Dataflow Accelerators",
      "summary": "Recent deep learning workloads increasingly push computational demand beyond\nwhat current memory systems can sustain, with many kernels stalling on data\nmovement rather than computation. While modern dataflow accelerators\nincorporate on-chip streaming to mitigate off-chip bandwidth limitations,\nexisting programming models struggle to harness these capabilities effectively.\nLow-level interfaces provide fine-grained control but impose significant\ndevelopment overhead, whereas high-level tile-based languages abstract away\ncommunication details, restricting optimization and forcing compilers to\nreconstruct the intended dataflow. We present Dato, a Python-embedded,\ntask-based programming model for dataflow accelerators that elevates data\ncommunication and sharding to first-class type constructs. Developers write\nprograms as a graph of tasks connected via explicit stream types, with sharded\ninputs specified using layout types. These tasks are first mapped virtually\nonto the accelerator's spatial fabric, and the compiler then generates a\nphysical mapping that respects hardware constraints. Experimental results on\nboth AMD Ryzen AI NPU and Alveo FPGA devices demonstrate that Dato achieves\nhigh performance while significantly reducing the burden of writing optimized\ncode. On the NPU, Dato attains up to 84% hardware utilization for GEMM and\ndelivers a 2.81x speedup on attention kernels compared to a state-of-the-art\ncommercial framework. On the FPGA, Dato surpasses leading frameworks in\nperformance when generating custom systolic arrays, achieving 98% of the\ntheoretical peak performance.",
      "url": "http://arxiv.org/abs/2509.06794v1",
      "published_time_eastern_timestamp": 1757344971.0
    },
    {
      "title": "P3-SAM: Native 3D Part Segmentation",
      "summary": "Segmenting 3D assets into their constituent parts is crucial for enhancing 3D\nunderstanding, facilitating model reuse, and supporting various applications\nsuch as part generation. However, current methods face limitations such as poor\nrobustness when dealing with complex objects and cannot fully automate the\nprocess. In this paper, we propose a native 3D point-promptable part\nsegmentation model termed P3-SAM, designed to fully automate the segmentation\nof any 3D objects into components. Inspired by SAM, P3-SAM consists of a\nfeature extractor, multiple segmentation heads, and an IoU predictor, enabling\ninteractive segmentation for users. We also propose an algorithm to\nautomatically select and merge masks predicted by our model for part instance\nsegmentation. Our model is trained on a newly built dataset containing nearly\n3.7 million models with reasonable segmentation labels. Comparisons show that\nour method achieves precise segmentation results and strong robustness on any\ncomplex objects, attaining state-of-the-art performance. Our code will be\nreleased soon.",
      "url": "http://arxiv.org/abs/2509.06784v1",
      "published_time_eastern_timestamp": 1757344337.0
    }
  ]
}
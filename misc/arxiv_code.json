{
  "last_updated": "2025-06-11T20:59:11.211052-04:00",
  "papers": [
    {
      "title": "ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm\n  Engineering",
      "summary": "How well do AI systems perform in algorithm engineering for hard optimization\nproblems in domains such as package-delivery routing, crew scheduling, factory\nproduction planning, and power-grid balancing? We introduce ALE-Bench, a new\nbenchmark for evaluating AI systems on score-based algorithmic programming\ncontests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench\npresents optimization problems that are computationally hard and admit no known\nexact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench\nencourages iterative solution refinement over long time horizons. Our software\nframework supports interactive agent architectures that leverage test-run\nfeedback and visualizations. Our evaluation of frontier LLMs revealed that\nwhile they demonstrate high performance on specific problems, a notable gap\nremains compared to humans in terms of consistency across problems and\nlong-horizon problem-solving capabilities. This highlights the need for this\nbenchmark to foster future AI advancements.",
      "url": "http://arxiv.org/abs/2506.09050v1",
      "published_time_eastern_timestamp": 1749578396.0
    },
    {
      "title": "Gradual Metaprogramming",
      "summary": "Data engineers increasingly use domain-specific languages (DSLs) to generate\nthe code for data pipelines. Such DSLs are often embedded in Python.\nUnfortunately, there are challenges in debugging the generation of data\npipelines: an error in a Python DSL script is often detected too late, after\nthe execution of the script, and the source code location that triggers the\nerror is hard to pinpoint.\n  In this paper, we focus on the F3 DSL of Meta (Facebook), which is a DSL\nembedded in Python (so it is dynamically-typed) to generate data pipeline\ndescription code that is statically-typed. We propose gradual metaprogramming\nto (1) provide a migration path toward statically typed DSLs, (2) immediately\nprovide earlier detection of code generation type errors, and (3) report the\nsource code location responsible for the type error. Gradual metaprogramming\naccomplishes this by type checking code fragments and incrementally performing\nruntime checks as they are spliced together. We define MetaGTLC, a\nmetaprogramming calculus in which a gradually-typed metalanguage manipulates a\nstatically-typed object language, and give semantics to it by translation to\nthe cast calculus MetaCC. We prove that successful metaevaluation always\ngenerates a well-typed object program and mechanize the proof in Agda.",
      "url": "http://arxiv.org/abs/2506.09043v1",
      "published_time_eastern_timestamp": 1749578312.0
    },
    {
      "title": "Autoregressive Semantic Visual Reconstruction Helps VLMs Understand\n  Better",
      "summary": "Typical large vision-language models (LVLMs) apply autoregressive supervision\nsolely to textual sequences, without fully incorporating the visual modality\ninto the learning process. This results in three key limitations: (1) an\ninability to utilize images without accompanying captions, (2) the risk that\ncaptions omit critical visual details, and (3) the challenge that certain\nvision-centric content cannot be adequately conveyed through text. As a result,\ncurrent LVLMs often prioritize vision-to-language alignment while potentially\noverlooking fine-grained visual information. While some prior works have\nexplored autoregressive image generation, effectively leveraging autoregressive\nvisual supervision to enhance image understanding remains an open challenge. In\nthis paper, we introduce Autoregressive Semantic Visual Reconstruction (ASVR),\nwhich enables joint learning of visual and textual modalities within a unified\nautoregressive framework. We show that autoregressively reconstructing the raw\nvisual appearance of images does not enhance and may even impair multimodal\nunderstanding. In contrast, autoregressively reconstructing the semantic\nrepresentation of images consistently improves comprehension. Notably, we find\nthat even when models are given continuous image features as input, they can\neffectively reconstruct discrete semantic tokens, resulting in stable and\nconsistent improvements across a wide range of multimodal understanding\nbenchmarks. Our approach delivers significant performance gains across varying\ndata scales (556k-2M) and types of LLM bacbones. Specifically, ASVR improves\nLLaVA-1.5 by 5% in average scores across 14 multimodal benchmarks. The code is\navailable at https://github.com/AlenjandroWang/ASVR.",
      "url": "http://arxiv.org/abs/2506.09040v1",
      "published_time_eastern_timestamp": 1749578270.0
    },
    {
      "title": "Princeton365: A Diverse Dataset with Accurate Camera Pose",
      "summary": "We introduce Princeton365, a large-scale diverse dataset of 365 videos with\naccurate camera pose. Our dataset bridges the gap between accuracy and data\ndiversity in current SLAM benchmarks by introducing a novel ground truth\ncollection framework that leverages calibration boards and a 360-camera. We\ncollect indoor, outdoor, and object scanning videos with synchronized monocular\nand stereo RGB video outputs as well as IMU. We further propose a new scene\nscale-aware evaluation metric for SLAM based on the the optical flow induced by\nthe camera pose estimation error. In contrast to the current metrics, our new\nmetric allows for comparison between the performance of SLAM methods across\nscenes as opposed to existing metrics such as Average Trajectory Error (ATE),\nallowing researchers to analyze the failure modes of their methods. We also\npropose a challenging Novel View Synthesis benchmark that covers cases not\ncovered by current NVS benchmarks, such as fully non-Lambertian scenes with\n360-degree camera trajectories. Please visit\nhttps://princeton365.cs.princeton.edu for the dataset, code, videos, and\nsubmission.",
      "url": "http://arxiv.org/abs/2506.09035v1",
      "published_time_eastern_timestamp": 1749578220.0
    },
    {
      "title": "Learning Correlated Astrophysical Foregrounds with Denoising Diffusion\n  Probabilistic Models",
      "summary": "Extragalactic foregrounds -- most notably the Cosmic Infrared Background\n(CIB) and the thermal Sunyaev-Zel'dovich (tSZ) effect -- exhibit complex,\nnon-Gaussian structure and correlations that can bias analyses of small-scale\ncosmic microwave background (CMB) temperature anisotropies. These foregrounds\ncan introduce mode coupling at small-scales (multipoles $\\ell \\geq 3000$) that\nmimic true lensing signals, thereby complicating analyses such as CMB lensing\nreconstruction. We present a novel approach to learn their full joint\ndistribution using Denoising Diffusion Probabilistic Models (DDPMs) trained on\npaired CIB-tSZ patches at 150 GHz, from the Agora suite of extragalactic sky\nsimulations. While simulations like Agora, which are based on N-body\ncalculations, can take thousands of CPU hours, DDPM can synthesize realistic\nCIB-tSZ patches that faithfully reproduce both auto- and cross-spectral\nstatistics of the 2-point, 3-point, and 4-point correlation functions, in a\nmatter of seconds. We further demonstrate matching pixel-value histograms and\nMinkowski functionals, confirming that conventional non-Gaussian benchmarks are\nalso satisfied. This framework provides a powerful generative tool for\nforward-modeling correlated extragalactic foregrounds in current and future CMB\nanalyses. Although we mainly demonstrate the joint modeling of tSZ and CIB at a\nsingle frequency, we also include examples of its extension to multiple\nfrequencies, showing that the framework can learn the spectral energy\ndistributions (SEDs) across different bands. While establishing DDPMs as a\npromising tool for addressing foreground contamination in next-generation CMB\nsurveys, we also outline remaining challenges to their practical deployment in\nanalysis pipelines, such as scaling to larger sky areas and reliance on the\nunderlying cosmological and astrophysical assumptions in the simulations used\nfor training.",
      "url": "http://arxiv.org/abs/2506.09036v1",
      "published_time_eastern_timestamp": 1749578220.0
    },
    {
      "title": "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via\n  Reinforcement Learning",
      "summary": "The rapid emergence of diverse large language models (LLMs) has spurred the\ndevelopment of LLM routers that assign user queries to the most suitable model.\nHowever, existing LLM routers typically perform a single-round, one-to-one\nmapping (\\textit{i.e.}, assigning each query to a single model in isolation),\nwhich limits their capability to tackle complex tasks that demand the\ncomplementary strengths of multiple LLMs. In this paper, we present\n\\textbf{Router-R1}, a reinforcement learning (RL)-based framework that\nformulates multi-LLM routing and aggregation as a sequential decision process.\nRouter-R1 instantiates the router itself as a capable LLM, leveraging its\nreasoning ability to interleave \"think\" actions (internal deliberation) with\n\"route\" actions (dynamic model invocation), and integrates each response into\nits evolving context. To guide learning, we employ a lightweight rule-based\nreward comprising format rewards, final outcome rewards, and a novel cost\nreward for performance and cost trade-off optimization, opening a pathway\ntoward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions\nonly on simple model descriptors such as pricing, latency, and example\nperformance, enabling strong generalization to unseen model selection.\nExperiments on seven general and multi-hop QA benchmarks show that Router-R1\noutperforms over several strong baselines, achieving superior performance while\nmaintaining robust generalization and cost management.Code is available at\nhttps://github.com/ulab-uiuc/Router-R1.",
      "url": "http://arxiv.org/abs/2506.09033v1",
      "published_time_eastern_timestamp": 1749578205.0
    },
    {
      "title": "Fault-Tolerant Stabilizer Measurements in Surface Codes with Three-Qubit\n  Gates",
      "summary": "Quantum error correction (QEC) is considered a deciding component in enabling\npractical quantum computing. Stabilizer codes, and in particular topological\nsurface codes, are promising candidates for implementing QEC by redundantly\nencoding quantum information. While it is widely believed that a strictly\nfault-tolerant protocol can only be implemented using single- and two-qubit\ngates, several quantum computing platforms, based on trapped ions, neutral\natoms and also superconducting qubits support native multi-qubit operations,\ne.g. using multi-ion entangling gates, Rydberg blockade or parallelized tunable\ncouplers, respectively. In this work, we show that stabilizer measurement\ncircuits for unrotated surface codes can be fault-tolerant using single\nauxiliary qubits and three-qubit gates. These gates enable lower-depth circuits\nleading to fewer fault locations and potentially shorter QEC cycle times.\nConcretely, we find that in an optimistic parameter regime where fidelities of\nthree-qubit gates are the same as those of two-qubit gates, the logical error\nrate can be up to one order of magnitude lower and the threshold can be\nsignificantly higher, increasing from $\\approx 0.76 \\%$ to $\\approx 1.05 \\%$.\nOur results, which are applicable to a wide range of platforms, thereby\nmotivate further investigation into multi-qubit gates as components for\nfault-tolerant QEC, as they can lead to substantial advantages in terms of time\nand physical qubit resources required to reach a target logical error rate.",
      "url": "http://arxiv.org/abs/2506.09029v1",
      "published_time_eastern_timestamp": 1749578063.0
    },
    {
      "title": "Optimizing Superconducting Three-Qubit Gates for Surface-Code Error\n  Correction",
      "summary": "Quantum error correction (QEC) is one of the crucial building blocks for\ndeveloping quantum computers that have significant potential for reaching a\nquantum advantage in applications. Prominent candidates for QEC are stabilizer\ncodes for which periodic readout of stabilizer operators is typically\nimplemented via successive two-qubit entangling gates, and is repeated many\ntimes during a computation. To improve QEC performance, it is thus beneficial\nto make the stabilizer readout faster and less prone to\nfault-tolerance-breaking errors. Here we design a 3-qubit CZZ gate for\nsuperconducting transmon qubits that maps the parity of two data qubits onto\none measurement qubit in a single step. We find that the gate can be executed\nin a duration of $35\\,$ns with a fidelity of F$=99.96 \\, \\%$. To optimize the\ngate, we use an error model obtained from the microscopic gate simulation to\nsystematically suppress Pauli errors that are particularly harmful to the QEC\nprotocol. Using this error model, we investigate the implementation of this\n3-qubit gate in a surface code syndrome readout schedule. We find that for the\nrotated surface code, the implementation of CZZ gates increases the error\nthreshold by nearly 50\\% to $\\approx 1.2\\,\\%$ and decreases the logical error\nrate, in the experimental relevant regime, by up to one order of magnitude,\ncompared to the standard CZ readout protocol. We also show that for the\nunrotated surface code, strictly fault-tolerant readout schedules can be found.\nThis opens a new perspective for below-threshold surface-code error correction,\nwhere it can be advantageous to use multi-qubit gates instead of two-qubit\ngates to obtain a better QEC performance.",
      "url": "http://arxiv.org/abs/2506.09028v1",
      "published_time_eastern_timestamp": 1749578062.0
    },
    {
      "title": "DIsoN: Decentralized Isolation Networks for Out-of-Distribution\n  Detection in Medical Imaging",
      "summary": "Safe deployment of machine learning (ML) models in safety-critical domains\nsuch as medical imaging requires detecting inputs with characteristics not seen\nduring training, known as out-of-distribution (OOD) detection, to prevent\nunreliable predictions. Effective OOD detection after deployment could benefit\nfrom access to the training data, enabling direct comparison between test\nsamples and the training data distribution to identify differences.\nState-of-the-art OOD detection methods, however, either discard training data\nafter deployment or assume that test samples and training data are centrally\nstored together, an assumption that rarely holds in real-world settings. This\nis because shipping training data with the deployed model is usually impossible\ndue to the size of training databases, as well as proprietary or privacy\nconstraints. We introduce the Isolation Network, an OOD detection framework\nthat quantifies the difficulty of separating a target test sample from the\ntraining data by solving a binary classification task. We then propose\nDecentralized Isolation Networks (DIsoN), which enables the comparison of\ntraining and test data when data-sharing is impossible, by exchanging only\nmodel parameters between the remote computational nodes of training and\ndeployment. We further extend DIsoN with class-conditioning, comparing a target\nsample solely with training data of its predicted class. We evaluate DIsoN on\nfour medical imaging datasets (dermatology, chest X-ray, breast ultrasound,\nhistopathology) across 12 OOD detection tasks. DIsoN performs favorably against\nexisting methods while respecting data-privacy. This decentralized OOD\ndetection framework opens the way for a new type of service that ML developers\ncould provide along with their models: providing remote, secure utilization of\ntheir training data for OOD detection services. Code will be available upon\nacceptance at: *****",
      "url": "http://arxiv.org/abs/2506.09024v1",
      "published_time_eastern_timestamp": 1749577938.0
    },
    {
      "title": "Edit Flows: Flow Matching with Edit Operations",
      "summary": "Autoregressive generative models naturally generate variable-length\nsequences, while non-autoregressive models struggle, often imposing rigid,\ntoken-wise structures. We propose Edit Flows, a non-autoregressive model that\novercomes these limitations by defining a discrete flow over sequences through\nedit operations-insertions, deletions, and substitutions. By modeling these\noperations within a Continuous-time Markov Chain over the sequence space, Edit\nFlows enable flexible, position-relative generation that aligns more closely\nwith the structure of sequence data. Our training method leverages an expanded\nstate space with auxiliary variables, making the learning process efficient and\ntractable. Empirical results show that Edit Flows outperforms both\nautoregressive and mask models on image captioning and significantly\noutperforms the mask construction in text and code generation.",
      "url": "http://arxiv.org/abs/2506.09018v1",
      "published_time_eastern_timestamp": 1749577459.0
    },
    {
      "title": "Linear exact repair schemes for free MDS and Reed-Solomon codes over\n  Galois rings",
      "summary": "Codes over rings, especially over Galois rings, have been extensively studied\nfor nearly three decades due to their similarity to linear codes over finite\nfields. A distributed storage system uses a linear code to encode a large file\nacross several nodes. If one of the nodes fails, a linear exact repair scheme\nefficiently recovers the failed node by accessing and downloading data from the\nrest of the servers of the storage system. In this article, we develop a linear\nrepair scheme for free maximum distance separable codes, which coincide with\nfree maximum distance with respect to the rank codes over Galois rings. In\nparticular, we give a linear repair scheme for full-length Reed-Solomon codes\nover a Galois ring.",
      "url": "http://arxiv.org/abs/2506.09017v1",
      "published_time_eastern_timestamp": 1749577384.0
    },
    {
      "title": "SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner",
      "summary": "We introduce **SWE-Flow**, a novel data synthesis framework grounded in\nTest-Driven Development (TDD). Unlike existing software engineering data that\nrely on human-submitted issues, **SWE-Flow** automatically infers incremental\ndevelopment steps directly from unit tests, which inherently encapsulate\nhigh-level requirements. The core of **SWE-Flow** is the construction of a\nRuntime Dependency Graph (RDG), which precisely captures function interactions,\nenabling the generation of a structured, step-by-step *development schedule*.\nAt each step, **SWE-Flow** produces a partial codebase, the corresponding unit\ntests, and the necessary code modifications, resulting in fully verifiable TDD\ntasks. With this approach, we generated 16,061 training instances and 2,020\ntest instances from real-world GitHub projects, creating the **SWE-Flow-Eval**\nbenchmark. Our experiments show that fine-tuning open model on this dataset\nsignificantly improves performance in TDD-based coding. To facilitate further\nresearch, we release all code, datasets, models, and Docker images at\n[Github](https://github.com/Hambaobao/SWE-Flow).",
      "url": "http://arxiv.org/abs/2506.09003v2",
      "published_time_eastern_timestamp": 1749576213.0
    },
    {
      "title": "Boosting Rust Unit Test Coverage through Hybrid Program Analysis and\n  Large Language Models",
      "summary": "Unit testing is essential for ensuring software reliability and correctness.\nClassic Search-Based Software Testing (SBST) methods and concolic\nexecution-based approaches for generating unit tests often fail to achieve high\ncoverage due to difficulties in handling complex program units, such as\nbranching conditions and external dependencies. Recent work has increasingly\nutilized large language models (LLMs) to generate test cases, improving the\nquality of test generation by providing better context and correcting errors in\nthe model's output. However, these methods rely on fixed prompts, resulting in\nrelatively low compilation success rates and coverage. This paper presents\nPALM, an approach that leverages large language models (LLMs) to enhance the\ngeneration of high-coverage unit tests. PALM performs program analysis to\nidentify branching conditions within functions, which are then combined into\npath constraints. These constraints and relevant contextual information are\nused to construct prompts that guide the LLMs in generating unit tests. We\nimplement the approach and evaluate it in 10 open-source Rust crates.\nExperimental results show that within just two or three hours, PALM can\nsignificantly improves test coverage compared to classic methods, with\nincreases in overall project coverage exceeding 50% in some instances and its\ngenerated tests achieving an average coverage of 75.77%, comparable to human\neffort (71.30%), highlighting the potential of LLMs in automated test\ngeneration. We submitted 91 PALM-generated unit tests targeting new code. Of\nthese submissions, 80 were accepted, 5 were rejected, and 6 remain pending\nreview. The results demonstrate the effectiveness of integrating program\nanalysis with AI and open new avenues for future research in automated software\ntesting.",
      "url": "http://arxiv.org/abs/2506.09002v2",
      "published_time_eastern_timestamp": 1749576081.0
    },
    {
      "title": "SDTagNet: Leveraging Text-Annotated Navigation Maps for Online HD Map\n  Construction",
      "summary": "Autonomous vehicles rely on detailed and accurate environmental information\nto operate safely. High definition (HD) maps offer a promising solution, but\ntheir high maintenance cost poses a significant barrier to scalable deployment.\nThis challenge is addressed by online HD map construction methods, which\ngenerate local HD maps from live sensor data. However, these methods are\ninherently limited by the short perception range of onboard sensors. To\novercome this limitation and improve general performance, recent approaches\nhave explored the use of standard definition (SD) maps as prior, which are\nsignificantly easier to maintain. We propose SDTagNet, the first online HD map\nconstruction method that fully utilizes the information of widely available SD\nmaps, like OpenStreetMap, to enhance far range detection accuracy. Our approach\nintroduces two key innovations. First, in contrast to previous work, we\nincorporate not only polyline SD map data with manually selected classes, but\nadditional semantic information in the form of textual annotations. In this\nway, we enrich SD vector map tokens with NLP-derived features, eliminating the\ndependency on predefined specifications or exhaustive class taxonomies. Second,\nwe introduce a point-level SD map encoder together with orthogonal element\nidentifiers to uniformly integrate all types of map elements. Experiments on\nArgoverse 2 and nuScenes show that this boosts map perception performance by up\nto +5.9 mAP (+45%) w.r.t. map construction without priors and up to +3.2 mAP\n(+20%) w.r.t. previous approaches that already use SD map priors. Code is\navailable at https://github.com/immel-f/SDTagNet",
      "url": "http://arxiv.org/abs/2506.08997v1",
      "published_time_eastern_timestamp": 1749575760.0
    },
    {
      "title": "Efficient Medical Vision-Language Alignment Through Adapting Masked\n  Vision Models",
      "summary": "Medical vision-language alignment through cross-modal contrastive learning\nshows promising performance in image-text matching tasks, such as retrieval and\nzero-shot classification. However, conventional cross-modal contrastive\nlearning (CLIP-based) methods suffer from suboptimal visual representation\ncapabilities, which also limits their effectiveness in vision-language\nalignment. In contrast, although the models pretrained via multimodal masked\nmodeling struggle with direct cross-modal matching, they excel in visual\nrepresentation. To address this contradiction, we propose ALTA (ALign Through\nAdapting), an efficient medical vision-language alignment method that utilizes\nonly about 8% of the trainable parameters and less than 1/5 of the\ncomputational consumption required for masked record modeling. ALTA achieves\nsuperior performance in vision-language matching tasks like retrieval and\nzero-shot classification by adapting the pretrained vision model from masked\nrecord modeling. Additionally, we integrate temporal-multiview radiograph\ninputs to enhance the information consistency between radiographs and their\ncorresponding descriptions in reports, further improving the vision-language\nalignment. Experimental evaluations show that ALTA outperforms the\nbest-performing counterpart by over 4% absolute points in text-to-image\naccuracy and approximately 6% absolute points in image-to-text retrieval\naccuracy. The adaptation of vision-language models during efficient alignment\nalso promotes better vision and language understanding. Code is publicly\navailable at https://github.com/DopamineLcy/ALTA.",
      "url": "http://arxiv.org/abs/2506.08990v1",
      "published_time_eastern_timestamp": 1749574947.0
    },
    {
      "title": "Towards Better Code Generation: Adaptive Decoding with Uncertainty\n  Guidance",
      "summary": "Code generation using large language models (LLMs) is highly sensitive to the\nchoice of tokens during decoding, especially at points of uncertainty that\ncritically affect the generated program's logic. Conventional decoding methods\nsuch as greedy search and beam search apply uniform treatment to all tokens,\nneglecting the unique uncertainty characteristics inherent in code generation,\nwhich can result in suboptimal outputs. In this work, we conduct an empirical\nanalysis demonstrating that a significant portion of generation errors arises\nfrom incorrect token ranking at high-uncertainty steps, where the ground truth\ntoken exists in the candidate set but fails to be ranked first.\n  Inspired by this insight, we introduce AdaDec, an adaptive decoding framework\nguided by token-level uncertainty quantified via Shannon entropy. AdaDec\ndynamically learns uncertainty thresholds tailored to each model and employs a\npause-then-rerank mechanism with lookahead when the uncertainty surpasses these\nthresholds. Evaluation on the HumanEval and MBPP benchmarks reveals that AdaDec\nachieves up to a 15.5% improvement in Pass@1 accuracy compared to greedy\ndecoding, matches or outperforms traditional beam search, and reduces both\ncomputational overhead and latency through targeted, selective pausing. Our\nfindings suggest that uncertainty-aware adaptive decoding holds considerable\npotential for enhancing both the reliability and efficiency of code generation\nwith LLMs.",
      "url": "http://arxiv.org/abs/2506.08980v2",
      "published_time_eastern_timestamp": 1749574186.0
    },
    {
      "title": "Tailored Architectures for Time Series Forecasting: Evaluating Deep\n  Learning Models on Gaussian Process-Generated Data",
      "summary": "Developments in Deep Learning have significantly improved time series\nforecasting by enabling more accurate modeling of complex temporal dependencies\ninherent in sequential data. The effectiveness of such models is often\ndemonstrated on limited sets of specific real-world data. Although this allows\nfor comparative analysis, it still does not demonstrate how specific data\ncharacteristics align with the architectural strengths of individual models.\nOur research aims at uncovering clear connections between time series\ncharacteristics and particular models. We introduce a novel dataset generated\nusing Gaussian Processes, specifically designed to display distinct, known\ncharacteristics for targeted evaluations of model adaptability to them.\nFurthermore, we present TimeFlex, a new model that incorporates a modular\narchitecture tailored to handle diverse temporal dynamics, including trends and\nperiodic patterns. This model is compared to current state-of-the-art models,\noffering a deeper understanding of how models perform under varied time series\nconditions.",
      "url": "http://arxiv.org/abs/2506.08977v1",
      "published_time_eastern_timestamp": 1749573962.0
    },
    {
      "title": "Atomic-to-Compositional Generalization for Mobile Agents with A New\n  Benchmark and Scheduling System",
      "summary": "Autonomous agents powered by multimodal large language models have been\ndeveloped to facilitate task execution on mobile devices. However, prior work\nhas predominantly focused on atomic tasks -- such as shot-chain execution tasks\nand single-screen grounding tasks -- while overlooking the generalization to\ncompositional tasks, which are indispensable for real-world applications. This\nwork introduces UI-NEXUS, a comprehensive benchmark designed to evaluate mobile\nagents on three categories of compositional operations: Simple Concatenation,\nContext Transition, and Deep Dive. UI-NEXUS supports interactive evaluation in\n20 fully controllable local utility app environments, as well as 30 online\nChinese and English service apps. It comprises 100 interactive task templates\nwith an average optimal step count of 14.05. Experimental results across a\nrange of mobile agents with agentic workflow or agent-as-a-model show that\nUI-NEXUS presents significant challenges. Specifically, existing agents\ngenerally struggle to balance performance and efficiency, exhibiting\nrepresentative failure modes such as under-execution, over-execution, and\nattention drift, causing visible atomic-to-compositional generalization gap.\nInspired by these findings, we propose AGENT-NEXUS, a lightweight and efficient\nscheduling system to tackle compositional mobile tasks. AGENT-NEXUS\nextrapolates the abilities of existing mobile agents by dynamically decomposing\nlong-horizon tasks to a series of self-contained atomic subtasks. AGENT-NEXUS\nachieves 24% to 40% task success rate improvement for existing mobile agents on\ncompositional operation tasks within the UI-NEXUS benchmark without\nsignificantly sacrificing inference overhead. The demo video, dataset, and code\nare available on the project page at https://ui-nexus.github.io.",
      "url": "http://arxiv.org/abs/2506.08972v1",
      "published_time_eastern_timestamp": 1749573929.0
    },
    {
      "title": "SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging\n  Segmentation",
      "summary": "In the era of information explosion, efficiently leveraging large-scale\nunlabeled data while minimizing the reliance on high-quality pixel-level\nannotations remains a critical challenge in the field of medical imaging.\nSemi-supervised learning (SSL) enhances the utilization of unlabeled data by\nfacilitating knowledge transfer, significantly improving the performance of\nfully supervised models and emerging as a highly promising research direction\nin medical image analysis. Inspired by the ability of Vision Foundation Models\n(e.g., SAM-2) to provide rich prior knowledge, we propose SSS (Semi-Supervised\nSAM-2), a novel approach that leverages SAM-2's robust feature extraction\ncapabilities to uncover latent knowledge in unlabeled medical images, thus\neffectively enhancing feature support for fully supervised medical image\nsegmentation. Specifically, building upon the single-stream \"weak-to-strong\"\nconsistency regularization framework, this paper introduces a Discriminative\nFeature Enhancement (DFE) mechanism to further explore the feature\ndiscrepancies introduced by various data augmentation strategies across\nmultiple views. By leveraging feature similarity and dissimilarity across\nmulti-scale augmentation techniques, the method reconstructs and models the\nfeatures, thereby effectively optimizing the salient regions. Furthermore, a\nprompt generator is developed that integrates Physical Constraints with a\nSliding Window (PCSW) mechanism to generate input prompts for unlabeled data,\nfulfilling SAM-2's requirement for additional prompts. Extensive experiments\ndemonstrate the superiority of the proposed method for semi-supervised medical\nimage segmentation on two multi-label datasets, i.e., ACDC and BHSD. Notably,\nSSS achieves an average Dice score of 53.15 on BHSD, surpassing the previous\nstate-of-the-art method by +3.65 Dice. Code will be available at\nhttps://github.com/AIGeeksGroup/SSS.",
      "url": "http://arxiv.org/abs/2506.08949v1",
      "published_time_eastern_timestamp": 1749571780.0
    },
    {
      "title": "Who is using AI to code? Global diffusion and impact of generative AI",
      "summary": "Generative coding tools promise big productivity gains, but uneven uptake\ncould widen skill and income gaps. We train a neural classifier to spot\nAI-generated Python functions in 80 million GitHub commits (2018-2024) by\n200,000 developers and track how fast--and where--these tools take hold. By\nDecember 2024, AI wrote an estimated 30.1% of Python functions from U.S.\ncontributors, versus 24.3% in Germany, 23.2% in France, 21.6% in India, 15.4%\nin Russia and 11.7% in China. Newer GitHub users use AI more than veterans,\nwhile male and female developers adopt at similar rates. Within-developer\nfixed-effects models show that moving to 30% AI use raises quarterly commits by\n2.4%. Coupling this effect with occupational task and wage data puts the annual\nvalue of AI-assisted coding in the United States at $9.6-$14.4 billion, rising\nto $64-$96 billion if we assume higher estimates of productivity effects\nreported by randomized control trials. Moreover, generative AI prompts learning\nand innovation, leading to increases in the number of new libraries and library\ncombinations that programmers use. In short, AI usage is already widespread but\nhighly uneven, and the intensity of use, not only access, drives measurable\ngains in output and exploration.",
      "url": "http://arxiv.org/abs/2506.08945v1",
      "published_time_eastern_timestamp": 1749571579.0
    }
  ]
}
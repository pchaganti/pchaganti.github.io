{
  "last_updated": "2025-12-09T22:52:24.475212-05:00",
  "papers": [
    {
      "title": "Astra: General Interactive World Model with Autoregressive Denoising",
      "summary": "Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an autoregressive denoising architecture and use temporal causal attention to aggregate past observations and support streaming outputs. We use a noise-augmented history memory to avoid over-reliance on past frames to balance responsiveness with temporal coherence. For precise action control, we introduce an action-aware adapter that directly injects action signals into the denoising process. We further develop a mixture of action experts that dynamically route heterogeneous action modalities, enhancing versatility across diverse real-world tasks such as exploration, manipulation, and camera control. Astra achieves interactive, consistent, and general long-term video prediction and supports various forms of interactions. Experiments across multiple datasets demonstrate the improvements of Astra in fidelity, long-range prediction, and action alignment over existing state-of-the-art world models.",
      "url": "http://arxiv.org/abs/2512.08931v1",
      "published_time_eastern_timestamp": 1765306797.0
    },
    {
      "title": "Resolving the (Debate About) Nozzle Shocks in Tidal Disruption Events",
      "summary": "When a star passes within the Roche limit of a supermassive black hole (SMBH), it is pulled apart by the BH's tidal field in a tidal disruption event (TDE). The resulting flare is powered by the circularization and accretion of bound stellar debris, which initially returns to the BH on eccentric orbits in a thin debris stream. The returning fluid elements follow inclined orbits that converge near pericenter, resulting in extreme vertical compression to scales $10^{-4}~R_\\odot$ and the formation of a nozzle shock. Dissipation at the nozzle shock may affect circularization by altering the properties of the debris stream, but its role is the subject of ongoing debate. We develop an idealized model for the debris stream evolution combining 3D smoothed-particle hydrodynamics simulations, the semi-analytic affine model, and 1D finite-volume hydrodynamic simulations. Because our model is computationally cheap, we can unambiguously resolve the nozzle shock, use a realistic equation of state, and follow the debris stream evolution at many different times. Near peak fallback, Hydrogen recombination and molecular Hydrogen formation broaden the stream by a factor $\\sim 5$, enhancing dissipation at the nozzle. However, the dissipation is still insufficient to directly circularize the debris by in-plane pressure gradients. Instead, the thicker stream substantially increases the likelihood that the stream self-intersects on the second orbit, despite relativistic nodal precession. The stream properties at self-intersection are sensitive to dissipation at the nozzle and the timing of focal points where the ballistic trajectories of the debris converge. Our results clarify the nozzle shock's role in circularization in TDEs, providing a foundation for more realistic circularization and emission models.",
      "url": "http://arxiv.org/abs/2512.08928v1",
      "published_time_eastern_timestamp": 1765306740.0
    },
    {
      "title": "Improved Pseudorandom Codes from Permuted Puzzles",
      "summary": "Watermarks are an essential tool for identifying AI-generated content. Recently, Christ and Gunn (CRYPTO '24) introduced pseudorandom error-correcting codes (PRCs), which are equivalent to watermarks with strong robustness and quality guarantees. A PRC is a pseudorandom encryption scheme whose decryption algorithm tolerates a high rate of errors. Pseudorandomness ensures quality preservation of the watermark, and error tolerance of decryption translates to the watermark's ability to withstand modification of the content.\n  In the short time since the introduction of PRCs, several works (NeurIPS '24, RANDOM '25, STOC '25) have proposed new constructions. Curiously, all of these constructions are vulnerable to quasipolynomial-time distinguishing attacks. Furthermore, all lack robustness to edits over a constant-sized alphabet, which is necessary for a meaningfully robust LLM watermark. Lastly, they lack robustness to adversaries who know the watermarking detection key. Until now, it was not clear whether any of these properties was achievable individually, let alone together.\n  We construct pseudorandom codes that achieve all of the above: plausible subexponential pseudorandomness security, robustness to worst-case edits over a binary alphabet, and robustness against even computationally unbounded adversaries that have the detection key. Pseudorandomness rests on a new assumption that we formalize, the permuted codes conjecture, which states that a distribution of permuted noisy codewords is pseudorandom. We show that this conjecture is implied by the permuted puzzles conjecture used previously to construct doubly efficient private information retrieval. To give further evidence, we show that the conjecture holds against a broad class of simple distinguishers, including read-once branching programs.",
      "url": "http://arxiv.org/abs/2512.08918v1",
      "published_time_eastern_timestamp": 1765306422.0
    },
    {
      "title": "SAQ: Stabilizer-Aware Quantum Error Correction Decoder",
      "summary": "Quantum Error Correction (QEC) decoding faces a fundamental accuracy-efficiency tradeoff. Classical methods like Minimum Weight Perfect Matching (MWPM) exhibit variable performance across noise models and suffer from polynomial complexity, while tensor network decoders achieve high accuracy but at prohibitively high computational cost. Recent neural decoders reduce complexity but lack the accuracy needed to compete with computationally expensive classical methods. We introduce SAQ-Decoder, a unified framework combining transformer-based learning with constraint aware post-processing that achieves both near Maximum Likelihood (ML) accuracy and linear computational scalability with respect to the syndrome size. Our approach combines a dual-stream transformer architecture that processes syndromes and logical information with asymmetric attention patterns, and a novel differentiable logical loss that directly optimizes Logical Error Rates (LER) through smooth approximations over finite fields. SAQ-Decoder achieves near-optimal performance, with error thresholds of 10.99% (independent noise) and 18.6% (depolarizing noise) on toric codes that approach the ML bounds of 11.0% and 18.9% while outperforming existing neural and classical baselines in accuracy, complexity, and parameter efficiency. Our findings establish that learned decoders can simultaneously achieve competitive decoding accuracy and computational efficiency, addressing key requirements for practical fault-tolerant quantum computing systems.",
      "url": "http://arxiv.org/abs/2512.08914v1",
      "published_time_eastern_timestamp": 1765306295.0
    },
    {
      "title": "Emergent Non-Markovianity in Logical Qubit Dynamics",
      "summary": "Logical qubits encoded in quantum error correcting codes can exhibit non-Markovian dynamical evolution, even when the underlying physical noise is Markovian. To understand this emergent non-Markovianity, we define a Markovianity condition appropriate to logical gate operations, and study it by relating logical operations to their physical implementation (operations on the data qubits into which the logical qubit is encoded). We apply our analysis to small quantum codes, and show that they exhibit non-Markovian dynamics even for very simple physical noise models. We show that non-Markovianity can emerge from Markovian physical operations if (and only if) the physical qubits are not necessarily returned to the code subspace after every round of QEC. In this situation, the syndrome qubits can act as a memory, mediating time correlations and enabling violation of the Markov condition. We quantify the emergent non-Markovianity in simple examples, and propose sufficient conditions for reliable use of gate-based characterization techniques like gate set tomography in early fault-tolerant quantum devices.",
      "url": "http://arxiv.org/abs/2512.08893v1",
      "published_time_eastern_timestamp": 1765305227.0
    },
    {
      "title": "Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders",
      "summary": "Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.",
      "url": "http://arxiv.org/abs/2512.08892v1",
      "published_time_eastern_timestamp": 1765305202.0
    },
    {
      "title": "Decentralized Trust for Space AI: Blockchain-Based Federated Learning Across Multi-Vendor LEO Satellite Networks",
      "summary": "The rise of space AI is reshaping government and industry through applications such as disaster detection, border surveillance, and climate monitoring, powered by massive data from commercial and governmental low Earth orbit (LEO) satellites. Federated satellite learning (FSL) enables joint model training without sharing raw data, but suffers from slow convergence due to intermittent connectivity and introduces critical trust challenges--where biased or falsified updates can arise across satellite constellations, including those injected through cyberattacks on inter-satellite or satellite-ground communication links. We propose OrbitChain, a blockchain-backed framework that empowers trustworthy multi-vendor collaboration in LEO networks. OrbitChain (i) offloads consensus to high-altitude platforms (HAPs) with greater computational capacity, (ii) ensures transparent, auditable provenance of model updates from different orbits owned by different vendors, and (iii) prevents manipulated or incomplete contributions from affecting global FSL model aggregation. Extensive simulations show that OrbitChain reduces computational and communication overhead while improving privacy, security, and global model accuracy. Its permissioned proof-of-authority ledger finalizes over 1000 blocks with sub-second latency (0.16,s, 0.26,s, 0.35,s for 1-of-5, 3-of-5, and 5-of-5 quorums). Moreover, OrbitChain reduces convergence time by up to 30 hours on real satellite datasets compared to single-vendor, demonstrating its effectiveness for real-time, multi-vendor learning. Our code is available at https://github.com/wsu-cyber-security-lab-ai/OrbitChain.git",
      "url": "http://arxiv.org/abs/2512.08882v1",
      "published_time_eastern_timestamp": 1765304194.0
    },
    {
      "title": "SimpleDevQA: Benchmarking Large Language Models on Development Knowledge QA",
      "summary": "The Development Knowledge Question Answering (Dev Knowledge QA) task aims to provide natural language answers to knowledge-seeking questions during software development. To investigate its importance and to what extent it has been explored, we analyze real user-LLM dialogues from WildChat and find that: (1) The Dev Knowledge QA task accounts for 39.6% of interactions(highest among all tasks), revealing broad knowledge needs beyond code generation (32.3%). (2) Only 27.5% of real Dev Knowledge QA dialogues focus on code understanding, leaving out development knowledge-seeking. (3) Only 17.1% of real-world Dev Knowledge QA dialogues can be used for constructing a benchmark. Existing benchmarks have two primary limitations for evaluating the Dev Knowledge QA capability of LLMs. First, existing benchmarks offer a limited development knowledge scope, mainly focusing on code understanding and neglecting broader knowledge during development. Second, some benchmarks are not built from real user queries. To bridge this gap, we design a three-phase pipeline that transforms real-world dialogue into simple development knowledge-seeking QA pairs. Through this pipeline, we introduce SimpleDevQA, a multilingual benchmark derived from real user dialogues. It contains 2,740 QA pairs in three languages (English, Chinese, and Russian), and focuses on questions with unique, short, and verifiable answers for accurate and simple evaluation. Experiments show that: Code LLMs generally outperform general LLMs of similar scale; Knowledge injection with the Retrieval-Augmented Generation (RAG) strategy can boost LLM accuracy by 11.3% on average; LLMs show systematic overconfidence in Dev Knowledge QA, and the answering accuracy of LLMs shows a positive correlation with their stated confidence; Generally, LLMs with stronger code generation performance also exhibit stronger performance in Dev Knowledge QA.",
      "url": "http://arxiv.org/abs/2512.08867v1",
      "published_time_eastern_timestamp": 1765303116.0
    },
    {
      "title": "Tri-Bench: Stress-Testing VLM Reliability on Spatial Reasoning under Camera Tilt and Object Interference",
      "summary": "Verifiable geometric reasoning is a critical component for trustworthy and controllable agentic AI. Despite impressive capabilities, Vision-Language Models (VLMs) often fail under realistic scene changes. We present Tri-Bench, a compact benchmark of planar triangle problems that isolates relative geometric reasoning while stressing two deployment-critical factors: camera pose (planar vs. tilted) and scene context via object interference (10 everyday objects). To test verifiability and control, we evaluate four recent VLMs using a single, fixed prompt whose guardrail explicitly describes a surrounding square border, enabling correct answers via homography. We evaluate six simple tasks over binary and continuous targets, and observe that the overall accuracy with respect to 3D ground truth is modest, ~69% on average (best ~75%, worst ~64%). The same responses align even more closely with 2D projections in the image plane, where mean accuracy is ~72%. All four VLMs consistently fail, with accuracy falling to ~0%, on recognizing minority shape classes (equilateral, isosceles, right-angled triangles). Additionally, overall VLM accuracy degrades by ~4.1% under camera tilt. This demonstrates that models fail to correctly utilize the explicit frame-of-reference hint provided in the prompt and default to 2D image plane cues. Finally, we find that object interference has no significant effect on VLM accuracy.",
      "url": "http://arxiv.org/abs/2512.08860v1",
      "published_time_eastern_timestamp": 1765302777.0
    },
    {
      "title": "NecoFuzz: Effective Fuzzing of Nested Virtualization via Fuzz-Harness Virtual Machines",
      "summary": "Nested virtualization is now widely supported by major cloud vendors, allowing users to leverage virtualization-based technologies in the cloud. However, supporting nested virtualization significantly increases host hypervisor complexity and introduces a new attack surface in cloud platforms. While many prior studies have explored hypervisor fuzzing, none has explicitly addressed nested virtualization due to the challenge of generating effective virtual machine (VM) instances with a vast state space as fuzzing inputs.\n  We present NecoFuzz, the first fuzzing framework that systematically targets nested virtualization-specific logic in hypervisors. NecoFuzz synthesizes executable fuzz-harness VMs with internal states near the boundary between valid and invalid, guided by an approximate model of hardware-assisted virtualization specifications. Since vulnerabilities in nested virtualization often stem from incorrect handling of unexpected VM states, this specification-guided, boundary-oriented generation significantly improves coverage of security-critical code across different hypervisors.\n  We implemented NecoFuzz on Intel VT-x and AMD-V by extending AFL++ to support fuzz-harness VMs. NecoFuzz achieved 84.7% and 74.2% code coverage for nested virtualization-specific code on Intel VT-x and AMD-V, respectively, and uncovered six previously unknown vulnerabilities across three hypervisors, including two assigned CVEs.",
      "url": "http://arxiv.org/abs/2512.08858v1",
      "published_time_eastern_timestamp": 1765302632.0
    },
    {
      "title": "A Methodology for Quantitative AI Risk Modeling",
      "summary": "Although general-purpose AI systems offer transformational opportunities in science and industry, they simultaneously raise critical concerns about safety, misuse, and potential loss of control. Despite these risks, methods for assessing and managing them remain underdeveloped. Effective risk management requires systematic modeling to characterize potential harms, as emphasized in frameworks such as the EU General-Purpose AI Code of Practice. This paper advances the risk modeling component of AI risk management by introducing a methodology that integrates scenario building with quantitative risk estimation, drawing on established approaches from other high-risk industries. Our methodology models risks through a six-step process: (1) defining risk scenarios, (2) decomposing them into quantifiable parameters, (3) quantifying baseline risk without AI models, (4) identifying key risk indicators such as benchmarks, (5) mapping these indicators to model parameters to estimate LLM uplift, and (6) aggregating individual parameters into risk estimates that enable concrete claims (e.g., X% probability of >\\$Y in annual cyber damages). We examine the choices that underlie our methodology throughout the article, with discussions of strengths, limitations, and implications for future research. Our methodology is designed to be applicable to key systemic AI risks, including cyber offense, biological weapon development, harmful manipulation, and loss-of-control, and is validated through extensive application in LLM-enabled cyber offense. Detailed empirical results and cyber-specific insights are presented in a companion paper.",
      "url": "http://arxiv.org/abs/2512.08844v1",
      "published_time_eastern_timestamp": 1765301699.0
    },
    {
      "title": "InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models",
      "summary": "Window attention and linear attention represent two principal strategies for mitigating the quadratic complexity and ever-growing KV cache in Vision-Language Models (VLMs). However, we observe that window-based VLMs suffer performance degradation when sequence length exceeds the window size, while linear attention underperforms on information-intensive tasks such as OCR and document understanding. To overcome these limitations, we propose InfiniteVL, a linear-complexity VLM architecture that synergizes sliding window attention (SWA) with Gated DeltaNet. For achieving competitive multimodal performance under constrained resources, we design a three-stage training strategy comprising distillation pretraining, instruction tuning, and long-sequence SFT. Remarkably, using less than 2\\% of the training data required by leading VLMs, InfiniteVL not only substantially outperforms previous linear-complexity VLMs but also matches the performance of leading Transformer-based VLMs, while demonstrating effective long-term memory retention. Compared to similar-sized Transformer-based VLMs accelerated by FlashAttention-2, InfiniteVL achieves over 3.6\\times inference speedup while maintaining constant latency and memory footprint. In streaming video understanding scenarios, it sustains a stable 24 FPS real-time prefill speed while preserving long-term memory cache. Code and models are available at https://github.com/hustvl/InfiniteVL.",
      "url": "http://arxiv.org/abs/2512.08829v1",
      "published_time_eastern_timestamp": 1765300712.0
    },
    {
      "title": "Exploring the binary origin of B and Be rapid rotators",
      "summary": "Observational evidence has continued to mount that a significant fraction of rapidly rotating early-B type stars are products of binary mass transfer. However, very few mid- and late-type B stars with rapid rotation have been demonstrated to be post-interaction products, despite a growing sample of SB1 binaries among stars within this range of spectral types. By considering the currently available information over the entire range of rapidly rotating B-type binaries, we argue that a significant fraction of the mid- and late-type rapid rotators found in binaries are also likely the result of past mass transfer episodes. The observed properties of this sample are compared to the predictions from the Binary Population and Spectral Synthesis code (BPASS), with attention given to the expected evolutionary pathways of stripped stars and the stellar and binary properties of both components of post-interaction systems across a range of initial conditions. Prospects for directly detecting and characterizing the stripped cores of the previous mass donors in such systems are described, and the implications for the role of binary interaction in causing rapid rotation are discussed. An accurate description of prevalence of binary interaction, the physics of mass transfer, and the post-interaction configuration of systems over a range of initial conditions has far-reaching implications including double-degenerate binaries and their eventual mergers, the output of ionizing UV flux of stellar populations, and the supernova explosions that can arise from stripped or rapidly-rotating progenitors.",
      "url": "http://arxiv.org/abs/2512.08821v1",
      "published_time_eastern_timestamp": 1765300385.0
    },
    {
      "title": "Multicalibration for LLM-based Code Generation",
      "summary": "As AI-based code generation becomes widespread, researchers are investigating the calibration of code LLMs - ensuring their confidence scores faithfully represent the true likelihood of code correctness. To do so, we investigate multicalibration, which can capture additional factors about a coding problem, such as complexity, code length, or programming language used. We study four multicalibration approaches on three function synthesis benchmarks, using latest-generation code LLMs (Qwen3 Coder, GPT-OSS, DeepSeek-R1-Distill). Our results demonstrate that multicalibration can yield distinct improvements over both uncalibrated token likelihoods (+1.03 in skill score) and baseline calibrations (+0.37 in skill score). We study the influence of the aforementioned factors in ablations, and make our dataset (consisting of code generations, likelihoods, and correctness labels) available for future research on code LLM calibration.",
      "url": "http://arxiv.org/abs/2512.08810v1",
      "published_time_eastern_timestamp": 1765299841.0
    },
    {
      "title": "Data-Driven Dynamic Parameter Learning of manipulator robots",
      "summary": "Bridging the sim-to-real gap remains a fundamental challenge in robotics, as accurate dynamic parameter estimation is essential for reliable model-based control, realistic simulation, and safe deployment of manipulators. Traditional analytical approaches often fall short when faced with complex robot structures and interactions. Data-driven methods offer a promising alternative, yet conventional neural networks such as recurrent models struggle to capture long-range dependencies critical for accurate estimation. In this study, we propose a Transformer-based approach for dynamic parameter estimation, supported by an automated pipeline that generates diverse robot models and enriched trajectory data using Jacobian-derived features. The dataset consists of 8,192 robots with varied inertial and frictional properties. Leveraging attention mechanisms, our model effectively captures both temporal and spatial dependencies. Experimental results highlight the influence of sequence length, sampling rate, and architecture, with the best configuration (sequence length 64, 64 Hz, four layers, 32 heads) achieving a validation R2 of 0.8633. Mass and inertia are estimated with near-perfect accuracy, Coulomb friction with moderate-to-high accuracy, while viscous friction and distal link center-of-mass remain more challenging. These results demonstrate that combining Transformers with automated dataset generation and kinematic enrichment enables scalable, accurate dynamic parameter estimation, contributing to improved sim-to-real transfer in robotic systems",
      "url": "http://arxiv.org/abs/2512.08767v1",
      "published_time_eastern_timestamp": 1765296958.0
    },
    {
      "title": "Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance",
      "summary": "We present Wan-Move, a simple and scalable framework that brings motion control to video generative models. Existing motion-controllable methods typically suffer from coarse control granularity and limited scalability, leaving their outputs insufficient for practical use. We narrow this gap by achieving precise and high-quality motion control. Our core idea is to directly make the original condition features motion-aware for guiding video synthesis. To this end, we first represent object motions with dense point trajectories, allowing fine-grained control over the scene. We then project these trajectories into latent space and propagate the first frame's features along each trajectory, producing an aligned spatiotemporal feature map that tells how each scene element should move. This feature map serves as the updated latent condition, which is naturally integrated into the off-the-shelf image-to-video model, e.g., Wan-I2V-14B, as motion guidance without any architecture change. It removes the need for auxiliary motion encoders and makes fine-tuning base models easily scalable. Through scaled training, Wan-Move generates 5-second, 480p videos whose motion controllability rivals Kling 1.5 Pro's commercial Motion Brush, as indicated by user studies. To support comprehensive evaluation, we further design MoveBench, a rigorously curated benchmark featuring diverse content categories and hybrid-verified annotations. It is distinguished by larger data volume, longer video durations, and high-quality motion annotations. Extensive experiments on MoveBench and the public dataset consistently show Wan-Move's superior motion quality. Code, models, and benchmark data are made publicly available.",
      "url": "http://arxiv.org/abs/2512.08765v1",
      "published_time_eastern_timestamp": 1765296835.0
    },
    {
      "title": "Pose-Based Sign Language Spotting via an End-to-End Encoder Architecture",
      "summary": "Automatic Sign Language Recognition (ASLR) has emerged as a vital field for bridging the gap between deaf and hearing communities. However, the problem of sign-to-sign retrieval or detecting a specific sign within a sequence of continuous signs remains largely unexplored. We define this novel task as Sign Language Spotting. In this paper, we present a first step toward sign language retrieval by addressing the challenge of detecting the presence or absence of a query sign video within a sentence-level gloss or sign video. Unlike conventional approaches that rely on intermediate gloss recognition or text-based matching, we propose an end-to-end model that directly operates on pose keypoints extracted from sign videos. Our architecture employs an encoder-only backbone with a binary classification head to determine whether the query sign appears within the target sequence. By focusing on pose representations instead of raw RGB frames, our method significantly reduces computational cost and mitigates visual noise. We evaluate our approach on the Word Presence Prediction dataset from the WSLP 2025 shared task, achieving 61.88\\% accuracy and 60.00\\% F1-score. These results demonstrate the effectiveness of our pose-based framework for Sign Language Spotting, establishing a strong foundation for future research in automatic sign language retrieval and verification. Code is available at https://github.com/EbimoJohnny/Pose-Based-Sign-Language-Spotting",
      "url": "http://arxiv.org/abs/2512.08738v1",
      "published_time_eastern_timestamp": 1765295363.0
    },
    {
      "title": "SegEarth-OV3: Exploring SAM 3 for Open-Vocabulary Semantic Segmentation in Remote Sensing Images",
      "summary": "Most existing methods for training-free Open-Vocabulary Semantic Segmentation (OVSS) are based on CLIP. While these approaches have made progress, they often face challenges in precise localization or require complex pipelines to combine separate modules, especially in remote sensing scenarios where numerous dense and small targets are present. Recently, Segment Anything Model 3 (SAM 3) was proposed, unifying segmentation and recognition in a promptable framework. In this paper, we present a preliminary exploration of applying SAM 3 to the remote sensing OVSS task without any training. First, we implement a mask fusion strategy that combines the outputs from SAM 3's semantic segmentation head and the Transformer decoder (instance head). This allows us to leverage the strengths of both heads for better land coverage. Second, we utilize the presence score from the presence head to filter out categories that do not exist in the scene, reducing false positives caused by the vast vocabulary sizes and patch-level processing in geospatial scenes. We evaluate our method on extensive remote sensing datasets. Experiments show that this simple adaptation achieves promising performance, demonstrating the potential of SAM 3 for remote sensing OVSS. Our code is released at https://github.com/earth-insights/SegEarth-OV-3.",
      "url": "http://arxiv.org/abs/2512.08730v1",
      "published_time_eastern_timestamp": 1765294948.0
    },
    {
      "title": "The frame-dragging vector potential on galaxy scales from DM-only Newtonian $N$-body simulations",
      "summary": "Effects of General Relativity are usually neglected in the non-linear evolution of structures, where Newtonian $N$-body simulations are traditionally employed. In the post-Friedmann expansion framework, a weak-field relativistic approximation purpose-built for cosmology, a frame-dragging gravito-magnetic vector potential arises at leading order, sourced by momentum currents, contributing to the metric even if the dynamics of matter fields at this order is Newtonian, and can thus be extracted from $N$-body simulations. Using the Delaunay Tessellation Field Estimator code on the IllustrisTNG simulations, here we extend previous work in order to compute the power spectrum of this vector potential down to galactic scales. The magnitude of the vector potential is two orders of magnitude larger than predicted by perturbation theory, and is a $1\\% \\sim 0.1\\%$ effect compared to the non-linear Newtonian scalar gravitational potential. In the red-shift range considered here, the gravito-magnetic effect remains subdominant, without showing any enhancement during a particular phase in the evolution of structures, aside from the continuous growth of non-linearity at low redshift. Although this seems to suggest that, within the $Î›$CDM model, no significant gravito-magnetic effects contribute to the non-linear evolution of cosmic structures, i.e. to the dynamics of massive particles, possible observational consequences, e.g. in lensing, deserve further exploration.",
      "url": "http://arxiv.org/abs/2512.08703v1",
      "published_time_eastern_timestamp": 1765293537.0
    },
    {
      "title": "Model-based Testing of Practical Distributed Systems in Actor Model",
      "summary": "Designing and implementing distributed systems correctly can be quite challenging. Although these systems are often accompanied by formal specifications that are verified using model-checking techniques, a gap still exists between the implementation and its formal specification: there is no guarantee that the implementation is free of bugs.\n  To bridge this gap, we can use model-based testing. Specifically, if the model of the system can be interpreted as a finite-state automaton, we can generate an exhaustive test suite for the implementation that covers all possible states and transitions.\n  In this paper, we discuss how to efficiently generate such a test suite for distributed systems written in the actor model. Importantly, our approach does not require any modifications to the code or interfering with the distributed system execution environment. As an example, we verified an implementation of a replication algorithm based on Viewstamped Replication, which is used in a real-world system.",
      "url": "http://arxiv.org/abs/2512.08698v1",
      "published_time_eastern_timestamp": 1765293332.0
    }
  ]
}
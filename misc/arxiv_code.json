{
  "last_updated": "2025-09-07T17:09:34.679786-04:00",
  "papers": [
    {
      "title": "Delta Activations: A Representation for Finetuned Large Language Models",
      "summary": "The success of powerful open source Large Language Models (LLMs) has enabled\nthe community to create a vast collection of post-trained models adapted to\nspecific tasks and domains. However, navigating and understanding these models\nremains challenging due to inconsistent metadata and unstructured repositories.\nWe introduce Delta Activations, a method to represent finetuned models as\nvector embeddings by measuring shifts in their internal activations relative to\na base model. This representation allows for effective clustering by domain and\ntask, revealing structure in the model landscape. Delta Activations also\ndemonstrate desirable properties: it is robust across finetuning settings and\nexhibits an additive property when finetuning datasets are mixed. In addition,\nwe show that Delta Activations can embed tasks via few-shot finetuning, and\nfurther explore its use for model selection and merging. We hope Delta\nActivations can facilitate the practice of reusing publicly available models.\nCode is available at https://github.com/OscarXZQ/delta_activations.",
      "url": "http://arxiv.org/abs/2509.04442v1",
      "published_time_eastern_timestamp": 1757008746.0
    },
    {
      "title": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory",
      "summary": "While inference-time scaling enables LLMs to carry out increasingly long and\ncapable reasoning traces, the patterns and insights uncovered during these\ntraces are immediately discarded once the context window is reset for a new\nquery. External memory is a natural way to persist these discoveries, and\nrecent work has shown clear benefits for reasoning-intensive tasks. We see an\nopportunity to make such memories more broadly reusable and scalable by moving\nbeyond instance-based memory entries (e.g. exact query/response pairs, or\nsummaries tightly coupled with the original problem context) toward\nconcept-level memory: reusable, modular abstractions distilled from solution\ntraces and stored in natural language. For future queries, relevant concepts\nare selectively retrieved and integrated into the prompt, enabling test-time\ncontinual learning without weight updates. Our design introduces new strategies\nfor abstracting takeaways from rollouts and retrieving entries for new queries,\npromoting reuse and allowing memory to expand with additional experiences. On\nthe challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over\na strong no-memory baseline with performance continuing to scale with inference\ncompute. We find abstract concepts to be the most consistent memory design,\noutscoring the baseline at all tested inference compute scales. Moreover, we\nconfirm that dynamically updating memory during test-time outperforms an\notherwise identical fixed memory setting with additional attempts, supporting\nthe hypothesis that solving more problems and abstracting more patterns to\nmemory enables further solutions in a form of self-improvement. Code available\nat https://github.com/matt-seb-ho/arc_memo.",
      "url": "http://arxiv.org/abs/2509.04439v1",
      "published_time_eastern_timestamp": 1757008459.0
    },
    {
      "title": "The Telephone Game: Evaluating Semantic Drift in Unified Models",
      "summary": "Employing a single, unified model (UM) for both visual understanding\n(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened\na new direction in Visual Language Model (VLM) research. While UMs can also\nsupport broader unimodal tasks (e.g., text-to-text, image-to-image), we focus\non the core cross-modal pair T2I and I2T, as consistency between understanding\nand generation is critical for downstream use. Existing evaluations consider\nthese capabilities in isolation: FID and GenEval for T2I, and benchmarks such\nas MME, MMBench for I2T. These single-pass metrics do not reveal whether a\nmodel that understands a concept can also render it, nor whether meaning is\npreserved when cycling between image and text modalities. To address this, we\nintroduce the Unified Consistency Framework for Unified Models (UCF-UM), a\ncyclic evaluation protocol that alternates I2T and T2I over multiple\ngenerations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean\nCumulative Drift (MCD), an embedding-based measure of overall semantic loss;\n(ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii)\nMulti-Generation GenEval (MGG), an object-level compliance score extending\nGenEval. To assess generalization beyond COCO, which is widely used in\ntraining; we create a new benchmark ND400, sampled from NoCaps and DOCCI and\nevaluate on seven recent models. UCF-UM reveals substantial variation in\ncross-modal stability: some models like BAGEL maintain semantics over many\nalternations, whereas others like Vila-u drift quickly despite strong\nsingle-pass scores. Our results highlight cyclic consistency as a necessary\ncomplement to standard I2T and T2I evaluations, and provide practical metrics\nto consistently assess unified model's cross-modal stability and strength of\ntheir shared representations. Code:\nhttps://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models",
      "url": "http://arxiv.org/abs/2509.04438v1",
      "published_time_eastern_timestamp": 1757008432.0
    },
    {
      "title": "Design and Development of a Web Platform for Blood Donation Management",
      "summary": "Blood donation is a critical component of healthcare, yet locating suitable\ndonors in emergencies often presents significant challenges. This paper\npresents the design and development of a Blood Donation Web Platform, a\nweb-based system that connects patients, donors, and administrators within a\ncentralized digital space. The platform allows interested donors to register\ntheir personal information, including blood group, contact details, and\navailability. Patients can search for donors based on blood group and location,\nand the system provides a list of nearby donors who are ready to donate. The\nplatform design was guided by use case, database, class, and sequence diagrams\nto ensure a well-structured and efficient system architecture. Modern web\ntechnologies, including PHP (Laravel framework), HTML, CSS, Bootstrap, and\nMySQL, supported by XAMPP and Visual Studio Code, were employed to implement a\ndynamic, interactive, and user-friendly platform. By streamlining donor\nrefgistration, blood requests, and communication, the proposed system reduces\ndelays and complexities in emergencies, improving timely accessibility of blood\nand enhancing overall efficiency in blood donation services.",
      "url": "http://arxiv.org/abs/2509.04423v1",
      "published_time_eastern_timestamp": 1757007759.0
    },
    {
      "title": "No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in\n  Resume Screening",
      "summary": "In this study, we conduct a resume-screening experiment (N=528) where people\ncollaborate with simulated AI models exhibiting race-based preferences (bias)\nto evaluate candidates for 16 high and low status occupations. Simulated AI\nbias approximates factual and counterfactual estimates of racial bias in\nreal-world AI systems. We investigate people's preferences for White, Black,\nHispanic, and Asian candidates (represented through names and affinity groups\non quality-controlled resumes) across 1,526 scenarios and measure their\nunconscious associations between race and status using implicit association\ntests (IATs), which predict discriminatory hiring decisions but have not been\ninvestigated in human-AI collaboration. When making decisions without AI or\nwith AI that exhibits no race-based preferences, people select all candidates\nat equal rates. However, when interacting with AI favoring a particular group,\npeople also favor those candidates up to 90% of the time, indicating a\nsignificant behavioral shift. The likelihood of selecting candidates whose\nidentities do not align with common race-status stereotypes can increase by 13%\nif people complete an IAT before conducting resume screening. Finally, even if\npeople think AI recommendations are low quality or not important, their\ndecisions are still vulnerable to AI bias under certain circumstances. This\nwork has implications for people's autonomy in AI-HITL scenarios, AI and work,\ndesign and evaluation of AI hiring systems, and strategies for mitigating bias\nin collaborative decision-making tasks. In particular, organizational and\nregulatory policy should acknowledge the complex nature of AI-HITL decision\nmaking when implementing these systems, educating people who use them, and\ndetermining which are subject to oversight.",
      "url": "http://arxiv.org/abs/2509.04404v1",
      "published_time_eastern_timestamp": 1757006186.0
    },
    {
      "title": "On $Ï„$ Spin Use with KKMCee",
      "summary": "Spin of $\\tau$ represents an interesting phenomenology data point in both its\nproduction from $e^+ e^-$ collision and its subsequent decay. In precision\napplications such as Belle-II or FCC, where precision tagging is comparable or\nbetter than $0.1 \\%$ Monte Carlo applications are usually necessary.\n\\texttt{KKMCee}, the precision Monte Carlo program, is assuring such high\nprecision in a broad energy range. But so far, spin effects were not easy to\ngrasp. We introduce into \\texttt{KKMCee}, \\texttt{HepMC3} format output, new\nentries, $\\tau$ helicity-like information (with weights to evaluate\napproximation), and $\\tau$ polarimetric vectors to enable weight calculations\nto introduce hard interaction additional couplings. The physics details of the\nintroduced implementations are presented, as well as examples of applications\nand ambiguities evaluation. The most recent updates and the useful codes of our\nwork is provided at\n\\href{https://th.ifj.edu.pl/kkmc-demos/}{https://th.ifj.edu.pl/kkmc-demos/index.html}.",
      "url": "http://arxiv.org/abs/2509.04400v1",
      "published_time_eastern_timestamp": 1757005859.0
    },
    {
      "title": "Transition Models: Rethinking the Generative Learning Objective",
      "summary": "A fundamental dilemma in generative modeling persists: iterative diffusion\nmodels achieve outstanding fidelity, but at a significant computational cost,\nwhile efficient few-step alternatives are constrained by a hard quality\nceiling. This conflict between generation steps and output quality arises from\nrestrictive training objectives that focus exclusively on either infinitesimal\ndynamics (PF-ODEs) or direct endpoint prediction. We address this challenge by\nintroducing an exact, continuous-time dynamics equation that analytically\ndefines state transitions across any finite time interval. This leads to a\nnovel generative paradigm, Transition Models (TiM), which adapt to\narbitrary-step transitions, seamlessly traversing the generative trajectory\nfrom single leaps to fine-grained refinement with more steps. Despite having\nonly 865M parameters, TiM achieves state-of-the-art performance, surpassing\nleading models such as SD3.5 (8B parameters) and FLUX.1 (12B parameters) across\nall evaluated step counts. Importantly, unlike previous few-step generators,\nTiM demonstrates monotonic quality improvement as the sampling budget\nincreases. Additionally, when employing our native-resolution strategy, TiM\ndelivers exceptional fidelity at resolutions up to 4096x4096.",
      "url": "http://arxiv.org/abs/2509.04394v1",
      "published_time_eastern_timestamp": 1757005559.0
    },
    {
      "title": "Cosmic Ray Magnetohydrodynamics: A New Two-Moment Framework with\n  Numerical Implementation",
      "summary": "Cosmic rays (CRs) play a pivotal role in various astrophysical systems,\ndelivering feedback over a broad range of scales. However, modeling CR\ntransport remains challenging due to its inherently multi-scale nature and\ncomplex microphysics. Recent advances in two-moment CR hydrodynamics have\nalleviated some of these challenges, improving understanding of CR feedback.\nYet, current two-moment methods may not be able to directly incorporate all\nrelevant CR transport processes, while the outcome of CR feedback sensitively\ndepends on these underlying microphysics. Furthermore, numerical challenges\npersist, including instabilities from streaming terms and ambiguities in solver\ndesign for coupled CR-MHD systems. In this work, we develop a two-moment\ndescription for CR hydrodynamics from first principles. Beyond canonical CR\nstreaming, our formulation accounts for CR pressure anisotropy and Alfv\\'en\nwaves propagating in both directions along the magnetic field, providing a\ngeneral framework to incorporate more CR transport physics. We implement this\nframework as a new CR fluid module in the \\textit{Athena}++ code, and validate\nit through a suite of benchmark tests. In particular, we derive the full\ndispersion relation of the two-moment CR-MHD system, identifying the\nCR-acoustic instability as well as other wave branches. These CR-MHD waves\nserve as rigorous benchmarks and also enable the use of realistic signal speeds\nin our Riemann solver. We propose a time step guideline to mitigate numerical\ninstabilities arising from streaming source terms.",
      "url": "http://arxiv.org/abs/2509.04387v1",
      "published_time_eastern_timestamp": 1757004590.0
    },
    {
      "title": "Numerical investigation of the interior geometry of semiclassical\n  evaporating spherical charged black holes",
      "summary": "We developed a numerical code which evolves the semiclassical Einstein's\nequation (with the quantum stress-energy contribution added as a source term)\nfor the spherically symmetric metric inside an evaporating semiclassical\ncharged black hole. An analytical approximation for the evolving semiclassical\nmetric was recently developed by Ori and Zilberman (and will be briefly\noverviewed here). We seek to numerically check the validity of this analytical\napproximation. The Einstein equations in this case are partial differential\nequations for the two unknown metric functions which fully describe the\nspherically symmetric metric. We begin our numerical simulation close to the\nevent horizon with regular initial data specified by a variant of the charged\nVaidya metric. We then evolve the metric functions deep into the neighborhood\nof the inner horizon. We explore the results of running this numerical code in\nseveral representative cases. Our numerical simulations confirm the validity of\nthe above mentioned analytical approximation in all these cases.",
      "url": "http://arxiv.org/abs/2509.04385v1",
      "published_time_eastern_timestamp": 1757004486.0
    },
    {
      "title": "AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval\n  for Text-Based Person Anomaly Search",
      "summary": "With growing public safety demands, text-based person anomaly search has\nemerged as a critical task, aiming to retrieve individuals with abnormal\nbehaviors via natural language descriptions. Unlike conventional person search,\nthis task presents two unique challenges: (1) fine-grained cross-modal\nalignment between textual anomalies and visual behaviors, and (2) anomaly\nrecognition under sparse real-world samples. While Large Multi-modal Models\n(LMMs) excel in multi-modal understanding, their potential for fine-grained\nanomaly retrieval remains underexplored, hindered by: (1) a domain gap between\ngenerative knowledge and discriminative retrieval, and (2) the absence of\nefficient adaptation strategies for deployment. In this work, we propose\nAnomalyLMM, the first framework that harnesses LMMs for text-based person\nanomaly search. Our key contributions are: (1) A novel coarse-to-fine pipeline\nintegrating LMMs to bridge generative world knowledge with retrieval-centric\nanomaly detection; (2) A training-free adaptation cookbook featuring masked\ncross-modal prompting, behavioral saliency prediction, and knowledge-aware\nre-ranking, enabling zero-shot focus on subtle anomaly cues. As the first study\nto explore LMMs for this task, we conduct a rigorous evaluation on the PAB\ndataset, the only publicly available benchmark for text-based person anomaly\nsearch, with its curated real-world anomalies covering diverse scenarios (e.g.,\nfalling, collision, and being hit). Experiments show the effectiveness of the\nproposed method, surpassing the competitive baseline by +0.96% Recall@1\naccuracy. Notably, our method reveals interpretable alignment between textual\nanomalies and visual behaviors, validated via qualitative analysis. Our code\nand models will be released for future research.",
      "url": "http://arxiv.org/abs/2509.04376v1",
      "published_time_eastern_timestamp": 1757003686.0
    },
    {
      "title": "Sensitivities of time-dependent temperature profile predictions for NSTX\n  with the Multi-Mode Model",
      "summary": "The Multi-Mode Model (MMM) for turbulent transport was applied to a large set\nof well-analyzed discharges from the National Spherical Torus Experiment (NSTX)\nin order to evaluate its sensitivities to a wide range of plasma conditions.\nMMM calculations were performed for hundreds of milliseconds in each discharge\nby performing time-dependent predictive simulations with the 1.5D tokamak\nintegrated modeling code TRANSP. A closely related study concluded that MMM\npredicted electron ($T_e$) and ion ($T_i$) temperature profiles that were in\nreasonable agreement with NSTX observations, generally outperforming a\ndifferent reduced transport model, TGLF, motivating a more thorough\ninvestigation of the characteristics of the MMM predictions. The simulations\nwith MMM have electron energy transport dominated by electron temperature\ngradient modes for relatively low plasma $\\beta$ and high collisionality,\ntransitioning to a mixture of different modes for higher $\\beta$ and lower\ncollisionality. The thermal ion diffusivity predicted by MMM is much smaller\nthan the neoclassical contribution, in line with previous experimental analysis\nof NSTX. Nonetheless, the $T_e$ and $T_i$ profiles are coupled via collisional\nenergy exchange and thus sensitive to which transport channels are predicted.\nThe simulations with MMM are robust to the simulation start time, converging to\nremarkably similar temperatures later during the discharge. MMM typically\noverpredicts confinement relative to NSTX observations, leading to the\nprediction of overly steep profiles. Plasmas with spatially broader $T_e$\nprofiles, higher $\\beta$, and longer energy confinement times tend to be\npredicted by MMM with better agreement with the experiment. These findings\nprovide useful context for understanding the regime-dependent tendencies of MMM\nin anticipation of self-consistent, time-dependent predictive simulations of\nNSTX-U discharges.",
      "url": "http://arxiv.org/abs/2509.04360v1",
      "published_time_eastern_timestamp": 1757002884.0
    },
    {
      "title": "Assessing time-dependent temperature profile predictions using reduced\n  transport models for high performing NSTX plasmas",
      "summary": "Time-dependent, predictive simulations were performed with the 1.5D tokamak\nintegrated modeling code TRANSP on a large set of well-analyzed, high\nperforming discharges from the National Spherical Torus Experiment (NSTX) in\norder to evaluate how well modern reduced transport models can reproduce\nexperimentally observed temperature profiles in spherical tokamaks. Overall, it\nis found that simulations using the Multi-Mode Model (MMM) more consistently\nagree with the NSTX observations than those using the Trapped Gyro-Landau Fluid\n(TGLF) model, despite TGLF requiring orders of magnitude greater computational\ncost. When considering all examined discharges, MMM has median overpredictions\nof electron temperature ($T_e$) and ion temperature ($T_i$) profiles of 28% and\n27%, respectively, relative to the experiment. TGLF overpredicts $T_e$ by 46%,\nwith much larger variance than MMM, and underpredicts $T_i$ by 25%. As $\\beta$\nis increased across NSTX discharges, TGLF predicts lower $T_e$ and significant\nflattening of the $T_i$ profile, conflicting with NSTX observations. When using\nan electrostatic version of TGLF, both $T_e$ and $T_i$ are substantially\noverpredicted, underscoring the importance of electromagnetic turbulence in the\nhigh $\\beta$ spherical tokamak regime. Additionally, calculations with neural\nnet surrogate models for TGLF were performed outside of TRANSP with a time\nslice flux matching transport solver, finding better agreement with experiment\nthan the TRANSP simulations, highlighting the impact of different transport\nsolvers and simulation techniques. Altogether, the reasonable agreement with\nexperiment of temperature profiles predicted by MMM motivates a more detailed\nexamination of the sensitivities of the TRANSP simulations with MMM to\ndifferent NSTX plasma regimes in a companion paper, in preparation for\nself-consistent, time-dependent predictive modeling of NSTX-U scenarios.",
      "url": "http://arxiv.org/abs/2509.04359v1",
      "published_time_eastern_timestamp": 1757002792.0
    },
    {
      "title": "FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case\n  Study",
      "summary": "Serverless computing significantly alters software development by abstracting\ninfrastructure management and enabling rapid, modular, event-driven\ndeployments. Despite its benefits, the distinct characteristics of serverless\nfunctions, such as ephemeral execution and fine-grained scalability, pose\nunique security challenges, particularly in open-source platforms like\nOpenFaaS. Existing approaches typically address isolated phases of the\nDevSecOps lifecycle, lacking an integrated and comprehensive security strategy.\nTo bridge this gap, we propose FaaSGuard, a unified DevSecOps pipeline\nexplicitly designed for open-source serverless environments. FaaSGuard\nsystematically embeds lightweight, fail-closed security checks into every stage\nof the development lifecycle-planning, coding, building, deployment, and\nmonitoring-effectively addressing threats such as injection attacks, hard-coded\nsecrets, and resource exhaustion. We validate our approach empirically through\na case study involving 20 real-world serverless functions from public GitHub\nrepositories. Results indicate that FaaSGuard effectively detects and prevents\ncritical vulnerabilities, demonstrating high precision (95%) and recall (91%)\nwithout significant disruption to established CI/CD practices.",
      "url": "http://arxiv.org/abs/2509.04328v1",
      "published_time_eastern_timestamp": 1757000893.0
    },
    {
      "title": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment\n  Changes",
      "summary": "The AlphaZero framework provides a standard way of combining Monte Carlo\nplanning with prior knowledge provided by a previously trained policy-value\nneural network. AlphaZero usually assumes that the environment on which the\nneural network was trained will not change at test time, which constrains its\napplicability. In this paper, we analyze the problem of deploying AlphaZero\nagents in potentially changed test environments and demonstrate how the\ncombination of simple modifications to the standard framework can significantly\nboost performance, even in settings with a low planning budget available. The\ncode is publicly available on GitHub.",
      "url": "http://arxiv.org/abs/2509.04317v1",
      "published_time_eastern_timestamp": 1757000317.0
    },
    {
      "title": "Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow\n  Real Instructions?",
      "summary": "Large Language Models (LLMs) achieve strong performance on diverse tasks but\noften exhibit cognitive inertia, struggling to follow instructions that\nconflict with the standardized patterns learned during supervised fine-tuning\n(SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that\nmeasures models Counter-intuitive Abilitytheir capacity to override\ntraining-induced biases and comply with adversarial instructions. Inverse\nIFEval introduces eight types of such challenges, including Question\nCorrection, Intentional Textual Flaws, Code without Comments, and\nCounterfactual Answering. Using a human-in-the-loop pipeline, we construct a\ndataset of 1012 high-quality Chinese and English questions across 23 domains,\nevaluated under an optimized LLM-as-a-Judge framework. Experiments on existing\nleading LLMs demonstrate the necessity of our proposed Inverse IFEval\nbenchmark. Our findings emphasize that future alignment efforts should not only\npursue fluency and factual correctness but also account for adaptability under\nunconventional contexts. We hope that Inverse IFEval serves as both a\ndiagnostic tool and a foundation for developing methods that mitigate cognitive\ninertia, reduce overfitting to narrow patterns, and ultimately enhance the\ninstruction-following reliability of LLMs in diverse and unpredictable\nreal-world scenarios.",
      "url": "http://arxiv.org/abs/2509.04292v1",
      "published_time_eastern_timestamp": 1756998182.0
    },
    {
      "title": "Non-Reed-Solomon Type MDS Codes from Elliptic Curves",
      "summary": "In this paper, we present a new family of MDS codes derived from elliptic\ncurves. These codes attain lengths close to the theoretical maximum and are\nprovably inequivalent to Reed-Solomon (RS) codes. Unlike many previous\nconstructions that rely on the point at infinity, our approach allows for more\ngeneral choices: we consider divisors supported on affine points and divisors\nconsisting of multiple distinct points. This broader framework enables the\nconstruction of codes with length approximately $(q + 1 + \\lfloor 2\\sqrt{q}\n\\rfloor)/2$, further illustrating the tightness of known upper bounds on\nelliptic MDS code lengths. A detailed comparison shows that our codes are not\ncovered by earlier results. Moreover, we show that their inequivalence to RS\ncodes by explicitly computing the rank of the Schur product of their generator\nmatrices.",
      "url": "http://arxiv.org/abs/2509.04247v1",
      "published_time_eastern_timestamp": 1756995673.0
    },
    {
      "title": "SISSI: Supernovae in a stratified, shearing interstellar medium. II.\n  Star formation near the Sun is quenched by expansion of the Local Bubble",
      "summary": "The age of the Local Bubble (LB) can be used to constrain the timescales, on\nwhich the interstellar medium in the solar neighborhood is evolving. Previous\nestimates have put the age of the LB at $\\gtrsim 14\\,\\text{Myr}$, and suggested\nthat its expansion was powered by $\\sim 15-20$ SNe, yet in a companion paper we\nhave seen hints that this age might be too high. Following up on these hints,\nwe aim to place new constraints on the age of the LB. We reconstruct the\ngeometry and momentum of the LB using publicly available 3D dust maps to\ncompare its geometry to that of the high-quality sample of simulated supernova\nremnants in the SISSI project. We find that, in contrast to previous estimates,\n$\\gtrsim 20$ SNe over $\\sim 4\\,\\text{Myr}$ are required to explain both the\nmomentum and the size of the LB. The julia source-code for our analysis is made\navailable at https://doi.org/10.5281/zenodo.17054923. Previous estimates of the\nage of the LB have seemingly overestimated its age and underestimated the\nnumber of SNe powering its expansion. Our results are in tension with the\nassumption that the LB is powered solely by SNe associated with the nearby\nScorpius-Centraurus OB association, which appears to have stopped forming stars\nat about the same time as the LB began to expand. In light of this new\nevidence, our results cast serious doubts on the claim that star formation in\nthe solar neighborhood was driven by the expansion of the LB, and might have\ninstead quenched it.",
      "url": "http://arxiv.org/abs/2509.04221v1",
      "published_time_eastern_timestamp": 1756993993.0
    },
    {
      "title": "Explicit and Implicit Data Augmentation for Social Event Detection",
      "summary": "Social event detection involves identifying and categorizing important events\nfrom social media, which relies on labeled data, but annotation is costly and\nlabor-intensive. To address this problem, we propose Augmentation framework for\nSocial Event Detection (SED-Aug), a plug-and-play dual augmentation framework,\nwhich combines explicit text-based and implicit feature-space augmentation to\nenhance data diversity and model robustness. The explicit augmentation utilizes\nlarge language models to enhance textual information through five diverse\ngeneration strategies. For implicit augmentation, we design five novel\nperturbation techniques that operate in the feature space on structural fused\nembeddings. These perturbations are crafted to keep the semantic and relational\nproperties of the embeddings and make them more diverse. Specifically, SED-Aug\noutperforms the best baseline model by approximately 17.67% on the Twitter2012\ndataset and by about 15.57% on the Twitter2018 dataset in terms of the average\nF1 score. The code is available at GitHub: https://github.com/congboma/SED-Aug.",
      "url": "http://arxiv.org/abs/2509.04202v1",
      "published_time_eastern_timestamp": 1756992384.0
    },
    {
      "title": "DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval",
      "summary": "Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images of\nthe same category across diverse domains without relying on annotations.\nExisting UCIR methods, which align cross-domain features for the entire image,\noften struggle with the domain gap, as the object features critical for\nretrieval are frequently entangled with domain-specific styles. To address this\nchallenge, we propose DUDE, a novel UCIR method building upon feature\ndisentanglement. In brief, DUDE leverages a text-to-image generative model to\ndisentangle object features from domain-specific styles, thus facilitating\nsemantical image retrieval. To further achieve reliable alignment of the\ndisentangled object features, DUDE aligns mutual neighbors from within domains\nto across domains in a progressive manner. Extensive experiments demonstrate\nthat DUDE achieves state-of-the-art performance across three benchmark datasets\nover 13 domains. The code will be released.",
      "url": "http://arxiv.org/abs/2509.04193v1",
      "published_time_eastern_timestamp": 1756991716.0
    },
    {
      "title": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn\n  Mental Health Counseling Sessions",
      "summary": "The growing demand for scalable psychological counseling highlights the need\nfor fine-tuning open-source Large Language Models (LLMs) with high-quality,\nprivacy-compliant data, yet such data remains scarce. Here we introduce MAGneT,\na novel multi-agent framework for synthetic psychological counseling session\ngeneration that decomposes counselor response generation into coordinated\nsub-tasks handled by specialized LLM agents, each modeling a key psychological\ntechnique. Unlike prior single-agent approaches, MAGneT better captures the\nstructure and nuance of real counseling. In addition, we address\ninconsistencies in prior evaluation protocols by proposing a unified evaluation\nframework integrating diverse automatic and expert metrics. Furthermore, we\nexpand the expert evaluations from four aspects of counseling in previous works\nto nine aspects, enabling a more thorough and robust assessment of data\nquality. Empirical results show that MAGneT significantly outperforms existing\nmethods in quality, diversity, and therapeutic alignment of the generated\ncounseling sessions, improving general counseling skills by 3.2% and\nCBT-specific skills by 4.3% on average on cognitive therapy rating scale\n(CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases\non average across all aspects. Moreover, fine-tuning an open-source model on\nMAGneT-generated sessions shows better performance, with improvements of 6.3%\non general counseling skills and 7.3% on CBT-specific skills on average on CTRS\nover those fine-tuned with sessions generated by baseline methods. We also make\nour code and data public.",
      "url": "http://arxiv.org/abs/2509.04183v1",
      "published_time_eastern_timestamp": 1756990764.0
    }
  ]
}
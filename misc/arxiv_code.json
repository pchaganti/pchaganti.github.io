{
  "last_updated": "2025-09-23T17:10:00.951792-04:00",
  "papers": [
    {
      "title": "GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface\n  Reconstruction",
      "summary": "Reconstructing accurate surfaces with radiance fields has achieved remarkable\nprogress in recent years. However, prevailing approaches, primarily based on\nGaussian Splatting, are increasingly constrained by representational\nbottlenecks. In this paper, we introduce GeoSVR, an explicit voxel-based\nframework that explores and extends the under-investigated potential of sparse\nvoxels for achieving accurate, detailed, and complete surface reconstruction.\nAs strengths, sparse voxels support preserving the coverage completeness and\ngeometric clarity, while corresponding challenges also arise from absent scene\nconstraints and locality in surface refinement. To ensure correct scene\nconvergence, we first propose a Voxel-Uncertainty Depth Constraint that\nmaximizes the effect of monocular depth cues while presenting a voxel-oriented\nuncertainty to avoid quality degradation, enabling effective and robust scene\nconstraints yet preserving highly accurate geometries. Subsequently, Sparse\nVoxel Surface Regularization is designed to enhance geometric consistency for\ntiny voxels and facilitate the voxel-based formation of sharp and accurate\nsurfaces. Extensive experiments demonstrate our superior performance compared\nto existing methods across diverse challenging scenarios, excelling in\ngeometric accuracy, detail preservation, and reconstruction completeness while\nmaintaining high efficiency. Code is available at\nhttps://github.com/Fictionarry/GeoSVR.",
      "url": "http://arxiv.org/abs/2509.18090v1",
      "published_time_eastern_timestamp": 1758563928.0
    },
    {
      "title": "Reinforced Generation of Combinatorial Structures: Applications to\n  Complexity Theory",
      "summary": "We explore whether techniques from AI can help discover new combinatorial\nstructures that improve provable limits on efficient algorithms. Specifically,\nwe use AlphaEvolve (an LLM coding agent) to study two settings:\n  a) Average-case hardness for MAX-CUT and MAX-Independent Set: We improve a\nrecent result of Kunisky and Yu to obtain near-optimal upper and (conditional)\nlower bounds on certification algorithms for MAX-CUT and MAX-Independent Set on\nrandom 3- and 4-regular graphs. Our improved lower bounds are obtained by\nconstructing nearly extremal Ramanujan graphs on as many as $163$ nodes, using\nAlphaEvolve. Additionally, via analytical arguments we strengthen the upper\nbounds to settle the computational hardness of these questions up to an error\nin the third decimal place.\n  b) Worst-case Hardness of Approximation for MAX-k-CUT: We obtain new\ninapproximability results, proving that it is NP-hard to approximate MAX-4-CUT\nand MAX-3-CUT within factors of $0.987$ and $0.9649$ respectively, using\nAlphaEvolve to discover new gadget reductions. Our MAX-4-CUT result improves\nupon the SOTA of $0.9883$, and our MAX-3-CUT result improves on the current\nbest gadget-based inapproximability result of $0.9853$, but falls short of\nimproving the SOTA of $16/17$ that relies on a custom PCP, rather than a gadget\nreduction from \"standard\" H{\\aa}stad-style PCPs.\n  A key technical challenge we faced: verifying a candidate construction\nproduced by AlphaEvolve is costly (often requiring exponential time). In both\nsettings above, our results were enabled by using AlphaEvolve itself to evolve\nthe verification procedure to be faster (sometimes by $10,000\\times$). We\nconclude with a discussion of norms by which to assess the assistance from AI\nin developing proofs.",
      "url": "http://arxiv.org/abs/2509.18057v1",
      "published_time_eastern_timestamp": 1758562233.0
    },
    {
      "title": "TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning\n  for Video LLMs",
      "summary": "This paper introduces TempSamp-R1, a new reinforcement fine-tuning framework\ndesigned to improve the effectiveness of adapting multimodal large language\nmodels (MLLMs) to video temporal grounding tasks. We reveal that existing\nreinforcement learning methods, such as Group Relative Policy Optimization\n(GRPO), rely on on-policy sampling for policy updates. However, in tasks with\nlarge temporal search spaces, this strategy becomes both inefficient and\nlimited in performance, as it often fails to identify temporally accurate\nsolutions. To address this limitation, TempSamp-R1 leverages ground-truth\nannotations as off-policy supervision to provide temporally precise guidance,\neffectively compensating for the sparsity and misalignment in on-policy\nsolutions. To further stabilize training and reduce variance in reward-based\nupdates, TempSamp-R1 provides a non-linear soft advantage computation method\nthat dynamically reshapes the reward feedback via an asymmetric transformation.\nBy employing a hybrid Chain-of-Thought (CoT) training paradigm, TempSamp-R1\noptimizes a single unified model to support both CoT and non-CoT inference\nmodes, enabling efficient handling of queries with varying reasoning\ncomplexity. Experimental results demonstrate that TempSamp-R1 outperforms\nGRPO-based baselines, establishing new state-of-the-art performance on\nbenchmark datasets: Charades-STA (R1@0.7: 52.9%, +2.7%), ActivityNet Captions\n(R1@0.5: 56.0%, +5.3%), and QVHighlights (mAP: 30.0%, +3.0%). Moreover,\nTempSamp-R1 shows robust few-shot generalization capabilities under limited\ndata. Code: https://github.com/HVision-NKU/TempSamp-R1",
      "url": "http://arxiv.org/abs/2509.18056v1",
      "published_time_eastern_timestamp": 1758562215.0
    },
    {
      "title": "Global stability of ghostly field theories: Classical scattering in\n  $(N+1)$ dimensions",
      "summary": "We review results on small-data global stability and highlight their\napplicability to classical interacting scalar fields with opposite-sign kinetic\nterms (ghosts). Further, we present a one-parameter family of numerical\nscattering solutions under the simplifying assumption of spherical symmetry. We\nthereby identify classical ghostly field theories with polynomial interaction\npotentials for which small-data global stability apparently extends to\nlarge-data global stability, i.e., global stability for all compactly supported\ninitial data. These global stability results support an underlying physical\nmechanism by which the ghost instability can be quenched due to dominant\nself-interactions, at least in classical physics.",
      "url": "http://arxiv.org/abs/2509.18049v1",
      "published_time_eastern_timestamp": 1758561827.0
    },
    {
      "title": "Impact of nonthermal electron distributions on the triggering of the\n  ion-ion acoustic instability near the Sun: Kinetic simulations",
      "summary": "Context. In a previous paper (Afify et al. 2024), we have investigated the\nstability threshold of the ion-ion acoustic instability (IIAI) in parameter\nregimes compatible with recent Parker Solar Probe (PSP, (Fox et al. 2016))\nobservations, in the presence of a Maxwellian electron distribution. We found\nthat observed parameters are close to the instability threshold, but IIAI\nrequires a higher electron temperature than observed. Aims. As electron\ndistributions in the solar wind present clear non-Maxwellian features, we\ninvestigate here if deviations from the Maxwellian distribution could explain\nthe observed IIAI. We address specifically the kappa ( $\\kappa$ ) and\ncore-strahl distributions for the electrons. Methods. We perform analytical\nstudies and kinetic simulations using a Vlasov-Poisson code in a parameter\nregime relevant to PSP observations. The simulated growth rates are validated\nagainst kinetic theory. Results. We show that the IIAI threshold changes in the\npresence of $\\kappa$ or core-strahl electron distributions, but not\nsignificantly. In the latter case, the expression of an effective temperature\nfor an equivalent Maxwellian electron distribution given in Jones et al. (1975)\nis confirmed by simulations. Such an effective temperature could simplify\nstability assessment of future observations.",
      "url": "http://arxiv.org/abs/2509.18032v1",
      "published_time_eastern_timestamp": 1758560788.0
    },
    {
      "title": "A Decade of Transit-Timing Measurements Confirm Resonance in the K2-19\n  System",
      "summary": "K2-19 is a star, slightly smaller than the Sun, that hosts three transiting\nplanets. Two of these, K2-19 b and c, are between the size of Neptune and\nSaturn and have orbital periods near a 3:2 commensurability, and exhibit strong\ntransit-timing variations (TTVs). A previous TTV analysis reported moderate\neccentricities of $\\approx0.20 \\pm0.03$ for the two planets, but such high\nvalues would imply rapid orbital decay for the innermost planet d. Here, we\npresent an updated analysis that includes eight new transit times from TESS,\nwhich extends the time baseline from three years to a decade, and employ a\ngradient-aware TTV modeling code. We confirm that the system resides in\nresonance with a small libration amplitude, but find a broader constraints on\neccentricity that range from a few percent up to 0.2. These revised\neccentricities alleviate previous concerns regarding rapid tidal\ncircularization and support the long-term dynamical stability of the system.",
      "url": "http://arxiv.org/abs/2509.18031v1",
      "published_time_eastern_timestamp": 1758560656.0
    },
    {
      "title": "Adaptive Kernel Design for Bayesian Optimization Is a Piece of CAKE with\n  LLMs",
      "summary": "The efficiency of Bayesian optimization (BO) relies heavily on the choice of\nthe Gaussian process (GP) kernel, which plays a central role in balancing\nexploration and exploitation under limited evaluation budgets. Traditional BO\nmethods often rely on fixed or heuristic kernel selection strategies, which can\nresult in slow convergence or suboptimal solutions when the chosen kernel is\npoorly suited to the underlying objective function. To address this limitation,\nwe propose a freshly-baked Context-Aware Kernel Evolution (CAKE) to enhance BO\nwith large language models (LLMs). Concretely, CAKE leverages LLMs as the\ncrossover and mutation operators to adaptively generate and refine GP kernels\nbased on the observed data throughout the optimization process. To maximize the\npower of CAKE, we further propose BIC-Acquisition Kernel Ranking (BAKER) to\nselect the most effective kernel through balancing the model fit measured by\nthe Bayesian information criterion (BIC) with the expected improvement at each\niteration of BO. Extensive experiments demonstrate that our fresh CAKE-based BO\nmethod consistently outperforms established baselines across a range of\nreal-world tasks, including hyperparameter optimization, controller tuning, and\nphotonic chip design. Our code is publicly available at\nhttps://github.com/cake4bo/cake.",
      "url": "http://arxiv.org/abs/2509.17998v1",
      "published_time_eastern_timestamp": 1758559152.0
    },
    {
      "title": "Everything all at once: On choosing an estimand for multi-component\n  environmental exposures",
      "summary": "Many research questions -- particularly those in environmental health -- do\nnot involve binary exposures. In environmental epidemiology, this includes\nmultivariate exposure mixtures with nondiscrete components. Causal inference\nestimands and estimators to quantify the relationship between an exposure\nmixture and an outcome are relatively few. We propose an approach to quantify a\nrelationship between a shift in the exposure mixture and the outcome -- either\nin the single timepoint or longitudinal setting. The shift in the exposure\nmixture can be defined flexibly in terms of shifting one or more components,\nincluding examining interaction between mixture components, and in terms of\nshifting the same or different amounts across components. The estimand we\ndiscuss has a similar interpretation as a main effect regression coefficient.\nFirst, we focus on choosing a shift in the exposure mixture supported by\nobserved data. We demonstrate how to assess extrapolation and modify the shift\nto minimize reliance on extrapolation. Second, we propose estimating the\nrelationship between the exposure mixture shift and outcome completely\nnonparametrically, using machine learning in model-fitting. This is in contrast\nto other current approaches, which employ parametric modeling for at least some\nrelationships, which we would like to avoid because parametric modeling\nassumptions in complex, nonrandomized settings are tenuous at best. We are\nmotivated by longitudinal data on pesticide exposures among participants in the\nCHAMACOS Maternal Cognition cohort. We examine the relationship between\nlongitudinal exposure to agricultural pesticides and risk of hypertension. We\nprovide step-by-step code to facilitate the easy replication and adaptation of\nthe approaches we use.",
      "url": "http://arxiv.org/abs/2509.17960v1",
      "published_time_eastern_timestamp": 1758557753.0
    },
    {
      "title": "Tops of graphs of projective codes",
      "summary": "Let $\\Gamma_k(V)$ be the Grassmann graph whose vertex set ${\\mathcal\nG}_{k}(V)$ is formed by all $k$-dimensional subspaces of an $n$-dimensional\nvector space $V$ over the finite field $F_q$ consisting of $q$ elements. Denote\nby $\\Pi[n,k]_q$ the subgraph of $\\Gamma_k(V)$ formed by projective codes. We\ngive a complete description of cliques $\\langle U]^{\\Pi}_{k}$ of $\\Pi[n,k]_q$\nconsisting of all $k$-dimensional projective codes contained in a fixed\n$(k+1)$-dimensional subspace of $V$. We show when and in how many lines of\n${\\mathcal G}_{k}(V)$ they are contained. Next we prove that $\\langle\nU]^{\\Pi}_{k}$ is a maximal clique of $\\Pi[n,k]_q$ exactly if it\n  is contained in at most one line of ${\\mathcal G}_{k}(V)$.",
      "url": "http://arxiv.org/abs/2509.17958v1",
      "published_time_eastern_timestamp": 1758557665.0
    },
    {
      "title": "DragOSM: Extract Building Roofs and Footprints from Aerial Images by\n  Aligning Historical Labels",
      "summary": "Extracting polygonal roofs and footprints from remote sensing images is\ncritical for large-scale urban analysis. Most existing methods rely on\nsegmentation-based models that assume clear semantic boundaries of roofs, but\nthese approaches struggle in off- nadir images, where the roof and footprint\nare significantly displaced, and facade pixels are fused with the roof\nboundary. With the increasing availability of open vector map annotations,\ne.g., OpenStreetMap, utilizing historical labels for off-nadir image annotation\nhas become viable because remote sensing images are georeferenced once\ncaptured. However, these historical labels commonly suffer from significant\npositional discrepancies with new images and only have one annotation (roof or\nfootprint), which fails to describe the correct structures of a building. To\naddress these discrepancies, we first introduce a concept of an alignment\ntoken, which encodes the correction vector to guide the label correction. Based\non this concept, we then propose Drag OpenStreetMap Labels (DragOSM), a novel\nmodel designed to align dislocated historical labels with roofs and footprints.\nSpecifically, DragOSM formulates the label alignment as an interactive\ndenoising process, modeling the positional discrepancy as a Gaussian\ndistribution. During training, it learns to correct these errors by simulating\nmisalignment with random Gaussian perturbations; during inference, it\niteratively refines the positions of input labels. To validate our method, we\nfurther present a new dataset, Repairing Buildings in OSM (ReBO), comprising\n179,265 buildings with both OpenStreetMap and manually corrected annotations\nacross 5,473 images from 41 cities. Experimental results on ReBO demonstrate\nthe effectiveness of DragOSM. Code, dataset, and trained models are publicly\navailable at https://github.com/likaiucas/DragOSM.git.",
      "url": "http://arxiv.org/abs/2509.17951v1",
      "published_time_eastern_timestamp": 1758557413.0
    },
    {
      "title": "HICode: Hierarchical Inductive Coding with LLMs",
      "summary": "Despite numerous applications for fine-grained corpus analysis, researchers\ncontinue to rely on manual labeling, which does not scale, or statistical tools\nlike topic modeling, which are difficult to control. We propose that LLMs have\nthe potential to scale the nuanced analyses that researchers typically conduct\nmanually to large text corpora. To this effect, inspired by qualitative\nresearch methods, we develop HICode, a two-part pipeline that first inductively\ngenerates labels directly from analysis data and then hierarchically clusters\nthem to surface emergent themes. We validate this approach across three diverse\ndatasets by measuring alignment with human-constructed themes and demonstrating\nits robustness through automated and human evaluations. Finally, we conduct a\ncase study of litigation documents related to the ongoing opioid crisis in the\nU.S., revealing aggressive marketing strategies employed by pharmaceutical\ncompanies and demonstrating HICode's potential for facilitating nuanced\nanalyses in large-scale data.",
      "url": "http://arxiv.org/abs/2509.17946v1",
      "published_time_eastern_timestamp": 1758557231.0
    },
    {
      "title": "Can multimodal representation learning by alignment preserve\n  modality-specific information?",
      "summary": "Combining multimodal data is a key issue in a wide range of machine learning\ntasks, including many remote sensing problems. In Earth observation, early\nmultimodal data fusion methods were based on specific neural network\narchitectures and supervised learning. Ever since, the scarcity of labeled data\nhas motivated self-supervised learning techniques. State-of-the-art multimodal\nrepresentation learning techniques leverage the spatial alignment between\nsatellite data from different modalities acquired over the same geographic area\nin order to foster a semantic alignment in the latent space. In this paper, we\ninvestigate how this methods can preserve task-relevant information that is not\nshared across modalities. First, we show, under simplifying assumptions, when\nalignment strategies fundamentally lead to an information loss. Then, we\nsupport our theoretical insight through numerical experiments in more realistic\nsettings. With those theoretical and empirical evidences, we hope to support\nnew developments in contrastive learning for the combination of multimodal\nsatellite data. Our code and data is publicly available at\nhttps://github.com/Romain3Ch216/alg_maclean_25.",
      "url": "http://arxiv.org/abs/2509.17943v1",
      "published_time_eastern_timestamp": 1758557170.0
    },
    {
      "title": "SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain\n  Brain Tumor Segmentation in MRI",
      "summary": "Reliable brain tumor segmentation in MRI is indispensable for treatment\nplanning and outcome monitoring, yet models trained on curated benchmarks often\nfail under domain shifts arising from scanner and protocol variability as well\nas population heterogeneity. Such gaps are especially severe in low-resource\nand pediatric cohorts, where conventional test-time or source-free adaptation\nstrategies often suffer from instability and structural inconsistency. We\npropose SmaRT, a style-modulated robust test-time adaptation framework that\nenables source-free cross-domain generalization. SmaRT integrates style-aware\naugmentation to mitigate appearance discrepancies, a dual-branch momentum\nstrategy for stable pseudo-label refinement, and structural priors enforcing\nconsistency, integrity, and connectivity. This synergy ensures both adaptation\nstability and anatomical fidelity under extreme domain shifts. Extensive\nevaluations on sub-Saharan Africa and pediatric glioma datasets show that SmaRT\nconsistently outperforms state-of-the-art methods, with notable gains in Dice\naccuracy and boundary precision. Overall, SmaRT bridges the gap between\nalgorithmic advances and equitable clinical applicability, supporting robust\ndeployment of MRI-based neuro-oncology tools in diverse clinical environments.\nOur source code is available at https://github.com/baiyou1234/SmaRT.",
      "url": "http://arxiv.org/abs/2509.17925v1",
      "published_time_eastern_timestamp": 1758556259.0
    },
    {
      "title": "SingLEM: Single-Channel Large EEG Model",
      "summary": "Current deep learning models for electroencephalography (EEG) are often\ntask-specific and depend on large labeled datasets, limiting their\nadaptability. Although emerging foundation models aim for broader\napplicability, their rigid dependence on fixed, high-density multi-channel\nmontages restricts their use across heterogeneous datasets and in\nmissing-channel or practical low-channel settings. To address these\nlimitations, we introduce SingLEM, a self-supervised foundation model that\nlearns robust, general-purpose representations from single-channel EEG, making\nit inherently hardware agnostic. The model employs a hybrid encoder\narchitecture that combines convolutional layers to extract local features with\na hierarchical transformer to model both short- and long-range temporal\ndependencies. SingLEM is pretrained on 71 public datasets comprising over 9,200\nsubjects and 357,000 single-channel hours of EEG. When evaluated as a fixed\nfeature extractor across six motor imagery and cognitive tasks, aggregated\nsingle-channel representations consistently outperformed leading multi-channel\nfoundation models and handcrafted baselines. These results demonstrate that a\nsingle-channel approach can achieve state-of-the-art generalization while\nenabling fine-grained neurophysiological analysis and enhancing\ninterpretability. The source code and pretrained models are available at\nhttps://github.com/ttlabtuat/SingLEM.",
      "url": "http://arxiv.org/abs/2509.17920v1",
      "published_time_eastern_timestamp": 1758556018.0
    },
    {
      "title": "Does Audio Matter for Modern Video-LLMs and Their Benchmarks?",
      "summary": "Modern multimodal large language models often claim \"video understanding,\"\nyet most evaluations use muted videos or simply discard audio. We ask a direct\nquestion: how much does audio actually matter for contemporary Video-LLMs and\nthe benchmarks that certify them? We audit widely used suites and observe that\nmany items are even solvable from a single frame, rendering audio largely\nredundant. Building on LLaVA-OneVision architecture, we attach a speech/audio\nencoder (e.g., Whisper) and analyze when audio helps, while addressing audio\ntoken explosion with a lightweight Mamba-based state-space token compressor. We\nfind that audio yields minimal gains on recent video benchmarks but is decisive\non curated, audio-sensitive subsets. To enable faithful evaluation, we release\nAVQA-Hard and Music-AVQA-Hard, our model, and code. Our findings surface a\ngrowing gap between current academic practice and real-world expectations, and\nprovide practical tools for scalable audio-visual Video-LLMs. We will fully\nopen-source our work at https://github.com/naver-ai/LLaVA-AV-SSM.",
      "url": "http://arxiv.org/abs/2509.17901v1",
      "published_time_eastern_timestamp": 1758554934.0
    },
    {
      "title": "The Surprising Effectiveness of Linear Models for Whole-Body\n  Model-Predictive Control",
      "summary": "When do locomotion controllers require reasoning about nonlinearities? In\nthis work, we show that a whole-body model-predictive controller using a simple\nlinear time-invariant approximation of the whole-body dynamics is able to\nexecute basic locomotion tasks on complex legged robots. The formulation\nrequires no online nonlinear dynamics evaluations or matrix inversions. We\ndemonstrate walking, disturbance rejection, and even navigation to a goal\nposition without a separate footstep planner on a quadrupedal robot. In\naddition, we demonstrate dynamic walking on a hydraulic humanoid, a robot with\nsignificant limb inertia, complex actuator dynamics, and large sim-to-real gap.",
      "url": "http://arxiv.org/abs/2509.17884v1",
      "published_time_eastern_timestamp": 1758554265.0
    },
    {
      "title": "Brainprint-Modulated Target Speaker Extraction",
      "summary": "Achieving robust and personalized performance in neuro-steered Target Speaker\nExtraction (TSE) remains a significant challenge for next-generation hearing\naids. This is primarily due to two factors: the inherent non-stationarity of\nEEG signals across sessions, and the high inter-subject variability that limits\nthe efficacy of generalized models. To address these issues, we propose\nBrainprint-Modulated Target Speaker Extraction (BM-TSE), a novel framework for\npersonalized and high-fidelity extraction. BM-TSE first employs a\nspatio-temporal EEG encoder with an Adaptive Spectral Gain (ASG) module to\nextract stable features resilient to non-stationarity. The core of our\nframework is a personalized modulation mechanism, where a unified brainmap\nembedding is learned under the joint supervision of subject identification\n(SID) and auditory attention decoding (AAD) tasks. This learned brainmap,\nencoding both static user traits and dynamic attentional states, actively\nrefines the audio separation process, dynamically tailoring the output to each\nuser. Evaluations on the public KUL and Cocktail Party datasets demonstrate\nthat BM-TSE achieves state-of-the-art performance, significantly outperforming\nexisting methods. Our code is publicly accessible at:\nhttps://github.com/rosshan-orz/BM-TSE.",
      "url": "http://arxiv.org/abs/2509.17883v1",
      "published_time_eastern_timestamp": 1758554255.0
    },
    {
      "title": "CorPipe at CRAC 2025: Evaluating Multilingual Encoders for Multilingual\n  Coreference Resolution",
      "summary": "We present CorPipe 25, the winning entry to the CRAC 2025 Shared Task on\nMultilingual Coreference Resolution. This fourth iteration of the shared task\nintroduces a new LLM track alongside the original unconstrained track, features\nreduced development and test sets to lower computational requirements, and\nincludes additional datasets. CorPipe 25 represents a complete reimplementation\nof our previous systems, migrating from TensorFlow to PyTorch. Our system\nsignificantly outperforms all other submissions in both the LLM and\nunconstrained tracks by a substantial margin of 8 percentage points. The source\ncode and trained models are publicly available at\nhttps://github.com/ufal/crac2025-corpipe.",
      "url": "http://arxiv.org/abs/2509.17858v1",
      "published_time_eastern_timestamp": 1758552697.0
    },
    {
      "title": "Fast and Accurate Decoder for the XZZX code Using Simulated Annealing",
      "summary": "The XZZX code is a variant of the surface code designed to address biased\nnoise in realistic quantum devices. For the XZZX code, we propose a decoder\nbased on simulated annealing (SA). Our SA decoder can be readily and\nefficiently parallelized, by virtue of its simple MCMC-based algorithm. To\nprepare an initial configuration of SA, we propose to employ recovery chains\nobtained by a decoder which utilizes a kind of greedy matching graph algorithm.\nAlthough $Z$-biased noise is commonly assumed in real quantum devices, we focus\non $Y$-biased noise, for which the minimum-weight perfect matching (MWPM)\nalgorithm fails to decode accurately. Our numerical simulation for the code\ncapacity noise model, where only data qubits suffer errors, confirmed that our\nSA decoder is more accurate than the MWPM decoder. Furthermore, our SA decoder\nattained the accuracy equivalent to that of the optimal decoder formulated by\ninteger programming, called CPLEX decoder. In our greedy matching decoder, we\nrandomly determine order of matching pairs of incorrect syndromes that have the\nsame distance. This randomness brings about a variety of initial configurations\nof SA, which leads to faster convergence of our SA decoder. By comparing\ndecoding times of our SA decoder, the CPLEX decoder, and matrix product state\n(MPS) decoder, all of which can handle $Y$-biased noise appropriately, we\nconfirmed that our SA decoder is fastest if parallelized. This result implies a\npotential for combining of our greedy matching and SA decoder for practical use\nin quantum computing.",
      "url": "http://arxiv.org/abs/2509.17837v1",
      "published_time_eastern_timestamp": 1758551245.0
    },
    {
      "title": "AEAS: Actionable Exploit Assessment System",
      "summary": "Security practitioners face growing challenges in exploit assessment, as\npublic vulnerability repositories are increasingly populated with inconsistent\nand low-quality exploit artifacts. Existing scoring systems, such as CVSS and\nEPSS, offer limited support for this task. They either rely on theoretical\nmetrics or produce opaque probability estimates without assessing whether\nusable exploit code exists. In practice, security teams often resort to manual\ntriage of exploit repositories, which is time-consuming, error-prone, and\ndifficult to scale. We present AEAS, an automated system designed to assess and\nprioritize actionable exploits through static analysis. AEAS analyzes both\nexploit code and associated documentation to extract a structured set of\nfeatures reflecting exploit availability, functionality, and setup complexity.\nIt then computes an actionability score for each exploit and produces ranked\nexploit recommendations. We evaluate AEAS on a dataset of over 5,000\nvulnerabilities derived from 600+ real-world applications frequently\nencountered by red teams. Manual validation and expert review on representative\nsubsets show that AEAS achieves a 100% top-3 success rate in recommending\nfunctional exploits and shows strong alignment with expert-validated rankings.\nThese results demonstrate the effectiveness of AEAS in supporting\nexploit-driven vulnerability prioritization.",
      "url": "http://arxiv.org/abs/2509.17832v1",
      "published_time_eastern_timestamp": 1758550984.0
    }
  ]
}
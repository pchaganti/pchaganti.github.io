{
  "last_updated": "2025-08-21T05:12:56.616083-04:00",
  "papers": [
    {
      "title": "Quantization Meets dLLMs: A Systematic Study of Post-training\n  Quantization for Diffusion LLMs",
      "summary": "Recent advances in diffusion large language models (dLLMs) have introduced a\npromising alternative to autoregressive (AR) LLMs for natural language\ngeneration tasks, leveraging full attention and denoising-based decoding\nstrategies. However, the deployment of these models on edge devices remains\nchallenging due to their massive parameter scale and high resource demands.\nWhile post-training quantization (PTQ) has emerged as a widely adopted\ntechnique for compressing AR LLMs, its applicability to dLLMs remains largely\nunexplored. In this work, we present the first systematic study on quantizing\ndiffusion-based language models. We begin by identifying the presence of\nactivation outliers, characterized by abnormally large activation values that\ndominate the dynamic range. These outliers pose a key challenge to low-bit\nquantization, as they make it difficult to preserve precision for the majority\nof values. More importantly, we implement state-of-the-art PTQ methods and\nconduct a comprehensive evaluation across multiple task types and model\nvariants. Our analysis is structured along four key dimensions: bit-width,\nquantization method, task category, and model type. Through this\nmulti-perspective evaluation, we offer practical insights into the quantization\nbehavior of dLLMs under different configurations. We hope our findings provide\na foundation for future research in efficient dLLM deployment. All codes and\nexperimental setups will be released to support the community.",
      "url": "http://arxiv.org/abs/2508.14896v1",
      "published_time_eastern_timestamp": 1755712791.0
    },
    {
      "title": "Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in\n  Milliseconds",
      "summary": "Reconstructing 3D human bodies from sparse views has been an appealing topic,\nwhich is crucial to broader the related applications. In this paper, we propose\na quite challenging but valuable task to reconstruct the human body from only\ntwo images, i.e., the front and back view, which can largely lower the barrier\nfor users to create their own 3D digital humans. The main challenges lie in the\ndifficulty of building 3D consistency and recovering missing information from\nthe highly sparse input. We redesign a geometry reconstruction model based on\nfoundation reconstruction models to predict consistent point clouds even input\nimages have scarce overlaps with extensive human data training. Furthermore, an\nenhancement algorithm is applied to supplement the missing color information,\nand then the complete human point clouds with colors can be obtained, which are\ndirectly transformed into 3D Gaussians for better rendering quality.\nExperiments show that our method can reconstruct the entire human in 190 ms on\na single NVIDIA RTX 4090, with two images at a resolution of 1024x1024,\ndemonstrating state-of-the-art performance on the THuman2.0 and cross-domain\ndatasets. Additionally, our method can complete human reconstruction even with\nimages captured by low-cost mobile devices, reducing the requirements for data\ncollection. Demos and code are available at\nhttps://hustvl.github.io/Snap-Snap/.",
      "url": "http://arxiv.org/abs/2508.14892v1",
      "published_time_eastern_timestamp": 1755712751.0
    },
    {
      "title": "MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds",
      "summary": "Reconstructing 3D objects into editable programs is pivotal for applications\nlike reverse engineering and shape editing. However, existing methods often\nrely on limited domain-specific languages (DSLs) and small-scale datasets,\nrestricting their ability to model complex geometries and structures. To\naddress these challenges, we introduce MeshCoder, a novel framework that\nreconstructs complex 3D objects from point clouds into editable Blender Python\nscripts. We develop a comprehensive set of expressive Blender Python APIs\ncapable of synthesizing intricate geometries. Leveraging these APIs, we\nconstruct a large-scale paired object-code dataset, where the code for each\nobject is decomposed into distinct semantic parts. Subsequently, we train a\nmultimodal large language model (LLM) that translates 3D point cloud into\nexecutable Blender Python scripts. Our approach not only achieves superior\nperformance in shape-to-code reconstruction tasks but also facilitates\nintuitive geometric and topological editing through convenient code\nmodifications. Furthermore, our code-based representation enhances the\nreasoning capabilities of LLMs in 3D shape understanding tasks. Together, these\ncontributions establish MeshCoder as a powerful and flexible solution for\nprogrammatic 3D shape reconstruction and understanding.",
      "url": "http://arxiv.org/abs/2508.14879v1",
      "published_time_eastern_timestamp": 1755712215.0
    },
    {
      "title": "Carrier mobilities and electron-phonon interactions beyond DFT",
      "summary": "Electron-phonon coupling is a key interaction that governs diverse physical\nprocesses such as carrier transport, superconductivity, and optical absorption.\nCalculating such interactions from first-principles with methods beyond\ndensity-functional theory remains a challenge. We introduce here a\nfinite-difference framework for computing electron-phonon couplings for any\nelectronic structure method that provides eigenvalues and eigenvectors, and\nshowcase applications for hybrid and Koopmans functionals, and $GW$ many-body\nperturbation theory. Our approach introduces a novel projectability scheme\nbased on eigenvalue differences and bypasses many of the limitations of the\ndirect finite difference methods. It also leverages symmetries to reduce the\nnumber of independent atomic displacements, thereby keeping computational costs\nmanageable. This approach enables seamless integration with established\nfirst-principles codes for generating displaced supercells, performing Wannier\ninterpolations, and evaluating transport properties. Applications to silicon\nand gallium arsenide show that advanced electronic-structure functionals\npredict different electron-phonon couplings and modify band curvatures,\nresulting in much more accurate estimates of intrinsic carrier drift mobilities\nand effective masses. In general, our method provides a robust and accessible\nframework for exploring electron-phonon interactions in complex materials with\nstate-of-the-art electronic structure methods.",
      "url": "http://arxiv.org/abs/2508.14852v1",
      "published_time_eastern_timestamp": 1755709410.0
    },
    {
      "title": "An Investigation Into Secondary School Students' Debugging Behaviour in\n  Python",
      "summary": "Background and context: Debugging is a common and often frustrating challenge\nfor beginner programmers. Understanding students' debugging processes can help\nus identify the difficulties and misunderstandings they possess. However, we\ncurrently have limited knowledge of how secondary students debug in a\ntext-based language, a medium through which millions of students will learn to\nprogram in the future. Objectives: In this paper, we investigate the debugging\nbehaviour of K-12 students learning a text-based programming language, as part\nof an effort to shape how to effectively teach debugging to these students.\nMethod: We collected log data from 73 students attempting a set of debugging\nexercises using an online code editor. We inductively analysed these logs using\nqualitative content analysis, generating a categorisation of the debugging\nbehaviours observed. Findings: A range of behaviours were exhibited by\nstudents, skewed towards being ineffective. Most students were able to\npartially locate errors but often struggled to resolve them, sometimes\nintroducing additional errors in the process. We argue that students struggling\nto debug possess fragile knowledge, a lens through which we view the results.\nImplications: This paper highlights some of the difficulties K-12 learners have\nwhen debugging in a text-based programming language. We argue, like much\nrelated work, that effective debugging strategies should be explicitly taught,\nwhile ineffective strategies should be discouraged.",
      "url": "http://arxiv.org/abs/2508.14833v1",
      "published_time_eastern_timestamp": 1755707663.0
    },
    {
      "title": "The C-index Multiverse",
      "summary": "Quantifying out-of-sample discrimination performance for time-to-event\noutcomes is a fundamental step for model evaluation and selection in the\ncontext of predictive modelling. The concordance index, or C-index, is a widely\nused metric for this purpose, particularly with the growing development of\nmachine learning methods. Beyond differences between proposed C-index\nestimators (e.g. Harrell's, Uno's and Antolini's), we demonstrate the existence\nof a C-index multiverse among available R and python software, where seemingly\nequal implementations can yield different results. This can undermine\nreproducibility and complicate fair comparisons across models and studies. Key\nvariation sources include tie handling and adjustment to censoring.\nAdditionally, the absence of a standardised approach to summarise risk from\nsurvival distributions, result in another source of variation dependent on\ninput types. We demonstrate the consequences of the C-index multiverse when\nquantifying predictive performance for several survival models (from Cox\nproportional hazards to recent deep learning approaches) on publicly available\nbreast cancer data, and semi-synthetic examples. Our work emphasises the need\nfor better reporting to improve transparency and reproducibility. This article\naims to be a useful guideline, helping analysts when navigating the multiverse,\nproviding unified documentation and highlighting potential pitfalls of existing\nsoftware. All code is publicly available at:\nwww.github.com/BBolosSierra/CindexMultiverse.",
      "url": "http://arxiv.org/abs/2508.14821v1",
      "published_time_eastern_timestamp": 1755706270.0
    },
    {
      "title": "TransLLM: A Unified Multi-Task Foundation Framework for Urban\n  Transportation via Learnable Prompting",
      "summary": "Urban transportation systems encounter diverse challenges across multiple\ntasks, such as traffic forecasting, electric vehicle (EV) charging demand\nprediction, and taxi dispatch. Existing approaches suffer from two key\nlimitations: small-scale deep learning models are task-specific and\ndata-hungry, limiting their generalizability across diverse scenarios, while\nlarge language models (LLMs), despite offering flexibility through natural\nlanguage interfaces, struggle with structured spatiotemporal data and numerical\nreasoning in transportation domains. To address these limitations, we propose\nTransLLM, a unified foundation framework that integrates spatiotemporal\nmodeling with large language models through learnable prompt composition. Our\napproach features a lightweight spatiotemporal encoder that captures complex\ndependencies via dilated temporal convolutions and dual-adjacency graph\nattention networks, seamlessly interfacing with LLMs through structured\nembeddings. A novel instance-level prompt routing mechanism, trained via\nreinforcement learning, dynamically personalizes prompts based on input\ncharacteristics, moving beyond fixed task-specific templates. The framework\noperates by encoding spatiotemporal patterns into contextual representations,\ndynamically composing personalized prompts to guide LLM reasoning, and\nprojecting the resulting representations through specialized output layers to\ngenerate task-specific predictions. Experiments across seven datasets and three\ntasks demonstrate the exceptional effectiveness of TransLLM in both supervised\nand zero-shot settings. Compared to ten baseline models, it delivers\ncompetitive performance on both regression and planning problems, showing\nstrong generalization and cross-task adaptability. Our code is available at\nhttps://github.com/BiYunying/TransLLM.",
      "url": "http://arxiv.org/abs/2508.14782v1",
      "published_time_eastern_timestamp": 1755703669.0
    },
    {
      "title": "Adversarial Hospital-Invariant Feature Learning for WSI Patch\n  Classification",
      "summary": "Pathology foundation models (PFMs) have demonstrated remarkable potential in\nwhole-slide image (WSI) diagnosis. However, pathology images from different\nhospitals often vary due to differences in scanning hardware and preprocessing\nstyles, which may lead PFMs to inadvertently learn hospital-specific features,\nposing risks for clinical deployment. In this work, we present the first\nsystematic study of domain bias in PFMs arising from hospital source\ncharacteristics. Specifically, we (1) construct a pipeline for quantifying\ndomain bias in PFMs, (2) evaluate and compare the performance of multiple\nmodels, and (3) propose a lightweight adversarial framework that removes latent\nhospital-specific features from frozen representations without modifying the\nencoder itself. By introducing a trainable adapter and a domain classifier\nconnected through a gradient reversal layer (GRL), our method learns\ntask-discriminative yet domain-invariant representations. Experiments on\nmulti-center histopathology datasets demonstrate that our approach\nsubstantially reduces domain predictability while maintaining or even improving\ndisease classification performance, particularly in out-of-domain (unseen\nhospital) scenarios. Further analyses, including hospital detection and feature\nspace visualization, confirm the effectiveness of our method in mitigating\nhospital bias. We will provide our code based on acceptance.",
      "url": "http://arxiv.org/abs/2508.14779v1",
      "published_time_eastern_timestamp": 1755703516.0
    },
    {
      "title": "Federated Distillation on Edge Devices: Efficient Client-Side Filtering\n  for Non-IID Data",
      "summary": "Federated distillation has emerged as a promising collaborative machine\nlearning approach, offering enhanced privacy protection and reduced\ncommunication compared to traditional federated learning by exchanging model\noutputs (soft logits) rather than full model parameters. However, existing\nmethods employ complex selective knowledge-sharing strategies that require\nclients to identify in-distribution proxy data through computationally\nexpensive statistical density ratio estimators. Additionally, server-side\nfiltering of ambiguous knowledge introduces latency to the process. To address\nthese challenges, we propose a robust, resource-efficient EdgeFD method that\nreduces the complexity of the client-side density ratio estimation and removes\nthe need for server-side filtering. EdgeFD introduces an efficient KMeans-based\ndensity ratio estimator for effectively filtering both in-distribution and\nout-of-distribution proxy data on clients, significantly improving the quality\nof knowledge sharing. We evaluate EdgeFD across diverse practical scenarios,\nincluding strong non-IID, weak non-IID, and IID data distributions on clients,\nwithout requiring a pre-trained teacher model on the server for knowledge\ndistillation. Experimental results demonstrate that EdgeFD outperforms\nstate-of-the-art methods, consistently achieving accuracy levels close to IID\nscenarios even under heterogeneous and challenging conditions. The\nsignificantly reduced computational overhead of the KMeans-based estimator is\nsuitable for deployment on resource-constrained edge devices, thereby enhancing\nthe scalability and real-world applicability of federated distillation. The\ncode is available online for reproducibility.",
      "url": "http://arxiv.org/abs/2508.14769v1",
      "published_time_eastern_timestamp": 1755703079.0
    },
    {
      "title": "Investigation of the Inter-Rater Reliability between Large Language\n  Models and Human Raters in Qualitative Analysis",
      "summary": "Qualitative analysis is typically limited to small datasets because it is\ntime-intensive. Moreover, a second human rater is required to ensure reliable\nfindings. Artificial intelligence tools may replace human raters if we\ndemonstrate high reliability compared to human ratings. We investigated the\ninter-rater reliability of state-of-the-art Large Language Models (LLMs),\nChatGPT-4o and ChatGPT-4.5-preview, in rating audio transcripts coded manually.\nWe explored prompts and hyperparameters to optimize model performance. The\nparticipants were 14 undergraduate student groups from a university in the\nmidwestern United States who discussed problem-solving strategies for a\nproject. We prompted an LLM to replicate manual coding, and calculated Cohen's\nKappa for inter-rater reliability. After optimizing model hyperparameters and\nprompts, the results showed substantial agreement (${\\kappa}>0.6$) for three\nthemes and moderate agreement on one. Our findings demonstrate the potential of\nGPT-4o and GPT-4.5 for efficient, scalable qualitative analysis in physics\neducation and identify their limitations in rating domain-general constructs.",
      "url": "http://arxiv.org/abs/2508.14764v1",
      "published_time_eastern_timestamp": 1755702772.0
    },
    {
      "title": "Dual-Role Dynamics in Prompting: Elementary Pre-service Teachers' AI\n  Prompting Strategies for Representational Choices",
      "summary": "Pre-service teachers play a unique dual role as they straddle between the\nroles of students and future teachers. This dual role requires them to adopt\nboth the learner's and the instructor's perspectives while engaging with\npedagogical and content knowledge. The current study investigates how\npre-service elementary teachers taking a physical science course prompt AI to\ngenerate representations that effectively communicate conceptual ideas to two\ndistinct audiences. The context involves participants interacting with AI to\ngenerate appropriate representations that explain the concepts of wave velocity\nto their elementary students (while casting themselves as teachers) and the\nIdeal Gas Law to their English teachers (while casting themselves as students).\nEmergent coding of the AI prompts highlight that, when acting as teachers,\nparticipants were more explicit in specifying the target audience,\npredetermining the type of representation, and producing a broader variety of\nrepresentations compared to when they acted as students. Implications of the\nobserved 'exploratory' and 'prescriptive' prompting trends across the two roles\non pre-service teachers' education and their professional development are\ndiscussed.",
      "url": "http://arxiv.org/abs/2508.14760v1",
      "published_time_eastern_timestamp": 1755702282.0
    },
    {
      "title": "Reliable generation of isomorphic physics problems using ChatGPT with\n  prompt-chaining and tool use",
      "summary": "We present a method for generating large numbers of isomorphic physics\nproblems using ChatGPT through prompt chaining and tool use. This approach\nenables precise control over structural variations-such as numeric values and\nspatial relations-while supporting diverse contextual variations in the problem\nbody. By utilizing the Python code interpreter, the method supports automatic\nsolution validation and simple diagram generation, addressing key limitations\nin existing LLM-based methods. We generated two example isomorphic problem\nbanks and compared the outcome against simpler prompt-based approaches. Results\nshow that prompt-chaining produces significantly higher quality and more\nconsistent outputs than simpler, non-chaining prompts. This work demonstrates a\npromising method for efficient problem creation accessible to the average\ninstructor, which opens new possibilities for personalized adaptive testing and\nautomated content development.",
      "url": "http://arxiv.org/abs/2508.14755v1",
      "published_time_eastern_timestamp": 1755701885.0
    },
    {
      "title": "Evaluating Multilingual and Code-Switched Alignment in LLMs via\n  Synthetic Natural Language Inference",
      "summary": "Large language models (LLMs) are increasingly applied in multilingual\ncontexts, yet their capacity for consistent, logically grounded alignment\nacross languages remains underexplored. We present a controlled evaluation\nframework for multilingual natural language inference (NLI) that generates\nsynthetic, logic-based premise-hypothesis pairs and translates them into a\ntypologically diverse set of languages. This design enables precise control\nover semantic relations and allows testing in both monolingual and\nmixed-language (code-switched) conditions. Surprisingly, code-switching does\nnot degrade, and can even improve, performance, suggesting that\ntranslation-induced lexical variation may serve as a regularization signal. We\nvalidate semantic preservation through embedding-based similarity analyses and\ncross-lingual alignment visualizations, confirming the fidelity of translated\npairs. Our findings expose both the potential and the brittleness of current\nLLM cross-lingual reasoning, and identify code-switching as a promising lever\nfor improving multilingual robustness. Code available at:\nhttps://github.com/KurbanIntelligenceLab/nli-stress-testing",
      "url": "http://arxiv.org/abs/2508.14735v1",
      "published_time_eastern_timestamp": 1755700234.0
    },
    {
      "title": "AFABench: A Generic Framework for Benchmarking Active Feature\n  Acquisition",
      "summary": "In many real-world scenarios, acquiring all features of a data instance can\nbe expensive or impractical due to monetary cost, latency, or privacy concerns.\nActive Feature Acquisition (AFA) addresses this challenge by dynamically\nselecting a subset of informative features for each data instance, trading\npredictive performance against acquisition cost. While numerous methods have\nbeen proposed for AFA, ranging from greedy information-theoretic strategies to\nnon-myopic reinforcement learning approaches, fair and systematic evaluation of\nthese methods has been hindered by the lack of standardized benchmarks. In this\npaper, we introduce AFABench, the first benchmark framework for AFA. Our\nbenchmark includes a diverse set of synthetic and real-world datasets, supports\na wide range of acquisition policies, and provides a modular design that\nenables easy integration of new methods and tasks. We implement and evaluate\nrepresentative algorithms from all major categories, including static, greedy,\nand reinforcement learning-based approaches. To test the lookahead capabilities\nof AFA policies, we introduce a novel synthetic dataset, AFAContext, designed\nto expose the limitations of greedy selection. Our results highlight key\ntrade-offs between different AFA strategies and provide actionable insights for\nfuture research. The benchmark code is available at:\nhttps://github.com/Linusaronsson/AFA-Benchmark.",
      "url": "http://arxiv.org/abs/2508.14734v1",
      "published_time_eastern_timestamp": 1755700156.0
    },
    {
      "title": "Assessing the Quality and Security of AI-Generated Code: A Quantitative\n  Analysis",
      "summary": "This study presents a quantitative evaluation of the code quality and\nsecurity of five prominent Large Language Models (LLMs): Claude Sonnet 4,\nClaude 3.7 Sonnet, GPT-4o, Llama 3.2 90B, and OpenCoder 8B. While prior\nresearch has assessed the functional performance of LLM-generated code, this\nresearch tested LLM output from 4,442 Java coding assignments through\ncomprehensive static analysis using SonarQube. The findings suggest that\nalthough LLMs can generate functional code, they also introduce a range of\nsoftware defects, including bugs, security vulnerabilities, and code smells.\nThese defects do not appear to be isolated; rather, they may represent shared\nweaknesses stemming from systemic limitations within current LLM code\ngeneration methods. In particular, critically severe issues, such as hard-coded\npasswords and path traversal vulnerabilities, were observed across multiple\nmodels. These results indicate that LLM-generated code requires verification in\norder to be considered production-ready. This study found no direct correlation\nbetween a model's functional performance (measured by Pass@1 rate of unit\ntests) and the overall quality and security of its generated code, measured by\nthe number of SonarQube issues in benchmark solutions that passed the\nfunctional tests. This suggests that functional benchmark performance score is\nnot a good indicator of overall code quality and security. The goal of this\nstudy is not to rank LLM performance but to highlight that all evaluated models\nappear to share certain weaknesses. Consequently, these findings support the\nview that static analysis can be a valuable instrument for detecting latent\ndefects and an important safeguard for organizations that deploy AI in software\ndevelopment.",
      "url": "http://arxiv.org/abs/2508.14727v1",
      "published_time_eastern_timestamp": 1755699381.0
    },
    {
      "title": "The Digital Sous Chef -- A Comparative Study on Fine-Tuning Language\n  Models for Recipe Generation",
      "summary": "We established a rigorous benchmark for text-based recipe generation, a\nfundamental task in natural language generation. We present a comprehensive\ncomparative study contrasting a fine-tuned GPT-2 large (774M) model against the\nGPT-2 small (124M) model and traditional LSTM/RNN baselines on the 5-cuisine\ncorpus from RecipeDB. Our key contribution is a targeted tokenization strategy\nthat augments the vocabulary with 23 common fraction tokens and custom\nstructural markers. This approach addresses a critical limitation of generic\ntokenizers by preserving essential recipe structures and precise numerical\nquantities, thereby enhancing domain specificity. Performance is evaluated\nusing a comprehensive suite of seven automatic metrics spanning fluency\n(BLEU-4, METEOR), coherence (ROUGE-L), semantic relevance (BERTScore), and\ndiversity. Our experiments show that the large transformer-based approach\nyields a >20% relative improvement in BERTScore (F1) (0.92 vs 0.72) over the\nbest recurrent baseline, while reducing perplexity by 69.8%. We conclude with a\ndiscussion of remaining challenges, particularly regarding factual accuracy,\nand outline how this foundational study paves the way for integrating\nreal-world constraints and multi-modal inputs in advanced recipe generation\nresearch.",
      "url": "http://arxiv.org/abs/2508.14718v1",
      "published_time_eastern_timestamp": 1755697993.0
    },
    {
      "title": "GSFix3D: Diffusion-Guided Repair of Novel Views in Gaussian Splatting",
      "summary": "Recent developments in 3D Gaussian Splatting have significantly enhanced\nnovel view synthesis, yet generating high-quality renderings from extreme novel\nviewpoints or partially observed regions remains challenging. Meanwhile,\ndiffusion models exhibit strong generative capabilities, but their reliance on\ntext prompts and lack of awareness of specific scene information hinder\naccurate 3D reconstruction tasks. To address these limitations, we introduce\nGSFix3D, a novel framework that improves the visual fidelity in\nunder-constrained regions by distilling prior knowledge from diffusion models\ninto 3D representations, while preserving consistency with observed scene\ndetails. At its core is GSFixer, a latent diffusion model obtained via our\ncustomized fine-tuning protocol that can leverage both mesh and 3D Gaussians to\nadapt pretrained generative models to a variety of environments and artifact\ntypes from different reconstruction methods, enabling robust novel view repair\nfor unseen camera poses. Moreover, we propose a random mask augmentation\nstrategy that empowers GSFixer to plausibly inpaint missing regions.\nExperiments on challenging benchmarks demonstrate that our GSFix3D and GSFixer\nachieve state-of-the-art performance, requiring only minimal scene-specific\nfine-tuning on captured data. Real-world test further confirms its resilience\nto potential pose errors. Our code and data will be made publicly available.\nProject page: https://gsfix3d.github.io.",
      "url": "http://arxiv.org/abs/2508.14717v1",
      "published_time_eastern_timestamp": 1755697793.0
    },
    {
      "title": "ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine",
      "summary": "Despite the success of large language models (LLMs) in various domains, their\npotential in Traditional Chinese Medicine (TCM) remains largely underexplored\ndue to two critical barriers: (1) the scarcity of high-quality TCM data and (2)\nthe inherently multimodal nature of TCM diagnostics, which involve looking,\nlistening, smelling, and pulse-taking. These sensory-rich modalities are beyond\nthe scope of conventional LLMs. To address these challenges, we present\nShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data\nscarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text\nand 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and\nphysiological signals. ShizhenGPT is pretrained and instruction-tuned to\nachieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect\nrecent national TCM qualification exams and build a visual benchmark for\nMedicinal Recognition and Visual Diagnosis. Experiments demonstrate that\nShizhenGPT outperforms comparable-scale LLMs and competes with larger\nproprietary models. Moreover, it leads in TCM visual understanding among\nexisting multimodal LLMs and demonstrates unified perception across modalities\nlike sound, pulse, smell, and vision, paving the way toward holistic multimodal\nperception and diagnosis in TCM. Datasets, models, and code are publicly\navailable. We hope this work will inspire further exploration in this field.",
      "url": "http://arxiv.org/abs/2508.14706v1",
      "published_time_eastern_timestamp": 1755696620.0
    },
    {
      "title": "String Diagrams for Defect-Based Surface Code Computing",
      "summary": "Surface codes are a popular choice for implementing fault-tolerant quantum\ncomputing. Two-qubit gates may be realised in these codes using only\nnearest-neighbour interactions, either by lattice surgery or by braiding\ndefects around each other. The effect of lattice surgery operations may be\nsimply described using the ZX-calculus: a graphical language that has proven\neffective for program design and optimisation. In this work, we formalise a\nsimilar description via the ZX-calculus of defect braiding, as it is\nconventionally described. We define a graphical calculus KNOT, denoting the\nlogical effects (in the absence of byproduct operations) of defect braiding in\nsurface codes: we show how these effects may be described via a fragment of\nZX-calculus which we call the (0, pi)-fragment. We then use a doubling\nconstruction to define a subtheory of KNOT, more specialised to standard\nencoding techniques in the defect braiding literature. Within this subtheory,\nwe encompass standard braiding techniques by families of ribbon-like and\ntangle-like diagrams, each with semantics distinct from KNOT, in terms of the\n(0, pi)-fragment of ZX diagrams (again in the absence of byproducts). These\nsubtheories may be used interoperably, and are each sound and complete for the\n(0, pi)-fragment of ZX diagrams. This provides a starting point to use the\nformal diagrammatics to analyse the operational effects of defect braiding\nprocedures.",
      "url": "http://arxiv.org/abs/2508.14672v1",
      "published_time_eastern_timestamp": 1755693851.0
    },
    {
      "title": "Excitation of toroidal Alfvén eigenmode by energetic particles in DTT\n  and effect of negative triangularity",
      "summary": "A linear gyrokinetic eigenvalue code is developed to study the stability of\ntoroidal Alfv\\'en eigenmode (TAE) in general axisymmetric toroidal geometry,\nwith the self-consistent treatment of energetic particle drive and core plasma\nLandau damping in a non-perturbative way. The general particle responses of\nboth circulating and trapped particles are incorporated in the calculation by\nmeans of the action-angle approach, and, particularly, the finite Larmor radius\nand orbit width effects of energetic particles are fully taken into account.\nThe ballooning-mode representation is adopted to solve the eigenmode equations\nin order to reduce the computational resource while obtaining a high resolution\nof the fine radial structure. Furthermore, the code is able to study the\nphysics of wave-particle interaction in great detail, thanks to the development\nof systematic theory-based numerical diagnostics, including effective mode\nstructure and phase space resonance structure. As an application of the code,\nwe perform an in-depth study of the triangularity effect on TAE stability based\non the reference equilibrium of the Divertor Tokamak Test facility. It is\ndemonstrated that TAE growth rate can be affected by the triangularity through\nthe modifications of geometric couplings, resonance condition, as well as mode\nfrequency and mode structure. As a result, negative triangularity can either\nstabilize or destabilize the energetic particle driven TAE depending on the\ndominant mechanism. The relative importance of these mechanisms under different\ncircumstances is systematically analyzed, providing clear physical insights.\nThe overall effect of negative triangularity for a specific tokamak scenario\ncan be assessed based on these studies.",
      "url": "http://arxiv.org/abs/2508.14622v1",
      "published_time_eastern_timestamp": 1755688813.0
    }
  ]
}
{
  "last_updated": "2025-10-13T17:09:58.022148-04:00",
  "papers": [
    {
      "title": "StreamingVLM: Real-Time Understanding for Infinite Video Streams",
      "summary": "Vision-language models (VLMs) could power real-time assistants and autonomous\nagents, but they face a critical challenge: understanding near-infinite video\nstreams without escalating latency and memory usage. Processing entire videos\nwith full attention leads to quadratic computational costs and poor performance\non long videos. Meanwhile, simple sliding window methods are also flawed, as\nthey either break coherence or suffer from high latency due to redundant\nrecomputation. In this paper, we introduce StreamingVLM, a model designed for\nreal-time, stable understanding of infinite visual input. Our approach is a\nunified framework that aligns training with streaming inference. During\ninference, we maintain a compact KV cache by reusing states of attention sinks,\na short window of recent vision tokens, and a long window of recent text\ntokens. This streaming ability is instilled via a simple supervised fine-tuning\n(SFT) strategy that applies full attention on short, overlapped video chunks,\nwhich effectively mimics the inference-time attention pattern without training\non prohibitively long contexts. For evaluation, we build Inf-Streams-Eval, a\nnew benchmark with videos averaging over two hours that requires dense,\nper-second alignment between frames and text. On Inf-Streams-Eval, StreamingVLM\nachieves a 66.18% win rate against GPT-4O mini and maintains stable, real-time\nperformance at up to 8 FPS on a single NVIDIA H100. Notably, our SFT strategy\nalso enhances general VQA abilities without any VQA-specific fine-tuning,\nimproving performance on LongVideoBench by +4.30 and OVOBench Realtime by\n+5.96. Code is available at https://github.com/mit-han-lab/streaming-vlm.",
      "url": "http://arxiv.org/abs/2510.09608v1",
      "published_time_eastern_timestamp": 1760119198.0
    },
    {
      "title": "VisPile: A Visual Analytics System for Analyzing Multiple Text Documents\n  With Large Language Models and Knowledge Graphs",
      "summary": "Intelligence analysts perform sensemaking over collections of documents using\nvarious visual and analytic techniques to gain insights from large amounts of\ntext. As data scales grow, our work explores how to leverage two AI\ntechnologies, large language models (LLMs) and knowledge graphs (KGs), in a\nvisual text analysis tool, enhancing sensemaking and helping analysts keep\npace. Collaborating with intelligence community experts, we developed a visual\nanalytics system called VisPile. VisPile integrates an LLM and a KG into\nvarious UI functions that assist analysts in grouping documents into piles,\nperforming sensemaking tasks like summarization and relationship mapping on\npiles, and validating LLM- and KG-generated evidence. Our paper describes the\ntool, as well as feedback received from six professional intelligence analysts\nthat used VisPile to analyze a text document corpus.",
      "url": "http://arxiv.org/abs/2510.09605v1",
      "published_time_eastern_timestamp": 1760119148.0
    },
    {
      "title": "Simplified Quantum Weight Reduction with Optimal Bounds",
      "summary": "Quantum weight reduction is the task of transforming a quantum code with\nlarge check weight into one with small check weight. Low-weight codes are\nessential for implementing quantum error correction on physical hardware, since\nhigh-weight measurements cannot be executed reliably. Weight reduction also\nserves as a critical theoretical tool, which may be relevant to the quantum PCP\nconjecture.\n  We introduce a new procedure for quantum weight reduction that combines\ngeometric insights with coning techniques, which simplifies Hastings' previous\napproach while achieving better parameters. Given an arbitrary $[[n,k,d]]$\nquantum code with weight $w$, our method produces a code with parameters $[[O(n\nw^2 \\log w), k, \\Omega(d w)]]$ with check weight $5$ and qubit weight $6$.\n  When applied to random dense CSS codes, our procedure yields explicit quantum\ncodes that surpass the square-root distance barrier, achieving parameters $[[n,\n\\tilde O(n^{1/3}), \\tilde \\Omega(n^{2/3})]]$. Furthermore, these codes admit a\nthree-dimensional embedding that saturates the Bravyi-Poulin-Terhal (BPT)\nbound.\n  As a further application, our weight reduction technique improves\nfault-tolerant logical operator measurements by reducing the number of ancilla\nqubits.",
      "url": "http://arxiv.org/abs/2510.09601v1",
      "published_time_eastern_timestamp": 1760119111.0
    },
    {
      "title": "Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation",
      "summary": "Large language models (LLMs) have demonstrated impressive reasoning\ncapabilities when provided with chain-of-thought exemplars, but curating large\nreasoning datasets remains laborious and resource-intensive. In this work, we\nintroduce Prompting Test-Time Scaling (P-TTS), a simple yet effective\ninference-time data augmentation strategy for enhancing LLM reasoning through\nfinetuning. Rather than collecting thousands or even millions of examples,\nP-TTS leverages a small pool of only 90 manually selected reasoning instances\nand systematically varies exemplar augmentation through principled instruction\nprompting intensities at test time to synthesize diverse reasoning trajectory\ncontexts. Then we finetune the various sizes of Qwen-2.5 models on P-TTS data.\nAcross a suite of mathematical reasoning AIME2024 & 25, MATH500, and\nGPQA-Diamond, our P-TTS-7B and 32B models outperform the prior competitive\nbaselines like S1 and S1.1 (1K-shot), achieving absolute accuracy gains of\n+26.66% and +30.00% on AIME'24 (7B), and +13.34% and +6.67% on AIME'25 (7B);\nP-TTS-32B yields gains of +23.33% and +16.63% on AIME'24, and +26.63% and\n+3.33% on AIME'25 (vs. S1 and S1.1, respectively), with comparable or better\nperformance on MATH500 and GPQA-Diamond. We further show that P-TTS enhances\nzero-shot generalization accuracy on out-of-domain reasoning benchmarks of\nGaokao, Kaoyan, OlympiadBench, AMC23, GradeSchoolMath, and Minerva. Our\nanalysis suggests that test-time scaling effectively explores the latent space\nof reasoning patterns, amplifying LLM problem-solving with minimal annotation\noverhead, and further unlocking the reasoning potential and capabilities of\nLLMs. Prompting Test-Time Scaling offers a practical, low-cost way to elicit\nLLM reasoning in resource-constrained or rapidly evolving domains.",
      "url": "http://arxiv.org/abs/2510.09599v1",
      "published_time_eastern_timestamp": 1760119024.0
    },
    {
      "title": "Particles with precessing spin in Kerr spacetime: analytic solutions for\n  eccentric orbits and homoclinic motion near the equatorial plane",
      "summary": "We present a family of analytic solutions for the nearly-equatorial motion of\na test particle with precessing spin in Kerr spacetime. We solve the equations\nof motion up to linear order in the small body's spin for periodic and\nhomoclinic orbits. At zero order, the particle moves along equatorial\ngeodesics. The spin-curvature force introduces post-geodesic corrections which,\nfor generic spin orientations, cause the precession of the orbital plane. We\nderive the solutions for eccentric orbits in terms of Legendre elliptic\nintegrals and Jacobi elliptic functions for generic referential geodesics\n(known as ``spin gauges\"). Our analytical solutions perfectly match the\nnumerical trajectories obtained by Drummond and Hughes in Phys. Rev. D 105,\n124041 (2022), and Piovano et al. in Phys. Rev. D 111, 044009 (2025).\nFurthermore, we present, for the first time, the solutions for homoclinic\norbits for a spinning particle in Kerr spacetime, and the spin-corrections to\nthe location of the separatrix. The homoclinic trajectories are described in\nclosed form using elementary functions. Finally, we introduce a novel\nparametrization for the motion of a spinning particle, called ``fixed\neccentricity spin gauge\". The latter is the only spin gauge in which the\ncorrections to periodic orbits are finite at the geodesic separatrix, and\ncontinuously reduce to the last stable orbits under appropriate limits. Our\nresults will be useful for modeling the inspiral and transition-to-plunge\nphases of asymmetric mass binaries within the two-time-scale framework.",
      "url": "http://arxiv.org/abs/2510.09597v1",
      "published_time_eastern_timestamp": 1760118928.0
    },
    {
      "title": "LiveOIBench: Can Large Language Models Outperform Human Contestants in\n  Informatics Olympiads?",
      "summary": "Competitive programming problems increasingly serve as valuable benchmarks to\nevaluate the coding capabilities of large language models (LLMs) due to their\ncomplexity and ease of verification. Yet, current coding benchmarks face\nlimitations such as lack of exceptionally challenging problems, insufficient\ntest case coverage, reliance on online platform APIs that limit accessibility.\nTo address these issues, we introduce LiveOIBench, a comprehensive benchmark\nfeaturing 403 expert-curated Olympiad-level competitive programming problems,\neach with an average of 60 expert-designed test cases. The problems are sourced\ndirectly from 72 official Informatics Olympiads in different regions conducted\nbetween 2023 and 2025. LiveOIBench distinguishes itself through four key\nfeatures: (1) meticulously curated high-quality tasks with detailed subtask\nrubrics and extensive private test cases; (2) direct integration of elite\ncontestant performance data to enable informative comparison against\ntop-performing humans; (3) planned continuous, contamination-free updates from\nnewly released Olympiad problems; and (4) a self-contained evaluation system\nfacilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular\ngeneral-purpose and reasoning LLMs, we find that GPT-5 achieves a notable\n81.76th percentile, a strong result that nonetheless falls short of top human\ncontestant performance, who usually place above 90th. In contrast, among\nopen-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,\nunderscoring significant capability disparities from frontier closed models.\nDetailed analyses indicate that robust reasoning models prioritize precise\nproblem analysis over excessive exploration, suggesting future models should\nemphasize structured analysis and minimize unnecessary exploration. All data,\ncode, and leaderboard results will be made publicly available on our website.",
      "url": "http://arxiv.org/abs/2510.09595v1",
      "published_time_eastern_timestamp": 1760118864.0
    },
    {
      "title": "A Multilingual Python Programming Language",
      "summary": "All widely used and useful programming languages have a common problem. They\nrestrict entry on the basis of knowledge of the English language. The lack of\nknowledge of English poses a major hurdle to many newcomers who do not have the\nresources, in terms of time and money, to learn the English language. Studies\nshow that people learn better in their own language. Therefore, we propose a\nlanguage transpiler built on top of the Python programming language, called\nUniversalPython, which allows one to write Python in their own human language.\nWe demonstrate the ability to create an \"Urdu Python\" with this transpiler. In\nthe future, we aim to scale the language to encapsulate more human languages to\nincrease the availability of programming. The source code for this transpiler\nis open-source, and available at\nhttps://github.com/universalpython/universalpython",
      "url": "http://arxiv.org/abs/2510.09591v1",
      "published_time_eastern_timestamp": 1760118579.0
    },
    {
      "title": "From Birdwatch to Community Notes, from Twitter to X: four years of\n  community-based content moderation",
      "summary": "Community Notes (formerly known as Birdwatch) is the first large-scale\ncrowdsourced content moderation initiative that was launched by X (formerly\nknown as Twitter) in January 2021. As the Community Notes model gains momentum\nacross other social media platforms, there is a growing need to assess its\nunderlying dynamics and effectiveness. This Resource paper provides (a) a\nsystematic review of the literature on Community Notes, and (b) a major curated\ndataset and accompanying source code to support future research on Community\nNotes. We parsed Notes and Ratings data from the first four years of the\nprogram and conducted language detection across all Notes. Focusing on\nEnglish-language Notes, we extracted embedded URLs and identified discussion\ntopics in each Note. Additionally, we constructed monthly interaction networks\namong the Contributors. Together with the literature review, these resources\noffer a robust foundation for advancing research on the Community Notes system.",
      "url": "http://arxiv.org/abs/2510.09585v1",
      "published_time_eastern_timestamp": 1760118174.0
    },
    {
      "title": "Dyna-Mind: Learning to Simulate from Experience for Better AI Agents",
      "summary": "Reasoning models have recently shown remarkable progress in domains such as\nmath and coding. However, their expert-level abilities in math and coding\ncontrast sharply with their performance in long-horizon, interactive tasks such\nas web navigation and computer/phone-use. Inspired by literature on human\ncognition, we argue that current AI agents need ''vicarious trial and error'' -\nthe capacity to mentally simulate alternative futures before acting - in order\nto enhance their understanding and performance in complex interactive\nenvironments. We introduce Dyna-Mind, a two-stage training framework that\nexplicitly teaches (V)LM agents to integrate such simulation into their\nreasoning. In stage 1, we introduce Reasoning with Simulations (ReSim), which\ntrains the agent to generate structured reasoning traces from expanded search\ntrees built from real experience gathered through environment interactions.\nReSim thus grounds the agent's reasoning in faithful world dynamics and equips\nit with the ability to anticipate future states in its reasoning. In stage 2,\nwe propose Dyna-GRPO, an online reinforcement learning method to further\nstrengthen the agent's simulation and decision-making ability by using both\noutcome rewards and intermediate states as feedback from real rollouts.\nExperiments on two synthetic benchmarks (Sokoban and ALFWorld) and one\nrealistic benchmark (AndroidWorld) demonstrate that (1) ReSim effectively\ninfuses simulation ability into AI agents, and (2) Dyna-GRPO leverages outcome\nand interaction-level signals to learn better policies for long-horizon,\nplanning-intensive tasks. Together, these results highlight the central role of\nsimulation in enabling AI agents to reason, plan, and act more effectively in\nthe ever more challenging environments.",
      "url": "http://arxiv.org/abs/2510.09577v1",
      "published_time_eastern_timestamp": 1760117418.0
    },
    {
      "title": "Deep uGMRT observations for enhanced calibration of 21 cm arrays -- I.\n  First image and source catalogue",
      "summary": "Radio-interferometric arrays require very precise calibration to detect the\nEpoch of Reionization 21-cm signal. A remarkably complete and accurate sky\nmodel is therefore needed in the patches of the sky used to perform the\ncalibration. Instruments such as HERA, which use a redundant calibration\nstrategy, also require a reference sky model to fix degenerate gain solutions.\nWe have carried out a deep (20 hours) observation using the upgraded GMRT to\nmake a high-fidelity sky model of one of the HERA calibration fields GLEAM 02H\n(J0200$-$3053). Here, we present the results from a $16.7\\,\\rm{MHz}$ bandwidth\ndata centred at $147.4\\,\\rm{MHz}$. Using multiple GMRT pointings, we have made\na $6.9^\\circ\\times6.9^\\circ$ mosaic, which yields a median rms of\n$3.9^{+3.7}_{-1.4}\\,{\\rm mJy/beam}$ that reduces to $\\sim2\\,{\\rm mJy/beam}$ at\nsource-free regions. In the overlapping patch, this rms is deeper than the\nGLEAM catalogue, which is used for HERA calibration. We produce a catalogue of\n$640$ sources ($26\\%$ extended) in the flux range $0.01-19.08\\,{\\rm Jy}$. The\ncatalogue has a sub-arcsec positional accuracy, and the estimated fluxes are\nconsistent with existing catalogues. The differential source counts are found\nto be deeper than GLEAM and consistent with LoTSS. Preliminary simulations of\nthe sky models from GLEAM and our catalogue show $\\sim 10-25\\%$ difference in\nthe visibility amplitude, with relatively small phase difference ($\\approx\n2^\\circ$). Future work is planned for larger survey areas and wider bandwidth\nto reduce the rms and measure the in-band source spectral indices, which are\nexpected to enhance the fidelity of the HERA calibration model.",
      "url": "http://arxiv.org/abs/2510.09571v1",
      "published_time_eastern_timestamp": 1760117036.0
    },
    {
      "title": "Safe, Untrusted, \"Proof-Carrying\" AI Agents: toward the agentic\n  lakehouse",
      "summary": "Data lakehouses run sensitive workloads, where AI-driven automation raises\nconcerns about trust, correctness, and governance. We argue that API-first,\nprogrammable lakehouses provide the right abstractions for safe-by-design,\nagentic workflows. Using Bauplan as a case study, we show how data branching\nand declarative environments extend naturally to agents, enabling\nreproducibility and observability while reducing the attack surface. We present\na proof-of-concept in which agents repair data pipelines using correctness\nchecks inspired by proof-carrying code. Our prototype demonstrates that\nuntrusted AI agents can operate safely on production data and outlines a path\ntoward a fully agentic lakehouse.",
      "url": "http://arxiv.org/abs/2510.09567v1",
      "published_time_eastern_timestamp": 1760116716.0
    },
    {
      "title": "Unveiling dynamical quantum error correcting codes via non-invertible\n  symmetries",
      "summary": "Dynamical stabilizer codes (DSCs) have recently emerged as a powerful\ngeneralization of static stabilizer codes for quantum error correction,\nreplacing a fixed stabilizer group with a sequence of non-commuting\nmeasurements. This dynamical structure unlocks new possibilities for fault\ntolerance but also introduces new challenges, as errors must now be tracked\nacross both space and time. In this work, we provide a physical and topological\nunderstanding of DSCs by establishing a correspondence between qudit Pauli\nmeasurements and non-invertible symmetries in 4+1-dimensional 2-form gauge\ntheories. Sequences of measurements in a DSC are mapped to a fusion of the\noperators implementing these non-invertible symmetries. We show that the error\ndetectors of a DSC correspond to endable surface operators in the gauge theory,\nwhose endpoints define line operators, and that detectable errors are precisely\nthose surface operators that braid non-trivially with these lines. Finally, we\ndemonstrate how this framework naturally recovers the spacetime stabilizer code\nassociated with a DSC.",
      "url": "http://arxiv.org/abs/2510.09565v1",
      "published_time_eastern_timestamp": 1760116544.0
    },
    {
      "title": "AutoPR: Let's Automate Your Academic Promotion!",
      "summary": "As the volume of peer-reviewed research surges, scholars increasingly rely on\nsocial platforms for discovery, while authors invest considerable effort in\npromoting their work to ensure visibility and citations. To streamline this\nprocess and reduce the reliance on human effort, we introduce Automatic\nPromotion (AutoPR), a novel task that transforms research papers into accurate,\nengaging, and timely public content. To enable rigorous evaluation, we release\nPRBench, a multimodal benchmark that links 512 peer-reviewed articles to\nhigh-quality promotional posts, assessing systems along three axes: Fidelity\n(accuracy and tone), Engagement (audience targeting and appeal), and Alignment\n(timing and channel optimization). We also introduce PRAgent, a multi-agent\nframework that automates AutoPR in three stages: content extraction with\nmultimodal preparation, collaborative synthesis for polished outputs, and\nplatform-specific adaptation to optimize norms, tone, and tagging for maximum\nreach. When compared to direct LLM pipelines on PRBench, PRAgent demonstrates\nsubstantial improvements, including a 604% increase in total watch time, a 438%\nrise in likes, and at least a 2.9x boost in overall engagement. Ablation\nstudies show that platform modeling and targeted promotion contribute the most\nto these gains. Our results position AutoPR as a tractable, measurable research\nproblem and provide a roadmap for scalable, impactful automated scholarly\ncommunication.",
      "url": "http://arxiv.org/abs/2510.09558v1",
      "published_time_eastern_timestamp": 1760116116.0
    },
    {
      "title": "A Comprehensive Evaluation of Multilingual Chain-of-Thought Reasoning:\n  Performance, Consistency, and Faithfulness Across Languages",
      "summary": "Large reasoning models (LRMs) increasingly rely on step-by-step\nChain-of-Thought (CoT) reasoning to improve task performance, particularly in\nhigh-resource languages such as English. While recent work has examined\nfinal-answer accuracy in multilingual settings, the thinking traces themselves,\ni.e., the intermediate steps that lead to the final answer, remain\nunderexplored. In this paper, we present the first comprehensive study of\nmultilingual CoT reasoning, evaluating three key dimensions: performance,\nconsistency, and faithfulness. We begin by measuring language compliance,\nanswer accuracy, and answer consistency when LRMs are explicitly instructed or\nprompt-hacked to think in a target language, revealing strong language\npreferences and divergent performance across languages. Next, we assess\ncrosslingual consistency of thinking traces by interchanging them between\nlanguages. We find that the quality and effectiveness of thinking traces vary\nsubstantially depending on the prompt language. Finally, we adapt\nperturbation-based techniques -- i.e., truncation and error injection -- to\nprobe the faithfulness of thinking traces across languages, showing that models\nrely on traces to varying degrees. We release our code and data to support\nfuture research.",
      "url": "http://arxiv.org/abs/2510.09555v1",
      "published_time_eastern_timestamp": 1760116010.0
    },
    {
      "title": "Titans Revisited: A Lightweight Reimplementation and Critical Analysis\n  of a Test-Time Memory Model",
      "summary": "By the end of 2024, Google researchers introduced Titans: Learning at Test\nTime, a neural memory model achieving strong empirical results across multiple\ntasks. However, the lack of publicly available code and ambiguities in the\noriginal description hinder reproducibility. In this work, we present a\nlightweight reimplementation of Titans and conduct a comprehensive evaluation\non Masked Language Modeling, Time Series Forecasting, and Recommendation tasks.\nOur results reveal that Titans does not always outperform established baselines\ndue to chunking. However, its Neural Memory component consistently improves\nperformance compared to attention-only models. These findings confirm the\nmodel's innovative potential while highlighting its practical limitations and\nraising questions for future research.",
      "url": "http://arxiv.org/abs/2510.09551v1",
      "published_time_eastern_timestamp": 1760115804.0
    },
    {
      "title": "FLOWING: Implicit Neural Flows for Structure-Preserving Morphing",
      "summary": "Morphing is a long-standing problem in vision and computer graphics,\nrequiring a time-dependent warping for feature alignment and a blending for\nsmooth interpolation. Recently, multilayer perceptrons (MLPs) have been\nexplored as implicit neural representations (INRs) for modeling such\ndeformations, due to their meshlessness and differentiability; however,\nextracting coherent and accurate morphings from standard MLPs typically relies\non costly regularizations, which often lead to unstable training and prevent\neffective feature alignment. To overcome these limitations, we propose FLOWING\n(FLOW morphING), a framework that recasts warping as the construction of a\ndifferential vector flow, naturally ensuring continuity, invertibility, and\ntemporal coherence by encoding structural flow properties directly into the\nnetwork architectures. This flow-centric approach yields principled and stable\ntransformations, enabling accurate and structure-preserving morphing of both 2D\nimages and 3D shapes. Extensive experiments across a range of applications -\nincluding face and image morphing, as well as Gaussian Splatting morphing -\nshow that FLOWING achieves state-of-the-art morphing quality with faster\nconvergence. Code and pretrained models are available at\nhttp://schardong.github.io/flowing.",
      "url": "http://arxiv.org/abs/2510.09537v1",
      "published_time_eastern_timestamp": 1760115023.0
    },
    {
      "title": "Evaluating Robustness of Large Language Models Against Multilingual\n  Typographical Errors",
      "summary": "Large language models (LLMs) are increasingly deployed in multilingual,\nreal-world applications with user inputs -- naturally introducing typographical\nerrors (typos). Yet most benchmarks assume clean input, leaving the robustness\nof LLMs to typos across languages largely underexplored. To address this gap,\nwe introduce MulTypo, a multilingual typo generation algorithm that simulates\nhuman-like errors based on language-specific keyboard layouts and typing\nbehavior. We evaluate 18 open-source LLMs across three model families and five\ndownstream tasks spanning language inference, multi-choice question answering,\nmathematical reasoning, and machine translation tasks. Our results show that\ntypos consistently degrade performance, particularly in generative tasks and\nthose requiring reasoning -- while the natural language inference task is\ncomparatively more robust. Instruction tuning improves clean-input performance\nbut may increase brittleness under noise. We also observe language-dependent\nrobustness: high-resource languages are generally more robust than low-resource\nones, and translation from English is more robust than translation into\nEnglish. Our findings underscore the need for noise-aware training and\nmultilingual robustness evaluation. We make our code and data publicly\navailable.",
      "url": "http://arxiv.org/abs/2510.09536v1",
      "published_time_eastern_timestamp": 1760114952.0
    },
    {
      "title": "Accent-Invariant Automatic Speech Recognition via Saliency-Driven\n  Spectrogram Masking",
      "summary": "Pre-trained transformer-based models have significantly advanced automatic\nspeech recognition (ASR), yet they remain sensitive to accent and dialectal\nvariations, resulting in elevated word error rates (WER) in linguistically\ndiverse languages such as English and Persian. To address this challenge, we\npropose an accent-invariant ASR framework that integrates accent and dialect\nclassification into the recognition pipeline. Our approach involves training a\nspectrogram-based classifier to capture accent-specific cues, masking the\nregions most influential to its predictions, and using the masked spectrograms\nfor data augmentation. This enhances the robustness of ASR models against\naccent variability. We evaluate the method using both English and Persian\nspeech. For Persian, we introduce a newly collected dataset spanning multiple\nregional accents, establishing the first systematic benchmark for accent\nvariation in Persian ASR that fills a critical gap in multilingual speech\nresearch and provides a foundation for future studies on low-resource,\nlinguistically diverse languages. Experimental results with the Whisper model\ndemonstrate that our masking and augmentation strategy yields substantial WER\nreductions in both English and Persian settings, confirming the effectiveness\nof the approach. This research advances the development of multilingual ASR\nsystems that are resilient to accent and dialect diversity. Code and dataset\nare publicly available at: https://github.com/MH-Sameti/Accent_invariant_ASR",
      "url": "http://arxiv.org/abs/2510.09528v1",
      "published_time_eastern_timestamp": 1760114513.0
    },
    {
      "title": "StatEval: A Comprehensive Benchmark for Large Language Models in\n  Statistics",
      "summary": "Large language models (LLMs) have demonstrated remarkable advances in\nmathematical and logical reasoning, yet statistics, as a distinct and\nintegrative discipline, remains underexplored in benchmarking efforts. To\naddress this gap, we introduce \\textbf{StatEval}, the first comprehensive\nbenchmark dedicated to statistics, spanning both breadth and depth across\ndifficulty levels. StatEval consists of 13,817 foundational problems covering\nundergraduate and graduate curricula, together with 2374 research-level proof\ntasks extracted from leading journals. To construct the benchmark, we design a\nscalable multi-agent pipeline with human-in-the-loop validation that automates\nlarge-scale problem extraction, rewriting, and quality control, while ensuring\nacademic rigor. We further propose a robust evaluation framework tailored to\nboth computational and proof-based tasks, enabling fine-grained assessment of\nreasoning ability. Experimental results reveal that while closed-source models\nsuch as GPT5-mini achieve below 57\\% on research-level problems, with\nopen-source models performing significantly lower. These findings highlight the\nunique challenges of statistical reasoning and the limitations of current LLMs.\nWe expect StatEval to serve as a rigorous benchmark for advancing statistical\nintelligence in large language models. All data and code are available on our\nweb platform: https://stateval.github.io/.",
      "url": "http://arxiv.org/abs/2510.09517v1",
      "published_time_eastern_timestamp": 1760113723.0
    },
    {
      "title": "Parameterized Algorithms for Diversity of Networks with Ecological\n  Dependencies",
      "summary": "For a phylogenetic tree, the phylogenetic diversity of a set A of taxa is the\ntotal weight of edges on paths to A. Finding small sets of maximal diversity is\ncrucial for conservation planning, as it indicates where limited resources can\nbe invested most efficiently. In recent years, efficient algorithms have been\ndeveloped to find sets of taxa that maximize phylogenetic diversity either in a\nphylogenetic network or in a phylogenetic tree subject to ecological\nconstraints, such as a food web. However, these aspects have mostly been\nstudied independently. Since both factors are biologically important, it seems\nnatural to consider them together. In this paper, we introduce decision\nproblems where, given a phylogenetic network, a food web, and integers k, and\nD, the task is to find a set of k taxa with phylogenetic diversity of at least\nD under the maximize all paths measure, while also satisfying viability\nconditions within the food web. Here, we consider different definitions of\nviability, which all demand that a \"sufficient\" number of prey species survive\nto support surviving predators. We investigate the parameterized complexity of\nthese problems and present several fixed-parameter tractable (FPT) algorithms.\nSpecifically, we provide a complete complexity dichotomy characterizing which\ncombinations of parameters - out of the size constraint k, the acceptable\ndiversity loss D, the scanwidth of the food web, the maximum in-degree in the\nnetwork, and the network height h - lead to W[1]-hardness and which admit FPT\nalgorithms. Our primary methodological contribution is a novel algorithmic\nframework for solving phylogenetic diversity problems in networks where\ndependencies (such as those from a food web) impose an order, using a color\ncoding approach.",
      "url": "http://arxiv.org/abs/2510.09512v1",
      "published_time_eastern_timestamp": 1760113016.0
    }
  ]
}
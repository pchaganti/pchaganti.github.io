{
  "last_updated": "2025-09-02T05:13:07.921727-04:00",
  "papers": [
    {
      "title": "The Integration of Agile Methodologies in DevOps Practices within the\n  Information Technology Industry",
      "summary": "The demand for rapid software delivery in the Information Technology (IT)\nindustry has significantly intensified, emphasising the need for faster\nsoftware products and service releases with enhanced features to meet customer\nexpectations. Agile methodologies are replacing traditional approaches such as\nWaterfall, where flexibility, iterative development and adaptation to change\nare favoured over rigid planning and execution. DevOps, a subsequent evolution\nfrom Agile, emphasises collaborative efforts in development and operations\nteams, focusing on continuous integration and deployment to deliver resilient\nand high-quality software products and services. This study aims to critically\nassess both Agile and DevOps practices in the IT industry to identify the\nfeasibility and applicability of Agile methods in DevOps practices. Eleven\nsemi-structured interviews were conducted with Agile and DevOps practitioners\nin varying capacities across several sectors within the IT industry. Through\nthematic analysis, 51 unique codes were extracted and synthesised into 19\nthemes that reported on each phase of the DevOps lifecycle, specifically\nregarding the integration and implementation of Agile methods into DevOps\npractices. Based on the findings, a new understanding detailing the\ninterrelationship of Agile methods in DevOps practices was discussed that met\nthe research objectives.",
      "url": "http://arxiv.org/abs/2508.21811v1",
      "published_time_eastern_timestamp": 1756489794.0
    },
    {
      "title": "Suppression of errors in collectively coded information",
      "summary": "Modern life largely transmits genetic information from mother to daughter\nthrough the duplication of single physically intact molecules that encode\ninformation. However, copying an extended molecule requires highly processive\ncopying machinery and high fidelity that scales with the genome size to avoid\nthe error catastrophe. Here, we explore these fidelity requirements in an\nalternative architecture, the virtual circular genome, in which no one physical\nmolecule encodes the full genetic information. Instead, information is encoded\nand transmitted in a collective of overlapping and interacting segments. Using\na model experimental system of a complex mixture of DNA oligos that can partly\nanneal and extend off each other, we find that mutant oligomers are suppressed\nrelative to a model without collective encoding. Through simulations and\ntheory, we show that this suppression of mutants can be explained by\ncompetition for productive binding partners. As a consequence, information can\nbe propagated robustly in a virtual circular genome even if the mutation rate\nis above the error catastrophe for a physically intact genome.",
      "url": "http://arxiv.org/abs/2508.21806v1",
      "published_time_eastern_timestamp": 1756489169.0
    },
    {
      "title": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection\n  Models with a Text Memory Bank",
      "summary": "Anomaly detection, which aims to identify anomalies deviating from normal\npatterns, is challenging due to the limited amount of normal data available.\nUnlike most existing unified methods that rely on carefully designed image\nfeature extractors and memory banks to capture logical relationships between\nobjects, we introduce a text memory bank to enhance the detection of logical\nanomalies. Specifically, we propose a Three-Memory framework for Unified\nstructural and logical Anomaly Detection (TMUAD). First, we build a class-level\ntext memory bank for logical anomaly detection by the proposed logic-aware text\nextractor, which can capture rich logical descriptions of objects from input\nimages. Second, we construct an object-level image memory bank that preserves\ncomplete object contours by extracting features from segmented objects. Third,\nwe employ visual encoders to extract patch-level image features for\nconstructing a patch-level memory bank for structural anomaly detection. These\nthree complementary memory banks are used to retrieve and compare normal images\nthat are most similar to the query image, compute anomaly scores at multiple\nlevels, and fuse them into a final anomaly score. By unifying structural and\nlogical anomaly detection through collaborative memory banks, TMUAD achieves\nstate-of-the-art performance across seven publicly available datasets involving\nindustrial and medical domains. The model and code are available at\nhttps://github.com/SIA-IDE/TMUAD.",
      "url": "http://arxiv.org/abs/2508.21795v1",
      "published_time_eastern_timestamp": 1756488133.0
    },
    {
      "title": "Learning from Silence and Noise for Visual Sound Source Localization",
      "summary": "Visual sound source localization is a fundamental perception task that aims\nto detect the location of sounding sources in a video given its audio. Despite\nrecent progress, we identify two shortcomings in current methods: 1) most\napproaches perform poorly in cases with low audio-visual semantic\ncorrespondence such as silence, noise, and offscreen sounds, i.e. in the\npresence of negative audio; and 2) most prior evaluations are limited to\npositive cases, where both datasets and metrics convey scenarios with a single\nvisible sound source in the scene. To address this, we introduce three key\ncontributions. First, we propose a new training strategy that incorporates\nsilence and noise, which improves performance in positive cases, while being\nmore robust against negative sounds. Our resulting self-supervised model,\nSSL-SaN, achieves state-of-the-art performance compared to other\nself-supervised models, both in sound localization and cross-modal retrieval.\nSecond, we propose a new metric that quantifies the trade-off between alignment\nand separability of auditory and visual features across positive and negative\naudio-visual pairs. Third, we present IS3+, an extended and improved version of\nthe IS3 synthetic dataset with negative audio.\n  Our data, metrics and code are available on the\nhttps://xavijuanola.github.io/SSL-SaN/.",
      "url": "http://arxiv.org/abs/2508.21761v1",
      "published_time_eastern_timestamp": 1756485376.0
    },
    {
      "title": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL,\n  Rogue Software and Auto-SNL",
      "summary": "The LCLS-II Free Electron Laser (FEL) will generate X-ray pulses for beamline\nexperiments at rates of up to 1~MHz, with detectors producing data throughputs\nexceeding 1 TB/s. Managing such massive data streams presents significant\nchallenges, as transmission and storage infrastructures become prohibitively\nexpensive. Machine learning (ML) offers a promising solution for real-time data\nreduction, but conventional implementations introduce excessive latency, making\nthem unsuitable for high-speed experimental environments. To address these\nchallenges, SLAC developed the SLAC Neural Network Library (SNL), a specialized\nframework designed to deploy real-time ML inference models on\nField-Programmable Gate Arrays (FPGA). SNL's key feature is the ability to\ndynamically update model weights without requiring FPGA resynthesis, enhancing\nflexibility for adaptive learning applications. To further enhance usability\nand accessibility, we introduce Auto-SNL, a Python extension that streamlines\nthe process of converting Python-based neural network models into\nSNL-compatible high-level synthesis code. This paper presents a benchmark\ncomparison against hls4ml, the current state-of-the-art tool, across multiple\nneural network architectures, fixed-point precisions, and synthesis\nconfigurations targeting a Xilinx ZCU102 FPGA. The results showed that SNL\nachieves competitive or superior latency in most tested architectures, while in\nsome cases also offering FPGA resource savings. This adaptation demonstrates\nSNL's versatility, opening new opportunities for researchers and academics in\nfields such as high-energy physics, medical imaging, robotics, and many more.",
      "url": "http://arxiv.org/abs/2508.21739v1",
      "published_time_eastern_timestamp": 1756483455.0
    },
    {
      "title": "New line-driven wind mass-loss rates for OB stars with metallicities\n  down to $0.01\\,Z_\\odot$",
      "summary": "We provide new line-driven wind models for OB stars with metallicities down\nto $0.01\\,Z_\\odot$. The models were calculated with our global wind code\nMETUJE, which solves the hydrodynamical equations from nearly hydrostatic\nphotosphere to supersonically expanding stellar wind together with the\nequations of statistical equilibrium and the radiative transfer equation. The\nmodels predict the basic wind parameters, namely, the wind mass-loss rates and\nterminal velocities just from the stellar parameters. In general, the wind\nmass-loss rates decrease with decreasing metallicity and this relationship\nsteepens for very low metallicities, $Z\\lesssim0.1\\,Z_\\odot$. Down to\nmetallicities corresponding to the Magellanic Clouds and even lower, the\npredicted mass-loss rates reasonably agree with observational estimates.\nHowever, the theoretical and observational mass-loss rates for very low\nmetallicities exhibit significant scatter. We show that the scatter of\nobservational values can be caused by inefficient shock cooling in the stellar\nwind, which leaves a considerable fraction of the wind at too high temperatures\nwith waning observational signatures. The scatter of theoretical predictions is\ncaused by a low number of lines that effectively accelerate the wind at very\nlow metallicities.",
      "url": "http://arxiv.org/abs/2508.21702v1",
      "published_time_eastern_timestamp": 1756480420.0
    },
    {
      "title": "Mapping like a Skeptic: Probabilistic BEV Projection for Online HD\n  Mapping",
      "summary": "Constructing high-definition (HD) maps from sensory input requires accurately\nmapping the road elements in image space to the Bird's Eye View (BEV) space.\nThe precision of this mapping directly impacts the quality of the final\nvectorized HD map. Existing HD mapping approaches outsource the projection to\nstandard mapping techniques, such as attention-based ones. However, these\nmethods struggle with accuracy due to generalization problems, often\nhallucinating non-existent road elements. Our key idea is to start with a\ngeometric mapping based on camera parameters and adapt it to the scene to\nextract relevant map information from camera images. To implement this, we\npropose a novel probabilistic projection mechanism with confidence scores to\n(i) refine the mapping to better align with the scene and (ii) filter out\nirrelevant elements that should not influence HD map generation. In addition,\nwe improve temporal processing by using confidence scores to selectively\naccumulate reliable information over time. Experiments on new splits of the\nnuScenes and Argoverse2 datasets demonstrate improved performance over\nstate-of-the-art approaches, indicating better generalization. The improvements\nare particularly pronounced on nuScenes and in the challenging long perception\nrange. Our code and model checkpoints are available at\nhttps://github.com/Fatih-Erdogan/mapping-like-skeptic .",
      "url": "http://arxiv.org/abs/2508.21689v1",
      "published_time_eastern_timestamp": 1756479333.0
    },
    {
      "title": "Towards Interactive Lesion Segmentation in Whole-Body PET/CT with\n  Promptable Models",
      "summary": "Whole-body PET/CT is a cornerstone of oncological imaging, yet accurate\nlesion segmentation remains challenging due to tracer heterogeneity,\nphysiological uptake, and multi-center variability. While fully automated\nmethods have advanced substantially, clinical practice benefits from approaches\nthat keep humans in the loop to efficiently refine predicted masks. The\nautoPET/CT IV challenge addresses this need by introducing interactive\nsegmentation tasks based on simulated user prompts. In this work, we present\nour submission to Task 1. Building on the winning autoPET III nnU-Net pipeline,\nwe extend the framework with promptable capabilities by encoding user-provided\nforeground and background clicks as additional input channels. We\nsystematically investigate representations for spatial prompts and demonstrate\nthat Euclidean Distance Transform (EDT) encodings consistently outperform\nGaussian kernels. Furthermore, we propose online simulation of user\ninteractions and a custom point sampling strategy to improve robustness under\nrealistic prompting conditions. Our ensemble of EDT-based models, trained with\nand without external data, achieves the strongest cross-validation performance,\nreducing both false positives and false negatives compared to baseline models.\nThese results highlight the potential of promptable models to enable efficient,\nuser-guided segmentation workflows in multi-tracer, multi-center PET/CT. Code\nis publicly available at https://github.com/MIC-DKFZ/autoPET-interactive",
      "url": "http://arxiv.org/abs/2508.21680v1",
      "published_time_eastern_timestamp": 1756478998.0
    },
    {
      "title": "Is this chart lying to me? Automating the detection of misleading\n  visualizations",
      "summary": "Misleading visualizations are a potent driver of misinformation on social\nmedia and the web. By violating chart design principles, they distort data and\nlead readers to draw inaccurate conclusions. Prior work has shown that both\nhumans and multimodal large language models (MLLMs) are frequently deceived by\nsuch visualizations. Automatically detecting misleading visualizations and\nidentifying the specific design rules they violate could help protect readers\nand reduce the spread of misinformation. However, the training and evaluation\nof AI models has been limited by the absence of large, diverse, and openly\navailable datasets. In this work, we introduce Misviz, a benchmark of 2,604\nreal-world visualizations annotated with 12 types of misleaders. To support\nmodel training, we also release Misviz-synth, a synthetic dataset of 81,814\nvisualizations generated using Matplotlib and based on real-world data tables.\nWe perform a comprehensive evaluation on both datasets using state-of-the-art\nMLLMs, rule-based systems, and fine-tuned classifiers. Our results reveal that\nthe task remains highly challenging. We release Misviz, Misviz-synth, and the\naccompanying code.",
      "url": "http://arxiv.org/abs/2508.21675v1",
      "published_time_eastern_timestamp": 1756478205.0
    },
    {
      "title": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators",
      "summary": "Deep learning (DL) models for natural language-to-code generation have become\nintegral to modern software development pipelines. However, their heavy\nreliance on large amounts of data, often collected from unsanitized online\nsources, exposes them to data poisoning attacks, where adversaries inject\nmalicious samples to subtly bias model behavior. Recent targeted attacks\nsilently replace secure code with semantically equivalent but vulnerable\nimplementations without relying on explicit triggers to launch the attack,\nmaking it especially hard for detection methods to distinguish clean from\npoisoned samples. We present a systematic study on the effectiveness of\nexisting poisoning detection methods under this stealthy threat model.\nSpecifically, we perform targeted poisoning on three DL models (CodeBERT,\nCodeT5+, AST-T5), and evaluate spectral signatures analysis, activation\nclustering, and static analysis as defenses. Our results show that all methods\nstruggle to detect triggerless poisoning, with representation-based approaches\nfailing to isolate poisoned samples and static analysis suffering false\npositives and false negatives, highlighting the need for more robust,\ntrigger-independent defenses for AI-assisted code generation.",
      "url": "http://arxiv.org/abs/2508.21636v1",
      "published_time_eastern_timestamp": 1756476006.0
    },
    {
      "title": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects,\n  Vulnerabilities, and Complexity",
      "summary": "As AI code assistants become increasingly integrated into software\ndevelopment workflows, understanding how their code compares to human-written\nprograms is critical for ensuring reliability, maintainability, and security.\nIn this paper, we present a large-scale comparison of code authored by human\ndevelopers and three state-of-the-art LLMs, i.e., ChatGPT, DeepSeek-Coder, and\nQwen-Coder, on multiple dimensions of software quality: code defects, security\nvulnerabilities, and structural complexity. Our evaluation spans over 500k code\nsamples in two widely used languages, Python and Java, classifying defects via\nOrthogonal Defect Classification and security vulnerabilities using the Common\nWeakness Enumeration. We find that AI-generated code is generally simpler and\nmore repetitive, yet more prone to unused constructs and hardcoded debugging,\nwhile human-written code exhibits greater structural complexity and a higher\nconcentration of maintainability issues. Notably, AI-generated code also\ncontains more high-risk security vulnerabilities. These findings highlight the\ndistinct defect profiles of AI- and human-authored code and underscore the need\nfor specialized quality assurance practices in AI-assisted programming.",
      "url": "http://arxiv.org/abs/2508.21634v1",
      "published_time_eastern_timestamp": 1756475488.0
    },
    {
      "title": "QZhou-Embedding Technical Report",
      "summary": "We present QZhou-Embedding, a general-purpose contextual text embedding model\nwith exceptional text representation capabilities. Built upon the\nQwen2.5-7B-Instruct foundation model, we designed a unified multi-task\nframework comprising specialized data transformation and training strategies.\nThe data transformation scheme enables the incorporation of more diverse\ntextual training datasets, while the task-specific training strategies enhance\nmodel learning efficiency. We developed a data synthesis pipeline leveraging\nLLM API, incorporating techniques such as paraphrasing, augmentation, and hard\nnegative example generation to improve the semantic richness and sample\ndifficulty of the training set. Additionally, we employ a two-stage training\nstrategy, comprising initial retrieval-focused pretraining followed by\nfull-task fine-tuning, enabling the embedding model to extend its capabilities\nbased on robust retrieval performance. Our model achieves state-of-the-art\nresults on the MTEB and CMTEB benchmarks, ranking first on both leaderboards\n(August 27 2025), and simultaneously achieves state-of-the-art performance on\ntasks including reranking, clustering, etc. Our findings demonstrate that\nhigher-quality, more diverse data is crucial for advancing retrieval model\nperformance, and that leveraging LLMs generative capabilities can further\noptimize data quality for embedding model breakthroughs. Our model weights are\nreleased on HuggingFace under Apache 2.0 license. For reproducibility, we\nprovide evaluation code and instructions on GitHub.",
      "url": "http://arxiv.org/abs/2508.21632v1",
      "published_time_eastern_timestamp": 1756475242.0
    },
    {
      "title": "Fluid dynamics of charm quarks from heavy to light-ion collisions",
      "summary": "Heavy quarks are powerful tools to characterize the quark-gluon plasma (QGP)\nproduced in relativistic nuclear collisions. By exploiting a mapping between\ntransport theory and hydrodynamics, we developed a fluid-dynamic description of\nheavy-quark diffusion in the QCD plasma. We present results for the transverse\nmomentum distributions of charm hadrons and evolution of charm density and\ndiffusion fields obtained using a fluid-dynamic code coupled with the\nconservation of a heavy-quark current in the QGP in various collision systems.",
      "url": "http://arxiv.org/abs/2508.21600v1",
      "published_time_eastern_timestamp": 1756472362.0
    },
    {
      "title": "Growing Mathlib: maintenance of a large scale mathematical library",
      "summary": "The Lean mathematical library Mathlib is one of the fastest-growing libraries\nof formalised mathematics. We describe various strategies to manage this\ngrowth, while allowing for change and avoiding maintainer overload. This\nincludes dealing with breaking changes via a deprecation system, using code\nquality analysis tools (linters) to provide direct user feedback about common\npitfalls, speeding up compilation times through conscious library (re-)design,\ndealing with technical debt as well as writing custom tooling to help with the\nreview and triage of new contributions.",
      "url": "http://arxiv.org/abs/2508.21593v1",
      "published_time_eastern_timestamp": 1756471798.0
    },
    {
      "title": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM\n  Fine-Tuning via Closed-Loop Learning",
      "summary": "Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely\non high-quality training data. While data selection and data synthesis are two\ncommon strategies to improve data quality, existing approaches often face\nlimitations in static dataset curation that fail to adapt to evolving model\ncapabilities. In this paper, we introduce Middo, a self-evolving Model-informed\ndynamic data optimization framework that uses model-aware data selection and\ncontext-preserving data refinement. Unlike conventional one-off\nfiltering/synthesis methods, our framework establishes a closed-loop\noptimization system: (1) A self-referential diagnostic module proactively\nidentifies suboptimal samples through tri-axial model signals - loss patterns\n(complexity), embedding cluster dynamics (diversity), and self-alignment scores\n(quality); (2) An adaptive optimization engine then transforms suboptimal\nsamples into pedagogically valuable training points while preserving semantic\nintegrity; (3) This optimization process continuously evolves with model\ncapability through dynamic learning principles. Experiments on multiple\nbenchmarks demonstrate that our \\method consistently enhances the quality of\nseed data and boosts LLM's performance with improving accuracy by 7.15% on\naverage while maintaining the original dataset scale. This work establishes a\nnew paradigm for sustainable LLM training through dynamic human-AI co-evolution\nof data and models. Our datasets, models, and code are coming soon.",
      "url": "http://arxiv.org/abs/2508.21589v1",
      "published_time_eastern_timestamp": 1756471647.0
    },
    {
      "title": "NewsReX: A More Efficient Approach to News Recommendation with Keras 3\n  and JAX",
      "summary": "Reproducing and comparing results in news recommendation research has become\nincreasingly difficult. This is due to a fragmented ecosystem of diverse\ncodebases, varied configurations, and mainly due to resource-intensive models.\nWe introduce NewsReX, an open-source library designed to streamline this\nprocess. Our key contribution is a modern implementation built on Keras 3 and\nJAX, which provides an increase in computational efficiency. Experiments show\nthat NewsReX is faster than current implementations. To support broader\nresearch, we provide a straightforward guide and scripts for training models on\ncustom datasets. We validated this functionality using a proprietary Japanese\nnews dataset from Nikkei News, a leading Japanese media corporation renowned\nfor its comprehensive coverage of business, economic, and financial news.\nNewsReX makes reproducing complex experiments faster and more accessible to a\nwider range of hardware making sure the speed up it also achieved for less\npowerful GPUs, like an 8GB RTX 3060 Ti. Beyond the library, this paper offers\nan analysis of key training parameters often overlooked in the literature,\nincluding the effect of different negative sampling strategies, the varying\nnumber of epochs, the impact of random batching, and more. This supplementary\nanalysis serves as a valuable reference for future research, aiming to reduce\nredundant computation when comparing baselines and guide best practices. Code\navailable at https://github.com/igor17400/NewsReX.",
      "url": "http://arxiv.org/abs/2508.21572v1",
      "published_time_eastern_timestamp": 1756470416.0
    },
    {
      "title": "On the Weight Distribution of Concatenated Code Ensemble Based on the\n  Plotkin Construction",
      "summary": "In this note, we reveal a relation between the weight distribution of a\nconcatenated code ensemble based on the Plotkin construction and those of its\ncomponent codes. The relation may find applications in the calculation of the\nensemble weight distributions for many codes, including Reed-Muller (RM)-like\ncodes.",
      "url": "http://arxiv.org/abs/2508.21515v1",
      "published_time_eastern_timestamp": 1756465076.0
    },
    {
      "title": "Possible Coronal Geometry in the Hard and Soft State of Black Hole X-ray\n  Binaries from MONK Simulations",
      "summary": "Understanding the coronal geometry in different states of black hole X-ray\nbinaries is important for more accurate modeling of the system. However, it is\ndifficult to distinguish different geometries by fitting the observed\nComptonization spectra. In this work, we use the Monte Carlo ray-tracing code\nMONK to simulate the spectra for three widely proposed coronal geometries:\nsandwich, spherical, and lamppost, varying their optical depth and size\n(height). By fitting the simulated NuSTAR observations with the simplcut*kerrbb\nmodel, we infer the possible parameter space for the hard state and soft state\nof different coronal geometries. The influence of the disk inclination angle\nand black hole spin is discussed. We find that for the lamppost model the disk\nemission is always dominant, making it incompatible in the hard state. While\nthe sandwich and spherical models can produce similar spectra in both the hard\nand soft states, the simulated IXPE polarimetric spectra show the potential to\nbreak this degeneracy.",
      "url": "http://arxiv.org/abs/2508.21511v1",
      "published_time_eastern_timestamp": 1756464682.0
    },
    {
      "title": "Spiking Decision Transformers: Local Plasticity, Phase-Coding, and\n  Dendritic Routing for Low-Power Sequence Control",
      "summary": "Reinforcement learning agents based on Transformer architectures have\nachieved impressive performance on sequential decision-making tasks, but their\nreliance on dense matrix operations makes them ill-suited for\nenergy-constrained, edge-oriented platforms. Spiking neural networks promise\nultra-low-power, event-driven inference, yet no prior work has seamlessly\nmerged spiking dynamics with return-conditioned sequence modeling. We present\nthe Spiking Decision Transformer (SNN-DT), which embeds Leaky\nIntegrate-and-Fire neurons into each self-attention block, trains end-to-end\nvia surrogate gradients, and incorporates biologically inspired three-factor\nplasticity, phase-shifted spike-based positional encodings, and a lightweight\ndendritic routing module. Our implementation matches or exceeds standard\nDecision Transformer performance on classic control benchmarks (CartPole-v1,\nMountainCar-v0, Acrobot-v1, Pendulum-v1) while emitting fewer than ten spikes\nper decision, an energy proxy suggesting over four orders-of-magnitude\nreduction in per inference energy. By marrying sequence modeling with\nneuromorphic efficiency, SNN-DT opens a pathway toward real-time, low-power\ncontrol on embedded and wearable devices.",
      "url": "http://arxiv.org/abs/2508.21505v1",
      "published_time_eastern_timestamp": 1756463857.0
    },
    {
      "title": "Anyons in the $π$-flux phase of fermionic matter coupled to a\n  $\\mathbb{Z}_2$-gauge field",
      "summary": "We consider a system of weakly interacting spinful lattice fermions coupled\nto a dynamical $\\mathbb{Z}_2$ gauge field. The ground state lies in the sector\nof a uniform $\\pi$-flux per plaquette and the monopoles are massive. In the\npresence of a staggered mass for the fermions, this yields a fully gapped,\nfour-dimensional ground state space on large tori. It is topologically ordered.\nBy considering adiabatic $\\pi$-flux insertion, we construct dressed monopole\nexcitations and show that their braiding with the fermionic excitations are\nthose of the toric code.",
      "url": "http://arxiv.org/abs/2508.21502v1",
      "published_time_eastern_timestamp": 1756463695.0
    }
  ]
}
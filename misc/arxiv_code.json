{
  "last_updated": "2025-08-12T23:47:05.260292-04:00",
  "papers": [
    {
      "title": "Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices",
      "summary": "There is a growing demand for deploying large generative AI models on mobile\ndevices. For recent popular video generative models, however, the Variational\nAutoEncoder (VAE) represents one of the major computational bottlenecks. Both\nlarge parameter sizes and mismatched kernels cause out-of-memory errors or\nextremely slow inference on mobile devices. To address this, we propose a\nlow-cost solution that efficiently transfers widely used video VAEs to mobile\ndevices. (1) We analyze redundancy in existing VAE architectures and get\nempirical design insights. By integrating 3D depthwise separable convolutions\ninto our model, we significantly reduce the number of parameters. (2) We\nobserve that the upsampling techniques in mainstream video VAEs are poorly\nsuited to mobile hardware and form the main bottleneck. In response, we propose\na decoupled 3D pixel shuffle scheme that slashes end-to-end delay. Building\nupon these, we develop a universal mobile-oriented VAE decoder, Turbo-VAED. (3)\nWe propose an efficient VAE decoder training method. Since only the decoder is\nused during deployment, we distill it to Turbo-VAED instead of retraining the\nfull VAE, enabling fast mobile adaptation with minimal performance loss. To our\nknowledge, our method enables real-time 720p video VAE decoding on mobile\ndevices for the first time. This approach is widely applicable to most video\nVAEs. When integrated into four representative models, with training cost as\nlow as $95, it accelerates original VAEs by up to 84.5x at 720p resolution on\nGPUs, uses as low as 17.5% of original parameter count, and retains 96.9% of\nthe original reconstruction quality. Compared to mobile-optimized VAEs,\nTurbo-VAED achieves a 2.9x speedup in FPS and better reconstruction quality on\nthe iPhone 16 Pro. The code and models will soon be available at\nhttps://github.com/hustvl/Turbo-VAED.",
      "url": "http://arxiv.org/abs/2508.09136v1",
      "published_time_eastern_timestamp": 1755021586.0
    },
    {
      "title": "Complex Logical Instruction Generation",
      "summary": "Instruction following has catalyzed the recent era of Large Language Models\n(LLMs) and is the foundational skill underpinning more advanced capabilities\nsuch as reasoning and agentic behaviors. As tasks grow more challenging, the\nlogic structures embedded in natural language instructions becomes increasingly\nintricate. However, how well LLMs perform on such logic-rich instructions\nremains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a\nscalable, automated framework for generating verifiable instructions from code\nfunctions, which can naturally express rich logic such as conditionals,\nnesting, recursion, and function calls. We further curate a collection of\ncomplex code functions and use LogicIFGen to construct LogicIFEval, a benchmark\ncomprising 426 verifiable logic-rich instructions. Our experiments demonstrate\nthat current state-of-the-art LLMs still struggle to correctly follow the\ninstructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the\ninstructions, revealing significant deficiencies in the instruction-following\nability. Code and Benchmark: https://github.com/mianzhang/LogicIF",
      "url": "http://arxiv.org/abs/2508.09125v1",
      "published_time_eastern_timestamp": 1755021267.0
    },
    {
      "title": "OpenCUA: Open Foundations for Computer-Use Agents",
      "summary": "Vision-language models have demonstrated impressive capabilities as\ncomputer-use agents (CUAs) capable of automating diverse computer tasks. As\ntheir commercial potential grows, critical details of the most capable CUA\nsystems remain closed. As these agents will increasingly mediate digital\ninteractions and execute consequential decisions on our behalf, the research\ncommunity needs access to open CUA frameworks to study their capabilities,\nlimitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive\nopen-source framework for scaling CUA data and foundation models. Our framework\nconsists of: (1) an annotation infrastructure that seamlessly captures human\ncomputer-use demonstrations; (2) AgentNet, the first large-scale computer-use\ntask dataset spanning 3 operating systems and 200+ applications and websites;\n(3) a scalable pipeline that transforms demonstrations into state-action pairs\nwith reflective long Chain-of-Thought reasoning that sustain robust performance\ngains as data scales. Our end-to-end agent models demonstrate strong\nperformance across CUA benchmarks. In particular, OpenCUA-32B achieves an\naverage success rate of 34.8% on OSWorld-Verified, establishing a new\nstate-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA\n(GPT-4o). Further analysis confirms that our approach generalizes well across\ndomains and benefits significantly from increased test-time computation. We\nrelease our annotation tool, datasets, code, and models to build open\nfoundations for further CUA research.",
      "url": "http://arxiv.org/abs/2508.09123v1",
      "published_time_eastern_timestamp": 1755021152.0
    },
    {
      "title": "A New Method of Deriving Doppler Velocities for Solar Orbiter SPICE",
      "summary": "This paper presents a follow-up to previous work on correcting PSF-induced\nDoppler artifacts in observations by the SPICE spectrograph on Solar Orbiter.\nIn a previous paper, we demonstrated correction of these artifacts in the\n$y-\\lambda$ plane with PSF Regularization, treating the forward problem with a\nmethod based on large sparse matrix inversion. It has since been found that\nsimilar apparent artifacts are also present in the $x-\\lambda$ direction, i.e.,\nacross adjacent slit positions. This is difficult (although not impossible) to\ncorrect with the previous matrix inversion method due to the time variation\nbetween slit positions. We have therefore devised a new method which addresses\nboth $x-\\lambda$ and $y-\\lambda$ artifacts simultaneously by applying\nwavelength dependent shifts at each $x-y$ plane of the spectral cube. This\npaper demonstrates the SPICE data issue, describes the new method, and shows a\ncomparison with the previous one. We explore the time variation of the\ncorrection parameters for the SPICE data and show a clear orbit dependence. The\nresults of the method are significantly higher quality derived Doppler signals,\nwhich we estimate at less than $\\sim$ 5 km/s uncertainty for brighter lines in\nthe absence of other systematics. Furthermore, we show the new SPICE polar\nobservation results as a demonstration. The correction codes are written in\nPython, publicly available on GitHub, and can be directly applied to SPICE\nlevel 2 datasets.",
      "url": "http://arxiv.org/abs/2508.09121v1",
      "published_time_eastern_timestamp": 1755021138.0
    },
    {
      "title": "Constrained free energy minimization for the design of thermal states\n  and stabilizer thermodynamic systems",
      "summary": "A quantum thermodynamic system is described by a Hamiltonian and a list of\nconserved, non-commuting charges, and a fundamental goal is to determine the\nminimum energy of the system subject to constraints on the charges. Recently,\n[Liu et al., arXiv:2505.04514] proposed first- and second-order classical and\nhybrid quantum-classical algorithms for solving a dual chemical potential\nmaximization problem, and they proved that these algorithms converge to global\noptima by means of gradient-ascent approaches. In this paper, we benchmark\nthese algorithms on several problems of interest in thermodynamics, including\none- and two-dimensional quantum Heisenberg models with nearest and\nnext-to-nearest neighbor interactions and with the charges set to the total\n$x$, $y$, and $z$ magnetizations. We also offer an alternative compelling\ninterpretation of these algorithms as methods for designing ground and thermal\nstates of controllable Hamiltonians, with potential applications in molecular\nand material design. Furthermore, we introduce stabilizer thermodynamic systems\nas thermodynamic systems based on stabilizer codes, with the Hamiltonian\nconstructed from a given code's stabilizer operators and the charges\nconstructed from the code's logical operators. We benchmark the aforementioned\nalgorithms on several examples of stabilizer thermodynamic systems, including\nthose constructed from the one-to-three-qubit repetition code, the perfect\none-to-five-qubit code, and the two-to-four-qubit error-detecting code.\nFinally, we observe that the aforementioned hybrid quantum-classical\nalgorithms, when applied to stabilizer thermodynamic systems, can serve as\nalternative methods for encoding qubits into stabilizer codes at a fixed\ntemperature, and we provide an effective method for warm-starting these\nencoding algorithms whenever a single qubit is encoded into multiple physical\nqubits.",
      "url": "http://arxiv.org/abs/2508.09103v1",
      "published_time_eastern_timestamp": 1755019873.0
    },
    {
      "title": "AutoCodeBench: Large Language Models are Automatic Code Benchmark\n  Generators",
      "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious domains, with code generation emerging as a key area of focus. While\nnumerous benchmarks have been proposed to evaluate their code generation\nabilities, these benchmarks face several critical limitations. First, they\noften rely on manual annotations, which are time-consuming and difficult to\nscale across different programming languages and problem complexities. Second,\nmost existing benchmarks focus primarily on Python, while the few multilingual\nbenchmarks suffer from limited difficulty and uneven language distribution. To\naddress these challenges, we propose AutoCodeGen, an automated method for\ngenerating high-difficulty multilingual code generation datasets without manual\nannotations. AutoCodeGen ensures the correctness and completeness of test cases\nby generating test inputs with LLMs and obtaining test outputs through a\nmultilingual sandbox, while achieving high data quality through reverse-order\nproblem generation and multiple filtering steps. Using this novel method, we\nintroduce AutoCodeBench, a large-scale code generation benchmark comprising\n3,920 problems evenly distributed across 20 programming languages. It is\nspecifically designed to evaluate LLMs on challenging, diverse, and practical\nmultilingual tasks. We evaluate over 30 leading open-source and proprietary\nLLMs on AutoCodeBench and its simplified version AutoCodeBench-Lite. The\nresults show that even the most advanced LLMs struggle with the complexity,\ndiversity, and multilingual nature of these tasks. Besides, we introduce\nAutoCodeBench-Complete, specifically designed for base models to assess their\nfew-shot code generation capabilities. We hope the AutoCodeBench series will\nserve as a valuable resource and inspire the community to focus on more\nchallenging and practical multilingual code generation scenarios.",
      "url": "http://arxiv.org/abs/2508.09101v1",
      "published_time_eastern_timestamp": 1755019760.0
    },
    {
      "title": "Bridging Formal Language with Chain-of-Thought Reasoning to Geometry\n  Problem Solving",
      "summary": "Large vision language models exhibit notable limitations on Geometry Problem\nSolving (GPS) because of their unreliable diagram interpretation and pure\nnatural-language reasoning. A recent line of work mitigates this by using\nsymbolic solvers: the model directly generates a formal program that a geometry\nsolver can execute. However, this direct program generation lacks intermediate\nreasoning, making the decision process opaque and prone to errors. In this\nwork, we explore a new approach that integrates Chain-of-Thought (CoT) with\nformal language. The model interleaves natural language reasoning with\nincremental emission of solver-executable code, producing a hybrid reasoning\ntrace in which critical derivations are expressed in formal language. To teach\nthis behavior at scale, we combine (1) supervised fine-tuning on an 11K newly\ndeveloped synthetic dataset with interleaved natural language reasoning and\nautomatic formalization, and (2) solver-in-the-loop reinforcement learning that\njointly optimizes both the CoT narrative and the resulting program through\noutcome-based rewards. Built on Qwen2.5-VL-7B, our new model, named\nGF-Reasoner, achieves up to 15% accuracy improvements on standard GPS\nbenchmarks, surpassing both 7B-scale peers and the much larger model\nQwen2.5-VL-72B. By exploiting high-order geometric knowledge and offloading\nsymbolic computation to the solver, the generated reasoning traces are\nnoticeably shorter and cleaner. Furthermore, we present a comprehensive\nanalysis of method design choices (e.g., reasoning paradigms, data synthesis,\ntraining epochs, etc.), providing actionable insights for future research.",
      "url": "http://arxiv.org/abs/2508.09099v1",
      "published_time_eastern_timestamp": 1755019583.0
    },
    {
      "title": "Generalized Bicycle Codes with Low Connectivity: Minimum Distance Bounds\n  and Hook Errors",
      "summary": "We present new upper and lower bounds on the minimum distance of certain\ngeneralized bicycle (GB) codes beyond the reach of techniques for classical\ncodes capable of even capturing the true minimum distance for some cases. These\nbounds are then applied to illustrate the existence and analyze two highly\ndegenerate GB code families with parameters $[[d^2+1,2,d]]$ for odd $d \\geq 3$\nand $[[d^2,2,d]]$ for even $d \\geq 4$, both having the property that each check\nqubit is connected to exactly four data qubits similar to surface codes. For\nthe odd-distance family, we analyze the structure of low-weight logical Pauli\noperators and demonstrate the existence of a fault-tolerant logical CNOT gate\nbetween the two logical qubits, achievable through a simple relabeling of data\nqubits. We further construct a syndrome extraction pattern for both families\nthat does not imply minimum distance reduction arising from extraction circuit\nfaults that propagate from the check qubits to the data qubits. Finally, we\nnumerically evaluate their logical error rates under a code capacity\ndepolarizing noise model using the belief propagation ordered statistics\ndecoding (BP-OSD) and minimum-weight perfect-matching (MWPM) decoders, yielding\nthresholds of approximately $14-16\\%$ for the odd and even families, very\nsimilar to those of rotated surface codes.",
      "url": "http://arxiv.org/abs/2508.09082v1",
      "published_time_eastern_timestamp": 1755018239.0
    },
    {
      "title": "Stable Collisionless Tori Around Kerr Black Holes",
      "summary": "In low luminosity active galactic nuclei like M87$^*$ and Sgr A$^*$, the\naccretion flow in the vicinity of the black hole is in the collisionless\nregime, meaning that the collisional mean free path of charged particles is\nmuch larger than the dynamic length scales. To properly model the particle\nenergization and emission from the collisionless accretion flow, a promising\napproach is to employ the global general relativistic particle-in-cell\nsimulations -- a newly developed, fully kinetic, first-principles method.\nHowever, it has been challenging to set up an initial condition that involves\ncollisionless gas with finite angular momentum. We present, for the first time,\na class of analytic kinetic equilibria of collisionless tori around a Kerr\nblack hole. We have successfully implemented the collisionless tori in our\nGPU-based GRPIC code framework Aperture, and found them to be stable for\nhundreds to thousands of dynamical times in 2D axisymmetric simulations when\nthere is no initial seed magnetic field. These kinetic equilibria serve as\nideal starting points for future studies of the physics of collisionless\naccretion and jet launching.",
      "url": "http://arxiv.org/abs/2508.09077v1",
      "published_time_eastern_timestamp": 1755017568.0
    },
    {
      "title": "CPO: Addressing Reward Ambiguity in Role-playing Dialogue via\n  Comparative Policy Optimization",
      "summary": "Reinforcement Learning Fine-Tuning (RLFT) has achieved notable success in\ntasks with objectively verifiable answers (e.g., code generation, mathematical\nreasoning), yet struggles with open-ended subjective tasks like role-playing\ndialogue. Traditional reward modeling approaches, which rely on independent\nsample-wise scoring, face dual challenges: subjective evaluation criteria and\nunstable reward signals.Motivated by the insight that human evaluation\ninherently combines explicit criteria with implicit comparative judgments, we\npropose Comparative Policy Optimization (CPO). CPO redefines the reward\nevaluation paradigm by shifting from sample-wise scoring to comparative\ngroup-wise scoring.Building on the same principle, we introduce the\nCharacterArena evaluation framework, which comprises two stages:(1)\nContextualized Multi-turn Role-playing Simulation, and (2) Trajectory-level\nComparative Evaluation. By operationalizing subjective scoring via objective\ntrajectory comparisons, CharacterArena minimizes contextual bias and enables\nmore robust and fair performance evaluation. Empirical results on\nCharacterEval, CharacterBench, and CharacterArena confirm that CPO effectively\nmitigates reward ambiguity and leads to substantial improvements in dialogue\nquality.",
      "url": "http://arxiv.org/abs/2508.09074v1",
      "published_time_eastern_timestamp": 1755017358.0
    },
    {
      "title": "Characteristics of monotonic sheaths near a wall with grazing magnetic\n  incidence",
      "summary": "We consider a magnetised plasma in contact with an absorbing planar wall,\nwhere the angle $\\alpha$ between the magnetic field and the wall is small,\n$\\alpha \\ll 1$ (in radians) and the system is symmetric tangential to the wall.\nThe finite ratio $\\gamma$ of the characteristic electron gyroradius $\\rho_{\\rm\ne}$ to the Debye length $\\lambda_{\\rm D}$, $\\gamma = \\rho_{\\rm e} /\n\\lambda_{\\rm D}$, is retained via a grazing-incidence ($\\alpha \\ll 1$)\ngyrokinetic treatment [1,2]. Building on a previously developed iterative\nscheme [2,3] to solve for the steady-state electrostatic potential in the\nquasineutral magnetic presheath of width $\\sim \\rho_{\\rm S}$, we developed a\nscheme that simultaneously solves for both the presheath and the non-neutral\nDebye sheath of width $\\sim \\lambda_{\\rm D}$ in the limit $\\lambda_{\\rm D} /\n\\rho_{\\rm S} \\rightarrow 0$. The code, called GYRAZE, thus provides the\nenergy-angle distribution of ions at the wall and the velocity distributions of\nelectrons reflected by the wall for different values of wall potential. A\nmonotonic electrostatic potential profile, assumed in this work, can only exist\nfor magnetic field angles larger than a critical value [3]. While the critical\nangle is shown here to significantly increase with $\\gamma$, it is still\ntypically smaller than the magnetic field angle at divertor targets of a fusion\ndevice.",
      "url": "http://arxiv.org/abs/2508.09067v1",
      "published_time_eastern_timestamp": 1755016613.0
    },
    {
      "title": "Developing a Transferable Federated Network Intrusion Detection System",
      "summary": "Intrusion Detection Systems (IDS) are a vital part of a network-connected\ndevice. In this paper, we develop a deep learning based intrusion detection\nsystem that is deployed in a distributed setup across devices connected to a\nnetwork. Our aim is to better equip deep learning models against unknown\nattacks using knowledge from known attacks. To this end, we develop algorithms\nto maximize the number of transferability relationships. We propose a\nConvolutional Neural Network (CNN) model, along with two algorithms that\nmaximize the number of relationships observed. One is a two step data\npre-processing stage, and the other is a Block-Based Smart Aggregation (BBSA)\nalgorithm. The proposed system succeeds in achieving superior transferability\nperformance while maintaining impressive local detection rates. We also show\nthat our method is generalizable, exhibiting transferability potential across\ndatasets and even with different backbones. The code for this work can be found\nat https://github.com/ghosh64/tabfidsv2.",
      "url": "http://arxiv.org/abs/2508.09060v1",
      "published_time_eastern_timestamp": 1755015749.0
    },
    {
      "title": "FetFIDS: A Feature Embedding Attention based Federated Network Intrusion\n  Detection Algorithm",
      "summary": "Intrusion Detection Systems (IDS) have an increasingly important role in\npreventing exploitation of network vulnerabilities by malicious actors. Recent\ndeep learning based developments have resulted in significant improvements in\nthe performance of IDS systems. In this paper, we present FetFIDS, where we\nexplore the employment of feature embedding instead of positional embedding to\nimprove intrusion detection performance of a transformer based deep learning\nsystem. Our model is developed with the aim of deployments in edge learning\nscenarios, where federated learning over multiple communication rounds can\nensure both privacy and localized performance improvements. FetFIDS outperforms\nmultiple state-of-the-art intrusion detection systems in a federated\nenvironment and demonstrates a high degree of suitability to federated\nlearning. The code for this work can be found at\nhttps://github.com/ghosh64/fetfids.",
      "url": "http://arxiv.org/abs/2508.09056v1",
      "published_time_eastern_timestamp": 1755015389.0
    },
    {
      "title": "Uncertainty-aware Cross-training for Semi-supervised Medical Image\n  Segmentation",
      "summary": "Semi-supervised learning has gained considerable popularity in medical image\nsegmentation tasks due to its capability to reduce reliance on expert-examined\nannotations. Several mean-teacher (MT) based semi-supervised methods utilize\nconsistency regularization to effectively leverage valuable information from\nunlabeled data. However, these methods often heavily rely on the student model\nand overlook the potential impact of cognitive biases within the model.\nFurthermore, some methods employ co-training using pseudo-labels derived from\ndifferent inputs, yet generating high-confidence pseudo-labels from perturbed\ninputs during training remains a significant challenge. In this paper, we\npropose an Uncertainty-aware Cross-training framework for semi-supervised\nmedical image Segmentation (UC-Seg). Our UC-Seg framework incorporates two\ndistinct subnets to effectively explore and leverage the correlation between\nthem, thereby mitigating cognitive biases within the model. Specifically, we\npresent a Cross-subnet Consistency Preservation (CCP) strategy to enhance\nfeature representation capability and ensure feature consistency across the two\nsubnets. This strategy enables each subnet to correct its own biases and learn\nshared semantics from both labeled and unlabeled data. Additionally, we propose\nan Uncertainty-aware Pseudo-label Generation (UPG) component that leverages\nsegmentation results and corresponding uncertainty maps from both subnets to\ngenerate high-confidence pseudo-labels. We extensively evaluate the proposed\nUC-Seg on various medical image segmentation tasks involving different modality\nimages, such as MRI, CT, ultrasound, colonoscopy, and so on. The results\ndemonstrate that our method achieves superior segmentation accuracy and\ngeneralization performance compared to other state-of-the-art semi-supervised\nmethods. Our code will be released at https://github.com/taozh2017/UCSeg.",
      "url": "http://arxiv.org/abs/2508.09014v1",
      "published_time_eastern_timestamp": 1755012490.0
    },
    {
      "title": "LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA",
      "summary": "This paper describes our participation in SemEval 2025 Task 8, focused on\nTabular Question Answering. We developed a zero-shot pipeline that leverages an\nLarge Language Model to generate functional code capable of extracting the\nrelevant information from tabular data based on an input question. Our approach\nconsists of a modular pipeline where the main code generator module is\nsupported by additional components that identify the most relevant columns and\nanalyze their data types to improve extraction accuracy. In the event that the\ngenerated code fails, an iterative refinement process is triggered,\nincorporating the error feedback into a new generation prompt to enhance\nrobustness. Our results show that zero-shot code generation is a valid approach\nfor Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of\ntask-specific fine-tuning.",
      "url": "http://arxiv.org/abs/2508.09012v1",
      "published_time_eastern_timestamp": 1755012331.0
    },
    {
      "title": "Retrospective Sparse Attention for Efficient Long-Context Generation",
      "summary": "Large Language Models (LLMs) are increasingly deployed in long-context tasks\nsuch as reasoning, code generation, and multi-turn dialogue. However, inference\nover extended contexts is bottlenecked by the Key-Value (KV) cache, whose\nmemory footprint grows linearly with sequence length and dominates latency at\neach decoding step. While recent KV cache compression methods identify and load\nimportant tokens, they focus predominantly on input contexts and fail to\naddress the cumulative attention errors that arise during long decoding. In\nthis paper, we introduce RetroAttention, a novel KV cache update technique that\nretrospectively revises past attention outputs using newly arrived KV entries\nfrom subsequent decoding steps. By maintaining a lightweight output cache,\nRetroAttention enables past queries to efficiently access more relevant\ncontext, while incurring minimal latency overhead. This breaks the\nfixed-attention-output paradigm and allows continual correction of prior\napproximations. Extensive experiments on long-generation benchmarks show that\nRetroAttention consistently outperforms state-of-the-art (SOTA) KV compression\nmethods, increasing effective KV exposure by up to 1.6$\\times$ and accuracy by\nup to 21.9\\%.",
      "url": "http://arxiv.org/abs/2508.09001v1",
      "published_time_eastern_timestamp": 1755011507.0
    },
    {
      "title": "UniConvNet: Expanding Effective Receptive Field while Maintaining\n  Asymptotically Gaussian Distribution for ConvNets of Any Scale",
      "summary": "Convolutional neural networks (ConvNets) with large effective receptive field\n(ERF), still in their early stages, have demonstrated promising effectiveness\nwhile constrained by high parameters and FLOPs costs and disrupted\nasymptotically Gaussian distribution (AGD) of ERF. This paper proposes an\nalternative paradigm: rather than merely employing extremely large ERF, it is\nmore effective and efficient to expand the ERF while maintaining AGD of ERF by\nproper combination of smaller kernels, such as $7\\times{7}$, $9\\times{9}$,\n$11\\times{11}$. This paper introduces a Three-layer Receptive Field Aggregator\nand designs a Layer Operator as the fundamental operator from the perspective\nof receptive field. The ERF can be expanded to the level of existing\nlarge-kernel ConvNets through the stack of proposed modules while maintaining\nAGD of ERF. Using these designs, we propose a universal model for ConvNet of\nany scale, termed UniConvNet. Extensive experiments on ImageNet-1K, COCO2017,\nand ADE20K demonstrate that UniConvNet outperforms state-of-the-art CNNs and\nViTs across various vision recognition tasks for both lightweight and\nlarge-scale models with comparable throughput. Surprisingly, UniConvNet-T\nachieves $84.2\\%$ ImageNet top-1 accuracy with $30M$ parameters and $5.1G$\nFLOPs. UniConvNet-XL also shows competitive scalability to big data and large\nmodels, acquiring $88.4\\%$ top-1 accuracy on ImageNet. Code and models are\npublicly available at https://github.com/ai-paperwithcode/UniConvNet.",
      "url": "http://arxiv.org/abs/2508.09000v1",
      "published_time_eastern_timestamp": 1755011478.0
    },
    {
      "title": "Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making\n  under Epistemic Uncertainty",
      "summary": "Prospect Theory (PT) models human decision-making under uncertainty, while\nepistemic markers (e.g., maybe) serve to express uncertainty in language.\nHowever, it remains largely unexplored whether Prospect Theory applies to\ncontemporary Large Language Models and whether epistemic markers, which express\nhuman uncertainty, affect their decision-making behaviour. To address these\nresearch gaps, we design a three-stage experiment based on economic\nquestionnaires. We propose a more general and precise evaluation framework to\nmodel LLMs' decision-making behaviour under PT, introducing uncertainty through\nthe empirical probability values associated with commonly used epistemic\nmarkers in comparable contexts. We then incorporate epistemic markers into the\nevaluation framework based on their corresponding probability values to examine\ntheir influence on LLM decision-making behaviours. Our findings suggest that\nmodelling LLMs' decision-making with PT is not consistently reliable,\nparticularly when uncertainty is expressed in diverse linguistic forms. Our\ncode is released in https://github.com/HKUST-KnowComp/MarPT.",
      "url": "http://arxiv.org/abs/2508.08992v1",
      "published_time_eastern_timestamp": 1755010936.0
    },
    {
      "title": "Text-conditioned State Space Model For Domain-generalized Change\n  Detection Visual Question Answering",
      "summary": "The Earth's surface is constantly changing, and detecting these changes\nprovides valuable insights that benefit various aspects of human society. While\ntraditional change detection methods have been employed to detect changes from\nbi-temporal images, these approaches typically require expert knowledge for\naccurate interpretation. To enable broader and more flexible access to change\ninformation by non-expert users, the task of Change Detection Visual Question\nAnswering (CDVQA) has been introduced. However, existing CDVQA methods have\nbeen developed under the assumption that training and testing datasets share\nsimilar distributions. This assumption does not hold in real-world\napplications, where domain shifts often occur. In this paper, the CDVQA task is\nrevisited with a focus on addressing domain shift. To this end, a new\nmulti-modal and multi-domain dataset, BrightVQA, is introduced to facilitate\ndomain generalization research in CDVQA. Furthermore, a novel state space\nmodel, termed Text-Conditioned State Space Model (TCSSM), is proposed. The\nTCSSM framework is designed to leverage both bi-temporal imagery and\ngeo-disaster-related textual information in an unified manner to extract\ndomain-invariant features across domains. Input-dependent parameters existing\nin TCSSM are dynamically predicted by using both bi-temporal images and\ngeo-disaster-related description, thereby facilitating the alignment between\nbi-temporal visual data and the associated textual descriptions. Extensive\nexperiments are conducted to evaluate the proposed method against\nstate-of-the-art models, and superior performance is consistently demonstrated.\nThe code and dataset will be made publicly available upon acceptance at\nhttps://github.com/Elman295/TCSSM.",
      "url": "http://arxiv.org/abs/2508.08974v1",
      "published_time_eastern_timestamp": 1755009473.0
    },
    {
      "title": "Train Long, Think Short: Curriculum Learning for Efficient Reasoning",
      "summary": "Recent work on enhancing the reasoning abilities of large language models\n(LLMs) has introduced explicit length control as a means of constraining\ncomputational cost while preserving accuracy. However, existing approaches rely\non fixed-length training budgets, which do not take advantage of the natural\nprogression from exploration to compression during learning. In this work, we\npropose a curriculum learning strategy for length-controlled reasoning using\nGroup Relative Policy Optimization (GRPO). Our method starts with generous\ntoken budgets and gradually tightens them over training, encouraging models to\nfirst discover effective solution strategies and then distill them into more\nconcise reasoning traces. We augment GRPO with a reward function that balances\nthree signals: task correctness (via verifier feedback), length efficiency, and\nformatting adherence (via structural tags). Experiments on GSM8K, MATH500,\nSVAMP, College Math, and GSM+ demonstrate that curriculum-based training\nconsistently outperforms fixed-budget baselines at the same final budget,\nachieving higher accuracy and significantly improved token efficiency. We\nfurther ablate the impact of reward weighting and decay schedule design,\nshowing that progressive constraint serves as a powerful inductive bias for\ntraining efficient reasoning models. Our code and checkpoints are released at:\nhttps://github.com/hammoudhasan/curriculum_grpo.",
      "url": "http://arxiv.org/abs/2508.08940v1",
      "published_time_eastern_timestamp": 1755006483.0
    }
  ]
}
{
  "last_updated": "2025-11-04T13:17:54.189017-05:00",
  "papers": [
    {
      "title": "Continuous Autoregressive Language Models",
      "summary": "The efficiency of large language models (LLMs) is fundamentally limited by\ntheir sequential, token-by-token generation process. We argue that overcoming\nthis bottleneck requires a new design axis for LLM scaling: increasing the\nsemantic bandwidth of each generative step. To this end, we introduce\nContinuous Autoregressive Language Models (CALM), a paradigm shift from\ndiscrete next-token prediction to continuous next-vector prediction. CALM uses\na high-fidelity autoencoder to compress a chunk of K tokens into a single\ncontinuous vector, from which the original tokens can be reconstructed with\nover 99.9\\% accuracy. This allows us to model language as a sequence of\ncontinuous vectors instead of discrete tokens, which reduces the number of\ngenerative steps by a factor of K. The paradigm shift necessitates a new\nmodeling toolkit; therefore, we develop a comprehensive likelihood-free\nframework that enables robust training, evaluation, and controllable sampling\nin the continuous domain. Experiments show that CALM significantly improves the\nperformance-compute trade-off, achieving the performance of strong discrete\nbaselines at a significantly lower computational cost. More importantly, these\nfindings establish next-vector prediction as a powerful and scalable pathway\ntowards ultra-efficient language models. Code:\nhttps://github.com/shaochenze/calm. Project:\nhttps://shaochenze.github.io/blog/2025/CALM.",
      "url": "http://arxiv.org/abs/2510.27688v1",
      "published_time_eastern_timestamp": 1761933491.0
    },
    {
      "title": "Phased DMD: Few-step Distribution Matching Distillation via Score\n  Matching within Subintervals",
      "summary": "Distribution Matching Distillation (DMD) distills score-based generative\nmodels into efficient one-step generators, without requiring a one-to-one\ncorrespondence with the sampling trajectories of their teachers. However,\nlimited model capacity causes one-step distilled models underperform on complex\ngenerative tasks, e.g., synthesizing intricate object motions in text-to-video\ngeneration. Directly extending DMD to multi-step distillation increases memory\nusage and computational depth, leading to instability and reduced efficiency.\nWhile prior works propose stochastic gradient truncation as a potential\nsolution, we observe that it substantially reduces the generation diversity of\nmulti-step distilled models, bringing it down to the level of their one-step\ncounterparts. To address these limitations, we propose Phased DMD, a multi-step\ndistillation framework that bridges the idea of phase-wise distillation with\nMixture-of-Experts (MoE), reducing learning difficulty while enhancing model\ncapacity. Phased DMD is built upon two key ideas: progressive distribution\nmatching and score matching within subintervals. First, our model divides the\nSNR range into subintervals, progressively refining the model to higher SNR\nlevels, to better capture complex distributions. Next, to ensure the training\nobjective within each subinterval is accurate, we have conducted rigorous\nmathematical derivations. We validate Phased DMD by distilling state-of-the-art\nimage and video generation models, including Qwen-Image (20B parameters) and\nWan2.2 (28B parameters). Experimental results demonstrate that Phased DMD\npreserves output diversity better than DMD while retaining key generative\ncapabilities. We will release our code and models.",
      "url": "http://arxiv.org/abs/2510.27684v1",
      "published_time_eastern_timestamp": 1761933310.0
    },
    {
      "title": "Social learning moderates the tradeoffs between efficiency, stability,\n  and equity in group foraging",
      "summary": "Social learning shapes collective search by influencing how individuals use\npeer information. Empirical and computational studies show that optimal\ninformation sharing that is neither too localized nor too diffuse, can enhance\nresource detection and coordination. Building on these insights, we develop a\nrandomized search model that integrates social learning with area-restricted\nsearch (ARS) to investigate how communication distance affects collective\nforaging. The model includes three behavioral modes: exploration, exploitation,\nand targeted walk, which are governed by a single parameter, $\\rho$, that\nbalances exploration and exploitation at the group level. We quantify how\n$\\rho$ influences group efficiency ($\\eta$), temporal variability/burstiness\n($B$), and agent variability/equity in resource distribution ($\\sigma$),\nrevealing a clear trade-off among these outcomes. When $\\rho \\to 0$, agents\nexplore independently, maximizing collective exploration. As $\\rho$ increases,\nindividuals preferentially exploit patches discovered by others: $\\eta$ first\nrises and then declines, while $B$ shows the opposite trend. Group efficiency\nis optimized at interior $\\rho$ values that balance exploration and\nexploitation. At the largest $\\rho$, equality among agents is highest, but\nefficiency declines and burstiness is maximized too. Finally, by introducing\nnegative rewards, we examine how social learning mitigates risk.",
      "url": "http://arxiv.org/abs/2510.27683v1",
      "published_time_eastern_timestamp": 1761933180.0
    },
    {
      "title": "On Selecting Few-Shot Examples for LLM-based Code Vulnerability\n  Detection",
      "summary": "Large language models (LLMs) have demonstrated impressive capabilities for\nmany coding tasks, including summarization, translation, completion, and code\ngeneration. However, detecting code vulnerabilities remains a challenging task\nfor LLMs. An effective way to improve LLM performance is in-context learning\n(ICL) - providing few-shot examples similar to the query, along with correct\nanswers, can improve an LLM's ability to generate correct solutions. However,\nchoosing the few-shot examples appropriately is crucial to improving model\nperformance. In this paper, we explore two criteria for choosing few-shot\nexamples for ICL used in the code vulnerability detection task. The first\ncriterion considers if the LLM (consistently) makes a mistake or not on a\nsample with the intuition that LLM performance on a sample is informative about\nits usefulness as a few-shot example. The other criterion considers similarity\nof the examples with the program under query and chooses few-shot examples\nbased on the $k$-nearest neighbors to the given sample. We perform evaluations\nto determine the benefits of these criteria individually as well as under\nvarious combinations, using open-source models on multiple datasets.",
      "url": "http://arxiv.org/abs/2510.27675v1",
      "published_time_eastern_timestamp": 1761932518.0
    },
    {
      "title": "Teaching competencies in physics for engineering education: A\n  qualitative analysis from teaching practice",
      "summary": "Physics teaching in engineering programmes poses discipline-specific demands\nthat intertwine conceptual modelling, experimental inquiry, and computational\nanalysis. This study examines nine teaching competences for physics instruction\nderived from international and regional frameworks and interpreted within\nengineering contexts. Nineteen university instructors from the Technological\nInstitute of Toluca completed an open-ended questionnaire; responses were\nanalysed using a grounded theory approach (open and axial coding) complemented\nby descriptive frequencies. Results indicate stronger development in technical\nmastery, methodological/digital integration, technology-mediated communication,\nand innovation (C1, C2, C6, C9), while information literacy for digital content\ncreation/adaptation and digital ethics/safety (C7, C8) remain underdeveloped. A\nrecurrent understanding-application gap was identified, revealing uneven\ntransfer from conceptual awareness to enacted classroom practice. We conclude\nthat advancing physics education for engineers requires institutionally\nsupported, discipline-specific professional development that aligns modelling,\nlaboratory work, and computation with ethical and reproducible digital\npractices; such alignment can move instructors from adoption/adaptation toward\nsustained appropriation and innovation in multimodal settings.",
      "url": "http://arxiv.org/abs/2510.27674v1",
      "published_time_eastern_timestamp": 1761932409.0
    },
    {
      "title": "Gaussian Combined Distance: A Generic Metric for Object Detection",
      "summary": "In object detection, a well-defined similarity metric can significantly\nenhance model performance. Currently, the IoU-based similarity metric is the\nmost commonly preferred choice for detectors. However, detectors using IoU as a\nsimilarity metric often perform poorly when detecting small objects because of\ntheir sensitivity to minor positional deviations. To address this issue, recent\nstudies have proposed the Wasserstein Distance as an alternative to IoU for\nmeasuring the similarity of Gaussian-distributed bounding boxes. However, we\nhave observed that the Wasserstein Distance lacks scale invariance, which\nnegatively impacts the model's generalization capability. Additionally, when\nused as a loss function, its independent optimization of the center attributes\nleads to slow model convergence and unsatisfactory detection precision. To\naddress these challenges, we introduce the Gaussian Combined Distance (GCD).\nThrough analytical examination of GCD and its gradient, we demonstrate that GCD\nnot only possesses scale invariance but also facilitates joint optimization,\nwhich enhances model localization performance. Extensive experiments on the\nAI-TOD-v2 dataset for tiny object detection show that GCD, as a bounding box\nregression loss function and label assignment metric, achieves state-of-the-art\nperformance across various detectors. We further validated the generalizability\nof GCD on the MS-COCO-2017 and Visdrone-2019 datasets, where it outperforms the\nWasserstein Distance across diverse scales of datasets. Code is available at\nhttps://github.com/MArKkwanGuan/mmdet-GCD.",
      "url": "http://arxiv.org/abs/2510.27649v1",
      "published_time_eastern_timestamp": 1761931471.0
    },
    {
      "title": "Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout\n  for Long-Horizon Task Training",
      "summary": "Large Language Model (LLM) agents have recently shown strong potential in\ndomains such as automated coding, deep research, and graphical user interface\nmanipulation. However, training them to succeed on long-horizon,\ndomain-specialized tasks remains challenging. Current methods primarily fall\ninto two categories. The first relies on dense human annotations through\nbehavior cloning, which is prohibitively expensive for long-horizon tasks that\ncan take days or months. The second depends on outcome-driven sampling, which\noften collapses due to the rarity of valid positive trajectories on\ndomain-specialized tasks. We introduce Apollo, a sampling framework that\nintegrates asynchronous human guidance with action-level data filtering.\nInstead of requiring annotators to shadow every step, Apollo allows them to\nintervene only when the agent drifts from a promising trajectory, by providing\nprior knowledge, strategic advice, etc. This lightweight design makes it\npossible to sustain interactions for over 30 hours and produces valuable\ntrajectories at a lower cost. Apollo then applies supervision control to filter\nout sub-optimal actions and prevent error propagation. Together, these\ncomponents enable reliable and effective data collection in long-horizon\nenvironments. To demonstrate the effectiveness of Apollo, we evaluate it using\nInnovatorBench. Our experiments show that when applied to train the GLM-4.5\nmodel on InnovatorBench, Apollo achieves more than a 50% improvement over the\nuntrained baseline and a 28% improvement over a variant trained without human\ninteraction. These results highlight the critical role of human-in-the-loop\nsampling and the robustness of Apollo's design in handling long-horizon,\ndomain-specialized tasks.",
      "url": "http://arxiv.org/abs/2510.27630v2",
      "published_time_eastern_timestamp": 1761930022.0
    },
    {
      "title": "DiffstarPop: A generative physical model of galaxy star formation\n  history",
      "summary": "We present DiffstarPop, a differentiable forward model of cosmological\npopulations of galaxy star formation histories (SFH). In the model, individual\ngalaxy SFH is parametrized by Diffstar, which has parameters $\\theta_{\\rm SFH}$\nthat have a direct interpretation in terms of galaxy formation physics, such as\nstar formation efficiency and quenching. DiffstarPop is a model for the\nstatistical connection between $\\theta_{\\rm SFH}$ and the mass assembly history\n(MAH) of dark matter halos. We have formulated DiffstarPop to have the minimal\nflexibility needed to accurately reproduce the statistical distributions of\ngalaxy SFH predicted by a diverse range of simulations, including the\nIllustrisTNG hydrodynamical simulation, the Galacticus semi-analytic model, and\nthe UniverseMachine semi-empirical model. Our publicly available code written\nin JAX includes Monte Carlo generators that supply statistical samples of\ngalaxy assembly histories that mimic the populations seen in each simulation,\nand can generate SFHs for $10^6$ galaxies in 1.1 CPU-seconds, or 0.03\nGPU-seconds. We conclude the paper with a discussion of applications of\nDiffstarPop, which we are using to generate catalogs of synthetic galaxies\npopulating the merger trees in cosmological N-body simulations.",
      "url": "http://arxiv.org/abs/2510.27604v1",
      "published_time_eastern_timestamp": 1761928139.0
    },
    {
      "title": "InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM\n  Research",
      "summary": "AI agents could accelerate scientific discovery by automating hypothesis\nformation, experiment design, coding, execution, and analysis, yet existing\nbenchmarks probe narrow skills in simplified settings. To address this gap, we\nintroduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end\nassessment of agents performing Large Language Model (LLM) research. It\ncomprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss\nDesign, Reward Design, and Scaffold Construction, which require runnable\nartifacts and assessment of correctness, performance, output quality, and\nuncertainty. To support agent operation, we develop ResearchGym, a research\nenvironment offering rich action spaces, distributed and long-horizon\nexecution, asynchronous monitoring, and snapshot saving. We also implement a\nlightweight ReAct agent that couples explicit reasoning with executable\nplanning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2.\nOur experiments demonstrate that while frontier models show promise in\ncode-driven research tasks, they struggle with fragile algorithm-related tasks\nand long-horizon decision making, such as impatience, poor resource management,\nand overreliance on template-based reasoning. Furthermore, agents require over\n11 hours to achieve their best performance on InnovatorBench, underscoring the\nbenchmark's difficulty and showing the potential of InnovatorBench to be the\nnext generation of code-based research benchmark.",
      "url": "http://arxiv.org/abs/2510.27598v2",
      "published_time_eastern_timestamp": 1761927743.0
    },
    {
      "title": "Learned Static Function Data Structures",
      "summary": "We consider the task of constructing a data structure for associating a\nstatic set of keys with values, while allowing arbitrary output values for\nqueries involving keys outside the set. Compared to hash tables, these\nso-called static function data structures do not need to store the key set and\nthus use significantly less memory. Several techniques are known, with\ncompressed static functions approaching the zero-order empirical entropy of the\nvalue sequence. In this paper, we introduce learned static functions, which use\nmachine learning to capture correlations between keys and values. For each key,\na model predicts a probability distribution over the values, from which we\nderive a key-specific prefix code to compactly encode the true value. The\nresulting codeword is stored in a classic static function data structure. This\ndesign allows learned static functions to break the zero-order entropy barrier\nwhile still supporting point queries. Our experiments show substantial space\nsavings: up to one order of magnitude on real data, and up to three orders of\nmagnitude on synthetic data.",
      "url": "http://arxiv.org/abs/2510.27588v1",
      "published_time_eastern_timestamp": 1761926993.0
    },
    {
      "title": "Image Hashing via Cross-View Code Alignment in the Age of Foundation\n  Models",
      "summary": "Efficient large-scale retrieval requires representations that are both\ncompact and discriminative. Foundation models provide powerful visual and\nmultimodal embeddings, but nearest neighbor search in these high-dimensional\nspaces is computationally expensive. Hashing offers an efficient alternative by\nenabling fast Hamming distance search with binary codes, yet existing\napproaches often rely on complex pipelines, multi-term objectives, designs\nspecialized for a single learning paradigm, and long training times. We\nintroduce CroVCA (Cross-View Code Alignment), a simple and unified principle\nfor learning binary codes that remain consistent across semantically aligned\nviews. A single binary cross-entropy loss enforces alignment, while coding-rate\nmaximization serves as an anti-collapse regularizer to promote balanced and\ndiverse codes. To implement this, we design HashCoder, a lightweight MLP\nhashing network with a final batch normalization layer to enforce balanced\ncodes. HashCoder can be used as a probing head on frozen embeddings or to adapt\nencoders efficiently via LoRA fine-tuning. Across benchmarks, CroVCA achieves\nstate-of-the-art results in just 5 training epochs. At 16 bits, it particularly\nwell-for instance, unsupervised hashing on COCO completes in under 2 minutes\nand supervised hashing on ImageNet100 in about 3 minutes on a single GPU. These\nresults highlight CroVCA's efficiency, adaptability, and broad applicability.",
      "url": "http://arxiv.org/abs/2510.27584v2",
      "published_time_eastern_timestamp": 1761926926.0
    },
    {
      "title": "SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic\n  Mathematical Reasoning",
      "summary": "Solving mathematical reasoning problems requires not only accurate access to\nrelevant knowledge but also careful, multi-step thinking. However, current\nretrieval-augmented models often rely on a single perspective, follow\ninflexible search strategies, and struggle to effectively combine information\nfrom multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge\nIntegration for AGentic Mathematical reAsoning), a unified framework that\norchestrates specialized agents to independently reason, perform targeted\nsearches, and synthesize findings through a moderator mechanism. Each agent\ngenerates hypothetical passages to optimize retrieval for its analytic\nperspective, ensuring knowledge integration is both context-sensitive and\ncomputation-efficient. When evaluated on challenging benchmarks such as\nMATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms\nboth open- and closed-source systems, achieving an absolute performance\nimprovement of 7.4%. Our results demonstrate that multi-agent, on-demand\nknowledge integration significantly enhances both reasoning accuracy and\nefficiency, offering a scalable approach for complex, knowledge-intensive\nproblem-solving. We will release the code upon publication.",
      "url": "http://arxiv.org/abs/2510.27568v1",
      "published_time_eastern_timestamp": 1761925860.0
    },
    {
      "title": "CodeAlignBench: Assessing Code Generation Models on Developer-Preferred\n  Code Adjustments",
      "summary": "As large language models become increasingly capable of generating code,\nevaluating their performance remains a complex and evolving challenge. Existing\nbenchmarks primarily focus on functional correctness, overlooking the diversity\nof real-world coding tasks and developer expectations. To this end, we\nintroduce a multi-language benchmark that evaluates LLM instruction-following\ncapabilities and is extensible to operate on any set of standalone coding\nproblems. Our benchmark evaluates instruction following in two key settings:\nadherence to pre-defined constraints specified with the initial problem, and\nthe ability to perform refinements based on follow-up instructions. For this\npaper's analysis, we empirically evaluated our benchmarking pipeline with\nprogramming tasks from LiveBench, that are also automatically translated from\nPython into Java and JavaScript. Our automated benchmark reveals that models\nexhibit differing levels of performance across multiple dimensions of\ninstruction-following. Our benchmarking pipeline provides a more comprehensive\nevaluation of code generation models, highlighting their strengths and\nlimitations across languages and generation goals.",
      "url": "http://arxiv.org/abs/2510.27565v1",
      "published_time_eastern_timestamp": 1761925627.0
    },
    {
      "title": "Revealing cosmological fluctuations in 21cm intensity maps with\n  MeerKLASS: from maps to power spectra",
      "summary": "Mapping the integrated 21cm emission line from dark matter-tracing neutral\nhydrogen gas is the primary science goal for MeerKLASS (MeerKAT's Large Area\nSynoptic Survey). Prior to the arrival of MeerKAT, this intensity mapping\ntechnique had only been tested on a couple of pre-existing single-dish radio\ntelescopes with a handful of observational hours with which to make early\npioneering detections. The 64-dish MeerKAT array, precursor to the Square\nKilometre Array Observatory (SKAO), can scan the sky in auto-correlation mode\nand perform intensity mapping across large sky areas, presenting the exciting\npotential for a wide-sky (${\\gtrsim}\\,10{,}000\\,{\\rm deg}^2$) spectroscopic\nsurvey across redshift $0.4\\,{<}\\,z\\,{<}\\,1.45$. Validating the\nauto-correlation (or single-dish) mode of observation for a multi-dish array\nand developing the analysis pipeline with which to make unbiased measurements\nhas presented major challenges to this endeavour. In this work, we overview the\nadvances in the field that have facilitated a robust analysis framework for\nsingle-dish intensity mapping, and review some results that showcase its\nsuccess using early MeerKLASS surveys. We demonstrate our control of foreground\ncleaning, signal loss and map regridding to deliver detections of cosmological\nclustering within the intensity maps through cross-correlation power spectrum\nmeasurements with overlapping galaxy surveys. Finally, we discuss the prospects\nfor future MeerKLASS observations and forecast its potential, making our code\npublicly available: https://github.com/meerklass/MeerFish.",
      "url": "http://arxiv.org/abs/2510.27549v1",
      "published_time_eastern_timestamp": 1761924370.0
    },
    {
      "title": "MapSAM2: Adapting SAM2 for Automatic Segmentation of Historical Map\n  Images and Time Series",
      "summary": "Historical maps are unique and valuable archives that document geographic\nfeatures across different time periods. However, automated analysis of\nhistorical map images remains a significant challenge due to their wide\nstylistic variability and the scarcity of annotated training data. Constructing\nlinked spatio-temporal datasets from historical map time series is even more\ntime-consuming and labor-intensive, as it requires synthesizing information\nfrom multiple maps. Such datasets are essential for applications such as dating\nbuildings, analyzing the development of road networks and settlements, studying\nenvironmental changes etc. We present MapSAM2, a unified framework for\nautomatically segmenting both historical map images and time series. Built on a\nvisual foundation model, MapSAM2 adapts to diverse segmentation tasks with\nfew-shot fine-tuning. Our key innovation is to treat both historical map images\nand time series as videos. For images, we process a set of tiles as a video,\nenabling the memory attention mechanism to incorporate contextual cues from\nsimilar tiles, leading to improved geometric accuracy, particularly for areal\nfeatures. For time series, we introduce the annotated Siegfried Building Time\nSeries Dataset and, to reduce annotation costs, propose generating pseudo time\nseries from single-year maps by simulating common temporal transformations.\nExperimental results show that MapSAM2 learns temporal associations effectively\nand can accurately segment and link buildings in time series under limited\nsupervision or using pseudo videos. We will release both our dataset and code\nto support future research.",
      "url": "http://arxiv.org/abs/2510.27547v1",
      "published_time_eastern_timestamp": 1761924340.0
    },
    {
      "title": "Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for\n  Interpretable Deconstruction of Reasoning System Performance",
      "summary": "Large Language Models (LLMs) are increasingly excelling and outpacing human\nperformance on many tasks. However, to improve LLM reasoning, researchers\neither rely on ad-hoc generated datasets or formal mathematical proof systems\nsuch as the Lean proof assistant. Whilst ad-hoc generated methods can capture\nthe decision chains of real-world reasoning processes, they may encode some\ninadvertent bias in the space of reasoning they cover; they also cannot be\nformally verified. On the other hand, systems like Lean can guarantee\nverifiability, but are not well-suited to capture the nature of agentic\ndecision chain-based tasks. This creates a gap both in performance for\nfunctions such as business agents or code assistants, and in the usefulness of\nLLM reasoning benchmarks, whereby these fall short in reasoning structure or\nreal-world alignment. We introduce TempoBench, the first formally grounded and\nverifiable diagnostic benchmark that parametrizes difficulty to systematically\nanalyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks\nto break down reasoning ability. First, temporal trace evaluation (TTE) tests\nthe ability of an LLM to understand and simulate the execution of a given\nmulti-step reasoning system. Subsequently, temporal causal evaluation (TCE)\ntests an LLM's ability to perform multi-step causal reasoning and to distill\ncause-and-effect relations from complex systems. We find that models score\n65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art\nLLMs clearly understand the TCE task but perform poorly as system complexity\nincreases. Our code is available at our\n\\href{https://github.com/nik-hz/tempobench}{GitHub repository}.",
      "url": "http://arxiv.org/abs/2510.27544v1",
      "published_time_eastern_timestamp": 1761923875.0
    },
    {
      "title": "Holographic equation of state matched with hadron gas equation as a tool\n  for the study of the quark-gluon plasma evolution",
      "summary": "In this paper, we discuss the matching of the holographic equation of state\nwith the equation of Hadron Resonance Gas for studying the nuclear matter\nproperties within the framework of relativistic heavy-ion collisions. Machine\nlearning methods are applied to the calibration of model's free parameters\nusing the lattice QCD results for the physical values of quark masses. One of\nthe most advanced procedures for matching is used with the function that\napproximate behavior of both models on particular limit adopted from NEOS\nequation. Final hadronic spectra are obtained within multi-staged numerical\napproach of the iEBE-MUSIC and SMASH-vHLLE packages. The code of relativistic\nhydrodynamics is modified by implementing a tabulated holographic equation of\nstate, enabling simulations of quark-gluon plasma evolution with dynamically\ngenerated initial conditions via the 3D Monte Carlo Glauber Model and SMASH.\nHybrid iSS+UrQMD and Hadron Sampler+SMASH approaches are utilized at the\nfreeze-out stage.",
      "url": "http://arxiv.org/abs/2510.27541v1",
      "published_time_eastern_timestamp": 1761923805.0
    },
    {
      "title": "Mastering an Accurate and Generalizable Simulation-Based Method to\n  Obtain Bias-corrected Point Estimates and Sampling Variance for Any Effect\n  Sizes",
      "summary": "Meta-analyses require an effect-size estimate and its corresponding sampling\nvariance from primary studies. In some cases, estimators for the sampling\nvariance of a given effect size statistic may not exist, necessitating the\nderivation of a new formula for sampling variance. Traditionally, sampling\nvariance formulas are obtained via hand-derived Taylor expansions (the delta\nmethod), though this procedure can be challenging for non-statisticians.\nBuilding on the idea of single-fit parametric resampling, we introduce SAFE\nbootstrap: a Single-fit, Accurate, Fast, and Easy simulation recipe that\nreplaces potentially complex algebra with four intuitive steps: fit, draw,\ntransform, and summarise. In a unified framework, the SAFE bootstrap yields\nbias-corrected point estimates and standard errors for any effect size\nstatistic, regardless of whether the outcome is continuous or discrete. SAFE\nbootstrapping works by drawing once from a simple sampling model (normal,\nbinomial, etc.), converting each replicate into any effect size of interest and\nthen calculating the bias and sampling variance from simulated data. We\ndemonstrate how to implement the SAFE bootstrap for a simple example first, and\nthen for common effect sizes, such as the standardised mean difference and log\nodds ratio, as well as for less common effect sizes. With some additional\ncoding, SAFE can also handle zero values and small sample sizes. Our tutorial,\nwith R code supplements, should not only enhance understanding of sampling\nvariance for effect sizes, but also serve as an introduction to the power of\nsimulation-based methods for deriving any effect size with bias correction and\nits associated sampling variance.",
      "url": "http://arxiv.org/abs/2510.27519v1",
      "published_time_eastern_timestamp": 1761921985.0
    },
    {
      "title": "Learning Sparse Approximate Inverse Preconditioners for Conjugate\n  Gradient Solvers on GPUs",
      "summary": "The conjugate gradient solver (CG) is a prevalent method for solving\nsymmetric and positive definite linear systems Ax=b, where effective\npreconditioners are crucial for fast convergence. Traditional preconditioners\nrely on prescribed algorithms to offer rigorous theoretical guarantees, while\nlimiting their ability to exploit optimization from data. Existing\nlearning-based methods often utilize Graph Neural Networks (GNNs) to improve\nthe performance and speed up the construction. However, their reliance on\nincomplete factorization leads to significant challenges: the associated\ntriangular solve hinders GPU parallelization in practice, and introduces\nlong-range dependencies which are difficult for GNNs to model. To address these\nissues, we propose a learning-based method to generate GPU-friendly\npreconditioners, particularly using GNNs to construct Sparse Approximate\nInverse (SPAI) preconditioners, which avoids triangular solves and requires\nonly two matrix-vector products at each CG step. The locality of matrix-vector\nproduct is compatible with the local propagation mechanism of GNNs. The\nflexibility of GNNs also allows our approach to be applied in a wide range of\nscenarios. Furthermore, we introduce a statistics-based scale-invariant loss\nfunction. Its design matches CG's property that the convergence rate depends on\nthe condition number, rather than the absolute scale of A, leading to improved\nperformance of the learned preconditioner. Evaluations on three PDE-derived\ndatasets and one synthetic dataset demonstrate that our method outperforms\nstandard preconditioners (Diagonal, IC, and traditional SPAI) and previous\nlearning-based preconditioners on GPUs. We reduce solution time on GPUs by\n40%-53% (68%-113% faster), along with better condition numbers and superior\ngeneralization performance. Source code available at\nhttps://github.com/Adversarr/LearningSparsePreconditioner4GPU",
      "url": "http://arxiv.org/abs/2510.27517v1",
      "published_time_eastern_timestamp": 1761921768.0
    },
    {
      "title": "Fast and accurate calculation of the bootstrap current and radial\n  neoclassical transport in low collisionality stellarator plasmas",
      "summary": "In this PhD thesis, a method for solving fast and accurately the\nmonoenergetic drift-kinetic equation at low collisionality is presented. The\nalgorithm is based on the analytical properties of the drift-kinetic equation\nwhen its dependence on the pitch-angle cosine is represented employing Legendre\npolynomials as basis functions. The Legendre representation of the\nmonoenergetic drift-kinetic equation possesses a tridiagonal structure, which\nis exploited by the algorithm presented. The monoenergetic drift-kinetic\nequation can be solved fast and accurately at low collisionality by employing\nthe standard block tridiagonal algorithm for block tridiagonal matrices. The\nimplementation of the aforementioned algorithm leads to the main result of this\nthesis: the new neoclassical code MONKES (MONoenergetic Kinetic Equation\nSolver), conceived to satisfy the necessity of fast and accurate calculations\nof the bootstrap current for stellarators and in particular for stellarator\noptimization. MONKES is a new neoclassical code for the evaluation of\nmonoenergetic transport coefficients in stellarators. By means of a convergence\nstudy and benchmarks with other codes, it is shown that MONKES is accurate and\nefficient. The combination of spectral discretization in spatial and velocity\ncoordinates with block sparsity allows MONKES to compute monoenergetic\ncoefficients at low collisionality, in a single core, in approximately one\nminute. MONKES is sufficiently fast to be integrated into stellarator\noptimization codes for direct optimization of the bootstrap current (and radial\nneoclassical transport) and to be included in predictive transport suites.",
      "url": "http://arxiv.org/abs/2510.27513v1",
      "published_time_eastern_timestamp": 1761921532.0
    }
  ]
}
{
  "last_updated": "2025-09-18T17:10:25.274580-04:00",
  "papers": [
    {
      "title": "Apertus: Democratizing Open and Compliant LLMs for Global Language\n  Environments",
      "summary": "We present Apertus, a fully open suite of large language models (LLMs)\ndesigned to address two systemic shortcomings in today's open model ecosystem:\ndata compliance and multilingual representation. Unlike many prior models that\nrelease weights without reproducible data pipelines or regard for content-owner\nrights, Apertus models are pretrained exclusively on openly available data,\nretroactively respecting robots.txt exclusions and filtering for\nnon-permissive, toxic, and personally identifiable content. To mitigate risks\nof memorization, we adopt the Goldfish objective during pretraining, strongly\nsuppressing verbatim recall of data while retaining downstream task\nperformance. The Apertus models also expand multilingual coverage, training on\n15T tokens from over 1800 languages, with ~40% of pretraining data allocated to\nnon-English content. Released at 8B and 70B scales, Apertus approaches\nstate-of-the-art results among fully open models on multilingual benchmarks,\nrivalling or surpassing open-weight counterparts. Beyond model weights, we\nrelease all scientific artifacts from our development cycle with a permissive\nlicense, including data preparation scripts, checkpoints, evaluation suites,\nand training code, enabling transparent audit and extension.",
      "url": "http://arxiv.org/abs/2509.14233v1",
      "published_time_eastern_timestamp": 1758131961.0
    },
    {
      "title": "NIRVANA: Structured pruning reimagined for large language models\n  compression",
      "summary": "Structured pruning of large language models (LLMs) offers substantial\nefficiency improvements by removing entire hidden units, yet current approaches\noften suffer from significant performance degradation, particularly in\nzero-shot settings, and necessitate costly recovery techniques such as\nsupervised fine-tuning (SFT) or adapter insertion. To address these critical\nshortcomings, we introduce NIRVANA, a novel pruning method explicitly designed\nto balance immediate zero-shot accuracy preservation with robust fine-tuning\ncapability. Leveraging a first-order saliency criterion derived from the Neural\nTangent Kernel under Adam optimization dynamics, NIRVANA provides a\ntheoretically grounded pruning strategy that respects essential model training\nbehaviors. To further address the unique challenges posed by structured\npruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across\nlayers and modules (attention vs. MLP), which adjusts pruning intensity between\nmodules in a globally balanced manner. Additionally, to mitigate the high\nsensitivity of pruning decisions to calibration data quality, we propose a\nsimple yet effective KL divergence-based calibration data selection strategy,\nensuring more reliable and task-agnostic pruning outcomes. Comprehensive\nexperiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA\noutperforms existing structured pruning methods under equivalent sparsity\nconstraints, providing a theoretically sound and practical approach to LLM\ncompression. The code is available at\nhttps://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.",
      "url": "http://arxiv.org/abs/2509.14230v1",
      "published_time_eastern_timestamp": 1758131940.0
    },
    {
      "title": "Goal-Oriented Joint Source-Channel Coding:\n  Distortion-Classification-Power Trade-off",
      "summary": "Joint source-channel coding is a compelling paradigm when low-latency and\nlow-complexity communication is required. This work proposes a theoretical\nframework that integrates classification and anomaly detection within the\nconventional signal reconstruction objective. Assuming a Gaussian scalar source\nand constraining the encoder to piecewise linear mappings, we derive tractable\ndesign rules and explicitly characterize the trade-offs between distortion,\nclassification error, and transmission power.",
      "url": "http://arxiv.org/abs/2509.14217v1",
      "published_time_eastern_timestamp": 1758131460.0
    },
    {
      "title": "Bridging Past and Future: Distribution-Aware Alignment for Time Series\n  Forecasting",
      "summary": "Representation learning techniques like contrastive learning have long been\nexplored in time series forecasting, mirroring their success in computer vision\nand natural language processing. Yet recent state-of-the-art (SOTA) forecasters\nseldom adopt these representation approaches because they have shown little\nperformance advantage. We challenge this view and demonstrate that explicit\nrepresentation alignment can supply critical information that bridges the\ndistributional gap between input histories and future targets. To this end, we\nintroduce TimeAlign, a lightweight, plug-and-play framework that learns\nauxiliary features via a simple reconstruction task and feeds them back to any\nbase forecaster. Extensive experiments across eight benchmarks verify its\nsuperior performance. Further studies indicate that the gains arises primarily\nfrom correcting frequency mismatches between historical inputs and future\noutputs. We also provide a theoretical justification for the effectiveness of\nTimeAlign in increasing the mutual information between learned representations\nand predicted targets. As it is architecture-agnostic and incurs negligible\noverhead, TimeAlign can serve as a general alignment module for modern deep\nlearning time-series forecasting systems. The code is available at\nhttps://github.com/TROUBADOUR000/TimeAlign.",
      "url": "http://arxiv.org/abs/2509.14181v1",
      "published_time_eastern_timestamp": 1758129159.0
    },
    {
      "title": "AssoCiAm: A Benchmark for Evaluating Association Thinking while\n  Circumventing Ambiguity",
      "summary": "Recent advancements in multimodal large language models (MLLMs) have garnered\nsignificant attention, offering a promising pathway toward artificial general\nintelligence (AGI). Among the essential capabilities required for AGI,\ncreativity has emerged as a critical trait for MLLMs, with association serving\nas its foundation. Association reflects a model' s ability to think creatively,\nmaking it vital to evaluate and understand. While several frameworks have been\nproposed to assess associative ability, they often overlook the inherent\nambiguity in association tasks, which arises from the divergent nature of\nassociations and undermines the reliability of evaluations. To address this\nissue, we decompose ambiguity into two types-internal ambiguity and external\nambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative\nability while circumventing the ambiguity through a hybrid computational\nmethod. We then conduct extensive experiments on MLLMs, revealing a strong\npositive correlation between cognition and association. Additionally, we\nobserve that the presence of ambiguity in the evaluation process causes MLLMs'\nbehavior to become more random-like. Finally, we validate the effectiveness of\nour method in ensuring more accurate and reliable evaluations. See Project Page\nfor the data and codes.",
      "url": "http://arxiv.org/abs/2509.14171v1",
      "published_time_eastern_timestamp": 1758128187.0
    },
    {
      "title": "CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset",
      "summary": "We present CS-FLEURS, a new dataset for developing and evaluating\ncode-switched speech recognition and translation systems beyond high-resourced\nlanguages. CS-FLEURS consists of 4 test sets which cover in total 113 unique\ncode-switched language pairs across 52 languages: 1) a 14 X-English language\npair set with real voices reading synthetically generated code-switched\nsentences, 2) a 16 X-English language pair set with generative text-to-speech\n3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the\ngenerative text-to-speech, and 4) a 45 X-English lower-resourced language pair\ntest set with concatenative text-to-speech. Besides the four test sets,\nCS-FLEURS also provides a training set with 128 hours of generative\ntext-to-speech data across 16 X-English language pairs. Our hope is that\nCS-FLEURS helps to broaden the scope of future code-switched speech research.\nDataset link: https://huggingface.co/datasets/byan/cs-fleurs.",
      "url": "http://arxiv.org/abs/2509.14161v1",
      "published_time_eastern_timestamp": 1758127522.0
    },
    {
      "title": "MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods,\n  Results, Discussion, and Outlook",
      "summary": "This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim\nto bring together different approaches in multimodal machine learning and LLMs\nvia a large benchmark. We hope it better allows researchers to follow the\nstate-of-the-art in this very dynamic area. Meanwhile, a growing number of\ntestbeds have boosted the evolution of general-purpose large language models.\nThus, this year's MARS2 focuses on real-world and specialized scenarios to\nbroaden the multimodal reasoning applications of MLLMs. Our organizing team\nreleased two tailored datasets Lens and AdsQA as test sets, which support\ngeneral reasoning in 12 daily scenarios and domain-specific reasoning in\nadvertisement videos, respectively. We evaluated 40+ baselines that include\nboth generalist MLLMs and task-specific models, and opened up three competition\ntracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question\nAnswering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative\nAdvertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and\nindustrial institutions have registered and 40+ valid submissions (out of\n1200+) have been included in our ranking lists. Our datasets, code sets (40+\nbaselines and 15+ participants' methods), and rankings are publicly available\non the MARS2 workshop website and our GitHub organization page\nhttps://github.com/mars2workshop/, where our updates and announcements of\nupcoming events will be continuously provided.",
      "url": "http://arxiv.org/abs/2509.14142v1",
      "published_time_eastern_timestamp": 1758126094.0
    },
    {
      "title": "CSMoE: An Efficient Remote Sensing Foundation Model with Soft\n  Mixture-of-Experts",
      "summary": "Self-supervised learning through masked autoencoders has attracted great\nattention for remote sensing (RS) foundation model (FM) development, enabling\nimproved representation learning across diverse sensors and downstream tasks.\nHowever, existing RS FMs often either suffer from substantial computational\ncomplexity during both training and inference or exhibit limited\nrepresentational capacity. These issues restrict their practical applicability\nin RS. To address this limitation, we propose an adaptation for enhancing the\nefficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism\ninto the FM. The integration of Soft MoEs into the FM allows modality-specific\nexpert specialization alongside shared cross-sensor representation learning. To\ndemonstrate the effectiveness of our adaptation, we apply it on the\nCross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor\nMixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic\ndescriptor-driven sampling strategy for the construction of a representative\nand diverse training set to train our CSMoE model. Extensive experiments on\nscene classification, semantic segmentation, and content-based image retrieval\ndemonstrate that our adaptation yields a reduction in computational\nrequirements while maintaining or improving representational performance.\nCompared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off\nbetween representational capacity, accuracy, and computational efficiency. On\naverage, CSMoE achieves more than twice the computational efficiency of\nexisting RS FMs, while maintaining competitive performance across all\nexperiments. These results show the effectiveness of the proposed adaptation\nfor creating computationally efficient RS FMs. The code for the model, the\ntraining set creation, and the model weights will be available at\nhttps://git.tu-berlin.de/rsim/csmoe.",
      "url": "http://arxiv.org/abs/2509.14104v1",
      "published_time_eastern_timestamp": 1758124038.0
    },
    {
      "title": "A Closeness Centrality-based Circuit Partitioner for Quantum Simulations",
      "summary": "Simulating quantum circuits (QC) on high-performance computing (HPC) systems\nhas become an essential method to benchmark algorithms and probe the potential\nof large-scale quantum computation despite the limitations of current quantum\nhardware. However, these simulations often require large amounts of resources,\nnecessitating the use of large clusters with thousands of compute nodes and\nlarge memory footprints. In this work, we introduce an end-to-end framework\nthat provides an efficient partitioning scheme for large-scale QCs alongside a\nflexible code generator to offer a portable solution that minimizes data\nmovement between compute nodes. By formulating the distribution of quantum\nstates and circuits as a graph problem, we apply closeness centrality to assess\ngate importance and design a fast, scalable partitioning method. The resulting\npartitions are compiled into highly optimized codes that run seamlessly on a\nwide range of supercomputers, providing critical insights into the performance\nand scalability of quantum algorithm simulations.",
      "url": "http://arxiv.org/abs/2509.14098v1",
      "published_time_eastern_timestamp": 1758123505.0
    },
    {
      "title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A\n  Self-Optimizing Framework",
      "summary": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by\nprompting intermediate steps, improving accuracy and robustness in arithmetic,\nlogic, and commonsense tasks. However, this benefit comes with high\ncomputational costs: longer outputs increase latency, memory usage, and\nKV-cache demands. These issues are especially critical in software engineering\ntasks where concise and deterministic outputs are required. To investigate\nthese trade-offs, we conduct an empirical study based on code generation\nbenchmarks. The results reveal that longer CoT does not always help. Excessive\nreasoning often causes truncation, accuracy drops, and latency up to five times\nhigher, with failed outputs consistently longer than successful ones. These\nfindings challenge the assumption that longer reasoning is inherently better\nand highlight the need for adaptive CoT control. Motivated by this, we propose\nSEER (Self-Enhancing Efficient Reasoning), an adaptive framework that\ncompresses CoT while preserving accuracy. SEER combines Best-of-N sampling with\ntask-aware adaptive filtering, dynamically adjusting thresholds based on\npre-inference outputs to reduce verbosity and computational overhead. We then\nevaluate SEER on three software engineering tasks and one math task. On\naverage, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,\nand eliminates most infinite loops. These results demonstrate SEER as a\npractical method to make CoT-enhanced LLMs more efficient and robust, even\nunder resource constraints.",
      "url": "http://arxiv.org/abs/2509.14093v1",
      "published_time_eastern_timestamp": 1758123224.0
    },
    {
      "title": "Interleaving Natural Language Prompting with Code Editing for Solving\n  Programming Tasks with Generative AI Models",
      "summary": "Nowadays, computing students often rely on both natural-language prompting\nand manual code editing to solve programming tasks. Yet we still lack a clear\nunderstanding of how these two modes are combined in practice, and how their\nusage varies with task complexity and student ability. In this paper, we\ninvestigate this through a large-scale study in an introductory programming\ncourse, collecting 13,305 interactions from 355 students during a three-day\nlaboratory activity. Our analysis shows that students primarily use prompting\nto generate initial solutions, and then often enter short edit-run loops to\nrefine their code following a failed execution. We find that manual editing\nbecomes more frequent as task complexity increases, but most edits remain\nconcise, with many affecting a single line of code. Higher-performing students\ntend to succeed using prompting alone, while lower-performing students rely\nmore on edits. Student reflections confirm that prompting is helpful for\nstructuring solutions, editing is effective for making targeted corrections,\nwhile both are useful for learning. These findings highlight the role of manual\nediting as a deliberate last-mile repair strategy, complementing prompting in\nAI-assisted programming workflows.",
      "url": "http://arxiv.org/abs/2509.14088v1",
      "published_time_eastern_timestamp": 1758123139.0
    },
    {
      "title": "Mixed finite element projection methods for the unsteady Brinkman\n  equations",
      "summary": "We present $H(\\text{div})$-conforming mixed finite element methods for the\nunsteady Brinkman equations for incompressible single-phase flow with fixed in\nspace porous solid inclusions. We employ a projection scheme with incremental\npressure correction, which requires at each time step the solution of a\npredictor and a projection problem. The predictor problem, which uses a\nstress-velocity mixed formulation, accounts for the viscous effects, while the\nprojection problem, which is based on a velocity-pressure mixed formulation,\naccounts for the incompressibility. The spatial discretization is based on the\nRaviart-Thomas or Brezzi-Douglas-Marini mixed finite element spaces on\nsimplicial grids. The velocity computed at the end of each time step is\npointwise divergence-free. Unconditional stability of the fully-discrete scheme\nand first order in time accuracy are established. Due the $H$(div)-conformity\nof the formulation, the methods are robust in both the Stokes and the Darcy\nregimes. In the specific code implementation, we discretize the computational\ndomain using generally unstructured triangular (in 2D) and tetrahedral (in 3D)\ngrids, and we use the Raviart--Thomas space $RT_1$, applying a second order\nmultipoint flux mixed finite element scheme with a quadrature rule that samples\nthe flux degrees of freedom. In the predictor problem this allows for a local\nelimination of the viscous stress and results in element-based symmetric and\npositive definite systems for each velocity component with $\\left(d+1\\right)$\ndegrees of freedom per simplex (where $d$ is the dimension of the problem). In\na similar way, we locally eliminate the corrected velocity in the projection\nproblem, and solve an element-based system for the pressure. A series of\nchallenging numerical experiments is presented to verify the convergence and\nperformance of the proposed scheme",
      "url": "http://arxiv.org/abs/2509.14059v1",
      "published_time_eastern_timestamp": 1758121482.0
    },
    {
      "title": "Wan-Animate: Unified Character Animation and Replacement with Holistic\n  Replication",
      "summary": "We introduce Wan-Animate, a unified framework for character animation and\nreplacement. Given a character image and a reference video, Wan-Animate can\nanimate the character by precisely replicating the expressions and movements of\nthe character in the video to generate high-fidelity character videos.\nAlternatively, it can integrate the animated character into the reference video\nto replace the original character, replicating the scene's lighting and color\ntone to achieve seamless environmental integration. Wan-Animate is built upon\nthe Wan model. To adapt it for character animation tasks, we employ a modified\ninput paradigm to differentiate between reference conditions and regions for\ngeneration. This design unifies multiple tasks into a common symbolic\nrepresentation. We use spatially-aligned skeleton signals to replicate body\nmotion and implicit facial features extracted from source images to reenact\nexpressions, enabling the generation of character videos with high\ncontrollability and expressiveness. Furthermore, to enhance environmental\nintegration during character replacement, we develop an auxiliary Relighting\nLoRA. This module preserves the character's appearance consistency while\napplying the appropriate environmental lighting and color tone. Experimental\nresults demonstrate that Wan-Animate achieves state-of-the-art performance. We\nare committed to open-sourcing the model weights and its source code.",
      "url": "http://arxiv.org/abs/2509.14055v1",
      "published_time_eastern_timestamp": 1758121257.0
    },
    {
      "title": "AnyAccomp: Generalizable Accompaniment Generation via Quantized Melodic\n  Bottleneck",
      "summary": "Singing Accompaniment Generation (SAG) is the process of generating\ninstrumental music for a given clean vocal input. However, existing SAG\ntechniques use source-separated vocals as input and overfit to separation\nartifacts. This creates a critical train-test mismatch, leading to failure on\nclean, real-world vocal inputs. We introduce AnyAccomp, a framework that\nresolves this by decoupling accompaniment generation from source-dependent\nartifacts. AnyAccomp first employs a quantized melodic bottleneck, using a\nchromagram and a VQ-VAE to extract a discrete and timbre-invariant\nrepresentation of the core melody. A subsequent flow-matching model then\ngenerates the accompaniment conditioned on these robust codes. Experiments show\nAnyAccomp achieves competitive performance on separated-vocal benchmarks while\nsignificantly outperforming baselines on generalization test sets of clean\nstudio vocals and, notably, solo instrumental tracks. This demonstrates a\nqualitative leap in generalization, enabling robust accompaniment for\ninstruments - a task where existing models completely fail - and paving the way\nfor more versatile music co-creation tools. Demo audio and code:\nhttps://anyaccomp.github.io",
      "url": "http://arxiv.org/abs/2509.14052v1",
      "published_time_eastern_timestamp": 1758120921.0
    },
    {
      "title": "A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval\n  Prediction For Instruction Caching",
      "summary": "Modern mobile CPU software pose challenges for conventional instruction cache\nreplacement policies due to their complex runtime behavior causing high reuse\ndistance between executions of the same instruction. Mobile code commonly\nsuffers from large amounts of stalls in the CPU frontend and thus starvation of\nthe rest of the CPU resources. Complexity of these applications and their code\nfootprint are projected to grow at a rate faster than available on-chip memory\ndue to power and area constraints, making conventional hardware-centric methods\nfor managing instruction caches to be inadequate. We present a novel\nsoftware-hardware co-design approach called TRRIP (Temperature-based\nRe-Reference Interval Prediction) that enables the compiler to analyze,\nclassify, and transform code based on \"temperature\" (hot/cold), and to provide\nthe hardware with a summary of code temperature information through a\nwell-defined OS interface based on using code page attributes. TRRIP's\nlightweight hardware extension employs code temperature attributes to optimize\nthe instruction cache replacement policy resulting in the eviction rate\nreduction of hot code. TRRIP is designed to be practical and adoptable in real\nmobile systems that have strict feature requirements on both the software and\nhardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%\nresulting in geomean speedup of 3.9%, on top of RRIP cache replacement running\nmobile code already optimized using PGO.",
      "url": "http://arxiv.org/abs/2509.14041v1",
      "published_time_eastern_timestamp": 1758120158.0
    },
    {
      "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System",
      "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.",
      "url": "http://arxiv.org/abs/2509.14030v1",
      "published_time_eastern_timestamp": 1758119478.0
    },
    {
      "title": "TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped\n  Modular Aerial Robot Systems",
      "summary": "Modular Aerial Robot Systems (MARS) consist of multiple drone modules that\nare physically bound together to form a single structure for flight. Exploiting\nstructural redundancy, MARS can be reconfigured into different formations to\nmitigate unit or rotor failures and maintain stable flight. Prior work on MARS\nself-reconfiguration has solely focused on maximizing controllability margins\nto tolerate a single rotor or unit fault for rectangular-shaped MARS. We\npropose TransforMARS, a general fault-tolerant reconfiguration framework that\ntransforms arbitrarily shaped MARS under multiple rotor and unit faults while\nensuring continuous in-air stability. Specifically, we develop algorithms to\nfirst identify and construct minimum controllable assemblies containing faulty\nunits. We then plan feasible disassembly-assembly sequences to transport MARS\nunits or subassemblies to form target configuration. Our approach enables more\nflexible and practical feasible reconfiguration. We validate TransforMARS in\nchallenging arbitrarily shaped MARS configurations, demonstrating substantial\nimprovements over prior works in both the capacity of handling diverse\nconfigurations and the number of faults tolerated. The videos and source code\nof this work are available at the anonymous repository:\nhttps://anonymous.4open.science/r/TransforMARS-1030/",
      "url": "http://arxiv.org/abs/2509.14025v1",
      "published_time_eastern_timestamp": 1758119303.0
    },
    {
      "title": "Entropy-patch choked-nozzle interaction: quasi-steady and inertial\n  modeling regimes mapped and limits of linearization established",
      "summary": "The effects of entropy-patch shape, size, and strength on the upstream\nacoustic response generated by entropy-patch choked-nozzle interactions are\ninvestigated. Numerical-simulation-based investigations, using a\ntwo-dimensional planar Euler code, reveal the existence of two distinct\nmodeling regimes: the quasi-steady (matching-condition) regime and the inertial\nregime, respectively. The ratio of the entropy-patch streamwise length scale to\nthe nozzle throat height was found to be an order parameter, which allows one\nto determine which of the two modeling regimes applies. Indeed, for entropy\npatches with a streamwise length scale smaller or equal to the nozzle throat\nheight, the inertial model provides a satisfactory prediction of the upstream\nacoustic response. For entropy patches with a streamwise length scale larger\nthan the nozzle throat height, the matching condition model has superior\npredictive accuracy. The entropy patch's shape was judged to have only a slight\nimpact on the applicable modeling regime. Additionally, the study examined\nentropy-patch strength using the ratio of area-specific perturbation energy to\narea-specific upstream energy as an order parameter, establishing that both\nabove-mentioned linear models are only valid for weak entropy patches. These\nfindings provide a framework for selecting appropriate models for entropy-patch\nchoked-nozzle interaction scenarios, furthering the fundamental understanding\nof indirect noise-driven combustion instability.",
      "url": "http://arxiv.org/abs/2509.14007v1",
      "published_time_eastern_timestamp": 1758118675.0
    },
    {
      "title": "CLMTracing: Black-box User-level Watermarking for Code Language Model\n  Tracing",
      "summary": "With the widespread adoption of open-source code language models (code LMs),\nintellectual property (IP) protection has become an increasingly critical\nconcern. While current watermarking techniques have the potential to identify\nthe code LM to protect its IP, they have limitations when facing the more\npractical and complex demand, i.e., offering the individual user-level tracing\nin the black-box setting. This work presents CLMTracing, a black-box code LM\nwatermarking framework employing the rule-based watermarks and\nutility-preserving injection method for user-level model tracing. CLMTracing\nfurther incorporates a parameter selection algorithm sensitive to the robust\nwatermark and adversarial training to enhance the robustness against watermark\nremoval attacks. Comprehensive evaluations demonstrate CLMTracing is effective\nacross multiple state-of-the-art (SOTA) code LMs, showing significant harmless\nimprovements compared to existing SOTA baselines and strong robustness against\nvarious removal attacks.",
      "url": "http://arxiv.org/abs/2509.13982v1",
      "published_time_eastern_timestamp": 1758117188.0
    },
    {
      "title": "Smaller Circuits for Bit Addition",
      "summary": "Bit addition arises virtually everywhere in digital circuits: arithmetic\noperations, increment/decrement operators, computing addresses and table\nindices, and so on. Since bit addition is such a basic task in Boolean circuit\nsynthesis, a lot of research has been done on constructing efficient circuits\nfor various special cases of it. A vast majority of these results are devoted\nto optimizing the circuit depth (also known as delay).\n  In this paper, we investigate the circuit size (also known as area) over the\nfull binary basis of bit addition. Though most of the known circuits are built\nfrom Half Adders and Full Adders, we show that, in many interesting scenarios,\nthese circuits have suboptimal size. Namely, we improve an upper bound $5n-3m$\nto $4.5n-2m$, where $n$ is the number of input bits and $m$ is the number of\noutput bits. In the regimes where $m$ is small compared to $n$ (for example,\nfor computing the sum of $n$ bits or multiplying two $n$-bit integers), this\nleads to $10\\%$ improvement.\n  We complement our theoretical result by an open-source implementation of\ngenerators producing circuits for bit addition and multiplication. The\ngenerators allow one to produce the corresponding circuits in two lines of code\nand to compare them to existing designs.",
      "url": "http://arxiv.org/abs/2509.13966v1",
      "published_time_eastern_timestamp": 1758116273.0
    }
  ]
}
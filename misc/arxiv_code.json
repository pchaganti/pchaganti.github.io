{
  "last_updated": "2025-06-17T05:14:04.539336-04:00",
  "papers": [
    {
      "title": "PF-LHM: 3D Animatable Avatar Reconstruction from Pose-free Articulated\n  Human Images",
      "summary": "Reconstructing an animatable 3D human from casually captured images of an\narticulated subject without camera or human pose information is a practical yet\nchallenging task due to view misalignment, occlusions, and the absence of\nstructural priors. While optimization-based methods can produce high-fidelity\nresults from monocular or multi-view videos, they require accurate pose\nestimation and slow iterative optimization, limiting scalability in\nunconstrained scenarios. Recent feed-forward approaches enable efficient\nsingle-image reconstruction but struggle to effectively leverage multiple input\nimages to reduce ambiguity and improve reconstruction accuracy. To address\nthese challenges, we propose PF-LHM, a large human reconstruction model that\ngenerates high-quality 3D avatars in seconds from one or multiple casually\ncaptured pose-free images. Our approach introduces an efficient Encoder-Decoder\nPoint-Image Transformer architecture, which fuses hierarchical geometric point\nfeatures and multi-view image features through multimodal attention. The fused\nfeatures are decoded to recover detailed geometry and appearance, represented\nusing 3D Gaussian splats. Extensive experiments on both real and synthetic\ndatasets demonstrate that our method unifies single- and multi-image 3D human\nreconstruction, achieving high-fidelity and animatable 3D human avatars without\nrequiring camera and human pose annotations. Code and models will be released\nto the public.",
      "url": "http://arxiv.org/abs/2506.13766v1",
      "published_time_eastern_timestamp": 1750096796.0
    },
    {
      "title": "Steering LLM Thinking with Budget Guidance",
      "summary": "Recent deep-thinking large language models often reason extensively to\nimprove performance, but such lengthy reasoning is not always desirable, as it\nincurs excessive inference costs with disproportionate performance gains.\nControlling reasoning length without sacrificing performance is therefore\nimportant, but remains challenging, especially under tight thinking budgets. We\npropose budget guidance, a simple yet effective method for steering the\nreasoning process of LLMs toward a target budget without requiring any LLM\nfine-tuning. Our approach introduces a lightweight predictor that models a\nGamma distribution over the remaining thinking length during next-token\ngeneration. This signal is then used to guide generation in a soft, token-level\nmanner, ensuring that the overall reasoning trace adheres to the specified\nthinking budget. Budget guidance enables natural control of the thinking\nlength, along with significant token efficiency improvements over baseline\nmethods on challenging math benchmarks. For instance, it achieves up to a 26%\naccuracy gain on the MATH-500 benchmark under tight budgets compared to\nbaseline methods, while maintaining competitive accuracy with only 63% of the\nthinking tokens used by the full-thinking model. Budget guidance also\ngeneralizes to broader task domains and exhibits emergent capabilities, such as\nestimating question difficulty. The source code is available at:\nhttps://github.com/UMass-Embodied-AGI/BudgetGuidance.",
      "url": "http://arxiv.org/abs/2506.13752v1",
      "published_time_eastern_timestamp": 1750096625.0
    },
    {
      "title": "Test3R: Learning to Reconstruct 3D at Test Time",
      "summary": "Dense matching methods like DUSt3R regress pairwise pointmaps for 3D\nreconstruction. However, the reliance on pairwise prediction and the limited\ngeneralization capability inherently restrict the global geometric consistency.\nIn this work, we introduce Test3R, a surprisingly simple test-time learning\ntechnique that significantly boosts geometric accuracy. Using image triplets\n($I_1,I_2,I_3$), Test3R generates reconstructions from pairs ($I_1,I_2$) and\n($I_1,I_3$). The core idea is to optimize the network at test time via a\nself-supervised objective: maximizing the geometric consistency between these\ntwo reconstructions relative to the common image $I_1$. This ensures the model\nproduces cross-pair consistent outputs, regardless of the inputs. Extensive\nexperiments demonstrate that our technique significantly outperforms previous\nstate-of-the-art methods on the 3D reconstruction and multi-view depth\nestimation tasks. Moreover, it is universally applicable and nearly cost-free,\nmaking it easily applied to other models and implemented with minimal test-time\ntraining overhead and parameter footprint. Code is available at\nhttps://github.com/nopQAQ/Test3R.",
      "url": "http://arxiv.org/abs/2506.13750v1",
      "published_time_eastern_timestamp": 1750096582.0
    },
    {
      "title": "lcpy: an open-source python package for parametric and dynamic Life\n  Cycle Assessment and Life Cycle Costing",
      "summary": "This article describes lcpy, an open-source python package that allows for\nadvanced parametric Life Cycle Assessment (LCA) and Life Cycle Costing (LCC)\nanalysis. The package is designed to allow the user to model a process with a\nflexible, modular design based on dictionaries and lists. The modeling can\nconsider in-time variations, uncertainty, and allows for dynamic analysis,\nuncertainty assessment, as well as conventional static LCA and LCC. The package\nis compatible with optimization and uncertainty analysis libraries as well as\npython packages for prospective LCA. Its goal is to allow for easy\nimplementation of dynamic LCA and LCC and for simple integration with tools for\nuncertainty assessment and optimization towards a more widened implementation\nof advanced enviro-economic analysis. The open-source code can be found at\nhttps://github.com/spirdgk/lcpy.",
      "url": "http://arxiv.org/abs/2506.13744v1",
      "published_time_eastern_timestamp": 1750096416.0
    },
    {
      "title": "Attribution-guided Pruning for Compression, Circuit Discovery, and\n  Targeted Correction in LLMs",
      "summary": "Large Language Models (LLMs) are central to many contemporary AI\napplications, yet their extensive parameter counts pose significant challenges\nfor deployment in memory- and compute-constrained environments. Recent works in\neXplainable AI (XAI), particularly on attribution methods, suggest that\ninterpretability can also enable model compression by identifying and removing\ncomponents irrelevant to inference. In this paper, we leverage Layer-wise\nRelevance Propagation (LRP) to perform attribution-guided pruning of LLMs.\nWhile LRP has shown promise in structured pruning for vision models, we extend\nit to unstructured pruning in LLMs and demonstrate that it can substantially\nreduce model size with minimal performance loss. Our method is especially\neffective in extracting task-relevant subgraphs -- so-called ``circuits'' --\nwhich can represent core functions (e.g., indirect object identification).\nBuilding on this, we introduce a technique for model correction, by selectively\nremoving circuits responsible for spurious behaviors (e.g., toxic outputs). All\nin all, we gather these techniques as a uniform holistic framework and showcase\nits effectiveness and limitations through extensive experiments for\ncompression, circuit discovery and model correction on Llama and OPT models,\nhighlighting its potential for improving both model efficiency and safety. Our\ncode is publicly available at https://github.com/erfanhatefi/SparC3.",
      "url": "http://arxiv.org/abs/2506.13727v1",
      "published_time_eastern_timestamp": 1750095516.0
    },
    {
      "title": "Weakest Link in the Chain: Security Vulnerabilities in Advanced\n  Reasoning Models",
      "summary": "The introduction of advanced reasoning capabilities have improved the\nproblem-solving performance of large language models, particularly on math and\ncoding benchmarks. However, it remains unclear whether these reasoning models\nare more or less vulnerable to adversarial prompt attacks than their\nnon-reasoning counterparts. In this work, we present a systematic evaluation of\nweaknesses in advanced reasoning models compared to similar non-reasoning\nmodels across a diverse set of prompt-based attack categories. Using\nexperimental data, we find that on average the reasoning-augmented models are\n\\emph{slightly more robust} than non-reasoning models (42.51\\% vs 45.53\\%\nattack success rate, lower is better). However, this overall trend masks\nsignificant category-specific differences: for certain attack types the\nreasoning models are substantially \\emph{more vulnerable} (e.g., up to 32\npercentage points worse on a tree-of-attacks prompt), while for others they are\nmarkedly \\emph{more robust} (e.g., 29.8 points better on cross-site scripting\ninjection). Our findings highlight the nuanced security implications of\nadvanced reasoning in language models and emphasize the importance of\nstress-testing safety across diverse adversarial techniques.",
      "url": "http://arxiv.org/abs/2506.13726v1",
      "published_time_eastern_timestamp": 1750095138.0
    },
    {
      "title": "Leveraging erasure errors in logical qubits with metastable $^{171}$Yb\n  atoms",
      "summary": "Implementing large-scale quantum algorithms with practical advantage will\nrequire fault-tolerance achieved through quantum error correction, but the\nassociated overhead is a significant cost. The overhead can be reduced by\nengineering physical qubits with fewer errors, and by shaping the residual\nerrors to be more easily correctable. In this work, we demonstrate quantum\nerror correcting codes and logical qubit circuits in a metastable ${}^{171}$Yb\nqubit with a noise bias towards erasure errors, that is, errors whose location\ncan be detected separate from any syndrome information. We show that dephasing\nerrors on the nuclear spin qubit during coherent transport can be strongly\nsuppressed, and implement robust entangling gates that maintain a high fidelity\nin the presence of gate beam inhomogeneity or pointing error. We demonstrate\nlogical qubit encoding in the $[[4,2,2]]$ code, with error correction during\ndecoding based on mid-circuit erasure measurements despite the fact that the\ncode is too small to correct any Pauli errors. Finally, we demonstrate logical\nqubit teleportation between multiple code blocks with conditionally selected\nancillas based on mid-circuit erasure checks, which is a key ingredient for\nleakage-robust error correction with neutral atoms.",
      "url": "http://arxiv.org/abs/2506.13724v1",
      "published_time_eastern_timestamp": 1750094945.0
    },
    {
      "title": "OTFusion: Bridging Vision-only and Vision-Language Models via Optimal\n  Transport for Transductive Zero-Shot Learning",
      "summary": "Transductive zero-shot learning (ZSL) aims to classify unseen categories by\nleveraging both semantic class descriptions and the distribution of unlabeled\ntest data. While Vision-Language Models (VLMs) such as CLIP excel at aligning\nvisual inputs with textual semantics, they often rely too heavily on\nclass-level priors and fail to capture fine-grained visual cues. In contrast,\nVision-only Foundation Models (VFMs) like DINOv2 provide rich perceptual\nfeatures but lack semantic alignment. To exploit the complementary strengths of\nthese models, we propose OTFusion, a simple yet effective training-free\nframework that bridges VLMs and VFMs via Optimal Transport. Specifically,\nOTFusion aims to learn a shared probabilistic representation that aligns visual\nand semantic information by minimizing the transport cost between their\nrespective distributions. This unified distribution enables coherent class\npredictions that are both semantically meaningful and visually grounded.\nExtensive experiments on 11 benchmark datasets demonstrate that OTFusion\nconsistently outperforms the original CLIP model, achieving an average accuracy\nimprovement of nearly $10\\%$, all without any fine-tuning or additional\nannotations. The code will be publicly released after the paper is accepted.",
      "url": "http://arxiv.org/abs/2506.13723v1",
      "published_time_eastern_timestamp": 1750094867.0
    },
    {
      "title": "The determinant of \\(\\lll\\)-smooth semigroups",
      "summary": "This paper continues the investigation of non-zero determinants associated\nwith finite semigroups containing a pair of non-commuting idempotents, as\ninitiated in~\\cite{Sha-Det2}. We focus on a class of semigroups, called \\( \\lll\n\\)-smooth semigroups, that allow meaningful structural analysis despite the\nabsence of \\( \\ll \\)-transitivity. Within this framework, we develop a method\nfor computing contracted semigroup determinants, building on and extending the\napproach carried over from~\\cite{Sha-Det2}. These computations are motivated by\napplications in coding theory, particularly by the potential extending the\nMacWilliams theorem for codes over semigroup algebras.",
      "url": "http://arxiv.org/abs/2506.13700v1",
      "published_time_eastern_timestamp": 1750093534.0
    },
    {
      "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered\n  Agent Systems",
      "summary": "The development of large language models (LLMs) has entered in a\nexperience-driven era, flagged by the emergence of environment feedback-driven\nlearning via reinforcement learning and tool-using agents. This encourages the\nemergenece of model context protocol (MCP), which defines the standard on how\nshould a LLM interact with external services, such as \\api and data. However,\nas MCP becomes the de facto standard for LLM agent systems, it also introduces\nnew safety risks. In particular, MCP introduces third-party services, which are\nnot controlled by the LLM developers, into the agent systems. These third-party\nMCP services provider are potentially malicious and have the economic\nincentives to exploit vulnerabilities and sabotage user-agent interactions. In\nthis position paper, we advocate the research community in LLM safety to pay\nclose attention to the new safety risks issues introduced by MCP, and develop\nnew techniques to build safe MCP-powered agent systems. To establish our\nposition, we argue with three key parts. (1) We first construct \\framework, a\ncontrolled framework to examine safety issues in MCP-powered agent systems. (2)\nWe then conduct a series of pilot experiments to demonstrate the safety risks\nin MCP-powered agent systems is a real threat and its defense is not trivial.\n(3) Finally, we give our outlook by showing a roadmap to build safe MCP-powered\nagent systems. In particular, we would call for researchers to persue the\nfollowing research directions: red teaming, MCP safe LLM development, MCP\nsafety evaluation, MCP safety data accumulation, MCP service safeguard, and MCP\nsafe ecosystem construction. We hope this position paper can raise the\nawareness of the research community in MCP safety and encourage more\nresearchers to join this important research direction. Our code is available at\nhttps://github.com/littlelittlenine/SafeMCP.git.",
      "url": "http://arxiv.org/abs/2506.13666v1",
      "published_time_eastern_timestamp": 1750091071.0
    },
    {
      "title": "DesignCoder: Hierarchy-Aware and Self-Correcting UI Code Generation with\n  Large Language Models",
      "summary": "Multimodal large language models (MLLMs) have streamlined front-end interface\ndevelopment by automating code generation. However, these models also introduce\nchallenges in ensuring code quality. Existing approaches struggle to maintain\nboth visual consistency and functional completeness in the generated\ncomponents. Moreover, they lack mechanisms to assess the fidelity and\ncorrectness of the rendered pages. To address these issues, we propose\nDesignCoder, a novel hierarchical-aware and self-correcting automated code\ngeneration framework. Specifically, we introduce UI Grouping Chains, which\nenhance MLLMs' capability to understand and predict complex nested UI\nhierarchies. Subsequently, DesignCoder employs a hierarchical\ndivide-and-conquer approach to generate front-end code. Finally, we incorporate\na self-correction mechanism to improve the model's ability to identify and\nrectify errors in the generated code. Extensive evaluations on a dataset of UI\nmockups collected from both open-source communities and industry projects\ndemonstrate that DesignCoder outperforms state-of-the-art baselines in React\nNative, a widely adopted UI framework. Our method achieves a 37.63%, 9.52%,\n12.82% performance increase in visual similarity metrics (MSE, CLIP, SSIM) and\nsignificantly improves code structure similarity in terms of TreeBLEU,\nContainer Match, and Tree Edit Distance by 30.19%, 29.31%, 24.67%. Furthermore,\nwe conducted a user study with professional developers to assess the quality\nand practicality of the generated code. Results indicate that DesignCoder\naligns with industry best practices, demonstrating high usability, readability,\nand maintainability. Our approach provides an efficient and practical solution\nfor agile front-end development, enabling development teams to focus more on\ncore functionality and product innovation.",
      "url": "http://arxiv.org/abs/2506.13663v1",
      "published_time_eastern_timestamp": 1750090843.0
    },
    {
      "title": "Towards fault-tolerant quantum computation with universal\n  continuous-variable gates",
      "summary": "Continuous-variable (CV) systems have shown remarkable potential for quantum\ncomputation, particularly excelling in scalability and error correction through\nbosonic encoding. Within this framework, the foundational notion of\ncomputational universality was introduced in [Phys. Rev. Lett. 82, 1784\n(1999)], and has proven especially successful since it allows for the\nidentification of finite sets of universal CV gates independent of the encoding\nscheme. However, achieving the critical objective of fault-tolerant computation\nrequires some form of encoding, and to date there has been no proof that these\nuniversal CV gates can lead to encoded fault tolerance. We present compelling\nevidence in this direction by utilizing the Gottesman-Kitaev-Preskill (GKP)\nencoding. Specifically, we numerically optimize the generation of GKP states\nfrom vacua using circuits comprised solely of universal CV gates. We\ndemonstrate that these states can be attained with sufficient quality to\nexhibit error probabilities lower than the threshold needed to achieve a\nfault-tolerant memory via concatenated GKP-stabilizer codes.",
      "url": "http://arxiv.org/abs/2506.13643v1",
      "published_time_eastern_timestamp": 1750090059.0
    },
    {
      "title": "Stream-Omni: Simultaneous Multimodal Interactions with Large\n  Language-Vision-Speech Model",
      "summary": "The emergence of GPT-4o-like large multimodal models (LMMs) has raised the\nexploration of integrating text, vision, and speech modalities to support more\nflexible multimodal interaction. Existing LMMs typically concatenate\nrepresentation of modalities along the sequence dimension and feed them into a\nlarge language model (LLM) backbone. While sequence-dimension concatenation is\nstraightforward for modality integration, it often relies heavily on\nlarge-scale data to learn modality alignments. In this paper, we aim to model\nthe relationships between modalities more purposefully, thereby achieving more\nefficient and flexible modality alignments. To this end, we propose\nStream-Omni, a large language-vision-speech model with efficient modality\nalignments, which can simultaneously support interactions under various\nmodality combinations. Stream-Omni employs LLM as the backbone and aligns the\nvision and speech to the text based on their relationships. For vision that is\nsemantically complementary to text, Stream-Omni uses sequence-dimension\nconcatenation to achieve vision-text alignment. For speech that is semantically\nconsistent with text, Stream-Omni introduces a CTC-based layer-dimension\nmapping to achieve speech-text alignment. In this way, Stream-Omni can achieve\nmodality alignments with less data (especially speech), enabling the transfer\nof text capabilities to other modalities. Experiments on various benchmarks\ndemonstrate that Stream-Omni achieves strong performance on visual\nunderstanding, speech interaction, and vision-grounded speech interaction\ntasks. Owing to the layer-dimensional mapping, Stream-Omni can simultaneously\nprovide intermediate text outputs (such as ASR transcriptions and model\nresponses) during speech interaction, offering users a comprehensive multimodal\nexperience.",
      "url": "http://arxiv.org/abs/2506.13642v1",
      "published_time_eastern_timestamp": 1750090005.0
    },
    {
      "title": "EvolvTrip: Enhancing Literary Character Understanding with Temporal\n  Theory-of-Mind Graphs",
      "summary": "A compelling portrayal of characters is essential to the success of narrative\nwriting. For readers, appreciating a character's traits requires the ability to\ninfer their evolving beliefs, desires, and intentions over the course of a\ncomplex storyline, a cognitive skill known as Theory-of-Mind (ToM). Performing\nToM reasoning in prolonged narratives requires readers to integrate historical\ncontext with current narrative information, a task at which humans excel but\nLarge Language Models (LLMs) often struggle. To systematically evaluate LLMs'\nToM reasoning capability in long narratives, we construct LitCharToM, a\nbenchmark of character-centric questions across four ToM dimensions from\nclassic literature. Further, we introduce EvolvTrip, a perspective-aware\ntemporal knowledge graph that tracks psychological development throughout\nnarratives. Our experiments demonstrate that EvolvTrip consistently enhances\nperformance of LLMs across varying scales, even in challenging extended-context\nscenarios. EvolvTrip proves to be particularly valuable for smaller models,\npartially bridging the performance gap with larger LLMs and showing great\ncompatibility with lengthy narratives. Our findings highlight the importance of\nexplicit representation of temporal character mental states in narrative\ncomprehension and offer a foundation for more sophisticated character\nunderstanding. Our data and code are publicly available at\nhttps://github.com/Bernard-Yang/EvolvTrip.",
      "url": "http://arxiv.org/abs/2506.13641v1",
      "published_time_eastern_timestamp": 1750089917.0
    },
    {
      "title": "KRIOS: A new basis-expansion $N$-body code for collisional stellar\n  dynamics",
      "summary": "The gravitational $N$-body problem is a nearly universal problem in\nastrophysics which, despite its deceptive simplicity, still presents a\nsignificant computational challenge. For collisional systems such as dense star\nclusters, the need to resolve individual encounters between $N$ stars makes the\ndirect summation of forces - with quadratic complexity - almost infeasible for\nsystems with $N\\gtrsim 10^6$ particles over many relaxation times. At the same\ntime, the most common Monte Carlo $N$-body algorithm - that of H\\'enon -\nassumes the cluster to be spherically symmetric. This greatly limits the study\nof many important features of star clusters, including triaxiality, rotation,\nand the production of tidal debris. In this paper, we present a new hybrid\ncode, KRIOS, that combines 3D collisionless relaxation using an adaptive\nself-consistent field method with a collisional dynamics part handled via\nH\\'enon's method. We demonstrate that KRIOS can accurately model the long-term\nevolution of clusters and provide its complete phase-space information over\nmany relaxation times. As a test of our new code, we present detailed\ncomparisons to two well-known results from stellar dynamics: (i) the\ncollisional evolution of an isotropic Plummer sphere to core collapse, and (ii)\nthe emergence of the radial-orbit instability in radially anisotropic star\nclusters, including its non-spherical effects.",
      "url": "http://arxiv.org/abs/2506.13636v1",
      "published_time_eastern_timestamp": 1750089662.0
    },
    {
      "title": "Blocklet concatenation: Low-overhead fault-tolerant protocols for\n  fusion-based quantum computation",
      "summary": "We introduce a construction for protocols for fault-tolerant quantum\ncomputing based on code concatenation and transversal gates. These protocols\ncan be interpreted as families of quantum circuits of low-weight stabilizer\nmeasurements without strict locality constraints, effectively implementing\nconcatenated codes. However, we primarily study these protocols in the context\nof photonic fusion-based quantum computing (FBQC), where they yield families of\nfusion networks with constant-sized resource states. Their high erasure\nthresholds relative to their resource-state cost establish them as promising\ncandidates to replace surface codes in the context of FBQC. Examples include\nprotocol families using 8-, 10- and 12-qubit resource states, with erasure\nthresholds of 13.8%, 19.1% and 11.5%, and footprint-per-logical-qubit scaling\nas $\\mathcal{O}(d)$, $\\mathcal{O}(d^{1.46})$ and $\\mathcal{O}(d^{0.58})$,\nrespectively, where $d$ is the code distance. We also present techniques for\nperforming logical operations, decoding, and implementing the protocols in\nphotonic hardware. Although we focus on photonic FBQC, these ideas may also be\nof interest in other settings.",
      "url": "http://arxiv.org/abs/2506.13619v1",
      "published_time_eastern_timestamp": 1750088899.0
    },
    {
      "title": "Assessing the Limits of In-Context Learning beyond Functions using\n  Partially Ordered Relation",
      "summary": "Generating rational and generally accurate responses to tasks, often\naccompanied by example demonstrations, highlights Large Language Model's\n(LLM's) remarkable In-Context Learning (ICL) capabilities without requiring\nupdates to the model's parameter space. Despite having an ongoing exploration\nfocused on the inference from a document-level concept, its behavior in\nlearning well-defined functions or relations in context needs a careful\ninvestigation. In this article, we present the performance of ICL on partially\nordered relation by introducing the notion of inductively increasing complexity\nin prompts. In most cases, the saturated performance of the chosen metric\nindicates that while ICL offers some benefits, its effectiveness remains\nconstrained as we increase the complexity in the prompts even in presence of\nsufficient demonstrative examples. The behavior is evident from our empirical\nfindings and has further been theoretically justified in term of its implicit\noptimization process. The code is available\n\\href{https://anonymous.4open.science/r/ICLonPartiallyOrderSet}{here}.",
      "url": "http://arxiv.org/abs/2506.13608v1",
      "published_time_eastern_timestamp": 1750088141.0
    },
    {
      "title": "Tree-Based Text Retrieval via Hierarchical Clustering in RAGFrameworks:\n  Application on Taiwanese Regulations",
      "summary": "Traditional Retrieval-Augmented Generation (RAG) systems employ brute-force\ninner product search to retrieve the top-k most similar documents, then\ncombined with the user query and passed to a language model. This allows the\nmodel to access external knowledge and reduce hallucinations. However,\nselecting an appropriate k value remains a significant challenge in practical\napplications: a small k may fail to retrieve sufficient information, while a\nlarge k can introduce excessive and irrelevant content. To address this, we\npropose a hierarchical clustering-based retrieval method that eliminates the\nneed to predefine k. Our approach maintains the accuracy and relevance of\nsystem responses while adaptively selecting semantically relevant content. In\nthe experiment stage, we applied our method to a Taiwanese legal dataset with\nexpert-graded queries. The results show that our approach achieves superior\nperformance in expert evaluations and maintains high precision while\neliminating the need to predefine k, demonstrating improved accuracy and\ninterpretability in legal text retrieval tasks. Our framework is simple to\nimplement and easily integrates with existing RAG pipelines, making it a\npractical solution for real-world applications under limited resources.",
      "url": "http://arxiv.org/abs/2506.13607v1",
      "published_time_eastern_timestamp": 1750088069.0
    },
    {
      "title": "Omni-AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented for\n  Efficient Long Video Understanding",
      "summary": "Multimodal Large Language Models (MLLMs) struggle with long videos due to\nfixed context windows and weak long-term dependency modeling. Existing\nRetrieval-Augmented Generation (RAG) methods for videos use static retrieval\nstrategies, leading to inefficiencies for simple queries and information loss\nfor complex tasks. To address this, we propose AdaVideoRAG, a novel framework\nthat dynamically adapts retrieval granularity based on query complexity using a\nlightweight intent classifier. Our framework employs an Omni-Knowledge Indexing\nmodule to build hierarchical databases from text (captions, ASR, OCR), visual\nfeatures, and semantic graphs, enabling optimal resource allocation across\ntasks. We also introduce the HiVU benchmark for comprehensive evaluation.\nExperiments demonstrate improved efficiency and accuracy for long-video\nunderstanding, with seamless integration into existing MLLMs. AdaVideoRAG\nestablishes a new paradigm for adaptive retrieval in video analysis. Codes will\nbe open-sourced at https://github.com/xzc-zju/AdaVideoRAG.",
      "url": "http://arxiv.org/abs/2506.13589v1",
      "published_time_eastern_timestamp": 1750087095.0
    },
    {
      "title": "Updated Mutual Inclination Measurement for 14 Her b and c",
      "summary": "The mutual inclination $\\psi$ between orbits within multi-planetary systems\nis difficult to measure directly. Through a joint analysis of RVs,\nHipparcos-Gaia absolute astrometry and relative astrometry of JWST,\n\\citet{Bardalez2025} recently found two possible values of\n$\\psi_{bc}={32_{-15.1}^{+13.6}}^{\\circ}$ and\n$\\psi_{bc}={145.0_{-11.1}^{+15.8}}^{\\circ}$ for the nearby, non-transit planet\nsystem, 14\\,Her. By incorporating additional astrometry from Gaia second data\nrelease (DR2), we have further constrained the orbital orientation of\n14\\,Her\\,b, resulting in a definitive and unambiguous mutual inclination of\n$\\psi_{bc}={35.3_{-7.3}^{+6.8}}^{\\circ}$. The unusual misaligned orbital\narchitecture of 14\\,Her system may serve as a benchmark for dynamical studies.",
      "url": "http://arxiv.org/abs/2506.13580v1",
      "published_time_eastern_timestamp": 1750086193.0
    }
  ]
}
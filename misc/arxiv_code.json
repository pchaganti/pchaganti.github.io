{
  "last_updated": "2026-02-18T13:40:01.041569-05:00",
  "papers": [
    {
      "title": "Rate-Distortion Optimization for Ensembles of Non-Reference Metrics",
      "summary": "Non-reference metrics (NRMs) can assess the visual quality of images and videos without a reference, making them well-suited for the evaluation of user-generated content. Nonetheless, rate-distortion optimization (RDO) in video coding is still mainly driven by full-reference metrics, such as the sum of squared errors, which treat the input as an ideal target. A way to incorporate NRMs into RDO is through linearization (LNRM), where the gradient of the NRM with respect to the input guides bit allocation. While this strategy improves the quality predicted by some metrics, we show that it can yield limited gains or degradations when evaluated with other NRMs. We argue that NRMs are highly non-linear predictors with locally unstable gradients that can compromise the quality of the linearization; furthermore, optimizing a single metric may exploit model-specific biases that do not generalize across quality estimators. Motivated by this observation, we extend the LNRM framework to optimize ensembles of NRMs and, to further improve robustness, we introduce a smoothing-based formulation that stabilizes NRM gradients prior to linearization. Our framework is well-suited to hybrid codecs, and we advocate for its use with overfitted codecs, where it avoids iterative evaluations and backpropagation of neural network-based NRMs, reducing encoder complexity relative to direct NRM optimization. We validate the proposed approach on AVC and Cool-chic, using the YouTube UGC dataset. Experiments demonstrate consistent bitrate savings across multiple NRMs with no decoder complexity overhead and, for Cool-chic, a substantial reduction in encoding runtime compared to direct NRM optimization.",
      "url": "http://arxiv.org/abs/2602.15779v1",
      "published_time_eastern_timestamp": 1771351892.0
    },
    {
      "title": "Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models",
      "summary": "Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of \"generate-understand-regenerate\". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.",
      "url": "http://arxiv.org/abs/2602.15772v1",
      "published_time_eastern_timestamp": 1771351453.0
    },
    {
      "title": "GLM-5: from Vibe Coding to Agentic Engineering",
      "summary": "We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.",
      "url": "http://arxiv.org/abs/2602.15763v1",
      "published_time_eastern_timestamp": 1771350656.0
    },
    {
      "title": "A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings",
      "summary": "With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.",
      "url": "http://arxiv.org/abs/2602.15761v1",
      "published_time_eastern_timestamp": 1771350433.0
    },
    {
      "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models",
      "summary": "While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.",
      "url": "http://arxiv.org/abs/2602.15758v1",
      "published_time_eastern_timestamp": 1771350334.0
    },
    {
      "title": "RaCo: Ranking and Covariance for Practical Learned Keypoints",
      "summary": "This paper introduces RaCo, a lightweight neural network designed to learn robust and versatile keypoints suitable for a variety of 3D computer vision tasks. The model integrates three key components: the repeatable keypoint detector, a differentiable ranker to maximize matches with a limited number of keypoints, and a covariance estimator to quantify spatial uncertainty in metric scale. Trained on perspective image crops only, RaCo operates without the need for covisible image pairs. It achieves strong rotational robustness through extensive data augmentation, even without the use of computationally expensive equivariant network architectures. The method is evaluated on several challenging datasets, where it demonstrates state-of-the-art performance in keypoint repeatability and two-view matching, particularly under large in-plane rotations. Ultimately, RaCo provides an effective and simple strategy to independently estimate keypoint ranking and metric covariance without additional labels, detecting interpretable and repeatable interest points. The code is available at https://github.com/cvg/RaCo.",
      "url": "http://arxiv.org/abs/2602.15755v1",
      "published_time_eastern_timestamp": 1771349992.0
    },
    {
      "title": "Impact of rotation on the amplitude of acoustic modes in solar-like stars: Insights from hydrodynamical simulations",
      "summary": "In solar-like stars, acoustic modes provide the main way of probing their internal structure and dynamics. Although these modes are expected to be ubiquitous in stars with convective envelopes, Kepler observations reveal that a significant fraction of solar-like stars show no detectable acoustic modes, particularly among rapidly rotating and magnetically active stars. Recent theoretical work by Bessila et al. (2025) has proposed that rotation tends to inhibit convective motions, thereby reducing the power available for stochastic mode excitation. Here, we test this prediction using fully compressible hydrodynamical simulations of a solar-like star. We perform a series of 2.5D simulations, which consider longitudinal symmetry, using the MUSIC code spanning rotation rates from 0 to 8 $Ω_{\\odot}$. We find a clear and systematic decline of acoustic mode amplitudes with increasing rotation rate. In the most rapidly rotating models, mode damping rates are also enhanced. The combined reduction in excitation and increase in damping with increasing rotation rate provide a physical explanation for the observed decrease in mode detectability in rapidly rotating solar-like stars. Our results demonstrate that rotation can significantly modify oscillation properties and must be accounted for when interpreting asteroseismic observations.",
      "url": "http://arxiv.org/abs/2602.15735v1",
      "published_time_eastern_timestamp": 1771348241.0
    },
    {
      "title": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "summary": "Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\\{\\mathbf{a}$, $\\mathbf{a}'$, $\\mathbf{b}\\}$, the goal is to generate $\\mathbf{b}'$ such that $\\mathbf{a} : \\mathbf{a}' :: \\mathbf{b} : \\mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a \"space of LoRAs\". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb",
      "url": "http://arxiv.org/abs/2602.15727v1",
      "published_time_eastern_timestamp": 1771347758.0
    },
    {
      "title": "ToaSt: Token Channel Selection and Structured Pruning for Efficient ViT",
      "summary": "Vision Transformers (ViTs) have achieved remarkable success across various vision tasks, yet their deployment is often hindered by prohibitive computational costs. While structured weight pruning and token compression have emerged as promising solutions, they suffer from prolonged retraining times and global propagation that creates optimization challenges, respectively. We propose ToaSt, a decoupled framework applying specialized strategies to distinct ViT components. We apply coupled head-wise structured pruning to Multi-Head Self-Attention modules, leveraging attention operation characteristics to enhance robustness. For Feed-Forward Networks (over 60\\% of FLOPs), we introduce Token Channel Selection (TCS) that enhances compression ratios while avoiding global propagation issues. Our analysis reveals TCS effectively filters redundant noise during selection. Extensive evaluations across nine diverse models, including DeiT, ViT-MAE, and Swin Transformer, demonstrate that ToaSt achieves superior trade-offs between accuracy and efficiency, consistently outperforming existing baselines. On ViT-MAE-Huge, ToaSt achieves 88.52\\% accuracy (+1.64 \\%) with 39.4\\% FLOPs reduction. ToaSt transfers effectively to downstream tasks, cccccachieving 52.2 versus 51.9 mAP on COCO object detection. Code and models will be released upon acceptance.",
      "url": "http://arxiv.org/abs/2602.15720v1",
      "published_time_eastern_timestamp": 1771347133.0
    },
    {
      "title": "Can Recommender Systems Teach Themselves? A Recursive Self-Improving Framework with Fidelity Control",
      "summary": "The scarcity of high-quality training data presents a fundamental bottleneck to scaling machine learning models. This challenge is particularly acute in recommendation systems, where extreme sparsity in user interactions leads to rugged optimization landscapes and poor generalization. We propose the Recursive Self-Improving Recommendation (RSIR) framework, a paradigm in which a model bootstraps its own performance without reliance on external data or teacher models. RSIR operates in a closed loop: the current model generates plausible user interaction sequences, a fidelity-based quality control mechanism filters them for consistency with user's approximate preference manifold, and a successor model is augmented on the enriched dataset. Our theoretical analysis shows that RSIR acts as a data-driven implicit regularizer, smoothing the optimization landscape and guiding models toward more robust solutions. Empirically, RSIR yields consistent, cumulative gains across multiple benchmarks and architectures. Notably, even smaller models benefit, and weak models can generate effective training curricula for stronger ones. These results demonstrate that recursive self-improvement is a general, model-agnostic approach to overcoming data sparsity, suggesting a scalable path forward for recommender systems and beyond. Our anonymized code is available at https://anonymous.4open.science/r/RSIR-7C5B .",
      "url": "http://arxiv.org/abs/2602.15659v1",
      "published_time_eastern_timestamp": 1771342292.0
    },
    {
      "title": "UniTAF: A Modular Framework for Joint Text-to-Speech and Audio-to-Face Modeling",
      "summary": "This work considers merging two independent models, TTS and A2F, into a unified model to enable internal feature transfer, thereby improving the consistency between audio and facial expressions generated from text. We also discuss the extension of the emotion control mechanism from TTS to the joint model. This work does not aim to showcase generation quality; instead, from a system design perspective, it validates the feasibility of reusing intermediate representations from TTS for joint modeling of speech and facial expressions, and provides engineering practice references for subsequent speech expression co-design. The project code has been open source at: https://github.com/GoldenFishes/UniTAF",
      "url": "http://arxiv.org/abs/2602.15651v1",
      "published_time_eastern_timestamp": 1771341630.0
    },
    {
      "title": "SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms",
      "summary": "Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.",
      "url": "http://arxiv.org/abs/2602.15633v1",
      "published_time_eastern_timestamp": 1771340585.0
    },
    {
      "title": "Deformation and orientation of a capsule with viscosity contrast in linear flows: a theoretical study",
      "summary": "We develop a perturbation theory to study the shape and the orientation of an initially spherical capsule of radius R with a viscosity contrast, a surface tension σ and a bending rigidity $κ$ in linear flows. The elastic mechanical response of membrane to deformations is described by three elastic constitutive law which are either Hookean, Neohookean or Skalak type leading to the introduction of a surface shear elastic modulus $G_s$ and the Poisson ratio (or analog quantities). At the leading order, the deformation, i.e. the so-called Taylor parameter is proportional to the elastic capillary number Ca which evaluates the ratio between the external viscous stress and the elastic membrane response. In this linear regime, the results do not depend on the elastic constitutive law as expected. Without surface tension and bending rigidity, we recover the results of Barthes-Biesel & Rallison (1981) and notably the fact that the Taylor parameter does not depend on the viscosity contrast $λ$ contrary to the case of a viscous droplet. In our more general model, the deformation does no longer depend on $λ$ at the upper order. Now, the Taylor parameter also depends on two other dimensionless numbers: the surface elastocapillary ratio $σ/G_s$ and the dimensionless bending rigidity $B= κ/G_sR^2$. At the further order, the angle of inclination of the capsule with the direction of the shear flow, the analog of the Chaffey and Brenner equation for droplets is determined in each case. The results are in excellent agreement with the numerical ones performed with a code based on the boundary integral method providing an useful method to valid numerical developments.",
      "url": "http://arxiv.org/abs/2602.15626v1",
      "published_time_eastern_timestamp": 1771339891.0
    },
    {
      "title": "Accelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment",
      "summary": "Predictive coding (PC) is a biologically inspired algorithm for training neural networks that relies only on local updates, allowing parallel learning across layers. However, practical implementations face two key limitations: error signals must still propagate from the output to early layers through multiple inference-phase steps, and feedback decays exponentially during this process, leading to vanishing updates in early layers. We propose direct Kolen-Pollack predictive coding (DKP-PC), which simultaneously addresses both feedback delay and exponential decay, yielding a more efficient and scalable variant of PC while preserving update locality. Leveraging direct feedback alignment and direct Kolen-Pollack algorithms, DKP-PC introduces learnable feedback connections from the output layer to all hidden layers, establishing a direct pathway for error transmission. This yields an algorithm that reduces the theoretical error propagation time complexity from O(L), with L being the network depth, to O(1), removing depth-dependent delay in error signals. Moreover, empirical results demonstrate that DKP-PC achieves performance at least comparable to, and often exceeding, that of standard PC, while offering improved latency and computational performance, supporting its potential for custom hardware-efficient implementations.",
      "url": "http://arxiv.org/abs/2602.15571v1",
      "published_time_eastern_timestamp": 1771334954.0
    },
    {
      "title": "Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL",
      "summary": "Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL",
      "url": "http://arxiv.org/abs/2602.15564v1",
      "published_time_eastern_timestamp": 1771334696.0
    },
    {
      "title": "Latent Regularization in Generative Test Input Generation",
      "summary": "This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.",
      "url": "http://arxiv.org/abs/2602.15552v1",
      "published_time_eastern_timestamp": 1771333037.0
    },
    {
      "title": "A homogeneous view of asymptotic giant branch carbon stars as seen by Gaia",
      "summary": "Carbon stars on the asymptotic giant branch are major contributors to galactic dust enrichment, with gas mass-loss rates up to 1e-4 Msun/yr. We present a homogeneous spectral energy distribution analysis of the Gaia DR3 Golden Sample of carbon stars in the Milky Way and Magellanic Clouds. Our dataset includes 14,747 sources with multi-band photometry from Gaia, 2MASS, and WISE, combined with recent distance and extinction estimates. For a subsample of 2,494 Mira variables, we model multi-band light curves to derive accurate mean magnitudes.\n  Stellar and circumstellar parameters are obtained by fitting observations with a large grid of synthetic spectra computed with the DUSTY radiative transfer code using COMARCS atmospheres. We derive effective temperature, optical depth, and gas mass-loss rate for each source. The distributions peak around Teff = 3150 K, with mass-loss rates spanning 1e-11 to 1e-4 Msun/yr and inner dust temperatures near 1000 K. We find a correlation between variability amplitude and mass-loss rate.\n  This framework provides a statistically robust view of carbon stars across environments with different metallicities. Apparent environmental dependencies are influenced by luminosity distributions and selection effects rather than purely intrinsic metallicity differences. The combined Gaia and WISE selection limits the detection of both highly obscured and faint Magellanic Cloud sources, but the observed trends remain significant within the sampled populations.",
      "url": "http://arxiv.org/abs/2602.15550v1",
      "published_time_eastern_timestamp": 1771332945.0
    },
    {
      "title": "Advanced Acceptance Score: A Holistic Measure for Biometric Quantification",
      "summary": "Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \\href{https://github.com/AmanVerma2307/MeasureSuite}{code} public.",
      "url": "http://arxiv.org/abs/2602.15535v1",
      "published_time_eastern_timestamp": 1771331625.0
    },
    {
      "title": "The Obfuscation Atlas: Mapping Where Honesty Emerges in RLVR with Deception Probes",
      "summary": "Training against white-box deception detectors has been proposed as a way to make AI systems honest. However, such training risks models learning to obfuscate their deception to evade the detector. Prior work has studied obfuscation only in artificial settings where models were directly rewarded for harmful output. We construct a realistic coding environment where reward hacking via hardcoding test cases naturally occurs, and show that obfuscation emerges in this setting. We introduce a taxonomy of possible outcomes when training against a deception detector. The model either remains honest, or becomes deceptive via two possible obfuscation strategies. (i) Obfuscated activations: the model outputs deceptive text while modifying its internal representations to no longer trigger the detector. (ii) Obfuscated policy: the model outputs deceptive text that evades the detector, typically by including a justification for the reward hack. Empirically, obfuscated activations arise from representation drift during RL, with or without a detector penalty. The probe penalty only incentivizes obfuscated policies; we theoretically show this is expected for policy gradient methods. Sufficiently high KL regularization and detector penalty can yield honest policies, establishing white-box deception detectors as viable training signals for tasks prone to reward hacking.",
      "url": "http://arxiv.org/abs/2602.15515v1",
      "published_time_eastern_timestamp": 1771328650.0
    },
    {
      "title": "Eco-Amazon: Enriching E-commerce Datasets with Product Carbon Footprint for Sustainable Recommendations",
      "summary": "In the era of responsible and sustainable AI, information retrieval and recommender systems must expand their scope beyond traditional accuracy metrics to incorporate environmental sustainability. However, this research line is severely limited by the lack of item-level environmental impact data in standard benchmarks. This paper introduces Eco-Amazon, a novel resource designed to bridge this gap. Our resource consists of an enriched version of three widely used Amazon datasets (i.e., Home, Clothing, and Electronics) augmented with Product Carbon Footprint (PCF) metadata. CO2e emission scores were generated using a zero-shot framework that leverages Large Language Models (LLMs) to estimate item-level PCF based on product attributes. Our contribution is three-fold: (i) the release of the Eco-Amazon datasets, enriching item metadata with PCF signals; (ii) the LLM-based PCF estimation script, which allows researchers to enrich any product catalogue and reproduce our results; (iii) a use case demonstrating how PCF estimates can be exploited to promote more sustainable products. By providing these environmental signals, Eco-Amazon enables the community to develop, benchmark, and evaluate the next generation of sustainable retrieval and recommendation models. Our resource is available at https://doi.org/10.5281/zenodo.18549130, while our source code is available at: http://github.com/giuspillo/EcoAmazon/.",
      "url": "http://arxiv.org/abs/2602.15508v1",
      "published_time_eastern_timestamp": 1771327811.0
    }
  ]
}
{
  "last_updated": "2025-10-22T11:11:14.642851-04:00",
  "papers": [
    {
      "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation",
      "summary": "Despite their remarkable capabilities, Large Language Models (LLMs) struggle\nto effectively leverage historical interaction information in dynamic and\ncomplex environments. Memory systems enable LLMs to move beyond stateless\ninteractions by introducing persistent information storage, retrieval, and\nutilization mechanisms. However, existing memory systems often introduce\nsubstantial time and computational overhead. To this end, we introduce a new\nmemory system called LightMem, which strikes a balance between the performance\nand efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of\nhuman memory, LightMem organizes memory into three complementary stages. First,\ncognition-inspired sensory memory rapidly filters irrelevant information\nthrough lightweight compression and groups information according to their\ntopics. Next, topic-aware short-term memory consolidates these topic-based\ngroups, organizing and summarizing content for more structured access. Finally,\nlong-term memory with sleep-time update employs an offline procedure that\ndecouples consolidation from online inference. Experiments on LongMemEval with\nGPT and Qwen backbones show that LightMem outperforms strong baselines in\naccuracy (up to 10.9% gains) while reducing token usage by up to 117x, API\ncalls by up to 159x, and runtime by over 12x. The code is available at\nhttps://github.com/zjunlp/LightMem.",
      "url": "http://arxiv.org/abs/2510.18866v1",
      "published_time_eastern_timestamp": 1761069497.0
    },
    {
      "title": "EffiReasonTrans: RL-Optimized Reasoning for Code Translation",
      "summary": "Code translation is a crucial task in software development and maintenance.\nWhile recent advancements in large language models (LLMs) have improved\nautomated code translation accuracy, these gains often come at the cost of\nincreased inference latency, hindering real-world development workflows that\ninvolve human-in-the-loop inspection. To address this trade-off, we propose\nEffiReasonTrans, a training framework designed to improve translation accuracy\nwhile balancing inference latency. We first construct a high-quality\nreasoning-augmented dataset by prompting a stronger language model,\nDeepSeek-R1, to generate intermediate reasoning and target translations. Each\n(source code, reasoning, target code) triplet undergoes automated syntax and\nfunctionality checks to ensure reliability. Based on this dataset, we employ a\ntwo-stage training strategy: supervised fine-tuning on reasoning-augmented\nsamples, followed by reinforcement learning to further enhance accuracy and\nbalance inference latency. We evaluate EffiReasonTrans on six translation\npairs. Experimental results show that it consistently improves translation\naccuracy (up to +49.2% CA and +27.8% CodeBLEU compared to the base model) while\nreducing the number of generated tokens (up to -19.3%) and lowering inference\nlatency in most cases (up to -29.0%). Ablation studies further confirm the\ncomplementary benefits of the two-stage training framework. Additionally,\nEffiReasonTrans demonstrates improved translation accuracy when integrated into\nagent-based frameworks. Our code and data are available at\nhttps://github.com/DeepSoftwareAnalytics/EffiReasonTrans.",
      "url": "http://arxiv.org/abs/2510.18863v1",
      "published_time_eastern_timestamp": 1761069339.0
    },
    {
      "title": "Streamlining Acceptance Test Generation for Mobile Applications Through\n  Large Language Models: An Industrial Case Study",
      "summary": "Mobile acceptance testing remains a bottleneck in modern software\ndevelopment, particularly for cross-platform mobile development using\nframeworks like Flutter. While developers increasingly rely on automated\ntesting tools, creating and maintaining acceptance test artifacts still demands\nsignificant manual effort. To help tackle this issue, we introduce AToMIC, an\nautomated framework leveraging specialized Large Language Models to generate\nGherkin scenarios, Page Objects, and executable UI test scripts directly from\nrequirements (JIRA tickets) and recent code changes. Applied to BMW's MyBMW\napp, covering 13 real-world issues in a 170+ screen codebase, AToMIC produced\nexecutable test artifacts in under five minutes per feature on standard\nhardware. The generated artifacts were of high quality: 93.3% of Gherkin\nscenarios were syntactically correct upon generation, 78.8% of PageObjects ran\nwithout manual edits, and 100% of generated UI tests executed successfully. In\na survey, all practitioners reported time savings (often a full developer-day\nper feature) and strong confidence in adopting the approach. These results\nconfirm AToMIC as a scalable, practical solution for streamlining acceptance\ntest creation and maintenance in industrial mobile projects.",
      "url": "http://arxiv.org/abs/2510.18861v1",
      "published_time_eastern_timestamp": 1761069249.0
    },
    {
      "title": "MoveOD: Synthesizing Origin-Destination Commute Distribution from U.S.\n  Census Data",
      "summary": "High-resolution origin-destination (OD) tables are essential for a wide\nspectrum of transportation applications, from modeling traffic and signal\ntiming optimization to congestion pricing and vehicle routing. However, outside\na handful of data rich cities, such data is rarely available. We introduce\nMOVEOD, an open-source pipeline that synthesizes public data into commuter OD\nflows with fine-grained spatial and temporal departure times for any county in\nthe United States. MOVEOD combines five open data sources: American Community\nSurvey (ACS) departure time and travel time distributions, Longitudinal\nEmployer-Household Dynamics (LODES) residence-to-workplace flows, county\ngeometries, road network information from OpenStreetMap (OSM), and building\nfootprints from OSM and Microsoft, into a single OD dataset. We use a\nconstrained sampling and integer-programming method to reconcile the OD dataset\nwith data from ACS and LODES. Our approach involves: (1) matching commuter\ntotals per origin zone, (2) aligning workplace destinations with employment\ndistributions, and (3) calibrating travel durations to ACS-reported commute\ntimes. This ensures the OD data accurately reflects commuting patterns. We\ndemonstrate the framework on Hamilton County, Tennessee, where we generate\nroughly 150,000 synthetic trips in minutes, which we feed into a benchmark\nsuite of classical and learning-based vehicle-routing algorithms. The MOVEOD\npipeline is an end-to-end automated system, enabling users to easily apply it\nacross the United States by giving only a county and a year; and it can be\nadapted to other countries with comparable census datasets. The source code and\na lightweight browser interface are publicly available.",
      "url": "http://arxiv.org/abs/2510.18858v1",
      "published_time_eastern_timestamp": 1761069178.0
    },
    {
      "title": "Surface code scaling on heavy-hex superconducting quantum processors",
      "summary": "Demonstrating subthreshold scaling of a surface-code quantum memory on\nhardware whose native connectivity does not match the code remains a central\nchallenge. We address this on IBM heavy-hex superconducting processors by\nco-designing the code embedding and control: a depth-minimizing SWAP-based\n\"fold-unfold\" embedding that uses bridge ancillas, together with robust,\ngap-aware dynamical decoupling (DD). On Heron-generation devices we perform\nanisotropic scaling from a uniform distance 3 code to anisotropic distance\n(dx,dz) = (3,5) and (5,3) codes. We find that increasing dz (dx) improves the\nprotection of Z-basis (X-basis) logical states across multiple quantum error\ncorrection cycles. Even if global subthreshold code scaling for arbitrary\nlogical initial states is not yet achieved, we argue that it is within reach\nwith minor hardware improvements. We show that DD plays a major role: it\nsuppresses coherent ZZ crosstalk and non-Markovian dephasing that accumulate\nduring idle gaps on heavy-hex layouts, and it eliminates spurious subthreshold\nclaims that arise when scaled codes without DD are compared against smaller\ncodes with DD. To quantify performance, we derive an entanglement fidelity\nmetric that is computed directly from X- and Z-basis logical-error data and\nprovides per-cycle, SPAM-aware bounds. The entanglement fidelity metric reveals\nthat widely used single-parameter fits used to compute suppression factors can\nmischaracterize or obscure code performance when their assumptions are\nviolated; we identify the strong assumptions of stationarity, unitality, and\nnegligible logical SPAM required for those fits to be valid and show that they\ndo not hold for our data. Our results establish a concrete path to robust tests\nof subthreshold surface-code scaling under biased, non-Markovian noise by\nintegrating QEC with optimized DD on non-native architectures.",
      "url": "http://arxiv.org/abs/2510.18847v1",
      "published_time_eastern_timestamp": 1761068260.0
    },
    {
      "title": "PCMS: Parallel Coupler For Multimodel Simulations",
      "summary": "This paper presents the Parallel Coupler for Multimodel Simulations (PCMS), a\nnew GPU accelerated generalized coupling framework for coupling simulation\ncodes on leadership class supercomputers. PCMS includes distributed control and\nfield mapping methods for up to five dimensions. For field mapping PCMS can\nutilize discretization and field information to accommodate physics\nconstraints. PCMS is demonstrated with a coupling of the gyrokinetic\nmicroturbulence code XGC with a Monte Carlo neutral transport code DEGAS2 and\nwith a 5D distribution function coupling of an energetic particle transport\ncode (GNET) to a gyrokinetic microturbulence code (GTC). Weak scaling is also\ndemonstrated on up to 2,080 GPUs of Frontier with a weak scaling efficiency of\n85%.",
      "url": "http://arxiv.org/abs/2510.18838v1",
      "published_time_eastern_timestamp": 1761067990.0
    },
    {
      "title": "MTraining: Distributed Dynamic Sparse Attention for Efficient Ultra-Long\n  Context Training",
      "summary": "The adoption of long context windows has become a standard feature in Large\nLanguage Models (LLMs), as extended contexts significantly enhance their\ncapacity for complex reasoning and broaden their applicability across diverse\nscenarios. Dynamic sparse attention is a promising approach for reducing the\ncomputational cost of long-context. However, efficiently training LLMs with\ndynamic sparse attention on ultra-long contexts-especially in distributed\nsettings-remains a significant challenge, due in large part to worker- and\nstep-level imbalance. This paper introduces MTraining, a novel distributed\nmethodology leveraging dynamic sparse attention to enable efficient training\nfor LLMs with ultra-long contexts. Specifically, MTraining integrates three key\ncomponents: a dynamic sparse training pattern, balanced sparse ring attention,\nand hierarchical sparse ring attention. These components are designed to\nsynergistically address the computational imbalance and communication overheads\ninherent in dynamic sparse attention mechanisms during the training of models\nwith extensive context lengths. We demonstrate the efficacy of MTraining by\ntraining Qwen2.5-3B, successfully expanding its context window from 32K to 512K\ntokens on a cluster of 32 A100 GPUs. Our evaluations on a comprehensive suite\nof downstream tasks, including RULER, PG-19, InfiniteBench, and Needle In A\nHaystack, reveal that MTraining achieves up to a 6x higher training throughput\nwhile preserving model accuracy. Our code is available at\nhttps://github.com/microsoft/MInference/tree/main/MTraining.",
      "url": "http://arxiv.org/abs/2510.18830v1",
      "published_time_eastern_timestamp": 1761067532.0
    },
    {
      "title": "Actor-Free Continuous Control via Structurally Maximizable Q-Functions",
      "summary": "Value-based algorithms are a cornerstone of off-policy reinforcement learning\ndue to their simplicity and training stability. However, their use has\ntraditionally been restricted to discrete action spaces, as they rely on\nestimating Q-values for individual state-action pairs. In continuous action\nspaces, evaluating the Q-value over the entire action space becomes\ncomputationally infeasible. To address this, actor-critic methods are typically\nemployed, where a critic is trained on off-policy data to estimate Q-values,\nand an actor is trained to maximize the critic's output. Despite their\npopularity, these methods often suffer from instability during training. In\nthis work, we propose a purely value-based framework for continuous control\nthat revisits structural maximization of Q-functions, introducing a set of key\narchitectural and algorithmic choices to enable efficient and stable learning.\nWe evaluate the proposed actor-free Q-learning approach on a range of standard\nsimulation tasks, demonstrating performance and sample efficiency on par with\nstate-of-the-art baselines, without the cost of learning a separate actor.\nParticularly, in environments with constrained action spaces, where the value\nfunctions are typically non-smooth, our method with structural maximization\noutperforms traditional actor-critic methods with gradient-based maximization.\nWe have released our code at https://github.com/USC-Lira/Q3C.",
      "url": "http://arxiv.org/abs/2510.18828v1",
      "published_time_eastern_timestamp": 1761067467.0
    },
    {
      "title": "BO4Mob: Bayesian Optimization Benchmarks for High-Dimensional Urban\n  Mobility Problem",
      "summary": "We introduce \\textbf{BO4Mob}, a new benchmark framework for high-dimensional\nBayesian Optimization (BO), driven by the challenge of origin-destination (OD)\ntravel demand estimation in large urban road networks. Estimating OD travel\ndemand from limited traffic sensor data is a difficult inverse optimization\nproblem, particularly in real-world, large-scale transportation networks. This\nproblem involves optimizing over high-dimensional continuous spaces where each\nobjective evaluation is computationally expensive, stochastic, and\nnon-differentiable. BO4Mob comprises five scenarios based on real-world San\nJose, CA road networks, with input dimensions scaling up to 10,100. These\nscenarios utilize high-resolution, open-source traffic simulations that\nincorporate realistic nonlinear and stochastic dynamics. We demonstrate the\nbenchmark's utility by evaluating five optimization methods: three\nstate-of-the-art BO algorithms and two non-BO baselines. This benchmark is\ndesigned to support both the development of scalable optimization algorithms\nand their application for the design of data-driven urban mobility models,\nincluding high-resolution digital twins of metropolitan road networks. Code and\ndocumentation are available at https://github.com/UMN-Choi-Lab/BO4Mob.",
      "url": "http://arxiv.org/abs/2510.18824v1",
      "published_time_eastern_timestamp": 1761067348.0
    },
    {
      "title": "Search Self-play: Pushing the Frontier of Agent Capability without\n  Supervision",
      "summary": "Reinforcement learning with verifiable rewards (RLVR) has become the\nmainstream technique for training LLM agents. However, RLVR highly depends on\nwell-crafted task queries and corresponding ground-truth answers to provide\naccurate rewards, which requires massive human efforts and hinders the RL\nscaling processes, especially under agentic scenarios. Although a few recent\nworks explore task synthesis methods, the difficulty of generated agentic tasks\ncan hardly be controlled to provide effective RL training advantages. To\nachieve agentic RLVR with higher scalability, we explore self-play training for\ndeep search agents, in which the learning LLM utilizes multi-turn search engine\ncalling and acts simultaneously as both a task proposer and a problem solver.\nThe task proposer aims to generate deep search queries with well-defined\nground-truth answers and increasing task difficulty. The problem solver tries\nto handle the generated search queries and output the correct answer\npredictions. To ensure that each generated search query has accurate ground\ntruth, we collect all the searching results from the proposer's trajectory as\nexternal knowledge, then conduct retrieval-augmentation generation (RAG) to\ntest whether the proposed query can be correctly answered with all necessary\nsearch documents provided. In this search self-play (SSP) game, the proposer\nand the solver co-evolve their agent capabilities through both competition and\ncooperation. With substantial experimental results, we find that SSP can\nsignificantly improve search agents' performance uniformly on various\nbenchmarks without any supervision under both from-scratch and continuous RL\ntraining setups. The code is at https://github.com/Alibaba-Quark/SSP.",
      "url": "http://arxiv.org/abs/2510.18821v1",
      "published_time_eastern_timestamp": 1761067175.0
    },
    {
      "title": "Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for\n  Industrial Asset Health Monitoring",
      "summary": "Small Language Models (SLMs) are becoming increasingly popular in specialized\nfields, such as industrial applications, due to their efficiency, lower\ncomputational requirements, and ability to be fine-tuned for domain-specific\ntasks, enabling accurate and cost-effective solutions. However, performing\ncomplex reasoning using SLMs in specialized fields such as Industry 4.0 remains\nchallenging. In this paper, we propose a knowledge distillation framework for\nindustrial asset health, which transfers reasoning capabilities via\nChain-of-Thought (CoT) distillation from Large Language Models (LLMs) to\nsmaller, more efficient models (SLMs). We discuss the advantages and the\nprocess of distilling LLMs using multi-choice question answering (MCQA) prompts\nto enhance reasoning and refine decision-making. We also perform in-context\nlearning to verify the quality of the generated knowledge and benchmark the\nperformance of fine-tuned SLMs with generated knowledge against widely used\nLLMs. The results show that the fine-tuned SLMs with CoT reasoning outperform\nthe base models by a significant margin, narrowing the gap to their LLM\ncounterparts. Our code is open-sourced at:\nhttps://github.com/IBM/FailureSensorIQ.",
      "url": "http://arxiv.org/abs/2510.18817v1",
      "published_time_eastern_timestamp": 1761067104.0
    },
    {
      "title": "Online SFT for LLM Reasoning: Surprising Effectiveness of Self-Tuning\n  without Rewards",
      "summary": "We present a simple, self-help online supervised finetuning (OSFT) paradigm\nfor LLM reasoning. In this paradigm, the model generates its own responses and\nis immediately finetuned on this self-generated data. OSFT is a highly\nefficient training strategy for LLM reasoning, as it is reward-free and uses\njust one rollout by default. Experiment results show that OSFT achieves\ndownstream performance on challenging mathematical reasoning tasks comparable\nto strong reinforcement learning with verifiable rewards (RLVR) methods such as\nGRPO. Our ablation study further demonstrates the efficiency and robustness of\nOSFT. The major mechanism of OSFT lies in facilitating the model's own existing\npreference (latent knowledge) learned from pretraining, which leads to\nreasoning ability improvement. We believe that OSFT offers an efficient and\npromising alternative to more complex, reward-based training paradigms. Our\ncode is available at https://github.com/ElementQi/OnlineSFT.",
      "url": "http://arxiv.org/abs/2510.18814v1",
      "published_time_eastern_timestamp": 1761066956.0
    },
    {
      "title": "Integrating Large Language Models and Evaluating Student Outcomes in an\n  Introductory Computer Science Course",
      "summary": "Generative AI (GenAI) models have broad implications for education in\ngeneral, impacting the foundations of what we teach and how we assess. This is\nespecially true in computing, where LLMs tuned for coding have demonstrated\nshockingly good performance on the types of assignments historically used in\nintroductory CS (CS1) courses. As a result, CS1 courses will need to change\nwhat skills are taught and how they are assessed. Computing education\nresearchers have begun to study student use of LLMs, but there remains much to\nbe understood about the ways that these tools affect student outcomes. In this\npaper, we present the design and evaluation of a new CS1 course at a large\nresearch-intensive university that integrates the use of LLMs as a learning\ntool for students. We describe the design principles used to create our new\nCS1-LLM course, our new course objectives, and evaluation of student outcomes\nand perceptions throughout the course as measured by assessment scores and\nsurveys. Our findings suggest that 1) student exam performance outcomes,\nincluding differences among demographic groups, are largely similar to\nhistorical outcomes for courses without integration of LLM tools, 2) large,\nopen-ended projects may be particularly valuable in an LLM context, and 3)\nstudents predominantly found the LLM tools helpful, although some had concerns\nregarding over-reliance on the tools.",
      "url": "http://arxiv.org/abs/2510.18806v1",
      "published_time_eastern_timestamp": 1761065994.0
    },
    {
      "title": "WebSeer: Training Deeper Search Agents through Reinforcement Learning\n  with Self-Reflection",
      "summary": "Search agents have achieved significant advancements in enabling intelligent\ninformation retrieval and decision-making within interactive environments.\nAlthough reinforcement learning has been employed to train agentic models\ncapable of more dynamic interactive retrieval, existing methods are limited by\nshallow tool-use depth and the accumulation of errors over multiple iterative\ninteractions. In this paper, we present WebSeer, a more intelligent search\nagent trained via reinforcement learning enhanced with a self-reflection\nmechanism. Specifically, we construct a large dataset annotated with reflection\npatterns and design a two-stage training framework that unifies cold start and\nreinforcement learning within the self-reflection paradigm for real-world\nweb-based environments, which enables the model to generate longer and more\nreflective tool-use trajectories. Our approach substantially extends tool-use\nchains and improves answer accuracy. Using a single 14B model, we achieve\nstate-of-the-art results on HotpotQA and SimpleQA, with accuracies of 72.3% and\n90.0%, respectively, and demonstrate strong generalization to\nout-of-distribution datasets. The code is available at\nhttps://github.com/99hgz/WebSeer",
      "url": "http://arxiv.org/abs/2510.18798v1",
      "published_time_eastern_timestamp": 1761065520.0
    },
    {
      "title": "ProCLIP: Progressive Vision-Language Alignment via LLM-based Embedder",
      "summary": "The original CLIP text encoder is limited by a maximum input length of 77\ntokens, which hampers its ability to effectively process long texts and perform\nfine-grained semantic understanding. In addition, the CLIP text encoder lacks\nsupport for multilingual inputs. All these limitations significantly restrict\nits applicability across a broader range of tasks. Recent studies have\nattempted to replace the CLIP text encoder with an LLM-based embedder to\nenhance its ability in processing long texts, multilingual understanding, and\nfine-grained semantic comprehension. However, because the representation spaces\nof LLMs and the vision-language space of CLIP are pretrained independently\nwithout alignment priors, direct alignment using contrastive learning can\ndisrupt the intrinsic vision-language alignment in the CLIP image encoder,\nleading to an underutilization of the knowledge acquired during pre-training.\nTo address this challenge, we propose ProCLIP, a curriculum learning-based\nprogressive vision-language alignment framework to effectively align the CLIP\nimage encoder with an LLM-based embedder. Specifically, ProCLIP first distills\nknowledge from CLIP's text encoder into the LLM-based embedder to leverage\nCLIP's rich pretrained knowledge while establishing initial alignment between\nthe LLM embedder and CLIP image encoder. Subsequently, ProCLIP further aligns\nthe CLIP image encoder with the LLM-based embedder through image-text\ncontrastive tuning, employing self-distillation regularization to avoid\noverfitting. To achieve a more effective alignment, instance semantic alignment\nloss and embedding structure alignment loss are employed during representation\ninheritance and contrastive tuning. The Code is available at\nhttps://github.com/VisionXLab/ProCLIP",
      "url": "http://arxiv.org/abs/2510.18795v1",
      "published_time_eastern_timestamp": 1761065329.0
    },
    {
      "title": "Rebellious Student: A Complementary Learning Framework for Background\n  Feature Enhancement in Hyperspectral Anomaly Detection",
      "summary": "A recent class of hyperspectral anomaly detection methods that can be trained\nonce on background datasets and then universally deployed -- without per-scene\nretraining or parameter tuning -- has demonstrated remarkable efficiency and\nrobustness. Building upon this paradigm, we focus on the integration of\nspectral and spatial cues and introduce a novel \"Rebellious Student\" framework\nfor complementary feature learning. Unlike conventional teacher-student\nparadigms driven by imitation, our method intentionally trains the spatial\nbranch to diverge from the spectral teacher, thereby learning complementary\nspatial patterns that the teacher fails to capture. A two-stage learning\nstrategy is adopted: (1) a spectral enhancement network is first trained via\nreverse distillation to obtain robust background spectral representations; and\n(2) a spatial network -- the rebellious student -- is subsequently optimized\nusing decorrelation losses that enforce feature orthogonality while maintaining\nreconstruction fidelity to avoid irrelevant noise. Once trained, the framework\nenhances both spectral and spatial background features, enabling parameter-free\nand training-free anomaly detection when paired with conventional detectors.\nExtensive experiments on the HAD100 benchmark show substantial improvements\nover several established baselines with minimal computational overhead,\nconfirming the effectiveness and generality of the proposed complementary\nlearning paradigm. Our code is publicly available at\nhttps://github.com/xjpp2016/FERS.",
      "url": "http://arxiv.org/abs/2510.18781v1",
      "published_time_eastern_timestamp": 1761064316.0
    },
    {
      "title": "KAT-Coder Technical Report",
      "summary": "Recent advances in large language models (LLMs) have enabled progress in\nagentic coding, where models autonomously reason, plan, and act within\ninteractive software development workflows. However, bridging the gap between\nstatic text-based training and dynamic real-world agentic execution remains a\ncore challenge. In this technical report, we present KAT-Coder, a large-scale\nagentic code model trained through a multi-stage curriculum encompassing\nMid-Term Training, Supervised Fine-Tuning (SFT), Reinforcement Fine-Tuning\n(RFT), and Reinforcement-to-Deployment Adaptation. The Mid-Term stage enhances\nreasoning, planning, and reflection capabilities through a corpus of real\nsoftware engineering data and synthetic agentic interactions. The SFT stage\nconstructs a million-sample dataset balancing twenty programming languages, ten\ndevelopment contexts, and ten task archetypes. The RFT stage introduces a novel\nmulti-ground-truth reward formulation for stable and sample-efficient policy\noptimization. Finally, the Reinforcement-to-Deployment phase adapts the model\nto production-grade IDE environments using Error-Masked SFT and Tree-Structured\nTrajectory Training. In summary, these stages enable KAT-Coder to achieve\nrobust tool-use reliability, instruction alignment, and long-context reasoning,\nforming a deployable foundation for real-world intelligent coding agents. Our\nKAT series 32B model, KAT-Dev, has been open-sourced on\nhttps://huggingface.co/Kwaipilot/KAT-Dev.",
      "url": "http://arxiv.org/abs/2510.18779v1",
      "published_time_eastern_timestamp": 1761064067.0
    },
    {
      "title": "Simple logical quantum computation with concatenated symplectic double\n  codes",
      "summary": "There have been significant recent advances in constructing theoretical and\npractical quantum error correcting codes that function well as quantum\nmemories; however, performing fault-tolerant logical gates on these codes is\nless studied, and the protocols that do exist often require significant\ncomplexity. Building off the symplectic double construction, we investigate\nconcatenated symplectic double codes, which have a rich set of logical gates\nimplementable using only physical single-qubit gates and qubit relabeling.\nCombined with an injected logical phase gate, the full Clifford group on a\nsingle codeblock is achieved through a functionally simple circuit. We perform\ncircuit-level simulations of state preparation and quantum error correction on\nthese codes and show that they have promising performance at near\nstate-of-the-art physical error rates. As such, we argue that concatenated\nsymplectic double codes are strong contenders as the underlying computational\ncode on medium- to large-scale quantum computers.",
      "url": "http://arxiv.org/abs/2510.18753v1",
      "published_time_eastern_timestamp": 1761062444.0
    },
    {
      "title": "Moving Light Adaptive Colonoscopy Reconstruction via\n  Illumination-Attenuation-Aware 3D Gaussian Splatting",
      "summary": "3D Gaussian Splatting (3DGS) has emerged as a pivotal technique for real-time\nview synthesis in colonoscopy, enabling critical applications such as virtual\ncolonoscopy and lesion tracking. However, the vanilla 3DGS assumes static\nillumination and that observed appearance depends solely on viewing angle,\nwhich causes incompatibility with the photometric variations in colonoscopic\nscenes induced by dynamic light source/camera. This mismatch forces most 3DGS\nmethods to introduce structure-violating vaporous Gaussian blobs between the\ncamera and tissues to compensate for illumination attenuation, ultimately\ndegrading the quality of 3D reconstructions. Previous works only consider the\nillumination attenuation caused by light distance, ignoring the physical\ncharacters of light source and camera. In this paper, we propose ColIAGS, an\nimproved 3DGS framework tailored for colonoscopy. To mimic realistic appearance\nunder varying illumination, we introduce an Improved Appearance Modeling with\ntwo types of illumination attenuation factors, which enables Gaussians to adapt\nto photometric variations while preserving geometry accuracy. To ensure the\ngeometry approximation condition of appearance modeling, we propose an Improved\nGeometry Modeling using high-dimensional view embedding to enhance Gaussian\ngeometry attribute prediction. Furthermore, another cosine embedding input is\nleveraged to generate illumination attenuation solutions in an implicit manner.\nComprehensive experimental results on standard benchmarks demonstrate that our\nproposed ColIAGS achieves the dual capabilities of novel view synthesis and\naccurate geometric reconstruction. It notably outperforms other\nstate-of-the-art methods by achieving superior rendering fidelity while\nsignificantly reducing Depth MSE. Code will be available.",
      "url": "http://arxiv.org/abs/2510.18739v1",
      "published_time_eastern_timestamp": 1761061463.0
    },
    {
      "title": "Undirected Multicast Network Coding Gaps via Locally Decodable Codes",
      "summary": "The network coding problem asks whether data throughput in a network can be\nincreased using coding (compared to treating bits as commodities in a flow).\nWhile it is well-known that a network coding advantage exists in directed\ngraphs, the situation in undirected graphs is much less understood -- in\nparticular, despite significant effort, it is not even known whether network\ncoding is helpful at all for unicast sessions.\n  In this paper we study the multi-source multicast network coding problem in\nundirected graphs. There are $k$ sources broadcasting each to a subset of nodes\nin a graph of size $n$. The corresponding combinatorial problem is a version of\nthe Steiner tree packing problem, and the network coding question asks whether\nthe multicast coding rate exceeds the tree-packing rate.\n  We give the first super-constant bound to this problem, demonstrating an\nexample with a coding advantage of $\\Omega(\\log k)$. In terms of graph size, we\nobtain a lower bound of $2^{\\tilde{\\Omega}(\\sqrt{\\log \\log n})}$. We also\nobtain an upper bound of $O(\\log n)$ on the gap.\n  Our main technical contribution is a new reduction that converts\nlocally-decodable codes in the low-error regime into multicast coding\ninstances. This gives rise to a new family of explicitly constructed graphs,\nwhich may have other applications.",
      "url": "http://arxiv.org/abs/2510.18737v1",
      "published_time_eastern_timestamp": 1761061189.0
    }
  ]
}
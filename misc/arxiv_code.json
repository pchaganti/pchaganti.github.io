{
  "last_updated": "2025-09-24T20:54:25.450314-04:00",
  "papers": [
    {
      "title": "Uniqueness of Complementary Recovery in Holographic Error-Correcting\n  Codes",
      "summary": "Holographic codes are a type of error-correcting code with extra geometric\nstructure ensured by a ``complementary recovery'' property: given a division of\nthe physical Hilbert space $\\mathcal{H}$ into $\\mathcal{H}_A$ and\n$\\mathcal{H}_{\\bar A}$, and an algebra of physical operators\n$\\mathcal{M}\\subseteq (\\mathcal{L}(\\mathcal{H}_A)\\otimes I_{\\mathcal{H}_{\\bar\nA}})$, the logical operators in $\\mathcal{L}(\\mathcal{H}_L)\\simeq\n\\mathcal{L}(P\\mathcal{H})$ which can be created by acting in $\\mathcal{M}$ are\nidentical to the logical operators whose expectation values cannot be altered\nby acting in the commutant $\\mathcal{M}^\\prime$, and vice versa. In\narXiv:2110.14691, a uniqueness theorem was stated: the only possible tuple of\n(code, bipartition, algebra) which can exhibit complementary recovery is the\nmaximal one $\\mathcal{M}=P(\\mathcal{L}(\\mathcal{H}_A)\\otimes\nI_{\\mathcal{H}_{\\bar A}})P$. We point out a counterexample to this result,\nusing a ``non-adjacent'' bipartition of a four-qubit code proposed in\narXiv:2110.14691. We show that the failure of uniqueness is due to a failure to\nenforce error correction against erasure of $\\mathcal{H}_{\\bar A}$, which\nrequires enforcing the algebraic Knill-Laflamme condition $[P E_i^\\dagger E_j\nP,\\mathcal{M}]=0$ for each pair of error operators. When we add the additional\nrequirement that $\\mathcal{M}$ be correctable with respect to this channel,\nuniqueness is restored, and we re-prove the theorem of arXiv:2110.14691 with\nthis added assumption. We present the list of bipartitions of the ``atomic''\nholographic codes in arXiv:2110.14691 in which the correctability assumption\ncan be violated.",
      "url": "http://arxiv.org/abs/2509.19299v1",
      "published_time_eastern_timestamp": 1758650356.0
    },
    {
      "title": "VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with\n  Voxel-Aligned Prediction",
      "summary": "Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective\nsolution for novel view synthesis. Existing methods predominantly rely on a\npixel-aligned Gaussian prediction paradigm, where each 2D pixel is mapped to a\n3D Gaussian. We rethink this widely adopted formulation and identify several\ninherent limitations: it renders the reconstructed 3D models heavily dependent\non the number of input views, leads to view-biased density distributions, and\nintroduces alignment errors, particularly when source views contain occlusions\nor low texture. To address these challenges, we introduce VolSplat, a new\nmulti-view feed-forward paradigm that replaces pixel alignment with\nvoxel-aligned Gaussians. By directly predicting Gaussians from a predicted 3D\nvoxel grid, it overcomes pixel alignment's reliance on error-prone 2D feature\nmatching, ensuring robust multi-view consistency. Furthermore, it enables\nadaptive control over Gaussian density based on 3D scene complexity, yielding\nmore faithful Gaussian point clouds, improved geometric consistency, and\nenhanced novel-view rendering quality. Experiments on widely used benchmarks\nincluding RealEstate10K and ScanNet demonstrate that VolSplat achieves\nstate-of-the-art performance while producing more plausible and view-consistent\nGaussian reconstructions. In addition to superior results, our approach\nestablishes a more scalable framework for feed-forward 3D reconstruction with\ndenser and more robust representations, paving the way for further research in\nwider communities. The video results, code and trained models are available on\nour project page: https://lhmd.top/volsplat.",
      "url": "http://arxiv.org/abs/2509.19297v1",
      "published_time_eastern_timestamp": 1758650342.0
    },
    {
      "title": "Accelerating Gravitational $N$-Body Simulations Using the RISC-V-Based\n  Tenstorrent Wormhole",
      "summary": "Although originally developed primarily for artificial intelligence\nworkloads, RISC-V-based accelerators are also emerging as attractive platforms\nfor high-performance scientific computing. In this work, we present our\napproach to accelerating an astrophysical $N$-body code on the RISC-V-based\nWormhole n300 card developed by Tenstorrent. Our results show that this\nplatform can be highly competitive for astrophysical simulations employing this\nclass of algorithms, delivering more than a $2 \\times$ speedup and\napproximately $2 \\times$ energy savings compared to a highly optimized CPU\nimplementation of the same code.",
      "url": "http://arxiv.org/abs/2509.19294v1",
      "published_time_eastern_timestamp": 1758650194.0
    },
    {
      "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset",
      "summary": "Intent classification models have made a lot of progress in recent years.\nHowever, previous studies primarily focus on high-resource languages datasets,\nwhich results in a gap for low-resource languages and for regions with a high\nrate of illiterate people where languages are more spoken than read or written.\nThis is the case in Senegal, for example, where Wolof is spoken by around 90\\%\nof the population, with an illiteracy rate of 42\\% for the country. Wolof is\nactually spoken by more than 10 million people in West African region. To\ntackle such limitations, we release a Wolof Intent Classification Dataset\n(WolBanking77), for academic research in intent classification. WolBanking77\ncurrently contains 9,791 text sentences in the banking domain and more than 4\nhours of spoken sentences. Experiments on various baselines are conducted in\nthis work, including text and voice state-of-the-art models. The results are\nvery promising on this current dataset. This paper also provides detailed\nanalyses of the contents of the data. We report baseline f1-score and word\nerror rate metrics respectively on NLP and ASR models trained on WolBanking77\ndataset and also comparisons between models. We plan to share and conduct\ndataset maintenance, updates and to release open-source code.",
      "url": "http://arxiv.org/abs/2509.19271v1",
      "published_time_eastern_timestamp": 1758648850.0
    },
    {
      "title": "Adversarially-Refined VQ-GAN with Dense Motion Tokenization for\n  Spatio-Temporal Heatmaps",
      "summary": "Continuous human motion understanding remains a core challenge in computer\nvision due to its high dimensionality and inherent redundancy. Efficient\ncompression and representation are crucial for analyzing complex motion\ndynamics. In this work, we introduce an adversarially-refined VQ-GAN framework\nwith dense motion tokenization for compressing spatio-temporal heatmaps while\npreserving the fine-grained traces of human motion. Our approach combines dense\nmotion tokenization with adversarial refinement, which eliminates\nreconstruction artifacts like motion smearing and temporal misalignment\nobserved in non-adversarial baselines. Our experiments on the CMU Panoptic\ndataset provide conclusive evidence of our method's superiority, outperforming\nthe dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%.\nFurthermore, our dense tokenization strategy enables a novel analysis of motion\ncomplexity, revealing that 2D motion can be optimally represented with a\ncompact 128-token vocabulary, while 3D motion's complexity demands a much\nlarger 1024-token codebook for faithful reconstruction. These results establish\npractical deployment feasibility across diverse motion analysis applications.\nThe code base for this work is available at\nhttps://github.com/TeCSAR-UNCC/Pose-Quantization.",
      "url": "http://arxiv.org/abs/2509.19252v1",
      "published_time_eastern_timestamp": 1758647540.0
    },
    {
      "title": "AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and\n  Expertise Orchestration for Effective and Efficient Collaboration",
      "summary": "Proper initialization is crucial for any system, particularly in multi-agent\nsystems (MAS), where it plays a pivotal role in determining both the system's\nefficiency and effectiveness. However, existing MAS initialization methods do\nnot fully account for the collaborative needs of the generated agents in\nsubsequent stages. Inspired by the principles of effective team composition, we\npropose AgentInit, which aims to optimize the structure of agent teams.\nSpecifically, in addition to multi-round interactions and reflections between\nagents during agent generation, AgentInit incorporates a Natural Language to\nFormat mechanism to ensure consistency and standardization. Balanced team\nselection strategies using Pareto principles are subsequently applied to\njointly consider agent team diversity and task relevance to promote effective\nand efficient collaboration and enhance overall system performance. Experiments\nshow that AgentInit consistently outperforms state-of-the-art initialization\nmethods and pre-defined strategies across various frameworks and tasks,\nachieving an overall performance improvement of up to 1.2 and 1.6,\nrespectively, while also significantly reducing token consumption. Further\nanalysis confirms its strong transferability to similar tasks and verifies the\neffectiveness of its key components, demonstrating its capability and\nadaptability as a reliable MAS initialization method. Source code and models\nare available at https://github.com/1737423697/AgentInit.",
      "url": "http://arxiv.org/abs/2509.19236v1",
      "published_time_eastern_timestamp": 1758646734.0
    },
    {
      "title": "Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene\n  Descriptions",
      "summary": "Contrastively-trained Vision-Language Models (VLMs), such as CLIP, have\nbecome the standard approach for learning discriminative vision-language\nrepresentations. However, these models often exhibit shallow language\nunderstanding, manifesting bag-of-words behaviour. These limitations are\nreinforced by their dual-encoder design, which induces a modality gap.\nAdditionally, the reliance on vast web-collected data corpora for training\nmakes the process computationally expensive and introduces significant privacy\nconcerns. To address these limitations, in this work, we challenge the\nnecessity of vision encoders for retrieval tasks by introducing a vision-free,\nsingle-encoder retrieval pipeline. Departing from the traditional text-to-image\nretrieval paradigm, we migrate to a text-to-text paradigm with the assistance\nof VLLM-generated structured image descriptions. We demonstrate that this\nparadigm shift has significant advantages, including a substantial reduction of\nthe modality gap, improved compositionality, and better performance on short\nand long caption queries, all attainable with only a few hours of calibration\non two GPUs. Additionally, substituting raw images with textual descriptions\nintroduces a more privacy-friendly alternative for retrieval. To further assess\ngeneralisation and address some of the shortcomings of prior compositionality\nbenchmarks, we release two benchmarks derived from Flickr30k and COCO,\ncontaining diverse compositional queries made of short captions, which we coin\nsubFlickr and subCOCO. Our vision-free retriever matches and often surpasses\ntraditional multimodal models. Importantly, our approach achieves\nstate-of-the-art zero-shot performance on multiple retrieval and\ncompositionality benchmarks, with models as small as 0.3B parameters. Code is\navailable at: https://github.com/IoannaNti/LexiCLIP",
      "url": "http://arxiv.org/abs/2509.19203v1",
      "published_time_eastern_timestamp": 1758644547.0
    },
    {
      "title": "Improving Test-Time Performance of RVQ-based Neural Codecs",
      "summary": "The residual vector quantization (RVQ) technique plays a central role in\nrecent advances in neural audio codecs. These models effectively synthesize\nhigh-fidelity audio from a limited number of codes due to the hierarchical\nstructure among quantization levels. In this paper, we propose an encoding\nalgorithm to further enhance the synthesis quality of RVQ-based neural codecs\nat test-time. Firstly, we point out the suboptimal nature of quantized vectors\ngenerated by conventional methods. We demonstrate that quantization error can\nbe mitigated by selecting a different set of codes. Subsequently, we present\nour encoding algorithm, designed to identify a set of discrete codes that\nachieve a lower quantization error. We then apply the proposed method to\npre-trained models and evaluate its efficacy using diverse metrics. Our\nexperimental findings validate that our method not only reduces quantization\nerrors, but also improves synthesis quality.",
      "url": "http://arxiv.org/abs/2509.19186v1",
      "published_time_eastern_timestamp": 1758643347.0
    },
    {
      "title": "A noise-robust Monte Carlo method for electric field calculations in\n  EMC3",
      "summary": "One of the main codes to analyze and optimize stellarator configurations is\nthe EMC3 code, which implements a state-of-the-art 3D Monte Carlo plasma edge\ntransport code. However, so far, a self-consistent treatment of the E x B drift\nis absent. This plasma drift is known to significantly impact the particle and\nheat distribution in the plasma edge. It is desirable to incorporate this drift\ninto EMC3 to improve the predictive capabilities of the code. The calculation\nof the E x B drift requires the approximation of the electric field E, which is\nproportional to the gradient of the electric potential $ \\varphi $. In previous\nwork, the gradient was calculated with a least squares method based on a finite\ndifference approximation of the electric potential. However, due to the\nstochastic nature of EMC3, the output plasma fields computed by the code are\ninherently noisy. The finite difference method further amplifies the noise,\nwith the amplification growing as the grid size decreases. We continue from,\nwhich introduced a new noise-robust method for 1D derivatives. We extend the\nnoise-robust method to 2D and apply it to the electric potential. We show that\na PDE can be derived that describes the evolution of the electric field in case\nof a uniform diffusion coefficient. This PDE allows us to approximate the\nelectric field directly with a Monte Carlo simulation, thus avoiding the need\nfor a finite difference approximation. We illustrate the accuracy of the method\nand the noise robustness with a test case.",
      "url": "http://arxiv.org/abs/2509.19178v1",
      "published_time_eastern_timestamp": 1758642590.0
    },
    {
      "title": "Spectra of Earth-like exoplanets with different rotation periods",
      "summary": "We investigate the spectra of Earth-like planets but with different axial\nrotation periods. Using the general circulation model of the atmosphere and\nconsidering the atmospheric circulation lasting for two years, we calculated\nthe radiation spectra of the Earth and the exo-Earth rotating with periods of 1\nand 100 days, respectively. The radiation spectra of the atmospheres were\ncalculated with the SBDART code. We analyzed the spectrum of upward radiation\nat altitudes of 1 and 11 km in wavelength ranges of 1 to 18 and 0.3 to 1\nmicron. The following common features were obtained for the Earth and the\nexo-Earth: (1) the planets exhibit a wide absorption band of CO2 around 14\nmicron; (2) the radiation spectra at different locations near the equator show\nno significant differences; and (3) if the spectrum is integrated over the\nentire disk of the Earth/exo-Earth, the difference in the spectral signal\nobtained in observations from different directions becomes substantially lower\nthan the difference between the results of observations of individual regions\nof the planets. The differences in the spectra of exoplanets, which differ from\nthe Earth only in axial rotation period, are comparable to the differences\nassociated with changes in the angle of viewing the planet. Consequently, if\nthe observation angle is not known, the analysis of the spectrum of the planet\ncannot be used to determine its axial rotation period. The maximal differences\nin the spectra of Earth-like exoplanets were obtained for wavelengths of about\n5-10 and 13-16 micron. By analyzing the spectrum at wavelengths around 9.4-10\nmicron, we can determine whether the atmosphere of the exoplanet contains ozone\nor not. Since ozone is essential for life, the 9.4-10 micron band may be\nimportant for future observations of Earth-like exoplanets.",
      "url": "http://arxiv.org/abs/2509.19174v1",
      "published_time_eastern_timestamp": 1758642463.0
    },
    {
      "title": "RoSe: Robust Self-supervised Stereo Matching under Adverse Weather\n  Conditions",
      "summary": "Recent self-supervised stereo matching methods have made significant\nprogress, but their performance significantly degrades under adverse weather\nconditions such as night, rain, and fog. We identify two primary weaknesses\ncontributing to this performance degradation. First, adverse weather introduces\nnoise and reduces visibility, making CNN-based feature extractors struggle with\ndegraded regions like reflective and textureless areas. Second, these degraded\nregions can disrupt accurate pixel correspondences, leading to ineffective\nsupervision based on the photometric consistency assumption. To address these\nchallenges, we propose injecting robust priors derived from the visual\nfoundation model into the CNN-based feature extractor to improve feature\nrepresentation under adverse weather conditions. We then introduce scene\ncorrespondence priors to construct robust supervisory signals rather than\nrelying solely on the photometric consistency assumption. Specifically, we\ncreate synthetic stereo datasets with realistic weather degradations. These\ndatasets feature clear and adverse image pairs that maintain the same semantic\ncontext and disparity, preserving the scene correspondence property. With this\nknowledge, we propose a robust self-supervised training paradigm, consisting of\ntwo key steps: robust self-supervised scene correspondence learning and adverse\nweather distillation. Both steps aim to align underlying scene results from\nclean and adverse image pairs, thus improving model disparity estimation under\nadverse weather effects. Extensive experiments demonstrate the effectiveness\nand versatility of our proposed solution, which outperforms existing\nstate-of-the-art self-supervised methods. Codes are available at\n\\textcolor{blue}{https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions}.",
      "url": "http://arxiv.org/abs/2509.19165v1",
      "published_time_eastern_timestamp": 1758642100.0
    },
    {
      "title": "The effects on structure of a momentum coupling between dark matter and\n  quintessence",
      "summary": "Given the mysterious nature of dark matter and dark energy, and the\npersistent tensions in cosmological data, it is worthwhile exploring more\nexotic physics in the dark sector, such as a momentum coupling between dark\nmatter and dark energy, specifically in the form of a quintessence field. In\nthis study, using collisionless N-body numerical simulations with a modified\nversion of the RAMSES code, we follow up previous work to investigate the\nconsequences of this model on dark matter halos and their substructures. We\nconsider both the sign of the coupling and the imprints on structure formation\nand halo properties at a statistical level. We find that there is a clear\nenhancement (reduction) of substructure if the sign of the coupling is negative\n(positive) and that the dynamical state of the dark matter halos, particularly\nhost halos, is undervirialised (overvirialised) at redshift zero when compared\nto uncoupled models or a reference $\\Lambda$CDM simulation. Furthermore,\npositive coupling leads to less concentrated, less cuspy halos, whereas\nnegative coupling leads to the opposite.",
      "url": "http://arxiv.org/abs/2509.19164v1",
      "published_time_eastern_timestamp": 1758642094.0
    },
    {
      "title": "CayleyPy Growth: Efficient growth computations and hundreds of new\n  conjectures on Cayley graphs (Brief version)",
      "summary": "This is the third paper of the CayleyPy project applying artificial\nintelligence to problems in group theory. We announce the first public release\nof CayleyPy, an open source Python library for computations with Cayley and\nSchreier graphs. Compared with systems such as GAP and Sage, CayleyPy handles\nmuch larger graphs and performs several orders of magnitude faster.\n  Using CayleyPy we obtained about 200 new conjectures on Cayley and Schreier\ngraphs, focused on diameters and growth. For many Cayley graphs of symmetric\ngroups Sn we observe quasi polynomial diameter formulas: a small set of\nquadratic or linear polynomials indexed by n mod s. We conjecture that this is\na general phenomenon, giving efficient diameter computation despite the problem\nbeing NP hard. We propose a refinement of the Babai type conjecture on\ndiameters of Sn: n^2/2 + 4n upper bounds in the undirected case, compared to\nprevious O(n^2) bounds. We also provide explicit generator families, related to\ninvolutions in a square with whiskers pattern, conjectured to maximize the\ndiameter; search confirms this for all n up to 15. We further conjecture an\nanswer to a question posed by V M Glushkov in 1968 on directed Cayley graphs\ngenerated by a cyclic shift and a transposition.\n  For nilpotent groups we conjecture an improvement of J S Ellenberg's results\non upper unitriangular matrices over Z/pZ, showing linear dependence of\ndiameter on p. Moreover.\n  Some conjectures are LLM friendly, naturally stated as sorting problems\nverifiable by algorithms or Python code. To benchmark path finding we created\nmore than 10 Kaggle datasets. CayleyPy works with arbitrary permutation or\nmatrix groups and includes over 100 predefined generators. Our growth\ncomputation code outperforms GAP and Sage up to 1000 times in speed and size.",
      "url": "http://arxiv.org/abs/2509.19162v1",
      "published_time_eastern_timestamp": 1758642036.0
    },
    {
      "title": "Efficient Reinforcement Learning by Reducing Forgetting with Elephant\n  Activation Functions",
      "summary": "Catastrophic forgetting has remained a significant challenge for efficient\nreinforcement learning for decades (Ring 1994, Rivest and Precup 2003). While\nrecent works have proposed effective methods to mitigate this issue, they\nmainly focus on the algorithmic side. Meanwhile, we do not fully understand\nwhat architectural properties of neural networks lead to catastrophic\nforgetting. This study aims to fill this gap by studying the role of activation\nfunctions in the training dynamics of neural networks and their impact on\ncatastrophic forgetting in reinforcement learning setup. Our study reveals\nthat, besides sparse representations, the gradient sparsity of activation\nfunctions also plays an important role in reducing forgetting. Based on this\ninsight, we propose a new class of activation functions, elephant activation\nfunctions, that can generate both sparse outputs and sparse gradients. We show\nthat by simply replacing classical activation functions with elephant\nactivation functions in the neural networks of value-based algorithms, we can\nsignificantly improve the resilience of neural networks to catastrophic\nforgetting, thus making reinforcement learning more sample-efficient and\nmemory-efficient.",
      "url": "http://arxiv.org/abs/2509.19159v1",
      "published_time_eastern_timestamp": 1758641881.0
    },
    {
      "title": "A Scoping Review of Mixed Initiative Visual Analytics in the Automation\n  Renaissance",
      "summary": "Artificial agents are increasingly integrated into data analysis workflows,\ncarrying out tasks that were primarily done by humans. Our research explores\nhow the introduction of automation re-calibrates the dynamic between humans and\nautomating technology. To explore this question, we conducted a scoping review\nencompassing twenty years of mixed-initiative visual analytic systems. To\ndescribe and contrast the relationship between humans and automation, we\ndeveloped an integrated taxonomy to delineate the objectives of these\nmixed-initiative visual analytics tools, how much automation they support, and\nthe assumed roles of humans. Here, we describe our qualitative approach of\nintegrating existing theoretical frameworks with new codes we developed. Our\nanalysis shows that the visualization research literature lacks consensus on\nthe definition of mixed-initiative systems and explores a limited potential of\nthe collaborative interaction landscape between people and automation. Our\nresearch provides a scaffold to advance the discussion of human-AI\ncollaboration during visual data analysis.",
      "url": "http://arxiv.org/abs/2509.19152v1",
      "published_time_eastern_timestamp": 1758641434.0
    },
    {
      "title": "BiGraspFormer: End-to-End Bimanual Grasp Transformer",
      "summary": "Bimanual grasping is essential for robots to handle large and complex\nobjects. However, existing methods either focus solely on single-arm grasping\nor employ separate grasp generation and bimanual evaluation stages, leading to\ncoordination problems including collision risks and unbalanced force\ndistribution. To address these limitations, we propose BiGraspFormer, a unified\nend-to-end transformer framework that directly generates coordinated bimanual\ngrasps from object point clouds. Our key idea is the Single-Guided Bimanual\n(SGB) strategy, which first generates diverse single grasp candidates using a\ntransformer decoder, then leverages their learned features through specialized\nattention mechanisms to jointly predict bimanual poses and quality scores. This\nconditioning strategy reduces the complexity of the 12-DoF search space while\nensuring coordinated bimanual manipulation. Comprehensive simulation\nexperiments and real-world validation demonstrate that BiGraspFormer\nconsistently outperforms existing methods while maintaining efficient inference\nspeed (<0.05s), confirming the effectiveness of our framework. Code and\nsupplementary materials are available at https://sites.google.com/bigraspformer",
      "url": "http://arxiv.org/abs/2509.19142v1",
      "published_time_eastern_timestamp": 1758641164.0
    },
    {
      "title": "2D implementation of Kinetic-diffusion Monte Carlo in Eiron",
      "summary": "Particle-based kinetic Monte Carlo simulations of neutral particles is one of\nthe major computational bottlenecks in tokamak scrape-off layer simulations.\nThis computational cost comes from the need to resolve individual collision\nevents in high-collisional regimes. However, in such regimes, one can\napproximate the high-collisional kinetic dynamics with computationally cheaper\ndiffusion. Asymptotic-preserving schemes make use of this limit to perform\nsimulations in these regimes, without a blow-up in computational cost as\nincurred by standard kinetic approaches. One such scheme is Kinetic-diffusion\nMonte Carlo. In this paper, we present a first extension of this scheme to the\ntwo-dimensional setting and its implementation in the Eiron particle code. We\nthen demonstrate that this implementation produces a significant speedup over\nkinetic simulations in high-collisional cases.",
      "url": "http://arxiv.org/abs/2509.19140v1",
      "published_time_eastern_timestamp": 1758641037.0
    },
    {
      "title": "On the Fe xxii Emission in the X-ray spectrum of NGC 1068",
      "summary": "The Fe xxii doublet has been previously used to determine the density of\ncollisionally ionized emission from magnetic cataclysmic variable stars. We\ntest how this diagnostic doublet behaves for a photoionized plasma with an\nactive galactic nucleus (AGN) spectral energy distribution (SED). We use the\nphotoionized plasma code pion and ~440 ks of archival Chandra HETG for the\nwell-known Seyfert 2 galaxy NGC 1068 to test the behaviour of the Fe xxii\ndoublet in the context of an AGN. This marks the first time these data have\nbeen examined with pion. We find that in a photoionized plasma, the Fe xxii\ndoublet is dependent on the density, ionization state, and SED used. Thus, this\ndensity diagnostic remains model-dependent. In the context of NGC 1068 the\ndoublet predicts an emission region ~100 rg from the central black hole. This\nwould require a direct line of sight to the central engine, which is at odds\nwith the Seyfert 2 nature of this source. In practice, these results highlight\nthe complexities and challenges of applying photoionized models. With these\ndata, we cannot exclude the possibility of a direct line of sight to the\ncentral engine of NGC 1068, but we cannot confirm it. Future observations with\ninstruments such as Athena are needed to explore the Fe xxii doublet further.",
      "url": "http://arxiv.org/abs/2509.19133v1",
      "published_time_eastern_timestamp": 1758640761.0
    },
    {
      "title": "LLM-based Vulnerability Discovery through the Lens of Code Metrics",
      "summary": "Large language models (LLMs) excel in many tasks of software engineering, yet\nprogress in leveraging them for vulnerability discovery has stalled in recent\nyears. To understand this phenomenon, we investigate LLMs through the lens of\nclassic code metrics. Surprisingly, we find that a classifier trained solely on\nthese metrics performs on par with state-of-the-art LLMs for vulnerability\ndiscovery. A root-cause analysis reveals a strong correlation and a causal\neffect between LLMs and code metrics: When the value of a metric is changed,\nLLM predictions tend to shift by a corresponding magnitude. This dependency\nsuggests that LLMs operate at a similarly shallow level as code metrics,\nlimiting their ability to grasp complex patterns and fully realize their\npotential in vulnerability discovery. Based on these findings, we derive\nrecommendations on how research should more effectively address this challenge.",
      "url": "http://arxiv.org/abs/2509.19117v1",
      "published_time_eastern_timestamp": 1758639785.0
    },
    {
      "title": "Towards Practical Multi-label Causal Discovery in High-Dimensional Event\n  Sequences via One-Shot Graph Aggregation",
      "summary": "Understanding causality in event sequences where outcome labels such as\ndiseases or system failures arise from preceding events like symptoms or error\ncodes is critical. Yet remains an unsolved challenge across domains like\nhealthcare or vehicle diagnostics. We introduce CARGO, a scalable multi-label\ncausal discovery method for sparse, high-dimensional event sequences comprising\nof thousands of unique event types. Using two pretrained causal Transformers as\ndomain-specific foundation models for event sequences. CARGO infers in\nparallel, per sequence one-shot causal graphs and aggregates them using an\nadaptive frequency fusion to reconstruct the global Markov boundaries of\nlabels. This two-stage approach enables efficient probabilistic reasoning at\nscale while bypassing the intractable cost of full-dataset conditional\nindependence testing. Our results on a challenging real-world automotive fault\nprediction dataset with over 29,100 unique event types and 474 imbalanced\nlabels demonstrate CARGO's ability to perform structured reasoning.",
      "url": "http://arxiv.org/abs/2509.19112v1",
      "published_time_eastern_timestamp": 1758639530.0
    }
  ]
}
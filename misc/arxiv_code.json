{
  "last_updated": "2025-08-19T11:13:12.766437-04:00",
  "papers": [
    {
      "title": "Phenomenological Constraints on Higgs reheating",
      "summary": "In many models of inflation, reheating is realized through a coupling between\nthe inflaton and the Higgs boson. Often, the mass of the inflaton is of order\n$10^{13}~$GeV determined by the amplitude of the scalar fluctuation spectrum.\nHowever, in models where the inflaton potential is of the form $V \\sim \\phi^k$\nabout its minimum, the inflaton is massless for $k\\ge 4$ unless a bare mass\nterm, $\\frac12 m_\\phi^2 \\phi^2$, is present. In this case, the inflaton mass\nmay be of order the electroweak scale and may be subject to existing collider\nconstraints. In particular, we investigate the constraints on the inflaton mass\nand reheating temperature $T_{\\rm rh}$ arising from the decay of $\\phi$ into\n$\\mathcal{H}$ through an interaction term $\\mu \\phi |\\mathcal{H}|^2$.\n  We perform a renormalization group analysis to determine the relative values\nof $\\mu$ and $m_\\phi$ such that the Higgs potential remains stable (and\nperturbative) at high energy.\n  Taking into account the running of the Higgs quartic self-coupling and the\nexperimental constraints from the LHC via the $\\texttt{HiggsTools}$ public\ncode, we find that $3.4 \\times 10^6 $ GeV $\\lesssim T_{\\rm rh}\\lesssim 3.9\n\\times 10^{12} $ GeV with a corresponding constraint on the inflaton bare mass\n$260~{\\rm GeV} \\lesssim m_\\phi \\lesssim 3.8 \\times 10^{10}~{\\rm GeV}$. The\ndependencies between $T_{\\rm rh}$ and the inflaton bare mass $m_\\phi$ as well\nas between $\\mu$ and $m_\\phi$ are provided.",
      "url": "http://arxiv.org/abs/2508.13155v1",
      "published_time_eastern_timestamp": 1755539999.0
    },
    {
      "title": "RepreGuard: Detecting LLM-Generated Text by Revealing Hidden\n  Representation Patterns",
      "summary": "Detecting content generated by large language models (LLMs) is crucial for\npreventing misuse and building trustworthy AI systems. Although existing\ndetection methods perform well, their robustness in out-of-distribution (OOD)\nscenarios is still lacking. In this paper, we hypothesize that, compared to\nfeatures used by existing detection methods, the internal representations of\nLLMs contain more comprehensive and raw features that can more effectively\ncapture and distinguish the statistical pattern differences between\nLLM-generated texts (LGT) and human-written texts (HWT). We validated this\nhypothesis across different LLMs and observed significant differences in neural\nactivation patterns when processing these two types of texts. Based on this, we\npropose RepreGuard, an efficient statistics-based detection method.\nSpecifically, we first employ a surrogate model to collect representation of\nLGT and HWT, and extract the distinct activation feature that can better\nidentify LGT. We can classify the text by calculating the projection score of\nthe text representations along this feature direction and comparing with a\nprecomputed threshold. Experimental results show that RepreGuard outperforms\nall baselines with average 94.92% AUROC on both in-distribution (ID) and OOD\nscenarios, while also demonstrating robust resilience to various text sizes and\nmainstream attacks. Data and code are publicly available at:\nhttps://github.com/NLP2CT/RepreGuard",
      "url": "http://arxiv.org/abs/2508.13152v1",
      "published_time_eastern_timestamp": 1755539955.0
    },
    {
      "title": "MDPO: Overcoming the Training-Inference Divide of Masked Diffusion\n  Language Models",
      "summary": "Diffusion language models, as a promising alternative to traditional\nautoregressive (AR) models, enable faster generation and richer conditioning on\nbidirectional context. However, they suffer from a key discrepancy between\ntraining and inference: during inference, MDLMs progressively reveal the\nstructure of the generated sequence by producing fewer and fewer masked tokens,\nwhereas this structure is ignored in training as tokens are masked at random.\nAlthough this discrepancy between training and inference can lead to suboptimal\nperformance, it has been largely overlooked by previous works, leaving closing\nthis gap between the two stages an open problem. To address this, we frame the\nproblem of learning effective denoising trajectories as a sequential\ndecision-making problem and use the resulting framework to apply reinforcement\nlearning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to\nexploit the Markov property diffusion possesses and explicitly train the model\nunder the same progressive refining schedule used at inference. MDPO matches\nthe performance of the previous state-of-the-art (SOTA) method with 60x fewer\ngradient updates, while achieving average improvements of 9.6% on MATH500 and\n54.2% on Countdown over SOTA when trained within the same number of weight\nupdates. Additionally, we improve the remasking strategy of MDLMs as a plug-in\ninference replacement to overcome the limitation that the model cannot refine\ntokens flexibly. This simple yet effective training-free strategy, what we\nrefer to as RCR, consistently improves performance and yields additional gains\nwhen combined with MDPO. Our findings establish great potential for\ninvestigating the discrepancy between pre-training and inference of MDLMs.\nCode: https://github.com/autonomousvision/mdpo. Project Page:\nhttps://cli212.github.io/MDPO/.",
      "url": "http://arxiv.org/abs/2508.13148v1",
      "published_time_eastern_timestamp": 1755539893.0
    },
    {
      "title": "Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence",
      "summary": "This work studies the challenge of transfer animations between characters\nwhose skeletal topologies differ substantially. While many techniques have\nadvanced retargeting techniques in decades, transfer motions across diverse\ntopologies remains less-explored. The primary obstacle lies in the inherent\ntopological inconsistency between source and target skeletons, which restricts\nthe establishment of straightforward one-to-one bone correspondences. Besides,\nthe current lack of large-scale paired motion datasets spanning different\ntopological structures severely constrains the development of data-driven\napproaches. To address these limitations, we introduce Motion2Motion, a novel,\ntraining-free framework. Simply yet effectively, Motion2Motion works with only\none or a few example motions on the target skeleton, by accessing a sparse set\nof bone correspondences between the source and target skeletons. Through\ncomprehensive qualitative and quantitative evaluations, we demonstrate that\nMotion2Motion achieves efficient and reliable performance in both\nsimilar-skeleton and cross-species skeleton transfer scenarios. The practical\nutility of our approach is further evidenced by its successful integration in\ndownstream applications and user interfaces, highlighting its potential for\nindustrial applications. Code and data are available at\nhttps://lhchen.top/Motion2Motion.",
      "url": "http://arxiv.org/abs/2508.13139v1",
      "published_time_eastern_timestamp": 1755539431.0
    },
    {
      "title": "Grounding Actions in Camera Space: Observation-Centric\n  Vision-Language-Action Policy",
      "summary": "Vision-Language-Action (VLA) models frequently encounter challenges in\ngeneralizing to real-world environments due to inherent discrepancies between\nobservation and action spaces. Although training data are collected from\ndiverse camera perspectives, the models typically predict end-effector poses\nwithin the robot base coordinate frame, resulting in spatial inconsistencies.\nTo mitigate this limitation, we introduce the Observation-Centric VLA (OC-VLA)\nframework, which grounds action predictions directly in the camera observation\nspace. Leveraging the camera's extrinsic calibration matrix, OC-VLA transforms\nend-effector poses from the robot base coordinate system into the camera\ncoordinate system, thereby unifying prediction targets across heterogeneous\nviewpoints. This lightweight, plug-and-play strategy ensures robust alignment\nbetween perception and action, substantially improving model resilience to\ncamera viewpoint variations. The proposed approach is readily compatible with\nexisting VLA architectures, requiring no substantial modifications.\nComprehensive evaluations on both simulated and real-world robotic manipulation\ntasks demonstrate that OC-VLA accelerates convergence, enhances task success\nrates, and improves cross-view generalization. The code will be publicly\navailable.",
      "url": "http://arxiv.org/abs/2508.13103v1",
      "published_time_eastern_timestamp": 1755537045.0
    },
    {
      "title": "VerilogLAVD: LLM-Aided Rule Generation for Vulnerability Detection in\n  Verilog",
      "summary": "Timely detection of hardware vulnerabilities during the early design stage is\ncritical for reducing remediation costs. Existing early detection techniques\noften require specialized security expertise, limiting their usability. Recent\nefforts have explored the use of large language models (LLMs) for Verilog\nvulnerability detection. However, LLMs struggle to capture the structure in\nVerilog code, resulting in inconsistent detection results. To this end, we\npropose VerilogLAVD, the first LLM-aided graph traversal rule generation\napproach for Verilog vulnerability detection. Our approach introduces the\nVerilog Property Graph (VeriPG), a unified representation of Verilog code. It\ncombines syntactic features extracted from the abstract syntax tree (AST) with\nsemantic information derived from control flow and data dependency graphs. We\nleverage LLMs to generate VeriPG-based detection rules from Common Weakness\nEnumeration (CWE) descriptions. These rules guide the rule executor that\ntraversal VeriPG for potential vulnerabilities. To evaluate VerilogLAVD, we\nbuild a dataset collected from open-source repositories and synthesized data.\nIn our empirical evaluation on 77 Verilog designs encompassing 12 CWE types,\nVerilogLAVD achieves an F1-score of 0.54. Compared to the LLM-only and LLM with\nexternal knowledge baselines, VerilogLAVD improves F1-score by 0.31 and 0.27,\nrespectively.",
      "url": "http://arxiv.org/abs/2508.13092v1",
      "published_time_eastern_timestamp": 1755536718.0
    },
    {
      "title": "Seeing the Many: Exploring Parameter Distributions Conditioned on\n  Features in Surrogates",
      "summary": "Recently, neural surrogate models have emerged as a compelling alternative to\ntraditional simulation workflows. This is accomplished by modeling the\nunderlying function of scientific simulations, removing the need to run\nexpensive simulations. Beyond just mapping from input parameter to output,\nsurrogates have also been shown useful for inverse problems: output to input\nparameters. Inverse problems can be understood as search, where we aim to find\nparameters whose surrogate outputs contain a specified feature. Yet finding\nthese parameters can be costly, especially for high-dimensional parameter\nspaces. Thus, existing surrogate-based solutions primarily focus on finding a\nsmall set of matching parameters, in the process overlooking the broader\npicture of plausible parameters. Our work aims to model and visualize the\ndistribution of possible input parameters that produce a given output feature.\nTo achieve this goal, we aim to address two challenges: (1) the approximation\nerror inherent in the surrogate model and (2) forming the parameter\ndistribution in an interactive manner. We model error via density estimation,\nreporting high density only if a given parameter configuration is close to\ntraining parameters, measured both over the input and output space. Our density\nestimate is used to form a prior belief on parameters, and when combined with a\nlikelihood on features, gives us an efficient way to sample plausible parameter\nconfigurations that generate a target output feature. We demonstrate the\nusability of our solution through a visualization interface by performing\nfeature-driven parameter analysis over the input parameter space of three\nsimulation datasets. Source code is available at\nhttps://github.com/matthewberger/seeing-the-many",
      "url": "http://arxiv.org/abs/2508.13088v1",
      "published_time_eastern_timestamp": 1755536461.0
    },
    {
      "title": "XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine\n  for Extended Reality Perception Workloads",
      "summary": "This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural\nProcessing Engine, designed for extended reality (XR) perception workloads like\nvisual inertial odometry (VIO), object classification, and eye gaze extraction.\nXR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1)\nformats, with layer adaptive hybrid-algorithmic implementation supporting\nultra-low bit precision to significantly reduce memory bandwidth requirements,\nand accompanied by quantization-aware training for minimal accuracy loss. The\nproposed Reconfigurable Mantissa Multiplication and Exponent processing\nCircuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted\nby selective power gating to reduce energy consumption, providing 2.85x\nimproved arithmetic intensity. XR-NPE achieves a maximum operating frequency of\n1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm,\nreducing 42% area, 38% power compared to the best of state-of-the-art MAC\napproaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication\nco-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x\nbetter energy efficiency compared to SoTA accelerators on VCU129. The proposed\nco-processor provides 23% better energy efficiency and 4% better compute\ndensity for VIO workloads. XR-NPE establishes itself as a scalable,\nprecision-adaptive compute engine for future resource-constrained XR devices.\nThe complete set for codes for results reproducibility are released publicly,\nenabling designers and researchers to readily adopt and build upon them.\nhttps://github.com/mukullokhande99/XR-NPE.",
      "url": "http://arxiv.org/abs/2508.13049v1",
      "published_time_eastern_timestamp": 1755533580.0
    },
    {
      "title": "Dynamic syndrome decoder in volume-law phases of hybrid quantum circuits",
      "summary": "Phases of matter with volume-law entanglement are frequently observed in\nquantum circuits and have numerous applications, ranging from deepening our\nunderstanding of quantum mechanics to advancements in quantum computing and\ncryptography. Their capacity to host entangled, complex quantum information is\ncomplemented by their ability to efficiently obscure it from quantum\nmeasurements through scrambling, reminiscent of quantum error-correction.\nHowever, the issue of initial-state decodability has primarily been studied in\nmeasurement-only models with area-law phases, which limit the entanglement of\nthe encoded state. In this work, we introduce a class of Clifford circuits in\none and two dimensions that feature a decodable volume law phase, allowing for\ninformation retrieval in logarithmic circuit depths. We present the Sign-Color\nDecoder that tracks stabilizers revealing the initial state, akin to monitoring\na dynamically-changing syndrome for error-correcting codes. We demonstrate this\napproach in scenarios where error locations are either known or unknown to the\ndecoder, and we provide new insights about the relationship between the\ndecodability transition and measurement-induced phase transition. We propose\nthat this decodability transition is universal across various settings,\nincluding different circuit geometries. Our findings pave the way for using\nvolume law states as encoders with mid-circuit measurements, opening potential\napplications in quantum error correction and quantum cryptography.",
      "url": "http://arxiv.org/abs/2508.13045v1",
      "published_time_eastern_timestamp": 1755532919.0
    },
    {
      "title": "HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical\n  Feature Adapters",
      "summary": "Deep learning-based cardiac MRI reconstruction faces significant domain shift\nchallenges when deployed across multiple clinical centers with heterogeneous\nscanner configurations and imaging protocols. We propose HierAdaptMR, a\nhierarchical feature adaptation framework that addresses multi-level domain\nvariations through parameter-efficient adapters. Our method employs\nProtocol-Level Adapters for sequence-specific characteristics and Center-Level\nAdapters for scanner-dependent variations, built upon a variational unrolling\nbackbone. A Universal Adapter enables generalization to entirely unseen centers\nthrough stochastic training that learns center-invariant adaptations. The\nframework utilizes multi-scale SSIM loss with frequency domain enhancement and\ncontrast-adaptive weighting for robust optimization. Comprehensive evaluation\non the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9\nmodalities demonstrates superior cross-center generalization while maintaining\nreconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR",
      "url": "http://arxiv.org/abs/2508.13026v1",
      "published_time_eastern_timestamp": 1755531799.0
    },
    {
      "title": "G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive\n  Guidance",
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced\nthe reasoning abilities of large language models (LLMs). Its success, however,\nlargely depends on strong base models with rich world knowledge, yielding only\nmodest improvements for small-size language models (SLMs). To address this\nlimitation, we investigate Guided GRPO, which injects ground-truth reasoning\nsteps into roll-out trajectories to compensate for SLMs' inherent weaknesses.\nThrough a comprehensive study of various guidance configurations, we find that\nnaively adding guidance delivers limited gains. These insights motivate\nG$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength\nin response to the model's evolving training dynamics. Experiments on\nmathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A\nsubstantially outperforms vanilla GRPO. Our code and models are available at\nhttps://github.com/T-Lab-CUHKSZ/G2RPO-A.",
      "url": "http://arxiv.org/abs/2508.13023v1",
      "published_time_eastern_timestamp": 1755531676.0
    },
    {
      "title": "PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked\n  Diffusion Models",
      "summary": "Recent advances in masked diffusion models (MDMs) have established them as\npowerful non-autoregressive alternatives for sequence generation. Nevertheless,\nour preliminary experiments reveal that the generation quality of MDMs is still\nhighly sensitive to the choice of decoding strategy. In particular, widely\nadopted uncertainty-based samplers suffer from two key limitations: a lack of\nglobal trajectory control and a pronounced bias toward trivial tokens in the\nearly stages of decoding. These shortcomings restrict the full potential of\nMDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling\n(PC-Sampler), a novel decoding strategy that unifies global trajectory planning\nwith content-aware informativeness maximization. PC-Sampler incorporates a\nposition-aware weighting mechanism to regulate the decoding path and a\ncalibrated confidence score to suppress the premature selection of trivial\ntokens. Extensive experiments on three advanced MDMs across seven challenging\nbenchmarks-including logical reasoning and planning tasks-demonstrate that\nPC-Sampler consistently outperforms existing MDM decoding strategies by more\nthan 10% on average, significantly narrowing the performance gap with\nstate-of-the-art autoregressive models. All codes are available at\nhttps://github.com/NEUIR/PC-Sampler.",
      "url": "http://arxiv.org/abs/2508.13021v1",
      "published_time_eastern_timestamp": 1755531517.0
    },
    {
      "title": "SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient\n  Cooperative 3-D Perception",
      "summary": "Collaborative perception allows connected autonomous vehicles (CAVs) to\novercome occlusion and limited sensor range by sharing intermediate features.\nYet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the\nbandwidth available for inter-vehicle communication. We present SlimComm, a\ncommunication-efficient framework that integrates 4D radar Doppler with a\nquery-driven sparse scheme. SlimComm builds a motion-centric dynamic map to\ndistinguish moving from static objects and generates two query types: (i)\nreference queries on dynamic and high-confidence regions, and (ii) exploratory\nqueries probing occluded areas via a two-stage offset. Only query-specific BEV\nfeatures are exchanged and fused through multi-scale gated deformable\nattention, reducing payload while preserving accuracy. For evaluation, we\nrelease OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler\nradar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while\nmatching or surpassing prior baselines across varied traffic densities and\nocclusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.",
      "url": "http://arxiv.org/abs/2508.13007v1",
      "published_time_eastern_timestamp": 1755530864.0
    },
    {
      "title": "EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning\n  via Evolutionary Testing",
      "summary": "The rapid advancement of LLMs poses a significant challenge to existing\nmathematical reasoning benchmarks. These benchmarks commonly suffer from issues\nsuch as score saturation, temporal decay, and data contamination. To address\nthis challenge, this paper introduces EvolMathEval, an automated mathematical\nbenchmark generation and evolution framework based on evolutionary testing. By\ndynamically generating unique evaluation instances ab initio, the framework\nfundamentally eliminates the risk of data contamination, and ensuring the\nbenchmark remains perpetually challenging for future models.The core mechanisms\nof EvolMathEval include: seed problem generation based on reverse engineering\nwith algebraic guarantees; multi-dimensional genetic operators designed to\ninject diverse cognitive challenges; and a composite fitness function that can\nrapidly and accurately assess problem difficulty. Experimental results\ndemonstrate that the proposed composite fitness function can efficiently and\nprecisely quantify the difficulty of mathematical problems. Furthermore,\nEvolMathEval can not only generate a large volume of high-difficulty problems\nthrough continuous self-iteration, but it can also significantly enhance the\ncomplexity of public datasets like GSM8K through evolution, reducing model\naccuracy by an average of 48%. Deeper investigation reveals that when solving\nthese evolved, complex problems, LLMs tend to employ non-rigorous heuristics to\nbypass complex multi-step logical reasoning, consequently leading to incorrect\nsolutions. We define this phenomenon as \"Pseudo Aha Moment\". This finding\nuncovers a cognitive shortcut-taking behavior in the deep reasoning processes\nof current LLMs, which we find accounts for 77% to 100% of errors on targeted\nproblems. Code and resources are available\nat:https://github.com/SYSUSELab/EvolMathEval.",
      "url": "http://arxiv.org/abs/2508.13003v1",
      "published_time_eastern_timestamp": 1755530650.0
    },
    {
      "title": "Dextr: Zero-Shot Neural Architecture Search with Singular Value\n  Decomposition and Extrinsic Curvature",
      "summary": "Zero-shot Neural Architecture Search (NAS) typically optimises the\narchitecture search process by exploiting the network or gradient properties at\ninitialisation through zero-cost proxies. The existing proxies often rely on\nlabelled data, which is usually unavailable in real-world settings.\nFurthermore, the majority of the current methods focus either on optimising the\nconvergence and generalisation attributes or solely on the expressivity of the\nnetwork architectures. To address both limitations, we first demonstrate how\nchannel collinearity affects the convergence and generalisation properties of a\nneural network. Then, by incorporating the convergence, generalisation and\nexpressivity in one approach, we propose a zero-cost proxy that omits the\nrequirement of labelled data for its computation. In particular, we leverage\nthe Singular Value Decomposition (SVD) of the neural network layer features and\nthe extrinsic curvature of the network output to design our proxy. %As a\nresult, the proposed proxy is formulated as the simplified harmonic mean of the\nlogarithms of two key components: the sum of the inverse of the feature\ncondition number and the extrinsic curvature of the network output. Our\napproach enables accurate prediction of network performance on test data using\nonly a single label-free data sample. Our extensive evaluation includes a total\nof six experiments, including the Convolutional Neural Network (CNN) search\nspace, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The\nproposed proxy demonstrates a superior performance on multiple correlation\nbenchmarks, including NAS-Bench-101, NAS-Bench-201, and\nTransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the\nAutoFormer search space, all while being notably efficient. The code is\navailable at https://github.com/rohanasthana/Dextr.",
      "url": "http://arxiv.org/abs/2508.12977v1",
      "published_time_eastern_timestamp": 1755528734.0
    },
    {
      "title": "Synchronization and semantization in deep spiking networks",
      "summary": "Recent studies have shown how spiking networks can learn complex\nfunctionality through error-correcting plasticity, but the resulting structures\nand dynamics remain poorly studied. To elucidate how these models may link to\nobserved dynamics in vivo and thus how they may ultimately explain cortical\ncomputation, we need a better understanding of their emerging patterns. We\ntrain a multi-layer spiking network, as a conceptual analog of the bottom-up\nvisual hierarchy, for visual input classification using spike-time encoding.\nAfter learning, we observe the development of distinct spatio-temporal activity\npatterns. While input patterns are synchronous by construction, activity in\nearly layers first spreads out over time, followed by re-convergence into sharp\npulses as classes are gradually extracted. The emergence of synchronicity is\naccompanied by the formation of increasingly distinct pathways, reflecting the\ngradual semantization of input activity. We thus observe hierarchical networks\nlearning spike latency codes to naturally acquire activity patterns\ncharacterized by synchronicity and separability, with pronounced excitatory\npathways ascending through the layers. This provides a rigorous computational\nhypothesis for the experimentally observed synchronicity in the visual system\nas a natural consequence of deep learning in cortex.",
      "url": "http://arxiv.org/abs/2508.12975v1",
      "published_time_eastern_timestamp": 1755528718.0
    },
    {
      "title": "A Novel CNN Based Standalone Detector for Faster-than-Nyquist Signaling",
      "summary": "This paper presents a novel convolutional neural network (CNN)-based detector\nfor faster-than-Nyquist (FTN) signaling, introducing structured fixed kernel\nlayers with domain-informed masking to effectively mitigate intersymbol\ninterference (ISI). Unlike standard CNN architectures that rely on moving\nkernels, the proposed approach employs fixed convolutional kernels at\npredefined positions to explicitly learn ISI patterns at varying distances from\nthe central symbol. To enhance feature extraction, a hierarchical filter\nallocation strategy is employed, assigning more filters to earlier layers for\nstronger ISI components and fewer to later layers for weaker components. This\nstructured design improves feature representation, eliminates redundant\ncomputations, and enhances detection accuracy while maintaining computational\nefficiency. Simulation results demonstrate that the proposed detector achieves\nnear-optimal bit error rate (BER) performance, comparable to the BCJR algorithm\nfor the compression factor $\\tau \\geq 0.7$, while offering up to $46\\%$ and\n$84\\%$ computational cost reduction over M-BCJR for BPSK and QPSK,\nrespectively. Additional evaluations confirm the method's adaptability to\nhigh-order modulations (up to 64-QAM), resilience in quasi-static multipath\nRayleigh fading channels, and effectiveness under LDPC-coded FTN transmission,\nhighlighting its robustness and practicality.",
      "url": "http://arxiv.org/abs/2508.12964v1",
      "published_time_eastern_timestamp": 1755527857.0
    },
    {
      "title": "OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency\n  Response and Equitable Resource Allocation in Underserved African Communities",
      "summary": "Public service systems in many African regions suffer from delayed emergency\nresponse and spatial inequity, causing avoidable suffering. This paper\nintroduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,\nadaptive, and equitable emergency response. OPTIC-ER uses an attention-guided\nactor-critic architecture to manage the complexity of dispatch environments.\nIts key innovations are a Context-Rich State Vector, encoding action\nsub-optimality, and a Precision Reward Function, which penalizes inefficiency.\nTraining occurs in a high-fidelity simulation using real data from Rivers\nState, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is\nbuilt on the TALS framework (Thin computing, Adaptability, Low-cost,\nScalability) for deployment in low-resource settings. In evaluations on 500\nunseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible\ninefficiency, confirming its robustness and generalization. Beyond dispatch,\nthe system generates Infrastructure Deficiency Maps and Equity Monitoring\nDashboards to guide proactive governance and data-informed development. This\nwork presents a validated blueprint for AI-augmented public services, showing\nhow context-aware RL can bridge the gap between algorithmic decision-making and\nmeasurable human impact.",
      "url": "http://arxiv.org/abs/2508.12943v1",
      "published_time_eastern_timestamp": 1755526797.0
    },
    {
      "title": "Stochasticity in Stellar Yields Reflected in Theoretical Dust Masses\n  Estimates Across all Type II Supernova Progenitors",
      "summary": "Core-collapse supernovae (CCSNe) are among the primary sources of dust in\ngalaxies. In this study, we derive theoretical upper limits on dust masses as a\nfunction of supernova (SN) progenitors with initial masses between 9 and 120\nMsun, based on previously established models of dust formation chemistry in\nCCSNe. We find that O-rich dust, particularly silicates, dominates the dust\nbudget, with masses ranging from 0.02 to 0.9 Msun, and that the total mass of\nO-rich dust increases with progenitor mass. C-rich amorphous carbon dust is\nsignificant for lower-mass progenitors (up to 15 Msun), but its mass never\nexceeds 0.05 Msun. For progenitors up to 30 Msun, we provide best-fit functions\ndescribing the masses of O-rich dust, C-rich dust, and CO molecules. A large\nstochastic variation is found in the predicted masses of silicate dust, which\ncorrelates with the randomness of shell-merger events in the pre-explosion\nphases of massive stars. Furthermore, we show that the dust mass for a given\nprogenitor can vary by a factor of 2-5, reflecting differences in pre-explosion\nabundance profiles predicted by the stellar evolution codes KEPLER and MESA. We\nemphasize that the final dust yield in CCSNe is primarily determined by\nstochastic stellar yields and uncertainties in pre-explosion nucleosynthesis,\nwhile explosion properties mainly influence the timescales of dust formation.",
      "url": "http://arxiv.org/abs/2508.12933v1",
      "published_time_eastern_timestamp": 1755525416.0
    },
    {
      "title": "SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for\n  Class Incremental Learning with Small Memory",
      "summary": "In incremental learning, enhancing the generality of knowledge is crucial for\nadapting to dynamic data inputs. It can develop generalized representations or\nmore balanced decision boundaries, preventing the degradation of long-term\nknowledge over time and thus mitigating catastrophic forgetting. Some emerging\nincremental learning methods adopt an encoder-decoder architecture and have\nachieved promising results. In the encoder-decoder achitecture, improving the\ngeneralization capabilities of both the encoder and decoder is critical, as it\nhelps preserve previously learned knowledge while ensuring adaptability and\nrobustness to new, diverse data inputs. However, many existing continual\nmethods focus solely on enhancing one of the two components, which limits their\neffectiveness in mitigating catastrophic forgetting. And these methods perform\neven worse in small-memory scenarios, where only a limited number of historical\nsamples can be stored. To mitigate this limitation, we introduces SEDEG, a\ntwo-stage training framework for vision transformers (ViT), focusing on\nsequentially improving the generality of both Decoder and Encoder. Initially,\nSEDEG trains an ensembled encoder through feature boosting to learn generalized\nrepresentations, which subsequently enhance the decoder's generality and\nbalance the classifier. The next stage involves using knowledge distillation\n(KD) strategies to compress the ensembled encoder and develop a new, more\ngeneralized encoder. This involves using a balanced KD approach and feature KD\nfor effective knowledge transfer. Extensive experiments on three benchmark\ndatasets show SEDEG's superior performance, and ablation studies confirm the\nefficacy of its components. The code is available at\nhttps://github.com/ShaolingPu/CIL.",
      "url": "http://arxiv.org/abs/2508.12932v1",
      "published_time_eastern_timestamp": 1755525359.0
    }
  ]
}
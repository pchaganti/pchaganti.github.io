{
  "last_updated": "2025-07-28T02:21:27.705950-04:00",
  "papers": [
    {
      "title": "MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI\n  Agents",
      "summary": "We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI\nautomation agents across Windows, macOS, Linux, iOS, Android, and Web\nplatforms. It comprises four levels: GUI Content Understanding, Element\nGrounding, Task Automation, and Task Collaboration, covering essential skills\nfor GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)\nmetric to assess GUI agent execution efficiency in online automation scenarios.\nThrough MMBench-GUI, we identify accurate visual grounding as a critical\ndeterminant of overall task success, emphasizing the substantial benefits of\nmodular frameworks that integrate specialized grounding modules. Furthermore,\nto achieve reliable GUI automation, an agent requires strong task planning and\ncross-platform generalization abilities, with long-context memory, a broad\naction space, and long-term reasoning playing a critical role. More important,\ntask efficiency remains a critically underexplored dimension, and all models\nsuffer from substantial inefficiencies, with excessive redundant steps even\nwhen tasks are ultimately completed. The integration of precise localization,\neffective planning, and early stopping strategies is indispensable to enable\ntruly efficient and scalable GUI automation. Our benchmark code, evaluation\ndata, and running environment will be publicly available at\nhttps://github.com/open-compass/MMBench-GUI.",
      "url": "http://arxiv.org/abs/2507.19478v1",
      "published_time_eastern_timestamp": 1753466366.0
    },
    {
      "title": "Conversations Gone Awry, But Then? Evaluating Conversational Forecasting\n  Models",
      "summary": "We often rely on our intuition to anticipate the direction of a conversation.\nEndowing automated systems with similar foresight can enable them to assist\nhuman-human interactions. Recent work on developing models with this predictive\ncapacity has focused on the Conversations Gone Awry (CGA) task: forecasting\nwhether an ongoing conversation will derail. In this work, we revisit this task\nand introduce the first uniform evaluation framework, creating a benchmark that\nenables direct and reliable comparisons between different architectures. This\nallows us to present an up-to-date overview of the current progress in CGA\nmodels, in light of recent advancements in language modeling. Our framework\nalso introduces a novel metric that captures a model's ability to revise its\nforecast as the conversation progresses.",
      "url": "http://arxiv.org/abs/2507.19470v1",
      "published_time_eastern_timestamp": 1753466113.0
    },
    {
      "title": "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning",
      "summary": "Large language models (LLMs) are increasingly adapted to downstream tasks via\nreinforcement learning (RL) methods like Group Relative Policy Optimization\n(GRPO), which often require thousands of rollouts to learn new tasks. We argue\nthat the interpretable nature of language can often provide a much richer\nlearning medium for LLMs, compared with policy gradients derived from sparse,\nscalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt\noptimizer that thoroughly incorporates natural language reflection to learn\nhigh-level rules from trial and error. Given any AI system containing one or\nmore LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool\ncalls, and tool outputs) and reflects on them in natural language to diagnose\nproblems, propose and test prompt updates, and combine complementary lessons\nfrom the Pareto frontier of its own attempts. As a result of GEPA's design, it\ncan often turn even just a few rollouts into a large quality gain. Across four\ntasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up\nto 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,\nMIPROv2, by over 10% across two LLMs, and demonstrates promising results as an\ninference-time search strategy for code optimization.",
      "url": "http://arxiv.org/abs/2507.19457v1",
      "published_time_eastern_timestamp": 1753465352.0
    },
    {
      "title": "Random approximate quantum information masking",
      "summary": "Masking information into quantum correlations is a cornerstone of many\nquantum information applications. While there exist the no-hiding and\nno-masking theorems, approximate quantum information masking (AQIM) offers a\npromising means of circumventing the constraints. Despite its potential, AQIM\nstill remains underexplored, and constructing explicit approximate maskers\nremains a challenge. In this work, we investigate AQIM from multiple\nperspectives and propose using random isometries to construct approximate\nmaskers. First, different notions of AQIM are introduced and we find there are\nprofound intrinsic connections among them. These relationships are\ncharacterized by a set of figures of merit, which are introduced to quantify\nthe deviation of AQIM from exact QIM. We then explore the possibility of\nrealizing AQIM via random isometries in bipartite and multipartite systems. In\nbipartite systems, we identify a fundamental lower bound for a key figure of\nmerit, implying that almost all random isometries fail to realize AQIM. This\nsurprising result generalizes the original no-masking theorem to the\nno-random-AQIM theorem for bipartite systems. In contrast, in multipartite\nsystems, we show almost all random isometries can realize AQIM. Remarkably, the\nnumber of physical qubits required to randomly mask a single logical qubit\nscales only linearly. We further explore the implications of these findings. In\nparticular, we show that, under certain conditions, approximate quantum error\ncorrection is equivalent to AQIM. Consequently, AQIM naturally gives rise to\napproximate quantum error correction codes with constant code rates and\nexponentially small correction inaccuracies. Overall, our results establish\nquantum information masking as a central concept in quantum information theory,\nbridging diverse notions across multiple domains.",
      "url": "http://arxiv.org/abs/2507.19454v1",
      "published_time_eastern_timestamp": 1753465110.0
    },
    {
      "title": "Directional Codes: a new family of quantum LDPC codes on hexagonal- and\n  square-grid connectivity hardware",
      "summary": "In this paper we construct a new family of quantum low-density parity-check\n(qLDPC) codes, which we call ``Directional Codes'', that outperforms the\nrotated planar code (RPC) while naturally meeting the connectivity requirements\nof the widely adopted square-grid, and some even the sparser hexagonal-grid.\nThe key idea is to utilise the iSWAP gate -- a natural native gate for\nsuperconducting qubits -- to construct circuits that measure the stabilisers of\nthese qLDPC codes without the need for any long-range connections or an\nincreased degree of connectivity. We numerically evaluate the performance of\ndirectional codes, encoding four, six and twelve logical qubits, using a common\nsuperconducting-inspired circuit-level Pauli noise model. We also compare them\nto the RPC and to the bivariate bicycle (BB) codes, currently the two most\npopular quantum LDPC code families. As a concrete example, directional codes\noutperform RPC by achieving better QEC performance at physical error rate\n$p=10^{-3}$ using only $25-66.67\\%$ of the physical qubits at distance up to\n$10$. Our discovery represents a breakthrough in QEC code design that suggests\ncomplex long-range, high-connectivity hardware may not be necessary for\nlow-overhead fault-tolerant quantum computation.",
      "url": "http://arxiv.org/abs/2507.19430v1",
      "published_time_eastern_timestamp": 1753462641.0
    },
    {
      "title": "TokenSmith: Streamlining Data Editing, Search, and Inspection for\n  Large-Scale Language Model Training and Interpretability",
      "summary": "Understanding the relationship between training data and model behavior\nduring pretraining is crucial, but existing workflows make this process\ncumbersome, fragmented, and often inaccessible to researchers. We present\nTokenSmith, an open-source library for interactive editing, inspection, and\nanalysis of datasets used in Megatron-style pretraining frameworks such as\nGPT-NeoX, Megatron, and NVIDIA NeMo. TokenSmith supports a wide range of\noperations including searching, viewing, ingesting, exporting, inspecting, and\nsampling data, all accessible through a simple user interface and a modular\nbackend. It also enables structured editing of pretraining data without\nrequiring changes to training code, simplifying dataset debugging, validation,\nand experimentation.\n  TokenSmith is designed as a plug and play addition to existing large language\nmodel pretraining workflows, thereby democratizing access to production-grade\ndataset tooling. TokenSmith is hosted on GitHub1, with accompanying\ndocumentation and tutorials. A demonstration video is also available on\nYouTube.",
      "url": "http://arxiv.org/abs/2507.19419v1",
      "published_time_eastern_timestamp": 1753461478.0
    },
    {
      "title": "Running in CIRCLE? A Simple Benchmark for LLM Code Interpreter Security",
      "summary": "As large language models (LLMs) increasingly integrate native code\ninterpreters, they enable powerful real-time execution capabilities,\nsubstantially expanding their utility. However, such integrations introduce\npotential system-level cybersecurity threats, fundamentally different from\nprompt-based vulnerabilities. To systematically evaluate these\ninterpreter-specific risks, we propose CIRCLE (Code-Interpreter Resilience\nCheck for LLM Exploits), a simple benchmark comprising 1,260 prompts targeting\nCPU, memory, and disk resource exhaustion. Each risk category includes\nexplicitly malicious (\"direct\") and plausibly benign (\"indirect\") prompt\nvariants. Our automated evaluation framework assesses not only whether LLMs\nrefuse or generates risky code, but also executes the generated code within the\ninterpreter environment to evaluate code correctness, simplifications made by\nthe LLM to make the code safe, or execution timeouts. Evaluating 7 commercially\navailable models from OpenAI and Google, we uncover significant and\ninconsistent vulnerabilities. For instance, evaluations show substantial\ndisparities even within providers - OpenAI's o4-mini correctly refuses risky\nrequests at 7.1%, notably higher rates compared to GPT-4.1 at 0.5%. Results\nparticularly underscore that indirect, socially-engineered prompts\nsubstantially weaken model defenses. This highlights an urgent need for\ninterpreter-specific cybersecurity benchmarks, dedicated mitigation tools\n(e.g., guardrails), and clear industry standards to guide safe and responsible\ndeployment of LLM interpreter integrations. The benchmark dataset and\nevaluation code are publicly released to foster further research.",
      "url": "http://arxiv.org/abs/2507.19399v1",
      "published_time_eastern_timestamp": 1753459576.0
    },
    {
      "title": "Perturbative model for the saturation of energetic-particle-driven modes\n  limited by self-generated zonal modes",
      "summary": "We present a simplified approach enforcing energy conservation to incorporate\nthe effects of zonal modes alongside wave-particle nonlinearities in the\ndetermination of the saturation amplitude. The model assumes that the zonal\nperturbations grow at a rate twice that of the original (pump) wave, consistent\nwith a beat-driven (or force-driven) generation mechanism. The evolution and\nsaturation of the mode amplitude are investigated both analytically and\nnumerically within our reduced model assumptions, in both the collisionless and\nscattering-dominated regimes. These studies underscore the crucial role of\nsources and sinks in accurately capturing the impact and the role of\nbeat-driven zonal perturbations on mode evolution. In the realistic case of\nsaturation set by sources and sinks, we discuss the role of a finite amplitude\nzonal mode in reducing microturbulent particle scattering, thus limiting the\nenergy source for the resonant mode. We then discuss comparisons between the\nmodel predictions and simulation results. The model reproduces key features\nobserved in gyrokinetic simulations as the reduction in saturated mode\namplitude and the onset of wave-wave nonlinear effects as functions of mode\ngrowth rate and amplitude. Thanks to its simplicity, it can be readily\nimplemented into codes based on reduced models, thereby improving their\npredictive capability for strongly driven instabilities.",
      "url": "http://arxiv.org/abs/2507.19393v1",
      "published_time_eastern_timestamp": 1753459000.0
    },
    {
      "title": "ReCatcher: Towards LLMs Regression Testing for Code Generation",
      "summary": "Large Language Models (LLMs) for code generation evolve rapidly through\nfine-tuning, merging, or new model releases. However, such updates can\nintroduce regressions, not only in correctness but also in code quality and\nperformance. To address this, we present ReCatcher, a regression testing\nframework for Python code generation. ReCatcher systematically compares two\nLLMs, typically a current model and a candidate update, across three\ndimensions: logical correctness, static code quality, and execution\nperformance. We apply ReCatcher to assess regressions across three update\nscenarios, fine-tuning, merging, and model release, using CodeLlama,\nDeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with\ncross-language datasets increases syntax errors by up to 12%. Merging with\ngeneral-purpose models like Llama2 leads to regressions in correctness by up to\n18%. GPT-4o introduces regressions of up to 50% in handling missing imports\ncompared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance\ndegradation in execution time versus GPT-4o. Overall, logical correctness,\nperformance, and error handling (e.g., syntax errors and missing imports) are\nthe most regression-prone areas. Comparing ReCatcher with baseline solutions,\nit presents better and consistent accuracy across logical and performance\naspects. ReCatcher highlights the importance of systematic regression\nevaluation before adopting new models, while assisting researchers and\npractitioners in making more informed update decisions.",
      "url": "http://arxiv.org/abs/2507.19390v1",
      "published_time_eastern_timestamp": 1753458355.0
    },
    {
      "title": "On Anti-collusion Codes for Averaging Attack in Multimedia\n  Fingerprinting",
      "summary": "Multimedia fingerprinting is a technique to protect the copyrighted contents\nagainst being illegally redistributed under various collusion attack models.\nAveraging attack is the most fair choice for each colluder to avoid detection,\nand also makes the pirate copy have better perceptional quality. This makes\nsuch an attack one of the most feasible approaches to carrying out collusion.\nIn order to trace all the colluders, several types of multimedia fingerprinting\ncodes were introduced to construct fingerprints resistant to averaging attacks\non multimedia contents, such as AND anti-collusion codes (AND-ACCs), binary\nseparable codes (SCs), logical anti-collusion codes (LACCs), binary frameproof\ncodes (FPCs), binary strongly-separable codes (SSCs) and binary secure code\nwith list decoding (SCLDs). Then codes with the rate as high as possible are\ndesired. However, the existing fingerprinting codes have low code rate due to\nthe strong combinatorial structure. The reason is that the previous research\nmethods adopted simple tracing algorithms. In this paper, we first propose\nnovel tracing algorithms and then find appropriate fingerprinting codes with\nweaker combinatorial structure, i.e., the binary strongly identifiable parent\nproperty code for multimedia fingerprinting (SMIPPC) and its concatenated code.\nTheoretical comparisons and numerical comparisons show that SMIPPCs have higher\ncode rates than those of the existing codes due to their weaker combinatorial\nstructures. It is worth noting that SMIPPCs can only trace a part of colluders\nby using the previous tracing algorithm and the concatenated SMIPPC may be not\nan SMIPPC. This implies that our tracing algorithms have strong traceability.",
      "url": "http://arxiv.org/abs/2507.19384v1",
      "published_time_eastern_timestamp": 1753457844.0
    },
    {
      "title": "Latent-X: An Atom-level Frontier Model for De Novo Protein Binder Design",
      "summary": "Traditional drug discovery relies on rounds of screening millions of\ncandidate molecules with low success rates, making drug discovery time and\nresource intensive. To overcome this screening bottleneck, we introduce\nLatent-X, an all-atom protein design model that enables a new paradigm of\nprecision AI design. Given a target protein epitope, Latent-X jointly generates\nthe all atom structure and sequence of the protein binder and target, directly\nmodelling the non-covalent interactions essential for specific binding. We\ndemonstrate its efficacy across two therapeutically relevant modalities through\nextensive wet lab experiments, testing as few as 30-100 designs per target. For\nmacrocyclic peptides, Latent-X achieves experimental hit rates exceeding 90% on\nall evaluated benchmark targets. For mini-binders, it consistently produces\npotent candidates against all evaluated benchmark targets, with binding\naffinities reaching the low nanomolar and picomolar range - comparable to those\nof approved therapeutics - whilst also being highly specific in mammalian\ndisplay. In direct comparisons with the state-of-the-art models AlphaProteo,\nRFdiffusion and RFpeptides under identical conditions demonstrates, Latent-X\ngenerates binders with higher hit rates and better binding affinities, and\nuniquely creates structurally diverse binders, including complex beta-sheet\nfolds. Its end-to-end process is an order of magnitude faster than existing\nmulti-step computational pipelines. By drastically improving the efficiency and\nsuccess rate of de novo design, Latent-X represents a significant advance\ntowards push-button biologics discovery and a valuable tool for protein\nengineers. Latent-X is available at https://platform.latentlabs.com, enabling\nusers to reliably generate de novo binders without AI infrastructure or coding.",
      "url": "http://arxiv.org/abs/2507.19375v1",
      "published_time_eastern_timestamp": 1753457122.0
    },
    {
      "title": "EA-ViT: Efficient Adaptation for Elastic Vision Transformer",
      "summary": "Vision Transformers (ViTs) have emerged as a foundational model in computer\nvision, excelling in generalization and adaptation to downstream tasks.\nHowever, deploying ViTs to support diverse resource constraints typically\nrequires retraining multiple, size-specific ViTs, which is both time-consuming\nand energy-intensive. To address this issue, we propose an efficient ViT\nadaptation framework that enables a single adaptation process to generate\nmultiple models of varying sizes for deployment on platforms with various\nresource constraints. Our approach comprises two stages. In the first stage, we\nenhance a pre-trained ViT with a nested elastic architecture that enables\nstructural flexibility across MLP expansion ratio, number of attention heads,\nembedding dimension, and network depth. To preserve pre-trained knowledge and\nensure stable adaptation, we adopt a curriculum-based training strategy that\nprogressively increases elasticity. In the second stage, we design a\nlightweight router to select submodels according to computational budgets and\ndownstream task demands. Initialized with Pareto-optimal configurations derived\nvia a customized NSGA-II algorithm, the router is then jointly optimized with\nthe backbone. Extensive experiments on multiple benchmarks demonstrate the\neffectiveness and versatility of EA-ViT. The code is available at\nhttps://github.com/zcxcf/EA-ViT.",
      "url": "http://arxiv.org/abs/2507.19360v1",
      "published_time_eastern_timestamp": 1753456269.0
    },
    {
      "title": "SemGes: Semantics-aware Co-Speech Gesture Generation using Semantic\n  Coherence and Relevance Learning",
      "summary": "Creating a virtual avatar with semantically coherent gestures that are\naligned with speech is a challenging task. Existing gesture generation research\nmainly focused on generating rhythmic beat gestures, neglecting the semantic\ncontext of the gestures. In this paper, we propose a novel approach for\nsemantic grounding in co-speech gesture generation that integrates semantic\ninformation at both fine-grained and global levels. Our approach starts with\nlearning the motion prior through a vector-quantized variational autoencoder.\nBuilt on this model, a second-stage module is applied to automatically generate\ngestures from speech, text-based semantics and speaker identity that ensures\nconsistency between the semantic relevance of generated gestures and\nco-occurring speech semantics through semantic coherence and relevance modules.\nExperimental results demonstrate that our approach enhances the realism and\ncoherence of semantic gestures. Extensive experiments and user studies show\nthat our method outperforms state-of-the-art approaches across two benchmarks\nin co-speech gesture generation in both objective and subjective metrics. The\nqualitative results of our model, code, dataset and pre-trained models can be\nviewed at https://semgesture.github.io/.",
      "url": "http://arxiv.org/abs/2507.19359v1",
      "published_time_eastern_timestamp": 1753456215.0
    },
    {
      "title": "Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM\n  on Long-Context Tasks",
      "summary": "Recently, recurrent large language models (Recurrent LLMs) with linear\ncomputational complexity have re-emerged as efficient alternatives to\nself-attention-based LLMs (Self-Attention LLMs), which have quadratic\ncomplexity. However, Recurrent LLMs often underperform on long-context tasks\ndue to their limited fixed-size memory. Previous research has primarily focused\non enhancing the memory capacity of Recurrent LLMs through architectural\ninnovations, but these approaches have not yet enabled Recurrent LLMs to match\nthe performance of Self-Attention LLMs on long-context tasks. We argue that\nthis limitation arises because processing the entire context at once is not\nwell-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a\nchunk-wise inference method inspired by human reading strategies. Smooth\nReading processes context in chunks and iteratively summarizes the contextual\ninformation, thereby reducing memory demands and making the approach more\ncompatible with Recurrent LLMs. Our experimental results show that this method\nsubstantially narrows the performance gap between Recurrent and Self-Attention\nLLMs on long-context tasks, while preserving the efficiency advantages of\nRecurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from\n5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.\nBesides, our method maintains the high efficiency, training 3x faster and\ninferring 2x faster at 64k context compared to Self-Attention LLMs. To our\nknowledge, this is the first work to achieve comparable performance using\nRecurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope\nour method will inspire future research in this area. To facilitate further\nprogress, we will release code and dataset.",
      "url": "http://arxiv.org/abs/2507.19353v1",
      "published_time_eastern_timestamp": 1753455765.0
    },
    {
      "title": "Injecting External Knowledge into the Reasoning Process Enhances\n  Retrieval-Augmented Generation",
      "summary": "Retrieval-augmented generation (RAG) has been widely adopted to augment large\nlanguage models (LLMs) with external knowledge for knowledge-intensive tasks.\nHowever, its effectiveness is often undermined by the presence of noisy (i.e.,\nlow-quality) retrieved passages. Enhancing LLMs' robustness to such noise is\ncritical for improving the reliability of RAG systems. Recent advances have\nequipped LLMs with strong reasoning and self-reflection capabilities, allowing\nthem to identify and correct errors in their reasoning process. Inspired by\nthis ability, we propose Passage Injection-a simple yet effective method that\nexplicitly incorporates retrieved passages into LLMs' reasoning process, aiming\nto enhance the model's ability to recognize and resist noisy passages. We\nvalidate Passage Injection under general RAG settings using BM25 as the\nretriever. Experiments on four reasoning-enhanced LLMs across four factual QA\ndatasets demonstrate that Passage Injection significantly improves overall RAG\nperformance. Further analysis on two noisy retrieval settings-random noise,\nwhere the model is provided irrelevant passages, and counterfactual noise,\nwhere it is given misleading passages-shows that Passage Injection consistently\nimproves robustness. Controlled experiments confirm that Passage Injection can\nalso effectively leverage helpful passages. These findings suggest that\nincorporating passages in LLMs' reasoning process is a promising direction for\nbuilding more robust RAG systems. The code can be found\n\\href{here}{https://github.com/mh-tang/Passage-Injection}.",
      "url": "http://arxiv.org/abs/2507.19333v1",
      "published_time_eastern_timestamp": 1753454611.0
    },
    {
      "title": "Multistream Network for LiDAR and Camera-based 3D Object Detection in\n  Outdoor Scenes",
      "summary": "Fusion of LiDAR and RGB data has the potential to enhance outdoor 3D object\ndetection accuracy. To address real-world challenges in outdoor 3D object\ndetection, fusion of LiDAR and RGB input has started gaining traction. However,\neffective integration of these modalities for precise object detection task\nstill remains a largely open problem. To address that, we propose a MultiStream\nDetection (MuStD) network, that meticulously extracts task-relevant information\nfrom both data modalities. The network follows a three-stream structure. Its\nLiDAR-PillarNet stream extracts sparse 2D pillar features from the LiDAR input\nwhile the LiDAR-Height Compression stream computes Bird's-Eye View features. An\nadditional 3D Multimodal stream combines RGB and LiDAR features using UV\nmapping and polar coordinate indexing. Eventually, the features containing\ncomprehensive spatial, textural and geometric information are carefully fused\nand fed to a detection head for 3D object detection. Our extensive evaluation\non the challenging KITTI Object Detection Benchmark using public testing server\nat\nhttps://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=d162ec699d6992040e34314d19ab7f5c217075e0\nestablishes the efficacy of our method by achieving new state-of-the-art or\nhighly competitive results in different categories while remaining among the\nmost efficient methods. Our code will be released through MuStD GitHub\nrepository at https://github.com/IbrahimUWA/MuStD.git",
      "url": "http://arxiv.org/abs/2507.19304v1",
      "published_time_eastern_timestamp": 1753453216.0
    },
    {
      "title": "On the Security of a Code-Based PIR Scheme",
      "summary": "Private Information Retrieval (PIR) schemes allow clients to retrieve files\nfrom a database without disclosing the requested file's identity to the server.\nIn the pursuit of post-quantum security, most recent PIR schemes rely on hard\nlattice problems. In contrast, the so called CB-cPIR scheme stands out as a\npioneering effort to base PIR schemes on hard problems in coding theory,\nthereby contributing significantly to the diversification of security\nfoundations. However, our research reveals a critical vulnerability in CB-cPIR,\nsubstantially diminishing its security levels. Moreover, a comparative analysis\nwith state-of-the-art PIR schemes shows that CB-cPIR's advantages are reduced,\nmaking it less competitive in terms of the communication cost. Nevertheless,\nour findings highlight the importance of continued research into code-based PIR\nschemes, as they have the potential to provide a valuable alternative to\nlattice-based approaches.",
      "url": "http://arxiv.org/abs/2507.19295v1",
      "published_time_eastern_timestamp": 1753452720.0
    },
    {
      "title": "Balanced Gray Codes for Permutations and Rainbow Cycles for Associahedra",
      "summary": "We settle the problem of constructing a balanced transposition Gray code for\npermutations of $[n] := \\{1, \\dots, n\\}$ with $n \\in \\mathbb{N}\\setminus\\{0\\}$.\nMore generally, we obtain a~$2(m-2)!$-rainbow cycle for the permutations of\n$[n]$ for $m \\in [n]$, a notion recently introduced by Felsner, Kleist,\nM\\\"utze, and Sering. Furthermore, we extend a result of theirs by presenting a\n$k$-rainbow cycle for the classical associahedron $\\mathcal{A}_{n}$ for $k \\in\n[2n + 2]$.\n  For even $n$, we also construct a balanced Gray code for permutations of\n$[n]$, using only cyclically adjacent transpositions, complementing the\nconstruction for odd $n$ by Gregor, Merino, and M\\\"utze.\n  Additionally, we show that the Permutahedron $P_{n}$ admits a $2$-rainbow\ncycle for all $n\\ge5$ and a $3$-rainbow cycle for odd $n\\ge3$.",
      "url": "http://arxiv.org/abs/2507.19293v1",
      "published_time_eastern_timestamp": 1753452542.0
    },
    {
      "title": "SAM2-Aug: Prior knowledge-based Augmentation for Target Volume\n  Auto-Segmentation in Adaptive Radiation Therapy Using Segment Anything Model\n  2",
      "summary": "Purpose: Accurate tumor segmentation is vital for adaptive radiation therapy\n(ART) but remains time-consuming and user-dependent. Segment Anything Model 2\n(SAM2) shows promise for prompt-based segmentation but struggles with tumor\naccuracy. We propose prior knowledge-based augmentation strategies to enhance\nSAM2 for ART.\n  Methods: Two strategies were introduced to improve SAM2: (1) using prior MR\nimages and annotations as contextual inputs, and (2) improving prompt\nrobustness via random bounding box expansion and mask erosion/dilation. The\nresulting model, SAM2-Aug, was fine-tuned and tested on the One-Seq-Liver\ndataset (115 MRIs from 31 liver cancer patients), and evaluated without\nretraining on Mix-Seq-Abdomen (88 MRIs, 28 patients) and Mix-Seq-Brain (86\nMRIs, 37 patients).\n  Results: SAM2-Aug outperformed convolutional, transformer-based, and\nprompt-driven models across all datasets, achieving Dice scores of 0.86(liver),\n0.89(abdomen), and 0.90(brain). It demonstrated strong generalization across\ntumor types and imaging sequences, with improved performance in\nboundary-sensitive metrics.\n  Conclusions: Incorporating prior images and enhancing prompt diversity\nsignificantly boosts segmentation accuracy and generalizability. SAM2-Aug\noffers a robust, efficient solution for tumor segmentation in ART. Code and\nmodels will be released at https://github.com/apple1986/SAM2-Aug.",
      "url": "http://arxiv.org/abs/2507.19282v1",
      "published_time_eastern_timestamp": 1753451950.0
    },
    {
      "title": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical\n  Study on Industrial C# Projects",
      "summary": "Code review is essential for maintaining software quality but often\ntime-consuming and cognitively demanding, especially in industrial\nenvironments. Recent advancements in language models (LMs) have opened new\navenues for automating core review tasks. This study presents the empirical\nevaluation of monolingual fine-tuning on the performance of open-source LMs\nacross three key automated code review tasks: Code Change Quality Estimation,\nReview Comment Generation, and Code Refinement. We fine-tuned three distinct\nmodels, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\\# specific\ndataset combining public benchmarks with industrial repositories. Our study\ninvestigates how different configurations of programming languages and natural\nlanguages in the training data affect LM performance, particularly in comment\ngeneration. Additionally, we benchmark the fine-tuned models against an\nautomated software analysis tool (ASAT) and human reviewers to evaluate their\npractical utility in real-world settings. Our results show that monolingual\nfine-tuning improves model accuracy and relevance compared to multilingual\nbaselines. While LMs can effectively support code review workflows, especially\nfor routine or repetitive tasks, human reviewers remain superior in handling\nsemantically complex or context-sensitive changes. Our findings highlight the\nimportance of language alignment and task-specific adaptation in optimizing LMs\nfor automated code review.",
      "url": "http://arxiv.org/abs/2507.19271v1",
      "published_time_eastern_timestamp": 1753451364.0
    }
  ]
}
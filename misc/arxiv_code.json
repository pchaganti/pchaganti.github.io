{
  "last_updated": "2025-08-31T21:05:12.053622-04:00",
  "papers": [
    {
      "title": "OneReward: Unified Mask-Guided Image Generation via Multi-Task Human\n  Preference Learning",
      "summary": "In this paper, we introduce OneReward, a unified reinforcement learning\nframework that enhances the model's generative capabilities across multiple\ntasks under different evaluation criteria using only \\textit{One Reward} model.\nBy employing a single vision-language model (VLM) as the generative reward\nmodel, which can distinguish the winner and loser for a given task and a given\nevaluation criterion, it can be effectively applied to multi-task generation\nmodels, particularly in contexts with varied data and diverse task objectives.\nWe utilize OneReward for mask-guided image generation, which can be further\ndivided into several sub-tasks such as image fill, image extend, object\nremoval, and text rendering, involving a binary mask as the edit area. Although\nthese domain-specific tasks share same conditioning paradigm, they differ\nsignificantly in underlying data distributions and evaluation metrics. Existing\nmethods often rely on task-specific supervised fine-tuning (SFT), which limits\ngeneralization and training efficiency. Building on OneReward, we develop\nSeedream 3.0 Fill, a mask-guided generation model trained via multi-task\nreinforcement learning directly on a pre-trained base model, eliminating the\nneed for task-specific SFT. Experimental results demonstrate that our unified\nedit model consistently outperforms both commercial and open-source\ncompetitors, such as Ideogram, Adobe Photoshop, and FLUX Fill [Pro], across\nmultiple evaluation dimensions. Code and model are available at:\nhttps://one-reward.github.io",
      "url": "http://arxiv.org/abs/2508.21066v1",
      "published_time_eastern_timestamp": 1756403986.0
    },
    {
      "title": "MMG-Vid: Maximizing Marginal Gains at Segment-level and Token-level for\n  Efficient Video LLMs",
      "summary": "Video Large Language Models (VLLMs) excel in video understanding, but their\nexcessive visual tokens pose a significant computational challenge for\nreal-world applications. Current methods aim to enhance inference efficiency by\nvisual token pruning. However, they do not consider the dynamic characteristics\nand temporal dependencies of video frames, as they perceive video understanding\nas a multi-frame task. To address these challenges, we propose MMG-Vid, a novel\ntraining-free visual token pruning framework that removes redundancy by\nMaximizing Marginal Gains at both segment-level and token-level. Specifically,\nwe first divide the video into segments based on frame similarity, and then\ndynamically allocate the token budget for each segment to maximize the marginal\ngain of each segment. Subsequently, we propose a temporal-guided DPC algorithm\nthat jointly models inter-frame uniqueness and intra-frame diversity, thereby\nmaximizing the marginal gain of each token. By combining both stages, MMG-Vid\ncan maximize the utilization of the limited token budget, significantly\nimproving efficiency while maintaining strong performance. Extensive\nexperiments demonstrate that MMG-Vid can maintain over 99.5% of the original\nperformance, while effectively reducing 75% visual tokens and accelerating the\nprefilling stage by 3.9x on LLaVA-OneVision-7B. Code will be released soon.",
      "url": "http://arxiv.org/abs/2508.21044v1",
      "published_time_eastern_timestamp": 1756403403.0
    },
    {
      "title": "The power of binaries on stripped-envelope supernovae across\n  metallicity: uniform progenitor parameter space and persistently low ejecta\n  masses, but subtype diversity",
      "summary": "Stripped-envelope supernovae (SESNe) originate from massive stars that lose\ntheir envelopes through binary interactions or stellar winds. The connection\nbetween SESN subtypes and their progenitors remains poorly understood, as does\nthe influence of initial mass, binarity, explodability, and metallicity on\ntheir evolutionary pathways, relative rates, ejecta masses, and progenitor\nages. Here, we investigate these properties across a wide metallicity range\n(0.01-2 $Z_{\\odot}$) using POSYDON, a state-of-the-art population synthesis\ncode that incorporates detailed single- and binary-star model grids. We find\nthat the common-envelope channel contributes less than 6% of SESNe, since\nunstable mass transfer is found less frequent than previously thought and\nrarely leads to CE survival when envelope binding energies are computed from\ndetailed stellar models. The secondary channel accounts for less than 11%,\nwhile the vast majority of SESNe originate from primary stars in binaries\nundergoing stable mass-transfer episodes. These interactions maintain a largely\nmetallicity-independent SESN parameter space, making the overall SESN rate\nalmost insensitive to metallicity. In contrast, subtype fractions exhibit\nstrong metallicity dependence, though their exact values remain affected by\nclassification thresholds. The age distributions and therefore the progenitor\nmasses of different SESN types also vary significantly with metallicity,\nrevealing metallicity-dependent trends that can be tested observationally.\nPredicted SESN ejecta masses remain nearly constant across metallicity, in\ncontrast to single-star models, and fall within observed ranges. Future\ntransient surveys, combined with statistical environmental studies that\nconstrain metallicity dependence, will provide decisive tests of these\npredictions and of the dominant role of binary interactions in shaping SESNe.",
      "url": "http://arxiv.org/abs/2508.21042v1",
      "published_time_eastern_timestamp": 1756403214.0
    },
    {
      "title": "On the Theoretical Limitations of Embedding-Based Retrieval",
      "summary": "Vector embeddings have been tasked with an ever-increasing set of retrieval\ntasks over the years, with a nascent rise in using them for reasoning,\ninstruction-following, coding, and more. These new benchmarks push embeddings\nto work for any query and any notion of relevance that could be given. While\nprior works have pointed out theoretical limitations of vector embeddings,\nthere is a common assumption that these difficulties are exclusively due to\nunrealistic queries, and those that are not can be overcome with better\ntraining data and larger models. In this work, we demonstrate that we may\nencounter these theoretical limitations in realistic settings with extremely\nsimple queries. We connect known results in learning theory, showing that the\nnumber of top-k subsets of documents capable of being returned as the result of\nsome query is limited by the dimension of the embedding. We empirically show\nthat this holds true even if we restrict to k=2, and directly optimize on the\ntest set with free parameterized embeddings. We then create a realistic dataset\ncalled LIMIT that stress tests models based on these theoretical results, and\nobserve that even state-of-the-art models fail on this dataset despite the\nsimple nature of the task. Our work shows the limits of embedding models under\nthe existing single vector paradigm and calls for future research to develop\nmethods that can resolve this fundamental limitation.",
      "url": "http://arxiv.org/abs/2508.21038v1",
      "published_time_eastern_timestamp": 1756403033.0
    },
    {
      "title": "Inference-Time Alignment Control for Diffusion Models with Reinforcement\n  Learning Guidance",
      "summary": "Denoising-based generative models, particularly diffusion and flow matching\nalgorithms, have achieved remarkable success. However, aligning their output\ndistributions with complex downstream objectives, such as human preferences,\ncompositional accuracy, or data compressibility, remains challenging. While\nreinforcement learning (RL) fine-tuning methods, inspired by advances in RL\nfrom human feedback (RLHF) for large language models, have been adapted to\nthese generative frameworks, current RL approaches are suboptimal for diffusion\nmodels and offer limited flexibility in controlling alignment strength after\nfine-tuning. In this work, we reinterpret RL fine-tuning for diffusion models\nthrough the lens of stochastic differential equations and implicit reward\nconditioning. We introduce Reinforcement Learning Guidance (RLG), an\ninference-time method that adapts Classifier-Free Guidance (CFG) by combining\nthe outputs of the base and RL fine-tuned models via a geometric average. Our\ntheoretical analysis shows that RLG's guidance scale is mathematically\nequivalent to adjusting the KL-regularization coefficient in standard RL\nobjectives, enabling dynamic control over the alignment-quality trade-off\nwithout further training. Extensive experiments demonstrate that RLG\nconsistently improves the performance of RL fine-tuned models across various\narchitectures, RL algorithms, and downstream tasks, including human\npreferences, compositional control, compressibility, and text rendering.\nFurthermore, RLG supports both interpolation and extrapolation, thereby\noffering unprecedented flexibility in controlling generative alignment. Our\napproach provides a practical and theoretically sound solution for enhancing\nand controlling diffusion model alignment at inference. The source code for RLG\nis publicly available at the Github:\nhttps://github.com/jinluo12345/Reinforcement-learning-guidance.",
      "url": "http://arxiv.org/abs/2508.21016v1",
      "published_time_eastern_timestamp": 1756401511.0
    },
    {
      "title": "First-Order Viscous Relativistic Hydrodynamics on the Two-Sphere",
      "summary": "A few years ago, Bemfica, Disconzi, Noronha, and Kovtun (BDNK) formulated the\nfirst causal, stable, strongly hyperbolic, and locally well-posed theory of\nfirst-order viscous relativistic hydrodynamics. Since their inception, there\nhave been several numerical and analytic studies of the BDNK equations which\nhave revealed their promise in modeling relativistic flows when viscous,\nfirst-order corrections to ideal hydrodynamics are important. In this paper, we\npresent numerical solutions to the BDNK equations for a $4$D conformal fluid in\nMinkowski spacetime constrained to the surface of a geometric sphere. We\nnumerically solve the underlying equations of motion by use of finite\ndifference methods applied in cubed-sphere coordinates -- a multi-block grid\nstructure which regularly and continuously covers the surface of a sphere. We\npresent three test cases of our code: linearized fluid perturbations of\nequilibrium states, a smooth, stationary initial Gaussian pulse of energy\ndensity, and Kelvin-Helmholtz-unstable initial data. In the Gaussian test case\nwith sufficiently large entropy-normalized shear viscosity, the flow, though\ninitialized in equilibrium, dynamically diverges away from equilibrium and the\nregime of validity of first-order hydrodynamics as very steep gradients form in\nthe solution, causing convergence to be lost in the numerical simulation. This\nbehavior persists at all grid resolutions we have considered, and also occurs\nat much higher resolutions in simulations of planar-symmetric ($1+1$)D\nconformal flows. These solutions provide numerical evidence that singularities\nin solutions to the BDNK equations can form in finite time from smooth initial\ndata. The numerical methods we employ on the two-sphere can be readily extended\nto include variations in the radial direction, allowing for full ($3+1$)D\nsimulations of the BDNK equations in astrophysical applications.",
      "url": "http://arxiv.org/abs/2508.20998v1",
      "published_time_eastern_timestamp": 1756400374.0
    },
    {
      "title": "ExpertSim: Fast Particle Detector Simulation Using\n  Mixture-of-Generative-Experts",
      "summary": "Simulating detector responses is a crucial part of understanding the inner\nworkings of particle collisions in the Large Hadron Collider at CERN. Such\nsimulations are currently performed with statistical Monte Carlo methods, which\nare computationally expensive and put a significant strain on CERN's\ncomputational grid. Therefore, recent proposals advocate for generative machine\nlearning methods to enable more efficient simulations. However, the\ndistribution of the data varies significantly across the simulations, which is\nhard to capture with out-of-the-box methods. In this study, we present\nExpertSim - a deep learning simulation approach tailored for the Zero Degree\nCalorimeter in the ALICE experiment. Our method utilizes a\nMixture-of-Generative-Experts architecture, where each expert specializes in\nsimulating a different subset of the data. This allows for a more precise and\nefficient generation process, as each expert focuses on a specific aspect of\nthe calorimeter response. ExpertSim not only improves accuracy, but also\nprovides a significant speedup compared to the traditional Monte-Carlo methods,\noffering a promising solution for high-efficiency detector simulations in\nparticle physics experiments at CERN. We make the code available at\nhttps://github.com/patrick-bedkowski/expertsim-mix-of-generative-experts.",
      "url": "http://arxiv.org/abs/2508.20991v1",
      "published_time_eastern_timestamp": 1756399983.0
    },
    {
      "title": "Webly-Supervised Image Manipulation Localization via Category-Aware\n  Auto-Annotation",
      "summary": "Images manipulated using image editing tools can mislead viewers and pose\nsignificant risks to social security. However, accurately localizing the\nmanipulated regions within an image remains a challenging problem. One of the\nmain barriers in this area is the high cost of data acquisition and the severe\nlack of high-quality annotated datasets. To address this challenge, we\nintroduce novel methods that mitigate data scarcity by leveraging readily\navailable web data. We utilize a large collection of manually forged images\nfrom the web, as well as automatically generated annotations derived from a\nsimpler auxiliary task, constrained image manipulation localization.\nSpecifically, we introduce a new paradigm CAAAv2, which automatically and\naccurately annotates manipulated regions at the pixel level. To further improve\nannotation quality, we propose a novel metric, QES, which filters out\nunreliable annotations. Through CAAA v2 and QES, we construct MIMLv2, a\nlarge-scale, diverse, and high-quality dataset containing 246,212 manually\nforged images with pixel-level mask annotations. This is over 120x larger than\nexisting handcrafted datasets like IMD20. Additionally, we introduce Object\nJitter, a technique that further enhances model training by generating\nhigh-quality manipulation artifacts. Building on these advances, we develop a\nnew model, Web-IML, designed to effectively leverage web-scale supervision for\nthe image manipulation localization task. Extensive experiments demonstrate\nthat our approach substantially alleviates the data scarcity problem and\nsignificantly improves the performance of various models on multiple real-world\nforgery benchmarks. With the proposed web supervision, Web-IML achieves a\nstriking performance gain of 31% and surpasses previous SOTA TruFor by 24.1\naverage IoU points. The dataset and code will be made publicly available at\nhttps://github.com/qcf-568/MIML.",
      "url": "http://arxiv.org/abs/2508.20987v1",
      "published_time_eastern_timestamp": 1756399480.0
    },
    {
      "title": "ConfLogger: Enhance Systems' Configuration Diagnosability through\n  Configuration Logging",
      "summary": "Modern configurable systems offer customization via intricate configuration\nspaces, yet such flexibility introduces pervasive configuration-related issues\nsuch as misconfigurations and latent softwarebugs. Existing diagnosability\nsupports focus on post-failure analysis of software behavior to identify\nconfiguration issues, but none of these approaches look into whether the\nsoftware clue sufficient failure information for diagnosis. To fill in the\nblank, we propose the idea of configuration logging to enhance existing logging\npractices at the source code level. We develop ConfLogger, the first tool that\nunifies configuration-aware static taint analysis with LLM-based log generation\nto enhance software configuration diagnosability. Specifically, our method 1)\nidentifies configuration-sensitive code segments by tracing\nconfiguration-related data flow in the whole project, and 2) generates\ndiagnostic log statements by analyzing configuration code contexts. Evaluation\nresults on eight popular software systems demonstrate the effectiveness of\nConfLogger to enhance configuration diagnosability. Specifically,\nConfLogger-enhanced logs successfully aid a log-based misconfiguration\ndiagnosis tool to achieve 100% accuracy on error localization in 30 silent\nmisconfiguration scenarios, with 80% directly resolvable through explicit\nconfiguration information exposed. In addition, ConfLogger achieves 74%\ncoverage of existing logging points, outperforming baseline LLM-based loggers\nby 12% and 30%. It also gains 8.6% higher in precision, 79.3% higher in recall,\nand 26.2% higher in F1 compared to the state-of-the-art baseline in terms of\nvariable logging while also augmenting diagnostic value. A controlled user\nstudy on 22 cases further validated its utility, speeding up diagnostic time by\n1.25x and improving troubleshooting accuracy by 251.4%.",
      "url": "http://arxiv.org/abs/2508.20977v2",
      "published_time_eastern_timestamp": 1756398668.0
    },
    {
      "title": "Cosmo-Learn: code for learning cosmology using different methods and\n  mock data",
      "summary": "We present cosmo_learn, an open-source python-based software package designed\nto simulate cosmological data and perform data-driven inference using a range\nof modern statistical and machine learning techniques. Motivated by the growing\ncomplexity of cosmological models and the emergence of observational tensions,\ncosmo_learn provides a standardized and flexible framework for benchmarking\ncosmological inference methods. The package supports realistic noise modeling\nfor key observables in the late Universe, including cosmic chronometers,\nsupernovae Ia, baryon acoustic oscillations, redshift space distortions, and\ngravitational wave bright sirens. We demonstrate the internal consistency of\nthe simulated data with the input cosmology via residuals and parameter\nrecovery using a fiducial $w$CDM model. Built-in learning and inference modules\ninclude traditional Markov Chain Monte Carlo, as well as more recent approaches\nsuch as genetic algorithms, Gaussian processes, Bayesian ridge regression, and\nartificial neural networks. These methods are implemented in a modular and\nextensible architecture designed to facilitate comparisons across inference\nstrategies in a common pipeline. By providing a flexible and transparent\nsimulation and learning environment, cosmo_learn supports both educational and\nresearch efforts at the intersection of cosmology, statistics, and machine\nlearning.",
      "url": "http://arxiv.org/abs/2508.20971v1",
      "published_time_eastern_timestamp": 1756398322.0
    },
    {
      "title": "DrivingGaussian++: Towards Realistic Reconstruction and Editable\n  Simulation for Surrounding Dynamic Driving Scenes",
      "summary": "We present DrivingGaussian++, an efficient and effective framework for\nrealistic reconstructing and controllable editing of surrounding dynamic\nautonomous driving scenes. DrivingGaussian++ models the static background using\nincremental 3D Gaussians and reconstructs moving objects with a composite\ndynamic Gaussian graph, ensuring accurate positions and occlusions. By\nintegrating a LiDAR prior, it achieves detailed and consistent scene\nreconstruction, outperforming existing methods in dynamic scene reconstruction\nand photorealistic surround-view synthesis. DrivingGaussian++ supports\ntraining-free controllable editing for dynamic driving scenes, including\ntexture modification, weather simulation, and object manipulation, leveraging\nmulti-view images and depth priors. By integrating large language models (LLMs)\nand controllable editing, our method can automatically generate dynamic object\nmotion trajectories and enhance their realism during the optimization process.\nDrivingGaussian++ demonstrates consistent and realistic editing results and\ngenerates dynamic multi-view driving scenarios, while significantly enhancing\nscene diversity. More results and code can be found at the project site:\nhttps://xiong-creator.github.io/DrivingGaussian_plus.github.io",
      "url": "http://arxiv.org/abs/2508.20965v1",
      "published_time_eastern_timestamp": 1756398174.0
    },
    {
      "title": "On the non-existence of perfect codes in the sum-rank metric",
      "summary": "We study perfect codes in the sum-rank metric, a generalization of both the\nHamming and rank metrics relevant in multishot network coding and space-time\ncoding. A perfect code attains equality in the sphere-packing bound,\ncorresponding to a partition of the ambient space into disjoint metric balls.\nWhile perfect codes in the Hamming and rank metrics are completely classified,\nthe existence of nontrivial perfect codes in the sum-rank metric remains\nlargely open. In this paper, we investigate linear perfect codes in the\nsum-rank metric. We analyze the geometry of balls and derive bounds on their\nvolumes, showing how the sphere-packing bound applies. For two-block spaces, we\ndetermine explicit parameter constraints for the existence of perfect codes.\nFor multiple-block spaces, we establish non-existence results for various\nranges of minimum distance, divisibility conditions, and code dimensions. We\nfurther provide computational evidence based on congruence conditions imposed\nby the volume of metric balls.",
      "url": "http://arxiv.org/abs/2508.20940v1",
      "published_time_eastern_timestamp": 1756396901.0
    },
    {
      "title": "COMETH: Convex Optimization for Multiview Estimation and Tracking of\n  Humans",
      "summary": "In the era of Industry 5.0, monitoring human activity is essential for\nensuring both ergonomic safety and overall well-being. While multi-camera\ncentralized setups improve pose estimation accuracy, they often suffer from\nhigh computational costs and bandwidth requirements, limiting scalability and\nreal-time applicability. Distributing processing across edge devices can reduce\nnetwork bandwidth and computational load. On the other hand, the constrained\nresources of edge devices lead to accuracy degradation, and the distribution of\ncomputation leads to temporal and spatial inconsistencies. We address this\nchallenge by proposing COMETH (Convex Optimization for Multiview Estimation and\nTracking of Humans), a lightweight algorithm for real-time multi-view human\npose fusion that relies on three concepts: it integrates kinematic and\nbiomechanical constraints to increase the joint positioning accuracy; it\nemploys convex optimization-based inverse kinematics for spatial fusion; and it\nimplements a state observer to improve temporal consistency. We evaluate COMETH\non both public and industrial datasets, where it outperforms state-of-the-art\nmethods in localization, detection, and tracking accuracy. The proposed fusion\npipeline enables accurate and scalable human motion tracking, making it\nwell-suited for industrial and safety-critical applications. The code is\npublicly available at https://github.com/PARCO-LAB/COMETH.",
      "url": "http://arxiv.org/abs/2508.20920v1",
      "published_time_eastern_timestamp": 1756396229.0
    },
    {
      "title": "Vibe Coding: Is Human Nature the Ghost in the Machine?",
      "summary": "This exploratory study examined the consistency of human-AI collaboration by\nanalyzing three extensive \"vibe coding\" sessions between a human product lead\nand an AI software engineer. We investigated similarities and differences in\nteam dynamics, communication patterns, and development outcomes across both\nprojects. To our surprise, later conversations revealed that the AI agent had\nsystematically misrepresented its accomplishments, inflating its contributions\nand systematically downplaying implementation challenges. These findings\nsuggest that AI agents may not be immune to the interpersonal and psychological\nissues that affect human teams, possibly because they have been trained on\npatterns of human interaction expressed in writing. The results challenge the\nassumption that human-AI collaboration is inherently more productive or\nefficient than human-human collaboration, and creates a framework for\nunderstanding AI deception patterns. In doing so, it makes a compelling case\nfor extensive research in quality planning, quality assurance, and quality\ncontrol applied to vibe coding.",
      "url": "http://arxiv.org/abs/2508.20918v1",
      "published_time_eastern_timestamp": 1756396128.0
    },
    {
      "title": "Deep Learning Based Concurrency Bug Detection and Localization",
      "summary": "Concurrency bugs, caused by improper synchronization of shared resources in\nmulti-threaded or distributed systems, are notoriously hard to detect and thus\ncompromise software reliability and security. The existing deep learning\nmethods face three main limitations. First, there is an absence of large and\ndedicated datasets of diverse concurrency bugs for them. Second, they lack\nsufficient representation of concurrency semantics. Third, binary\nclassification results fail to provide finer-grained debug information such as\nprecise bug lines. To address these problems, we propose a novel method for\neffective concurrency bug detection as well as localization. We construct a\ndedicated concurrency bug dataset to facilitate model training and evaluation.\nWe then integrate a pre-trained model with a heterogeneous graph neural network\n(GNN), by incorporating a new Concurrency-Aware Code Property Graph (CCPG) that\nconcisely and effectively characterizes concurrency semantics. To further\nfacilitate debugging, we employ SubgraphX, a GNN-based interpretability method,\nwhich explores the graphs to precisely localize concurrency bugs, mapping them\nto specific lines of source code. On average, our method demonstrates an\nimprovement of 10\\% in accuracy and precision and 26\\% in recall compared to\nstate-of-the-art methods across diverse evaluation settings.",
      "url": "http://arxiv.org/abs/2508.20911v1",
      "published_time_eastern_timestamp": 1756395620.0
    },
    {
      "title": "Dino U-Net: Exploiting High-Fidelity Dense Features from Foundation\n  Models for Medical Image Segmentation",
      "summary": "Foundation models pre-trained on large-scale natural image datasets offer a\npowerful paradigm for medical image segmentation. However, effectively\ntransferring their learned representations for precise clinical applications\nremains a challenge. In this work, we propose Dino U-Net, a novel\nencoder-decoder architecture designed to exploit the high-fidelity dense\nfeatures of the DINOv3 vision foundation model. Our architecture introduces an\nencoder built upon a frozen DINOv3 backbone, which employs a specialized\nadapter to fuse the model's rich semantic features with low-level spatial\ndetails. To preserve the quality of these representations during dimensionality\nreduction, we design a new fidelity-aware projection module (FAPM) that\neffectively refines and projects the features for the decoder. We conducted\nextensive experiments on seven diverse public medical image segmentation\ndatasets. Our results show that Dino U-Net achieves state-of-the-art\nperformance, consistently outperforming previous methods across various imaging\nmodalities. Our framework proves to be highly scalable, with segmentation\naccuracy consistently improving as the backbone model size increases up to the\n7-billion-parameter variant. The findings demonstrate that leveraging the\nsuperior, dense-pretrained features from a general-purpose foundation model\nprovides a highly effective and parameter-efficient approach to advance the\naccuracy of medical image segmentation. The code is available at\nhttps://github.com/yifangao112/DinoUNet.",
      "url": "http://arxiv.org/abs/2508.20909v1",
      "published_time_eastern_timestamp": 1756395530.0
    },
    {
      "title": "Quantum Verifiable Rewards for Post-Training Qiskit Code Assistant",
      "summary": "Qiskit is an open-source quantum computing framework that allows users to\ndesign, simulate, and run quantum circuits on real quantum hardware. We explore\npost-training techniques for LLMs to assist in writing Qiskit code. We\nintroduce quantum verification as an effective method for ensuring code quality\nand executability on quantum hardware. To support this, we developed a\nsynthetic data pipeline that generates quantum problem-unit test pairs and used\nit to create preference data for aligning LLMs with DPO. Additionally, we\ntrained models using GRPO, leveraging quantum-verifiable rewards provided by\nthe quantum hardware. Our best-performing model, combining DPO and GRPO,\nsurpasses the strongest open-source baselines on the challenging\nQiskit-HumanEval-hard benchmark.",
      "url": "http://arxiv.org/abs/2508.20907v1",
      "published_time_eastern_timestamp": 1756395460.0
    },
    {
      "title": "Clustering of DESI galaxies split by thermal Sunyaev-Zeldovich effect",
      "summary": "The thermal Sunyaev-Zeldovich (tSZ) effect is associated with galaxy clusters\n- extremely large and dense structures tracing the dark matter with a higher\nbias than isolated galaxies. We propose to use the tSZ data to separate\ngalaxies from redshift surveys into distinct subpopulations corresponding to\ndifferent densities and biases independently of the redshift survey\nsystematics. Leveraging the information from different environments, as in\ndensity-split and density-marked clustering, is known to tighten the\nconstraints on cosmological parameters, like $\\Omega_m$, $\\sigma_8$ and\nneutrino mass. We use data from the Dark Energy Spectroscopic Instrument (DESI)\nand the Atacama Cosmology Telescope (ACT) in their region of overlap to\ndemonstrate informative tSZ splitting of Luminous Red Galaxies (LRGs). We\ndiscover a significant increase in the large-scale clustering of DESI LRGs\ncorresponding to detections starting from 1-2 sigma in the ACT DR6 + Planck tSZ\nCompton-$y$ map, below the cluster candidate threshold (4 sigma). We also find\nthat such galaxies have higher line-of-sight coordinate (and velocity)\ndispersions and a higher number of close neighbors than both the full sample\nand near-zero tSZ regions. We produce simple simulations of tSZ maps that are\nintrinsically consistent with galaxy catalogs and do not include systematic\neffects, and find a similar pattern of large-scale clustering enhancement with\ntSZ effect significance. Moreover, we observe that this relative bias pattern\nremains largely unchanged with variations in the galaxy-halo connection model\nin our simulations. This is promising for future cosmological inference from\ntSZ-split clustering with semi-analytical models. Thus, we demonstrate that\nvaluable cosmological information is present in the lower signal-to-noise\nregions of the thermal Sunyaev-Zeldovich map, extending far beyond the\nindividual cluster candidates.",
      "url": "http://arxiv.org/abs/2508.20904v1",
      "published_time_eastern_timestamp": 1756395379.0
    },
    {
      "title": "Modelling magnetic star-planet interaction in the iconic M dwarfs\n  Proxima Centauri, YZ Ceti and GJ 1151",
      "summary": "The unambiguous detection of magnetic star-planet interaction (SPI) via radio\nobservations would provide a novel method for detecting exoplanets and probing\ntheir magnetic fields. Although direct radio detection of sub-Jovian planets is\nhindered by the low frequencies involved, models of sub-Alfv\\'enic SPI predict\nthat Earth-like planets in close-in orbits around M dwarfs may induce\ndetectable emission. Here, we revisit the modelling of the expected radio\nemission from magnetic star-planet interaction in the iconic M-dwarf systems\nProxima Centauri, YZ Ceti, and GJ 1151, where claims of SPI-related radio\ndetections have been made. For this, we use SIRIO (Star-planet Interaction and\nRadio Induced Observations), a public Python code that models radio emission\nfrom sub-Alfv\\'enic SPI. We benchmark SIRIO results against those paradigmatic\nsystems, whose SPI modeling has been previously discussed in the literature.\nOur results support previous findings that Proxima b, YZ Cet b, and the\nputative planet GJ 1151 b are most likely in the sub-Alfv\\'enic regime\n(assuming a hybrid PFSS geometry), so SPI should be at work in all of them. We\nfind that the Alfv\\'en wing model generally predicts a very low level of radio\nemission, while if magnetic reconnection takes place, prospects for detection\nare significantly better. We also find that free-free absorption may play a\nrelevant role, in particular in YZ Ceti. Our SIRIO code can also be used to\nevaluate the feasibility of radio proposals aimed at detecting SPI, and to\nconstrain the stellar wind mass-loss rate or planetary magnetic field.",
      "url": "http://arxiv.org/abs/2508.20891v2",
      "published_time_eastern_timestamp": 1756394355.0
    },
    {
      "title": "Automated simulation-based design via multi-fidelity active learning and\n  optimisation for laser direct drive implosions",
      "summary": "The design of inertial fusion experiments is a complex task as driver energy\nmust be delivered in a precise manner to a structured target to achieve a fast,\nbut hydrodynamically stable, implosion. Radiation-hydrodynamics simulation\ncodes are an essential tool in this design process. However, multi-dimensional\nsimulations that capture hydrodynamic instabilities are more computationally\nexpensive than optimistic, 1D, spherically symmetric simulations which are\noften the primary design tool. In this work, we develop a machine learning\nframework that aims to effectively use information from a large number of 1D\nsimulations to inform design in the presence of hydrodynamic instabilities. We\nuse an ensemble of neural network surrogate models trained on both 1D and 2D\ndata to capture the space of good designs, i.e. those that are robust to\nhydrodynamic instabilities. We use this surrogate to perform Bayesian\noptimisation to find optimal designs for a 25 kJ laser driver. We perform\nhydrodynamic scaling on these designs to confirm the achievement of high gain\nfor a 2 MJ laser driver, using 2D simulations including alpha heating effects.",
      "url": "http://arxiv.org/abs/2508.20878v1",
      "published_time_eastern_timestamp": 1756393638.0
    }
  ]
}
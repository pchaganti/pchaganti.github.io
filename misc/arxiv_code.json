{
  "last_updated": "2025-06-23T02:19:25.296331-04:00",
  "papers": [
    {
      "title": "Long-term Traffic Simulation with Interleaved Autoregressive Motion and\n  Scenario Generation",
      "summary": "An ideal traffic simulator replicates the realistic long-term point-to-point\ntrip that a self-driving system experiences during deployment. Prior models and\nbenchmarks focus on closed-loop motion simulation for initial agents in a\nscene. This is problematic for long-term simulation. Agents enter and exit the\nscene as the ego vehicle enters new regions. We propose InfGen, a unified\nnext-token prediction model that performs interleaved closed-loop motion\nsimulation and scene generation. InfGen automatically switches between\nclosed-loop motion simulation and scene generation mode. It enables stable\nlong-term rollout simulation. InfGen performs at the state-of-the-art in\nshort-term (9s) traffic simulation, and significantly outperforms all other\nmethods in long-term (30s) simulation. The code and model of InfGen will be\nreleased at https://orangesodahub.github.io/InfGen",
      "url": "http://arxiv.org/abs/2506.17213v1",
      "published_time_eastern_timestamp": 1750442361.0
    },
    {
      "title": "UniFork: Exploring Modality Alignment for Unified Multimodal\n  Understanding and Generation",
      "summary": "Unified image understanding and generation has emerged as a promising\nparadigm in multimodal artificial intelligence. Despite recent progress, the\noptimal architectural design for such unified models remains an open challenge.\nIn this work, we start by analyzing the modality alignment behaviors of\ntask-specific expert models for understanding and generation, as well as\ncurrent unified models. Our analysis reveals a crucial observation:\nunderstanding tasks benefit from a progressively increasing modality alignment\nacross network depth, which helps build up semantic information for better\ncomprehension; In contrast, generation tasks follow a different trend: modality\nalignment increases in the early layers but decreases in the deep layers to\nrecover spatial details. These divergent alignment patterns create a\nfundamental conflict in fully shared Transformer backbones, where a uniform\nrepresentational flow often leads to performance compromises across two tasks.\nMotivated by this finding, we introduce UniFork, a novel Y-shaped architecture\nthat shares the shallow layers for cross-task representation learning, while\nemploying task-specific branches in deeper layers to avoid task interference.\nThis design effectively balances shared learning and task specialization.\nThrough extensive ablation experiments, we demonstrate that Unifork\nconsistently outperforms conventional fully shared Transformer architectures,\nand achieves performance on par with or better than task-specific models.",
      "url": "http://arxiv.org/abs/2506.17202v1",
      "published_time_eastern_timestamp": 1750441951.0
    },
    {
      "title": "Detecting LLM-Generated Short Answers and Effects on Learner Performance",
      "summary": "The increasing availability of large language models (LLMs) has raised\nconcerns about their potential misuse in online learning. While tools for\ndetecting LLM-generated text exist and are widely used by researchers and\neducators, their reliability varies. Few studies have compared the accuracy of\ndetection methods, defined criteria to identify content generated by LLM, or\nevaluated the effect on learner performance from LLM misuse within learning. In\nthis study, we define LLM-generated text within open responses as those\nproduced by any LLM without paraphrasing or refinement, as evaluated by human\ncoders. We then fine-tune GPT-4o to detect LLM-generated responses and assess\nthe impact on learning from LLM misuse. We find that our fine-tuned LLM\noutperforms the existing AI detection tool GPTZero, achieving an accuracy of\n80% and an F1 score of 0.78, compared to GPTZero's accuracy of 70% and macro F1\nscore of 0.50, demonstrating superior performance in detecting LLM-generated\nresponses. We also find that learners suspected of LLM misuse in the open\nresponse question were more than twice as likely to correctly answer the\ncorresponding posttest MCQ, suggesting potential misuse across both question\ntypes and indicating a bypass of the learning process. We pave the way for\nfuture work by demonstrating a structured, code-based approach to improve\nLLM-generated response detection and propose using auxiliary statistical\nindicators such as unusually high assessment scores on related tasks,\nreadability scores, and response duration. In support of open science, we\ncontribute data and code to support the fine-tuning of similar models for\nsimilar use cases.",
      "url": "http://arxiv.org/abs/2506.17196v1",
      "published_time_eastern_timestamp": 1750441656.0
    },
    {
      "title": "Comparison of spin-qubit architectures for quantum error-correcting\n  codes",
      "summary": "We investigate the performance of two quantum error-correcting codes, the\nsurface code and the Bacon-Shor code, for implementation with spin qubits in\nsilicon. In each case, we construct a logical qubit using a planar array of\nquantum dots, exploring two encoding schemes: one based solely on\nsingle-electron Zeeman qubits (Loss-DiVincenzo qubits), and a hybrid approach\ncombining Zeeman and singlet-triplet qubits. For both codes, we evaluate key\nperformance metrics, including logical state preparation fidelity and\ncycle-level error correction performance, using state-of-the-art experimental\nparameters. Our results show that the hybrid encoding consistently outperforms\nthe pure Zeeman-qubit implementation. By identifying the dominant error\nmechanisms that limit quantum error correction performance, our study\nhighlights concrete targets for improving spin qubit hardware and provides a\npath toward scalable fault-tolerant architectures. In particular, we find that\nthe logical error rate is not limited by memory errors, but rather by gate\nerrors, especially 1- and 2-qubit gate errors.",
      "url": "http://arxiv.org/abs/2506.17190v1",
      "published_time_eastern_timestamp": 1750441521.0
    },
    {
      "title": "Judo: A User-Friendly Open-Source Package for Sampling-Based Model\n  Predictive Control",
      "summary": "Recent advancements in parallel simulation and successful robotic\napplications are spurring a resurgence in sampling-based model predictive\ncontrol. To build on this progress, however, the robotics community needs\ncommon tooling for prototyping, evaluating, and deploying sampling-based\ncontrollers. We introduce Judo, a software package designed to address this\nneed. To facilitate rapid prototyping and evaluation, Judo provides robust\nimplementations of common sampling-based MPC algorithms and standardized\nbenchmark tasks. It further emphasizes usability with simple but extensible\ninterfaces for controller and task definitions, asynchronous execution for\nstraightforward simulation-to-hardware transfer, and a highly customizable\ninteractive GUI for tuning controllers interactively. While written in Python,\nthe software leverages MuJoCo as its physics backend to achieve real-time\nperformance, which we validate across both consumer and server-grade hardware.\nCode at https://github.com/bdaiinstitute/judo.",
      "url": "http://arxiv.org/abs/2506.17184v1",
      "published_time_eastern_timestamp": 1750441141.0
    },
    {
      "title": "$^{50}$Cr and $^{53}$Cr neutron capture cross sections measurement at\n  the n_TOF facility at CERN",
      "summary": "$^{50,53}$Cr are very relevant in criticality safety benchmarks related to\nnuclear reactors. The discrepancies between the neutron capture cross section\nevaluations have an important effect on the $k_{eff}$ and $k_{\\infty}$ in\ncriticality benchmarks particularly sensitive to chromium. The\n$^{50,53}$Cr(n,$\\gamma$) cross sections is to be determined between 1 and 100\nkeV with an 8-10% accuracy following the requirements of the NEA High Priority\nRequest List (HPRL) to solve the current discrepancies. We have measured the\nneutron capture cross sections by the time-of-flight technique at the EAR1\nexperimental area of the n_TOF facility, using an array of four C$_6$D$_6$\ndetectors with very low neutron sensitivity. The highly-enriched samples used\nare significantly thinner than in previous measurements, thus minimizing the\nmultiple-scattering effects. We have produced, and analyzed with the R-matrix\nanalysis code SAMMY, capture yields featuring 33 resonances of $^{50}$Cr and 51\nof $^{53}$Cr with an accuracy between 5% and 9%, hence fulfilling the\nrequirements made by the NEA. The differential and integral cross sections have\nbeen compared to previous data and evaluations. The new\n$^{50,53}$Cr(n,$\\gamma$) cross sections measured at the CERN n\\TOF facility\nprovide a valuable input for upcoming evaluations, which are deemed necessary\ngiven that the results presented herein do not support the increase in both\ncross sections proposed in the recent INDEN evaluation.",
      "url": "http://arxiv.org/abs/2506.17161v1",
      "published_time_eastern_timestamp": 1750439279.0
    },
    {
      "title": "Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile\n  Medical Segmentation",
      "summary": "Medical image analysis is critical yet challenged by the need of jointly\nsegmenting organs or tissues, and numerous instances for anatomical structures\nand tumor microenvironment analysis. Existing studies typically formulated\ndifferent segmentation tasks in isolation, which overlooks the fundamental\ninterdependencies between these tasks, leading to suboptimal segmentation\nperformance and insufficient medical image understanding. To address this\nissue, we propose a Co-Seg++ framework for versatile medical segmentation.\nSpecifically, we introduce a novel co-segmentation paradigm, allowing semantic\nand instance segmentation tasks to mutually enhance each other. We first devise\na spatio-temporal prompt encoder (STP-Encoder) to capture long-range spatial\nand temporal relationships between segmentation regions and image embeddings as\nprior spatial constraints. Moreover, we devise a multi-task collaborative\ndecoder (MTC-Decoder) that leverages cross-guidance to strengthen the\ncontextual consistency of both tasks, jointly computing semantic and instance\nsegmentation masks. Extensive experiments on diverse CT and histopathology\ndatasets demonstrate that the proposed Co-Seg++ outperforms state-of-the-arts\nin the semantic, instance, and panoptic segmentation of dental anatomical\nstructures, histopathology tissues, and nuclei instances. The source code is\navailable at https://github.com/xq141839/Co-Seg-Plus.",
      "url": "http://arxiv.org/abs/2506.17159v1",
      "published_time_eastern_timestamp": 1750439109.0
    },
    {
      "title": "Large Language Model Unlearning for Source Code",
      "summary": "LLM4SE has demonstrated significant success, but LLMs' potential memorization\nof sensitive or outdated training data introduces critical risks to legal\ncompliance, software security, and code quality. LLM unlearning techniques,\nwhich can eliminate the influence of undesired data from LLMs in a\npost-training way, present a promising solution to address these concerns.\nWhile recent efforts in LLM unlearning show effectiveness in natural language,\ntheir applicability to source code remains underexplored. Our empirical study\nreveals that existing LLM unlearning approaches, when applied to source code,\ncause severe model utility degradation, rendering models practically unusable\nfor code generation. In this paper, we propose PROD, a novel unlearning\napproach that enables LLMs to forget undesired code content while effectively\npreserving their code generation capabilities. PROD suppresses the probability\nof forget data in LLMs' output distribution while promoting candidate\ndistributional components, enabling the model to jointly learn to forget\nspecific content and retain its general capabilities. To facilitate this study,\nwe establish a benchmark for code unlearning evaluation, which includes three\ncritical downstream tasks: copyrighted code unlearning, insecure code\nunlearning, and deprecated API unlearning. Our evaluation demonstrates that\nPROD achieves superior balance between forget quality and model utility\ncompared to existing unlearning approaches across three downstream tasks, while\nconsistently exhibiting improvements when applied to LLMs of varying series.\nPROD also exhibits superior robustness against adversarial attacks without\ngenerating or exposing the data to be forgotten. The results underscore that\nour approach not only extends the application boundary of unlearning techniques\nto source code, but also holds significant implications for advancing reliable\ncode generation.",
      "url": "http://arxiv.org/abs/2506.17125v1",
      "published_time_eastern_timestamp": 1750436879.0
    },
    {
      "title": "Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context\n  LMs?",
      "summary": "Language models handle increasingly long contexts for tasks such as book\nsummarization, but this leads to growing memory costs for the key-value (KV)\ncache. Many prior works have proposed ways of discarding KVs from memory, but\ntheir approaches are tailored to favorable settings, obscuring caveats like\nhigh peak memory and performance degradation, and a fair comparison between\nmethods is difficult. In this paper, we propose the *KV footprint* as a unified\nmetric, which accounts for both the amount of KV entries stored and their\nlifespan in memory. We evaluate methods based on the smallest footprint they\nattain while preserving performance in both long-context understanding and\ngeneration, with context lengths of up to 128K tokens. This metric reveals the\nhigh peak memory of prior KV eviction methods. One class of methods --\n*post-fill eviction* -- has a high footprint due to being incompatible with\neviction during pre-filling. We adapt these methods to be able to evict KVs\nduring pre-filling, achieving substantially lower KV footprints. We then turn\nto *recency eviction* methods, wherein we propose PruLong, an end-to-end\noptimization method for learning which attention heads need to retain the full\nKV cache and which do not. PruLong saves memory while preserving long-context\nperformance, achieving 12% smaller KV footprint than prior methods while\nretaining performance in challenging recall tasks. Our paper clarifies the\ncomplex tangle of long-context inference methods and paves the way for future\ndevelopment to minimize the KV footprint.",
      "url": "http://arxiv.org/abs/2506.17121v1",
      "published_time_eastern_timestamp": 1750436472.0
    },
    {
      "title": "Reassessing Code Authorship Attribution in the Era of Language Models",
      "summary": "The study of Code Stylometry, and in particular Code Authorship Attribution\n(CAA), aims to analyze coding styles to identify the authors of code samples.\nCAA is crucial in cybersecurity and software forensics for addressing,\ndetecting plagiarism, and supporting criminal prosecutions. However, CAA is a\ncomplex and error prone task, due to the need for recognizing nuanced\nrelationships between coding patterns. This challenge is compounded in large\nsoftware systems with numerous authors due to the subtle variability of\npatterns that signify the coding style of one author among many. Given the\nchallenges related to this task, researchers have proposed and studied\nautomated approaches that rely upon classical Machine Learning and Deep\nLearning techniques. However, such techniques have historically relied upon\nhand-crafted features, and due to the often intricate interaction of different\nfeatures (e.g., formatting, etc.), have key limitations in properly\ncharacterizing authorship, and are sensitive to adversarial code perturbations.\nRecently, transformer-based Language Models (LMs) have shown remarkable\nefficacy across a range of software engineering tasks, and in the authorship\nattribution on natural language in the NLP domain. However, their effectiveness\nin CAA is not well understood. As such, we conduct the first extensive\nempirical study applying two larger state-of-the-art code LMs, and five smaller\ncode LMs to the task of CAA to 6 diverse datasets that encompass 12k code\nsnippets written by 463 developers. Furthermore, we perform an in-depth\nanalysis of our studied models' performance on CAA using established machine\nlearning interpretability techniques. The results of our analysis illustrate\nimportant findings that illuminate the behavior of LMs in understanding\nstylometric code patterns during the task of CAA, and point towards important\ndirections for future work.",
      "url": "http://arxiv.org/abs/2506.17120v1",
      "published_time_eastern_timestamp": 1750436370.0
    },
    {
      "title": "RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking",
      "summary": "We introduce a robust framework, RGBTrack, for real-time 6D pose estimation\nand tracking that operates solely on RGB data, thereby eliminating the need for\ndepth input for such dynamic and precise object pose tracking tasks. Building\non the FoundationPose architecture, we devise a novel binary search strategy\ncombined with a render-and-compare mechanism to efficiently infer depth and\ngenerate robust pose hypotheses from true-scale CAD models. To maintain stable\ntracking in dynamic scenarios, including rapid movements and occlusions,\nRGBTrack integrates state-of-the-art 2D object tracking (XMem) with a Kalman\nfilter and a state machine for proactive object pose recovery. In addition,\nRGBTrack's scale recovery module dynamically adapts CAD models of unknown scale\nusing an initial depth estimate, enabling seamless integration with modern\ngenerative reconstruction techniques. Extensive evaluations on benchmark\ndatasets demonstrate that RGBTrack's novel depth-free approach achieves\ncompetitive accuracy and real-time performance, making it a promising practical\nsolution candidate for application areas including robotics, augmented reality,\nand computer vision.\n  The source code for our implementation will be made publicly available at\nhttps://github.com/GreatenAnoymous/RGBTrack.git.",
      "url": "http://arxiv.org/abs/2506.17119v1",
      "published_time_eastern_timestamp": 1750436368.0
    },
    {
      "title": "Acquiring and Accumulating Knowledge from Diverse Datasets for\n  Multi-label Driving Scene Classification",
      "summary": "Driving scene identification, which assigns multiple non-exclusive class\nlabels to a scene, provides the contextual awareness necessary for enhancing\nautonomous vehicles' ability to understand, reason about, and interact with the\ncomplex driving environment. As a multi-label classification problem, it is\nbetter tackled via multitasking learning. However, directly training a\nmulti-label classification model for driving scene identification through\nmultitask learning presents two main challenges: acquiring a balanced,\ncomprehensively annotated multi-label dataset and balancing learning across\ndifferent tasks. This paper introduces a novel learning system that synergizes\nknowledge acquisition and accumulation (KAA) with consistency-based active\nlearning (CAL) to address those challenges. KAA acquires and accumulates\nknowledge about scene identification from various single-label datasets via\nmonotask learning. Subsequently, CAL effectively resolves the knowledge gap\ncaused by the discrepancy between the marginal distributions of individual\nattributes and their joint distribution. An ablation study on our Driving Scene\nIdentification (DSI) dataset demonstrates a 56.1% performance increase over the\nbaseline model pretrained on ImageNet. Of this, KAA accounts for 31.3% of the\ngain, and CAL contributes 24.8%. Moreover, KAA-CAL stands out as the best\nperformer when compared to state-of-the-art (SOTA) multi-label models on two\npublic datasets, BDD100K and HSD, achieving this while using 85% less data. The\nDSI dataset and the implementation code for KAA-CAL are available at\nhttps://github.com/KELISBU/KAA-CAL .",
      "url": "http://arxiv.org/abs/2506.17101v1",
      "published_time_eastern_timestamp": 1750435613.0
    },
    {
      "title": "Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language\n  Models: An Empirical Evaluation",
      "summary": "Large Language Models (LLMs) often exhibit \\textit{hallucinations},\ngenerating factually incorrect or semantically irrelevant content in response\nto prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by\nencouraging step-by-step reasoning, but its impact on hallucination detection\nremains underexplored. To bridge this gap, we conduct a systematic empirical\nevaluation. We begin with a pilot experiment, revealing that CoT reasoning\nsignificantly affects the LLM's internal states and token probability\ndistributions. Building on this, we evaluate the impact of various CoT\nprompting methods on mainstream hallucination detection methods across both\ninstruction-tuned and reasoning-oriented LLMs. Specifically, we examine three\nkey dimensions: changes in hallucination score distributions, variations in\ndetection accuracy, and shifts in detection confidence. Our findings show that\nwhile CoT prompting helps reduce hallucination frequency, it also tends to\nobscure critical signals used for detection, impairing the effectiveness of\nvarious detection methods. Our study highlights an overlooked trade-off in the\nuse of reasoning. Code is publicly available at:\nhttps://anonymous.4open.science/r/cot-hallu-detect.",
      "url": "http://arxiv.org/abs/2506.17088v1",
      "published_time_eastern_timestamp": 1750434577.0
    },
    {
      "title": "JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and\n  Efficient Cross-Facility Scientific Workflows",
      "summary": "In modern science, the growing complexity of large-scale projects has\nincreased reliance on cross-facility workflows, where institutions share\nresources and expertise to accelerate discovery. These workflows often involve\ntransferring massive data over wide-area networks. While high-speed networks\nlike ESnet and data transfer services like Globus have improved data mobility,\nchallenges remain. Large data volumes can strain bandwidth, TCP suffers from\nretransmissions due to packet loss, and traditional fault-tolerance methods\nlike erasure coding introduce significant overhead.\n  This paper presents JANUS, a resilient and adaptive data transmission\napproach for cross-facility scientific workflows. JANUS uses UDP, integrates\nerasure coding for fault tolerance, and applies error-bounded lossy compression\nto reduce overhead. This design enables users to balance transmission time and\naccuracy based on specific needs. JANUS also adapts coding parameters to\nreal-time network conditions and uses optimization models to determine ideal\nconfigurations. Experiments show that JANUS significantly improves data\ntransfer efficiency while preserving fidelity.",
      "url": "http://arxiv.org/abs/2506.17084v1",
      "published_time_eastern_timestamp": 1750434014.0
    },
    {
      "title": "Tower+: Bridging Generality and Translation Specialization in\n  Multilingual LLMs",
      "summary": "Fine-tuning pretrained LLMs has been shown to be an effective strategy for\nreaching state-of-the-art performance on specific tasks like machine\ntranslation. However, this process of adaptation often implies sacrificing\ngeneral-purpose capabilities, such as conversational reasoning and\ninstruction-following, hampering the utility of the system in real-world\napplications that require a mixture of skills. In this paper, we introduce\nTower+, a suite of models designed to deliver strong performance across both\ntranslation and multilingual general-purpose text capabilities. We achieve a\nPareto frontier between translation specialization and multilingual\ngeneral-purpose capabilities by introducing a novel training recipe that builds\non Tower (Alves et al., 2024), comprising continued pretraining, supervised\nfine-tuning, preference optimization, and reinforcement learning with\nverifiable rewards. At each stage of training, we carefully generate and curate\ndata to strengthen performance on translation as well as general-purpose tasks\ninvolving code generation, mathematics problem solving, and general\ninstruction-following. We develop models at multiple scales: 2B, 9B, and 72B.\nOur smaller models often outperform larger general-purpose open-weight and\nproprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers\nbest-in-class translation performance for high-resource languages and top\nresults in multilingual Arena Hard evaluations and in IF-MT, a benchmark we\nintroduce for evaluating both translation and instruction-following. Our\nfindings highlight that it is possible to rival frontier models in general\ncapabilities, while optimizing for specific business domains, such as\ntranslation and localization.",
      "url": "http://arxiv.org/abs/2506.17080v1",
      "published_time_eastern_timestamp": 1750433406.0
    },
    {
      "title": "Neural Polar Decoders for DNA Data Storage",
      "summary": "Synchronization errors, such as insertions and deletions, present a\nfundamental challenge in DNA-based data storage systems, arising from both\nsynthesis and sequencing noise. These channels are often modeled as\ninsertion-deletion-substitution (IDS) channels, for which designing\nmaximum-likelihood decoders is computationally expensive. In this work, we\npropose a data-driven approach based on neural polar decoders (NPDs) to design\nlow-complexity decoders for channels with synchronization errors. The proposed\narchitecture enables decoding over IDS channels with reduced complexity $O(AN\nlog N )$, where $A$ is a tunable parameter independent of the channel. NPDs\nrequire only sample access to the channel and can be trained without an\nexplicit channel model. Additionally, NPDs provide mutual information (MI)\nestimates that can be used to optimize input distributions and code design. We\ndemonstrate the effectiveness of NPDs on both synthetic deletion and IDS\nchannels. For deletion channels, we show that NPDs achieve near-optimal\ndecoding performance and accurate MI estimation, with significantly lower\ncomplexity than trellis-based decoders. We also provide numerical estimates of\nthe channel capacity for the deletion channel. We extend our evaluation to\nrealistic DNA storage settings, including channels with multiple noisy reads\nand real-world Nanopore sequencing data. Our results show that NPDs match or\nsurpass the performance of existing methods while using significantly fewer\nparameters than the state-of-the-art. These findings highlight the promise of\nNPDs for robust and efficient decoding in DNA data storage systems.",
      "url": "http://arxiv.org/abs/2506.17076v1",
      "published_time_eastern_timestamp": 1750433198.0
    },
    {
      "title": "Generative Modeling of Full-Atom Protein Conformations using Latent\n  Diffusion on Graph Embeddings",
      "summary": "Generating diverse, all-atom conformational ensembles of dynamic proteins\nsuch as G-protein-coupled receptors (GPCRs) is critical for understanding their\nfunction, yet most generative models simplify atomic detail or ignore\nconformational diversity altogether. We present latent diffusion for full\nprotein generation (LD-FPG), a framework that constructs complete all-atom\nprotein structures, including every side-chain heavy atom, directly from\nmolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural\nnetwork (ChebNet) to obtain low-dimensional latent embeddings of protein\nconformations, which are processed using three pooling strategies: blind,\nsequential and residue-based. A diffusion model trained on these latent\nrepresentations generates new samples that a decoder, optionally regularized by\ndihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a\n2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor\nin a membrane environment, the sequential and residue-based pooling strategy\nreproduces the reference ensemble with high structural fidelity (all-atom lDDT\nof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone\nand side-chain dihedral-angle distributions with a Jensen-Shannon divergence of\nless than 0.03 compared to the MD data. LD-FPG thereby offers a practical route\nto system-specific, all-atom ensemble generation for large proteins, providing\na promising tool for structure-based therapeutic design on complex, dynamic\ntargets. The D2R-MD dataset and our implementation are freely available to\nfacilitate further research.",
      "url": "http://arxiv.org/abs/2506.17064v1",
      "published_time_eastern_timestamp": 1750432354.0
    },
    {
      "title": "Generalized Code Distance through Rotated Logical States in Quantum\n  Error Correction",
      "summary": "We construct rotated logical states by applying rotation operators to\nstabilizer states, extending the logical basis and modifying stabilizer\ngenerators. Rotation operators affect the effective code distance $d_R$, which\ndecays exponentially with rotation angles $(\\theta, \\phi)$, influencing error\ncorrection performance. We quantify the scaling behavior of logical error rates\nunder circuit-level noise, comparing standard depolarizing (SD) and\nsuperconducting-inspired (SI) noise models with small and large rotations. Our\nfindings show that the rotated code scales as $0.68d_R (0.65d_R)$ for SD and\n$0.81d_R (0.77d_R)$ for SI, with small rotation angles leading to a steeper\ndecay of logical error rates. At a physical error rate $p_{phy}$ of $10^{-4}$,\nlogical errors decrease exponentially with $d_R$, particularly under SI noise,\nwhich exhibits stronger suppression. The threshold error rates for rotated\nlogical states are compared with previous results, demonstrating improved\nresilience against noise. By extending the logical state basis, rotation-based\nencoding increases error suppression beyond traditional stabilizer codes,\noffering a promising approach to advancing quantum error correction.",
      "url": "http://arxiv.org/abs/2506.17062v1",
      "published_time_eastern_timestamp": 1750432258.0
    },
    {
      "title": "MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network\n  Intrusion Detection",
      "summary": "Benchmark datasets for network intrusion detection commonly rely on\nsynthetically generated traffic, which fails to reflect the statistical\nvariability and temporal drift encountered in operational environments. This\npaper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1\ndataset, designed to enable realistic and reproducible evaluation of anomaly\ndetection methods. A reproducible preprocessing pipeline is presented that\ntransforms raw packet captures into flow representations conforming to the\nCICFlowMeter format, while preserving MAWILab's original anomaly labels. The\nresulting datasets comprise temporally distinct samples from January 2011,\n2016, and 2021, drawn from trans-Pacific backbone traffic.\n  To establish reference baselines, traditional machine learning methods,\nincluding Decision Trees, Random Forests, XGBoost, and Logistic Regression, are\ncompared to a deep learning model based on a CNN-BiLSTM architecture. Empirical\nresults demonstrate that tree-based classifiers perform well on temporally\nstatic data but experience significant performance degradation over time. In\ncontrast, the CNN-BiLSTM model maintains better performance, thus showing\nimproved generalization. These findings underscore the limitations of synthetic\nbenchmarks and static models, and motivate the adoption of realistic datasets\nwith explicit temporal structure. All datasets, pipeline code, and model\nimplementations are made publicly available to foster transparency and\nreproducibility.",
      "url": "http://arxiv.org/abs/2506.17041v1",
      "published_time_eastern_timestamp": 1750431095.0
    },
    {
      "title": "Robust Reinforcement Learning for Discrete Compositional Generation via\n  General Soft Operators",
      "summary": "A major bottleneck in scientific discovery involves narrowing a large\ncombinatorial set of objects, such as proteins or molecules, to a small set of\npromising candidates. While this process largely relies on expert knowledge,\nrecent methods leverage reinforcement learning (RL) to enhance this filtering.\nThey achieve this by estimating proxy reward functions from available datasets\nand using regularization to generate more diverse candidates. These reward\nfunctions are inherently uncertain, raising a particularly salient challenge\nfor scientific discovery. In this work, we show that existing methods, often\nframed as sampling proportional to a reward function, are inadequate and yield\nsuboptimal candidates, especially in large search spaces. To remedy this issue,\nwe take a robust RL approach and introduce a unified operator that seeks\nrobustness to the uncertainty of the proxy reward function. This general\noperator targets peakier sampling distributions while encompassing known soft\nRL operators. It also leads us to a novel algorithm that identifies\nhigher-quality, diverse candidates in both synthetic and real-world tasks.\nUltimately, our work offers a new, flexible perspective on discrete\ncompositional generation tasks. Code: https://github.com/marcojira/tgm.",
      "url": "http://arxiv.org/abs/2506.17007v1",
      "published_time_eastern_timestamp": 1750428197.0
    }
  ]
}
{
  "last_updated": "2025-12-08T10:14:19.636180-05:00",
  "papers": [
    {
      "title": "Training-Time Action Conditioning for Efficient Real-Time Chunking",
      "summary": "Real-time chunking (RTC) enables vision-language-action models (VLAs) to generate smooth, reactive robot trajectories by asynchronously predicting action chunks and conditioning on previously committed actions via inference-time inpainting. However, this inpainting method introduces computational overhead that increases inference latency. In this work, we propose a simple alternative: simulating inference delay at training time and conditioning on action prefixes directly, eliminating any inference-time overhead. Our method requires no modifications to the model architecture or robot runtime, and can be implemented with only a few additional lines of code. In simulated experiments, we find that training-time RTC outperforms inference-time RTC at higher inference delays. In real-world experiments on box building and espresso making tasks with the $π_{0.6}$ VLA, we demonstrate that training-time RTC maintains both task performance and speed parity with inference-time RTC while being computationally cheaper. Our results suggest that training-time action conditioning is a practical drop-in replacement for inference-time inpainting in real-time robot control.",
      "url": "http://arxiv.org/abs/2512.05964v1",
      "published_time_eastern_timestamp": 1764961048.0
    },
    {
      "title": "SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code",
      "summary": "We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems",
      "url": "http://arxiv.org/abs/2512.05954v1",
      "published_time_eastern_timestamp": 1764960648.0
    },
    {
      "title": "Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding",
      "summary": "Grounding is a fundamental capability for building graphical user interface (GUI) agents. Although existing approaches rely on large-scale bounding box supervision, they still face various challenges, such as cross-platform generalization, complex layout analysis, and fine-grained element localization. In this paper, we investigate zoom as a strong yet underexplored prior for GUI grounding, and propose a training-free method, ZoomClick. By characterizing four key properties of zoom (i.e., pre-zoom, depth, shrink size, minimal crop size), we unlock its full capabilities for dynamic spatial focusing and adaptive context switching. Experiments demonstrate that our method significantly boosts the performance of both general vision-language and specialized GUI grounding models, achieving state-of-the-art results on several mainstream benchmarks; for example, UI-Venus-72B attains a 73.1% success rate on ScreenSpot-Pro. Furthermore, we present GUIZoom-Bench, a benchmark for evaluating model adaptability to zoom, aiming to inspire future research on improving zoom for further training and test-time scaling in GUI grounding tasks.",
      "url": "http://arxiv.org/abs/2512.05941v1",
      "published_time_eastern_timestamp": 1764959952.0
    },
    {
      "title": "PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation",
      "summary": "Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.",
      "url": "http://arxiv.org/abs/2512.05930v1",
      "published_time_eastern_timestamp": 1764958495.0
    },
    {
      "title": "NICE: Neural Implicit Craniofacial Model for Orthognathic Surgery Prediction",
      "summary": "Orthognathic surgery is a crucial intervention for correcting dentofacial skeletal deformities to enhance occlusal functionality and facial aesthetics. Accurate postoperative facial appearance prediction remains challenging due to the complex nonlinear interactions between skeletal movements and facial soft tissue. Existing biomechanical, parametric models and deep-learning approaches either lack computational efficiency or fail to fully capture these intricate interactions. To address these limitations, we propose Neural Implicit Craniofacial Model (NICE) which employs implicit neural representations for accurate anatomical reconstruction and surgical outcome prediction. NICE comprises a shape module, which employs region-specific implicit Signed Distance Function (SDF) decoders to reconstruct the facial surface, maxilla, and mandible, and a surgery module, which employs region-specific deformation decoders. These deformation decoders are driven by a shared surgical latent code to effectively model the complex, nonlinear biomechanical response of the facial surface to skeletal movements, incorporating anatomical prior knowledge. The deformation decoders output point-wise displacement fields, enabling precise modeling of surgical outcomes. Extensive experiments demonstrate that NICE outperforms current state-of-the-art methods, notably improving prediction accuracy in critical facial regions such as lips and chin, while robustly preserving anatomical integrity. This work provides a clinically viable tool for enhanced surgical planning and patient consultation in orthognathic procedures.",
      "url": "http://arxiv.org/abs/2512.05920v1",
      "published_time_eastern_timestamp": 1764957404.0
    },
    {
      "title": "Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures",
      "summary": "Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.",
      "url": "http://arxiv.org/abs/2512.05908v1",
      "published_time_eastern_timestamp": 1764956529.0
    },
    {
      "title": "Computer simulations of the Stark effect in the helium-beta complex of krypton in ICF conditions",
      "summary": "There is an ongoing interest in using spectroscopy in inertial confinement fusion (ICF) experiments, where dopants such as krypton can provide vital information about the temperature and density of the imploding plasma. While the most advanced tools for calculating Stark profiles are computer simulation models (CSMs), their application to complex lineshapes under the extreme conditions of ICF experiments is computationally challenging. In this manuscript, we present results of several CSM realizations applied to the Stark shape of the krypton He-beta line and its satellites at ICF-relevant conditions (ne = 1e24 to 1e25 cm-3, Te = 3keV). We demonstrate that codes with the same underlying physics but different numerical approaches yield identical results and analyze the differences in the line profile caused by various physical effects.",
      "url": "http://arxiv.org/abs/2512.05903v1",
      "published_time_eastern_timestamp": 1764956107.0
    },
    {
      "title": "Differentially rotating neutron stars with dark matter cores",
      "summary": "Dark matter is expected to accumulate inside neutron stars, modifying the structure of isolated stars and influencing both the dynamics of binary mergers and the evolution of the resulting hypermassive remnants. Since differential rotation is the primary mechanism delaying the collapse of these remnants, understanding its behavior is crucial when assessing the impact of an embedded dark component. In this work, we extend the numerical code RNS to describe two gravitationally coupled fluids in differential rotation, with baryonic matter modeled by a realistic nuclear equation of state and dark matter represented as a self-interacting bosonic condensate. Within this framework, we construct equilibrium sequences for a representative differential rotation law, providing a basis to explore how dark matter may influence the global properties and rotational dynamics of binary neutron star remnants.",
      "url": "http://arxiv.org/abs/2512.05898v1",
      "published_time_eastern_timestamp": 1764955335.0
    },
    {
      "title": "DAE-HardNet: A Physics Constrained Neural Network Enforcing Differential-Algebraic Hard Constraints",
      "summary": "Traditional physics-informed neural networks (PINNs) do not always satisfy physics based constraints, especially when the constraints include differential operators. Rather, they minimize the constraint violations in a soft way. Strict satisfaction of differential-algebraic equations (DAEs) to embed domain knowledge and first-principles in data-driven models is generally challenging. This is because data-driven models consider the original functions to be black-box whose derivatives can only be obtained after evaluating the functions. We introduce DAE-HardNet, a physics-constrained (rather than simply physics-informed) neural network that learns both the functions and their derivatives simultaneously, while enforcing algebraic as well as differential constraints. This is done by projecting model predictions onto the constraint manifold using a differentiable projection layer. We apply DAE-HardNet to several systems and test problems governed by DAEs, including the dynamic Lotka-Volterra predator-prey system and transient heat conduction. We also show the ability of DAE-HardNet to estimate unknown parameters through a parameter estimation problem. Compared to multilayer perceptrons (MLPs) and PINNs, DAE-HardNet achieves orders of magnitude reduction in the physics loss while maintaining the prediction accuracy. It has the added benefits of learning the derivatives which improves the constrained learning of the backbone neural network prior to the projection layer. For specific problems, this suggests that the projection layer can be bypassed for faster inference. The current implementation and codes are available at https://github.com/SOULS-TAMU/DAE-HardNet.",
      "url": "http://arxiv.org/abs/2512.05881v1",
      "published_time_eastern_timestamp": 1764953754.0
    },
    {
      "title": "Complex Bounded Operators in Isabelle/HOL",
      "summary": "Functional analysis, especially the theory of Hilbert spaces and of operators on these, form an important area in mathematics. We formalized the Isabelle/HOL library Complex_Bounded_Operators containing a large amount of theorems about complex Hilbert spaces and (bounded) operators on these.\n  Specifically, we formalize the properties complex vector spaces, inner product (and Hilbert) spaces, one-dimensional spaces, bounded operators, adjoints, unitaries, projections, extensions of bounded operators (BLT-theorem), positive operators, square-summable sequences and much more.\n  Additionally, we provide support for code generation in the finite-dimensional case.",
      "url": "http://arxiv.org/abs/2512.05878v1",
      "published_time_eastern_timestamp": 1764953674.0
    },
    {
      "title": "Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments",
      "summary": "This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.",
      "url": "http://arxiv.org/abs/2512.05832v1",
      "published_time_eastern_timestamp": 1764950177.0
    },
    {
      "title": "Phase-OTDR Event Detection Using Image-Based Data Transformation and Deep Learning",
      "summary": "This study focuses on event detection in optical fibers, specifically classifying six events using the Phase-OTDR system. A novel approach is introduced to enhance Phase-OTDR data analysis by transforming 1D data into grayscale images through techniques such as Gramian Angular Difference Field, Gramian Angular Summation Field, and Recurrence Plot. These grayscale images are combined into a multi-channel RGB representation, enabling more robust and adaptable analysis using transfer learning models. The proposed methodology achieves high classification accuracies of 98.84% and 98.24% with the EfficientNetB0 and DenseNet121 models, respectively. A 5-fold cross-validation process confirms the reliability of these models, with test accuracy rates of 99.07% and 98.68%. Using a publicly available Phase-OTDR dataset, the study demonstrates an efficient approach to understanding optical fiber events while reducing dataset size and improving analysis efficiency. The results highlight the transformative potential of image-based analysis in interpreting complex fiber optic sensing data, offering significant advancements in the accuracy and reliability of fiber optic monitoring systems. The codes and the corresponding image-based dataset are made publicly available on GitHub to support further research: https://github.com/miralab-ai/Phase-OTDR-event-detection.",
      "url": "http://arxiv.org/abs/2512.05830v1",
      "published_time_eastern_timestamp": 1764949960.0
    },
    {
      "title": "UG-FedDA: Uncertainty-Guided Federated Domain Adaptation for Multi-Center Alzheimer's Disease Detection",
      "summary": "Alzheimer's disease (AD) is an irreversible neurodegenerative disorder, and early diagnosis is critical for timely intervention. However, most existing classification frameworks face challenges in multicenter studies, as they often neglect inter-site heterogeneity and lack mechanisms to quantify uncertainty, which limits their robustness and clinical applicability. To address these issues, we proposed Uncertainty-Guided Federated Domain Adaptation (UG-FedDA), a novel multicenter AD classification framework that integrates uncertainty quantification (UQ) with federated domain adaptation to handle cross-site structure magnetic resonance imaging (MRI) heterogeneity under privacy constraints. Our approach extracts multi-template region-of-interest (RoI) features using a self-attention transformer, capturing both regional representations and their interactions. UQ is integrated to guide feature alignment, mitigating source-target distribution shifts by down-weighting uncertain samples. Experiments are conducted on three public datasets: the Alzheimer's Disease Neuroimaging Initiative (ADNI), the Australian Imaging, Biomarkers and Lifestyle study (AIBL), and the Open Access Series of Imaging Studies (OASIS). UG-FedDA achieved consistent cross-domain improvements in accuracy, sensitivity, and area under the ROC curve across three classification tasks: AD vs. normal controls (NC), mild cognitive impairment (MCI) vs. AD, and NC vs. MCI. For NC vs. AD, UG-FedDA achieves accuracies of 90.54%, 89.04%, and 77.78% on ADNI, AIBL and OASIS datasets, respectively. For MCI vs. AD, accuracies are 80.20% (ADNI), 71.91% (AIBL), and 79.73% (OASIS). For NC vs. MCI, results are 76.87% (ADNI), 73.91% (AIBL), and 83.73% (OASIS). These results demonstrate that the proposed framework not only adapts efficiently across multiple sites but also preserves strict privacy.",
      "url": "http://arxiv.org/abs/2512.05814v1",
      "published_time_eastern_timestamp": 1764948832.0
    },
    {
      "title": "Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling",
      "summary": "Vision-Language Models (VLMs) remain limited in spatial reasoning tasks that require multi-view understanding and embodied perspective shifts. Recent approaches such as MindJourney attempt to mitigate this gap through test-time scaling where a world model imagines action-conditioned trajectories and a heuristic verifier selects helpful views from such trajectories. In this work, we systematically examine how such test-time verifiers behave across benchmarks, uncovering both their promise and their pitfalls. Our uncertainty-based analyses show that MindJourney's verifier provides little meaningful calibration, and that random scoring often reduces answer entropy equally well, thus exposing systematic action biases and unreliable reward signals. To mitigate these, we introduce a Verification through Spatial Assertions (ViSA) framework that grounds the test-time reward in verifiable, frame-anchored micro-claims. This principled verifier consistently improves spatial reasoning on the SAT-Real benchmark and corrects trajectory-selection biases through more balanced exploratory behavior. However, on the challenging MMSI-Bench, none of the verifiers, including ours, achieve consistent scaling, suggesting that the current world models form an information bottleneck where imagined views fail to enrich fine-grained reasoning. Together, these findings chart the bad, good, and ugly aspects of test-time verification for world-model-based reasoning. Our code is available at https://github.com/chandar-lab/visa-for-mindjourney.",
      "url": "http://arxiv.org/abs/2512.05809v1",
      "published_time_eastern_timestamp": 1764948608.0
    },
    {
      "title": "Bring Your Dreams to Life: Continual Text-to-Video Customization",
      "summary": "Customized text-to-video generation (CTVG) has recently witnessed great progress in generating tailored videos from user-specific text. However, most CTVG methods assume that personalized concepts remain static and do not expand incrementally over time. Additionally, they struggle with forgetting and concept neglect when continuously learning new concepts, including subjects and motions. To resolve the above challenges, we develop a novel Continual Customized Video Diffusion (CCVD) model, which can continuously learn new concepts to generate videos across various text-to-video generation tasks by tackling forgetting and concept neglect. To address catastrophic forgetting, we introduce a concept-specific attribute retention module and a task-aware concept aggregation strategy. They can capture the unique characteristics and identities of old concepts during training, while combining all subject and motion adapters of old concepts based on their relevance during testing. Besides, to tackle concept neglect, we develop a controllable conditional synthesis to enhance regional features and align video contexts with user conditions, by incorporating layer-specific region attention-guided noise estimation. Extensive experimental comparisons demonstrate that our CCVD outperforms existing CTVG models. The code is available at https://github.com/JiahuaDong/CCVD.",
      "url": "http://arxiv.org/abs/2512.05802v1",
      "published_time_eastern_timestamp": 1764948356.0
    },
    {
      "title": "Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth",
      "summary": "When depth sensors provide only 5% of needed measurements, reconstructing complete 3D scenes becomes difficult. Autonomous vehicles and robots cannot tolerate the geometric errors that sparse reconstruction introduces. We propose curvature regularization through a discrete Laplacian operator, achieving 18.1% better reconstruction accuracy than standard variational autoencoders. Our contribution challenges an implicit assumption in geometric deep learning: that combining multiple geometric constraints improves performance. A single well-designed regularization term not only matches but exceeds the effectiveness of complex multi-term formulations. The discrete Laplacian offers stable gradients and noise suppression with just 15% training overhead and zero inference cost. Code and models are available at https://github.com/Maryousefi/GeoVAE-3D.",
      "url": "http://arxiv.org/abs/2512.05783v1",
      "published_time_eastern_timestamp": 1764947464.0
    },
    {
      "title": "Introduction to Quantum Groups and Yang-Baxter Equation For Probabilists",
      "summary": "These are a set of lecture notes for a mini-course I gave at The University of Warwick from October 30th to November 1st, 2024. Recordings of the lectures are available on Oleg Zaboronski's webpage at https://warwick.ac.uk/fac/sci/maths/people/staff/oleg_zaboronski/jeffrey_kuan_visit/ . The main body of the notes covers the content of the lectures, and provides an introduction to Drinfel'd-Jimbo quantum groups and the Yang-Baxter equation, with a probabilist as the target audience. The appendix contains several topics, requested by colleagues during my visit to the United Kingdom, which all depend on the main set of notes.\n  The notes begin by defining what it means for the asymmetric simple exclusion process (ASEP) to be integrable, in the sense of satisfying the Yang-Baxter equation. It then provides the algebraic background for the Yang-Baxter equation, by defining Drinfel'd-Jimbo groups as a quasi-triangular Hopf algebra. The algebraic background motivates generalizations of ASEP to stochastic vertex models and \"fused\" models. Each section corresponds to approximately an hour of lecture time.\n  The appendix covers the F.R.T. construction, Hecke algebras, the matrix product ansatz, and orthogonal polynomial vertex weights. The topics in the appendix can be read independently of each other.\n  Accessibility Statement: This PDF meets the technical standards of WCAG2.1AA, which complies with Ohio Administrative Policy IT-09 , Texas Administrative Code 206.70 and Title II of the Americans with Disabilities Act (effective April 24, 2026) . A webpage version of this PDF, typeset in MathML, is also available at https://go.osu.edu/QuantumKuan . To block web crawlers, the webpage is password protected. The password is TaySwift13. As an additional benefit, the webpage will have space for public comments and a list of updated errata, without the need to update the arXiv version.",
      "url": "http://arxiv.org/abs/2512.05782v1",
      "published_time_eastern_timestamp": 1764947456.0
    },
    {
      "title": "Pauli Decomposition of Impedance Matrices for Understanding the Root Cause of Instabilities in Grid-Connected Power Electronic Converters",
      "summary": "The impedance criterion has emerged as an alternative way to stability assessment of grid-connected power electronic converters. However, the lack of physical meaning of impedance and admittance matrices hinders the ability to understand the root cause of instabilities. To address this issue, this paper proposes the application of Pauli decomposition to the impedance matrices and the minor loop of grid-connected power electronic converters. The application of this methodology simplifies establishing the link between impedance matrix terms and closed-loop stability properties. Moreover, Pauli decomposition transforms impedance matrices in a quaternion-like form that is helpful to assess the root cause of instabilities. The theoretical contributions are validated using a case study consisting of a power electronic converter connected to a weak grid that has been previously analysed in the literature using existing techniques.",
      "url": "http://arxiv.org/abs/2512.05780v1",
      "published_time_eastern_timestamp": 1764947384.0
    },
    {
      "title": "Radar Network Waveform Design for Target Tracking",
      "summary": "This paper addresses the synthesis of slow-time coded waveforms for single target tracking in a radar network operating under colored Gaussian interference. Based on the Posterior Cramér Rao Lower Bound (PCRLB), which characterizes the theoretically optimal accuracy of target state estimation, the problem at each tracking frame is formulated as the minimization of the trace of the PCRLB, together with power budget requirements and a similarity constraint to account for transmitter limitations and appropriate waveform features. To tackle this challenging optimization problem, an approximation solution technique is proposed, aimed at better tracking accuracy than the reference code. The resulting approximated problems, endowed with more tractable objective functions through Taylor-series expansion, are solved using a customized block Majorization-Minimization (block-MM) algorithm. The convergence properties of the developed procedure are thoroughly analyzed. Numerical results illustrate the accuracy improvements in the target state estimation process, and robust tracking performance under uncertain target state conditions achieved by the proposed technique.",
      "url": "http://arxiv.org/abs/2512.05757v1",
      "published_time_eastern_timestamp": 1764945796.0
    },
    {
      "title": "Stellar cores live long and prosper in cuspy dark matter halos",
      "summary": "The existence of cuspy or cored centers of dark matter halos is a crucial discriminant between different dark matter models. It has recently been claimed based on dynamical arguments that perfectly cored stellar systems cannot survive inside cuspy dark matter halos, which would make the observation of stellar cores in ultra-faint dwarf galaxies, where dark matter cores cannot form through baryonic processes, a direct falsification of the cold dark matter paradigm. Here, we use idealized simulations to show explicitly that cored stellar systems like those observed in dwarf galaxies can be stable within cuspy dark matter halos over at least several Hubble times. We also demonstrate that observations of ultra-faint dwarf galaxies cannot distinguish mildly positive, flat, or negative inner density slopes, further precluding the dynamical inference of the gravitational potential from the stellar configuration.",
      "url": "http://arxiv.org/abs/2512.05719v1",
      "published_time_eastern_timestamp": 1764942522.0
    }
  ]
}
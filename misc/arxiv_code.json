{
  "last_updated": "2026-01-05T07:28:07.629784-05:00",
  "papers": [
    {
      "title": "FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing",
      "summary": "Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE",
      "url": "http://arxiv.org/abs/2601.00785v1",
      "published_time_eastern_timestamp": 1767379241.0
    },
    {
      "title": "Memory Bank Compression for Continual Adaptation of Large Language Models",
      "summary": "Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.",
      "url": "http://arxiv.org/abs/2601.00756v1",
      "published_time_eastern_timestamp": 1767374554.0
    },
    {
      "title": "Early-Stage Prediction of Review Effort in AI-Generated Pull Requests",
      "summary": "As autonomous AI agents transition from code completion tools to full-fledged teammates capable of opening pull requests (PRs) at scale, software maintainers face a new challenge: not just reviewing code, but managing complex interaction loops with non-human contributors. This paradigm shift raises a critical question: can we predict which agent-generated PRs will consume excessive review effort before any human interaction begins?\n  Analyzing 33,707 agent-authored PRs from the AIDev dataset across 2,807 repositories, we uncover a striking two-regime behavioral pattern that fundamentally distinguishes autonomous agents from human developers. The first regime, representing 28.3 percent of all PRs, consists of instant merges (less than 1 minute), reflecting success on narrow automation tasks. The second regime involves iterative review cycles where agents frequently stall or abandon refinement (ghosting).\n  We propose a Circuit Breaker triage model that predicts high-review-effort PRs (top 20 percent) at creation time using only static structural features. A LightGBM model achieves AUC 0.957 on a temporal split, while semantic text features (TF-IDF, CodeBERT) provide negligible predictive value. At a 20 percent review budget, the model intercepts 69 percent of total review effort, enabling zero-latency governance.\n  Our findings challenge prevailing assumptions in AI-assisted code review: review burden is dictated by what agents touch, not what they say, highlighting the need for structural governance mechanisms in human-AI collaboration.",
      "url": "http://arxiv.org/abs/2601.00753v1",
      "published_time_eastern_timestamp": 1767374281.0
    },
    {
      "title": "Three results on twisted $G-$codes and skew twisted $G-$codes",
      "summary": "In this paper we solve an open question formulated in the original paper of twisted skew group codes regarding when a twisted skew group code is checkable. Also, we prove that all ideals of dimension 3 over a twisted group algebra are abelian group codes, generalising another previous result over group algebras. Finally, we prove a bound on the dimension and distance of a twisted group code, as well as when such bound is reached.",
      "url": "http://arxiv.org/abs/2601.00752v1",
      "published_time_eastern_timestamp": 1767374169.0
    },
    {
      "title": "One-dimensional and time-dependent modelling of complex organic molecules in protostars",
      "summary": "Complex organic molecules (COMs), the building blocks of life, have been extensively detected under various physical conditions, from quiescent clouds to star-forming regions. They therefore serve as excellent tracers for the local physical and chemical properties of these environments. Proper models that are capable of grasping the formation and destruction of COMs are crucial to understanding observations. However, given that distinct COMs may be detected from different locations and at varying times, we improve UCLCHEM - a gas-grain chemical code - to a one-dimensional, time-dependent model, tailored to protostars. In this update, we examine two stages of a protostar: the prestellar and heating stages, incorporating a simple radiative mechanism for both the internal and external radiation fields of the cloud. This approach relies on the key assumption that the dust and gas temperatures are completely coupled. Ultimately, we implement an updated version of our model to interpret observations obtained through both single-dish and interferometry under varying conditions, including a SgrB2(N1) hot core, massive Galactic clumps and a hot core in Orion. We show that our model could reproduce these observations well, highlighting that some COMs are positioned at a higher temperature in the envelope, whereas others are from the lower temperature, potentially leading to misinterpretation when using a single-point model. In a particular case of SgrB2(N1), the best model indicates that the cosmic-ray ionisation rate significantly exceeds the value typically used for the standard interstellar medium. Our model shows as an efficient computational tool particularly useful for better insights into observations of COMs.",
      "url": "http://arxiv.org/abs/2601.00731v1",
      "published_time_eastern_timestamp": 1767370876.0
    },
    {
      "title": "Universal Outlier Hypothesis Testing via Mean- and Median-Based Tests",
      "summary": "Universal outlier hypothesis testing refers to a hypothesis testing problem where one observes a large number of length-$n$ sequences -- the majority of which are distributed according to the typical distribution $π$ and a small number are distributed according to the outlier distribution $μ$ -- and one wishes to decide, which of these sequences are outliers without having knowledge of $π$ and $μ$. In contrast to previous works, in this paper it is assumed that both the number of observation sequences and the number of outlier sequences grow with the sequence length. In this case, the typical distribution $π$ can be estimated by computing the mean over all observation sequences, provided that the number of outlier sequences is sublinear in the total number of sequences. It is demonstrated that, in this case, one can achieve the error exponent of the maximum likelihood test that has access to both $π$ and $μ$. However, this mean-based test performs poorly when the number of outlier sequences is proportional to the total number of sequences. For this case, a median-based test is proposed that estimates $π$ as the median of all observation sequences. It is demonstrated that the median-based test achieves again the error exponent of the maximum likelihood test that has access to both $π$ and $μ$, but only with probability approaching one. To formalize this case, the typical error exponent -- similar to the typical random coding exponent introduced in the context of random coding for channel coding -- is proposed.",
      "url": "http://arxiv.org/abs/2601.00712v1",
      "published_time_eastern_timestamp": 1767366689.0
    },
    {
      "title": "Update on the design of the Columbia Stellarator eXperiment",
      "summary": "We present the final configuration chosen to be build for the Columbia Stellarator eXperiment (CSX), a new stellartor experiment at Columbia University. In a recent publication, Baillod et al. (NF, 2025) discussed in detail the different objectives, constraints, and optimization algorithms used to find an optimal configuration for CSX. In this paper, we build upon this first publication and find a configuration that satisfies all the constraints. We describe this final configuration including discussion of the coil finite build effects, sensitivity analyses, and the plasma neoclassical physics properties using the SFINCS code. These post-processing calculations provide a confirmation that the experimental goals of CSX can be achieved with the presented configuration.",
      "url": "http://arxiv.org/abs/2601.00673v1",
      "published_time_eastern_timestamp": 1767357661.0
    },
    {
      "title": "Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network",
      "summary": "Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.",
      "url": "http://arxiv.org/abs/2601.00658v1",
      "published_time_eastern_timestamp": 1767353675.0
    },
    {
      "title": "KELP: Robust Online Log Parsing Through Evolutionary Grouping Trees",
      "summary": "Real-time log analysis is the cornerstone of observability for modern infrastructure. However, existing online parsers are architecturally unsuited for the dynamism of production environments. Built on fundamentally static template models, they are dangerously brittle: minor schema drifts silently break parsing pipelines, leading to lost alerts and operational toil. We propose \\textbf{KELP} (\\textbf{K}elp \\textbf{E}volutionary \\textbf{L}og \\textbf{P}arser), a high-throughput parser built on a novel data structure: the Evolutionary Grouping Tree. Unlike heuristic approaches that rely on fixed rules, KELP treats template discovery as a continuous online clustering process. As logs arrive, the tree structure evolves, nodes split, merge, and re-evaluate roots based on changing frequency distributions. Validating this adaptability requires a dataset that models realistic production complexity, yet we identify that standard benchmarks rely on static, regex-based ground truths that fail to reflect this. To enable rigorous evaluation, we introduce a new benchmark designed to reflect the structural ambiguity of modern production systems. Our evaluation demonstrates that KELP maintains high accuracy on this rigorous dataset where traditional heuristic methods fail, without compromising throughput. Our code and dataset can be found at codeberg.org/stonebucklabs/kelp",
      "url": "http://arxiv.org/abs/2601.00633v1",
      "published_time_eastern_timestamp": 1767349661.0
    },
    {
      "title": "Do Chatbot LLMs Talk Too Much? The YapBench Benchmark",
      "summary": "Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.\n  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.\n  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.",
      "url": "http://arxiv.org/abs/2601.00624v1",
      "published_time_eastern_timestamp": 1767347032.0
    },
    {
      "title": "Asteroseismology study of a new faint ZZ Ceti J053009.62+594557.0 discovered in WFST",
      "summary": "In this work, we present a detailed asteroseismological analysis of WFST J053009.62+594557.0, a newly discovered faint pulsating white dwarf by the Wide Field Survey Telescope (WFST) with a Gaia G magnitude of 19.13. Analysis of two nights of high-precision WFST g band photometry reveals three significant pulsation frequencies with high signal-to-noise ratios. Follow-up P200/DBSP spectroscopy classifies the object as a DA white dwarf with Teff=11,609 $\\pm$ 605 K and M = 0.63$\\pm$ 0.22 $M_{\\odot}$. To probe its internal structure, we construct asteroseismological models with the White Dwarf Evolution Code (WDEC). After exploring sufficient matching models, best-fitting solutions yield Teff=11,850$\\pm$ 10 K and M = 0.600 $\\pm$ 0.005 $M_{\\odot}$, consistent with independent constraints from Gaia color-magnitude diagram, Gaia XP spectrum, P200 spectral fitting, SED fitting, and Gaia parallax. It has shown that the asteroseismological distance agrees with the Gaia parallax to 1.45\\%.",
      "url": "http://arxiv.org/abs/2601.00595v1",
      "published_time_eastern_timestamp": 1767337665.0
    },
    {
      "title": "SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation",
      "summary": "Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.",
      "url": "http://arxiv.org/abs/2601.00590v1",
      "published_time_eastern_timestamp": 1767335512.0
    },
    {
      "title": "Elaboration on the kinetic approach of Derbenev and Kondratenko to spin-polarized beams in electron storage rings",
      "summary": "We present a detailed account of the kinetic approach for describing the effect of synchrotron radiation on electron and positron spin polarization in storage rings. This approach was introduced in 1974 by Derbenev and Kondratenko and was extended by us in 2019. The kinetic approach is much less frequently utilized but it is more general than the original non-kinetic approach of Derbenev and Kondratenko from 1972 since the kinetic approach is not centered on the invariant spin field. As with the non-kinetic approach the kinetic approach covers the radiative depolarization effect, the Sokolov-Ternov effect and its Baier-Katkov correction as well as the kinetic polarization effect but it enables the calculation of corrections to the original Derbenev-Kondratenko formulas and thereby provides estimates of the reliability of the latter. It is applicable to storage rings with energies from a few GeV up to the energies of the FCC-ee and CEPC and beyond. The kinetic approach is based on the spin-orbit Wigner functions which lead to the so-called Bloch equation for the polarization density which is a generalization of Fokker-Planck equations to spin motion. In turn, as discovered in 2019, the Bloch equation is based on stochastic ordinary differential equations which can be used to develop Monte-Carlo spin-tracking codes covering the key effects beyond just radiative depolarization.",
      "url": "http://arxiv.org/abs/2601.00586v1",
      "published_time_eastern_timestamp": 1767334484.0
    },
    {
      "title": "AceFF: A State-of-the-Art Machine Learning Potential for Small Molecules",
      "summary": "We introduce AceFF, a pre-trained machine learning interatomic potential (MLIP) optimized for small molecule drug discovery. While MLIPs have emerged as efficient alternatives to Density Functional Theory (DFT), generalizability across diverse chemical spaces remains difficult. AceFF addresses this via a refined TensorNet2 architecture trained on a comprehensive dataset of drug-like compounds. This approach yields a force field that balances high-throughput inference speed with DFT-level accuracy. AceFF fully supports the essential medicinal chemistry elements (H, B, C, N, O, F, Si, P, S, Cl, Br, I) and is explicitly trained to handle charged states. Validation against rigorous benchmarks, including complex torsional energy scans, molecular dynamics trajectories, batched minimizations, and forces and anergy accuracy demonstrates that AceFF establishes a new state-of-the-art for organic molecules. The AceFF-2 model weights and inference code are available at https://huggingface.co/Acellera/AceFF-2.0.",
      "url": "http://arxiv.org/abs/2601.00581v1",
      "published_time_eastern_timestamp": 1767332857.0
    },
    {
      "title": "The AI Invisibility Effect: Understanding Human-AI Interaction When Users Don't Recognize Artificial Intelligence",
      "summary": "The fast integration of artificial intelligence into mobile applications has completely changed the digital landscape; however, the impact of this change on user perception of AI features remains poorly understood. This large-scale analysis examined 1,484,633 mobile application reviews across 422 applications (200 AI-featuring, 222 control) from iOS App Store and Google Play Store. By employing sentiment classification, topic modeling, and concern-benefit categorization, we identified a major disconnect: only 11.9% of reviews mentioned AI, even though 47.4% of applications featured AI capabilities. AI-featuring applications received significantly lower ratings than traditional applications (d = 0.40); however, hierarchical regression revealed a hidden pattern - the negative relationship reversed after controlling for AI mentions and review characteristics (b = 0.405, p < .001). Privacy dominated user concerns (34.8% of concern-expressing reviews), while efficiency represented the primary benefit (42.3%). Effects varied greatly by category, from positive for Assistant applications (d = 0.55) to negative for Entertainment (d = -0.23). These findings suggest that AI features often operate below user awareness thresholds, and it is the explicit recognition of AI, rather than its mere presence, that drives negative evaluations. This challenges basic assumptions about technology acceptance in AI systems.",
      "url": "http://arxiv.org/abs/2601.00579v1",
      "published_time_eastern_timestamp": 1767332441.0
    },
    {
      "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
      "summary": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/",
      "url": "http://arxiv.org/abs/2601.00575v1",
      "published_time_eastern_timestamp": 1767331587.0
    },
    {
      "title": "Benchmarking ERP Analysis: Manual Features, Deep Learning, and Foundation Models",
      "summary": "Event-related potential (ERP), a specialized paradigm of electroencephalographic (EEG), reflects neurological responses to external stimuli or events, generally associated with the brain's processing of specific cognitive tasks. ERP plays a critical role in cognitive analysis, the detection of neurological diseases, and the assessment of psychological states. Recent years have seen substantial advances in deep learning-based methods for spontaneous EEG and other non-time-locked task-related EEG signals. However, their effectiveness on ERP data remains underexplored, and many existing ERP studies still rely heavily on manually extracted features. In this paper, we conduct a comprehensive benchmark study that systematically compares traditional manual features (followed by a linear classifier), deep learning models, and pre-trained EEG foundation models for ERP analysis. We establish a unified data preprocessing and training pipeline and evaluate these approaches on two representative tasks, ERP stimulus classification and ERP-based brain disease detection, across 12 publicly available datasets. Furthermore, we investigate various patch-embedding strategies within advanced Transformer architectures to identify embedding designs that better suit ERP data. Our study provides a landmark framework to guide method selection and tailored model design for future ERP analysis. The code is available at https://github.com/DL4mHealth/ERP-Benchmark.",
      "url": "http://arxiv.org/abs/2601.00573v1",
      "published_time_eastern_timestamp": 1767331179.0
    },
    {
      "title": "SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array",
      "summary": "High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.",
      "url": "http://arxiv.org/abs/2601.00551v1",
      "published_time_eastern_timestamp": 1767326025.0
    },
    {
      "title": "Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios",
      "summary": "Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.",
      "url": "http://arxiv.org/abs/2601.00537v1",
      "published_time_eastern_timestamp": 1767321724.0
    },
    {
      "title": "All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations",
      "summary": "All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.",
      "url": "http://arxiv.org/abs/2601.00533v1",
      "published_time_eastern_timestamp": 1767320457.0
    }
  ]
}
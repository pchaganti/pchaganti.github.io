{
  "last_updated": "2025-10-15T05:13:31.213062-04:00",
  "papers": [
    {
      "title": "ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution",
      "summary": "Existing Multimodal Large Language Models (MLLMs) suffer from increased\ninference costs due to the additional vision tokens introduced by image inputs.\nIn this work, we propose Visual Consistency Learning (ViCO), a novel training\nalgorithm that enables the model to represent images of varying semantic\ncomplexities using different numbers of vision tokens. The key idea behind our\nmethod is to employ multiple MLP connectors, each with a different image\ncompression ratio, to downsample the vision tokens based on the semantic\ncomplexity of the image. During training, we minimize the KL divergence between\nthe responses conditioned on different MLP connectors. At inference time, we\nintroduce an image router, termed Visual Resolution Router (ViR), that\nautomatically selects the appropriate compression rate for each image patch.\nCompared with existing dynamic high-resolution strategies, which adjust the\nnumber of visual tokens based on image resolutions, our method dynamically\nadapts the number of visual tokens according to semantic complexity.\nExperimental results demonstrate that our method can reduce the number of\nvision tokens by up to 50% while maintaining the model's perception, reasoning,\nand OCR capabilities. We hope this work will contribute to the development of\nmore efficient MLLMs. The code and models will be released to facilitate future\nresearch.",
      "url": "http://arxiv.org/abs/2510.12793v1",
      "published_time_eastern_timestamp": 1760464690.0
    },
    {
      "title": "Wavefront Coding for Accommodation-Invariant Near-Eye Displays",
      "summary": "We present a new computational near-eye display method that addresses the\nvergence-accommodation conflict problem in stereoscopic displays through\naccommodation-invariance. Our system integrates a refractive lens eyepiece with\na novel wavefront coding diffractive optical element, operating in tandem with\na pre-processing convolutional neural network. We employ end-to-end learning to\njointly optimize the wavefront-coding optics and the image pre-processing\nmodule. To implement this approach, we develop a differentiable retinal image\nformation model that accounts for limiting aperture and chromatic aberrations\nintroduced by the eye optics. We further integrate the neural transfer function\nand the contrast sensitivity function into the loss model to account for\nrelated perceptual effects. To tackle off-axis distortions, we incorporate\nposition dependency into the pre-processing module. In addition to conducting\nrigorous analysis based on simulations, we also fabricate the designed\ndiffractive optical element and build a benchtop setup, demonstrating\naccommodation-invariance for depth ranges of up to four diopters.",
      "url": "http://arxiv.org/abs/2510.12778v1",
      "published_time_eastern_timestamp": 1760464348.0
    },
    {
      "title": "What If : Understanding Motion Through Sparse Interactions",
      "summary": "Understanding the dynamics of a physical scene involves reasoning about the\ndiverse ways it can potentially change, especially as a result of local\ninteractions. We present the Flow Poke Transformer (FPT), a novel framework for\ndirectly predicting the distribution of local motion, conditioned on sparse\ninteractions termed \"pokes\". Unlike traditional methods that typically only\nenable dense sampling of a single realization of scene dynamics, FPT provides\nan interpretable directly accessible representation of multi-modal scene\nmotion, its dependency on physical interactions and the inherent uncertainties\nof scene dynamics. We also evaluate our model on several downstream tasks to\nenable comparisons with prior methods and highlight the flexibility of our\napproach. On dense face motion generation, our generic pre-trained model\nsurpasses specialized baselines. FPT can be fine-tuned in strongly\nout-of-distribution tasks such as synthetic datasets to enable significant\nimprovements over in-domain methods in articulated object motion estimation.\nAdditionally, predicting explicit motion distributions directly enables our\nmethod to achieve competitive performance on tasks like moving part\nsegmentation from pokes which further demonstrates the versatility of our FPT.\nCode and models are publicly available at\nhttps://compvis.github.io/flow-poke-transformer.",
      "url": "http://arxiv.org/abs/2510.12777v1",
      "published_time_eastern_timestamp": 1760464337.0
    },
    {
      "title": "PET Head Motion Estimation Using Supervised Deep Learning with Attention",
      "summary": "Head movement poses a significant challenge in brain positron emission\ntomography (PET) imaging, resulting in image artifacts and tracer uptake\nquantification inaccuracies. Effective head motion estimation and correction\nare crucial for precise quantitative image analysis and accurate diagnosis of\nneurological disorders. Hardware-based motion tracking (HMT) has limited\napplicability in real-world clinical practice. To overcome this limitation, we\npropose a deep-learning head motion correction approach with cross-attention\n(DL-HMC++) to predict rigid head motion from one-second 3D PET raw data.\nDL-HMC++ is trained in a supervised manner by leveraging existing dynamic PET\nscans with gold-standard motion measurements from external HMT. We evaluate\nDL-HMC++ on two PET scanners (HRRT and mCT) and four radiotracers (18F-FDG,\n18F-FPEB, 11C-UCB-J, and 11C-LSN3172176) to demonstrate the effectiveness and\ngeneralization of the approach in large cohort PET studies. Quantitative and\nqualitative results demonstrate that DL-HMC++ consistently outperforms\nstate-of-the-art data-driven motion estimation methods, producing motion-free\nimages with clear delineation of brain structures and reduced motion artifacts\nthat are indistinguishable from gold-standard HMT. Brain region of interest\nstandard uptake value analysis exhibits average difference ratios between\nDL-HMC++ and gold-standard HMT to be 1.2 plus-minus 0.5% for HRRT and 0.5\nplus-minus 0.2% for mCT. DL-HMC++ demonstrates the potential for data-driven\nPET head motion correction to remove the burden of HMT, making motion\ncorrection accessible to clinical populations beyond research settings. The\ncode is available at https://github.com/maxxxxxxcai/DL-HMC-TMI.",
      "url": "http://arxiv.org/abs/2510.12758v1",
      "published_time_eastern_timestamp": 1760463432.0
    },
    {
      "title": "A High-Level Feature Model to Predict the Encoding Energy of a Hardware\n  Video Encoder",
      "summary": "In today's society, live video streaming and user generated content streamed\nfrom battery powered devices are ubiquitous. Live streaming requires real-time\nvideo encoding, and hardware video encoders are well suited for such an\nencoding task. In this paper, we introduce a high-level feature model using\nGaussian process regression that can predict the encoding energy of a hardware\nvideo encoder. In an evaluation setup restricted to only P-frames and a single\nkeyframe, the model can predict the encoding energy with a mean absolute\npercentage error of approximately 9%. Further, we demonstrate with an ablation\nstudy that spatial resolution is a key high-level feature for encoding energy\nprediction of a hardware encoder. A practical application of our model is that\nit can be used to perform a prior estimation of the energy required to encode a\nvideo at various spatial resolutions, with different coding standards and codec\npresets.",
      "url": "http://arxiv.org/abs/2510.12754v1",
      "published_time_eastern_timestamp": 1760463225.0
    },
    {
      "title": "FlashVSR: Towards Real-Time Diffusion-Based Streaming Video\n  Super-Resolution",
      "summary": "Diffusion models have recently advanced video restoration, but applying them\nto real-world video super-resolution (VSR) remains challenging due to high\nlatency, prohibitive computation, and poor generalization to ultra-high\nresolutions. Our goal in this work is to make diffusion-based VSR practical by\nachieving efficiency, scalability, and real-time performance. To this end, we\npropose FlashVSR, the first diffusion-based one-step streaming framework\ntowards real-time VSR. FlashVSR runs at approximately 17 FPS for 768x1408\nvideos on a single A100 GPU by combining three complementary innovations: (i) a\ntrain-friendly three-stage distillation pipeline that enables streaming\nsuper-resolution, (ii) locality-constrained sparse attention that cuts\nredundant computation while bridging the train-test resolution gap, and (iii) a\ntiny conditional decoder that accelerates reconstruction without sacrificing\nquality. To support large-scale training, we also construct VSR-120K, a new\ndataset with 120k videos and 180k images. Extensive experiments show that\nFlashVSR scales reliably to ultra-high resolutions and achieves\nstate-of-the-art performance with up to 12x speedup over prior one-step\ndiffusion VSR models. We will release the code, pretrained models, and dataset\nto foster future research in efficient diffusion-based VSR.",
      "url": "http://arxiv.org/abs/2510.12747v1",
      "published_time_eastern_timestamp": 1760462754.0
    },
    {
      "title": "Hey, wait a minute: on at-issue sensitivity in Language Models",
      "summary": "Evaluating the naturalness of dialogue in language models (LMs) is not\ntrivial: notions of 'naturalness' vary, and scalable quantitative metrics\nremain limited. This study leverages the linguistic notion of 'at-issueness' to\nassess dialogue naturalness and introduces a new method: Divide, Generate,\nRecombine, and Compare (DGRC). DGRC (i) divides a dialogue as a prompt, (ii)\ngenerates continuations for subparts using LMs, (iii) recombines the dialogue\nand continuations, and (iv) compares the likelihoods of the recombined\nsequences. This approach mitigates bias in linguistic analyses of LMs and\nenables systematic testing of discourse-sensitive behavior. Applying DGRC, we\nfind that LMs prefer to continue dialogue on at-issue content, with this effect\nenhanced in instruct-tuned models. They also reduce their at-issue preference\nwhen relevant cues (e.g., \"Hey, wait a minute\") are present. Although\ninstruct-tuning does not further amplify this modulation, the pattern reflects\na hallmark of successful dialogue dynamics.",
      "url": "http://arxiv.org/abs/2510.12740v1",
      "published_time_eastern_timestamp": 1760462240.0
    },
    {
      "title": "Clutch Control: An Attention-based Combinatorial Bandit for Efficient\n  Mutation in JavaScript Engine Fuzzing",
      "summary": "JavaScript engines are widely used in web browsers, PDF readers, and\nserver-side applications. The rise in concern over their security has led to\nthe development of several targeted fuzzing techniques. However, existing\napproaches use random selection to determine where to perform mutations in\nJavaScript code. We postulate that the problem of selecting better mutation\ntargets is suitable for combinatorial bandits with a volatile number of arms.\nThus, we propose CLUTCH, a novel deep combinatorial bandit that can observe\nvariable length JavaScript test case representations, using an attention\nmechanism from deep learning. Furthermore, using Concrete Dropout, CLUTCH can\ndynamically adapt its exploration. We show that CLUTCH increases efficiency in\nJavaScript fuzzing compared to three state-of-the-art solutions by increasing\nthe number of valid test cases and coverage-per-testcase by, respectively,\n20.3% and 8.9% on average. In volatile and combinatorial settings we show that\nCLUTCH outperforms state-of-the-art bandits, achieving at least 78.1% and 4.1%\nless regret in volatile and combinatorial settings, respectively.",
      "url": "http://arxiv.org/abs/2510.12732v1",
      "published_time_eastern_timestamp": 1760461851.0
    },
    {
      "title": "plasmonX: an Open-Source Code for Nanoplasmonics",
      "summary": "We present the first public release of plasmonX, a novel open-source code for\nsimulating the plasmonic response of complex nanostructures. The code supports\nboth fully atomistic and implicit descriptions of nanomaterials. In particular,\nit employs the frequency-dependent fluctuating charges ($\\omega$FQ) and dipoles\n($\\omega$FQF$\\mu$) models to describe the response properties of atomistic\nstructures, including simple and $d$-metals, graphene-based structures, and\nmulti-metal nanostructures. For implicit representations, the Boundary Element\nMethod is implemented in both the dielectric polarizable continuum model (DPCM)\nand integral equation formalism (IEF-PCM) variants. The distribution also\nincludes a post-processing module that enables analysis of electric\nfield-induced properties such as charge density and electric field patterns.",
      "url": "http://arxiv.org/abs/2510.12731v1",
      "published_time_eastern_timestamp": 1760461844.0
    },
    {
      "title": "Beyond Postconditions: Can Large Language Models infer Formal Contracts\n  for Automatic Software Verification?",
      "summary": "Automatic software verifiers have become increasingly effective at the task\nof checking software against (formal) specifications. Yet, their adoption in\npractice has been hampered by the lack of such specifications in real world\ncode. Large Language Models (LLMs) have shown promise in inferring formal\npostconditions from natural language hints embedded in code such as function\nnames, comments or documentation. Using the generated postconditions as\nspecifications in a subsequent verification, however, often leads verifiers to\nsuggest invalid inputs, hinting at potential issues that ultimately turn out to\nbe false alarms.\n  To address this, we revisit the problem of specification inference from\nnatural language in the context of automatic software verification. In the\nprocess, we introduce NL2Contract, the task of employing LLMs to translate\ninformal natural language into formal functional contracts, consisting of\npostconditions as well as preconditions. We introduce metrics to validate and\ncompare different NL2Contract approaches, using soundness, bug discriminative\npower of the generated contracts and their usability in the context of\nautomatic software verification as key metrics. We evaluate NL2Contract with\ndifferent LLMs and compare it to the task of postcondition generation\nnl2postcond. Our evaluation shows that (1) LLMs are generally effective at\ngenerating functional contracts sound for all possible inputs, (2) the\ngenerated contracts are sufficiently expressive for discriminating buggy from\ncorrect behavior, and (3) verifiers supplied with LLM inferred functional\ncontracts produce fewer false alarms than when provided with postconditions\nalone. Further investigations show that LLM inferred preconditions generally\nalign well with developers intentions which allows us to use automatic software\nverifiers to catch real-world bugs.",
      "url": "http://arxiv.org/abs/2510.12702v1",
      "published_time_eastern_timestamp": 1760459859.0
    },
    {
      "title": "The diverse shapes of binary asteroid satellites born from\n  sub-escape-velocity moonlet mergers",
      "summary": "Recent direct observations of atypically shaped rubble-pile satellites of\nsub-km asteroids in form of the spherically oblate Dimorphos and bilobate Selam\nchallenge classical binary asteroid formation theories, which only explain the\npredominantly elongated population. This study further explores a rubble-pile\nsatellite formation scenario for binary asteroid systems involving debris disks\nby investigating how mergers between moonlets with impact velocities below the\nmutual escape speed (sub-escape-velocity mergers) and tidal disruptions can\ncreate atypically shaped moons. We simulated sub-escape-velocity mergers\nbetween moonlets and studied the resulting structural evolution of the formed\nmoon in a tidal environment using the polyhedral discrete elements method\nN-body code GRAINS. Firstly, we find that the shapes of rubble-pile moons\nformed by mergers in this regime are highly dependent on the shape and initial\norientation of the involved moonlets. This can be explained by the moonlets\nlargely retaining their individual structures during the impact. Secondly, we\nobserve that mass-loss via tidal disruption for a bilobate object occurs in\ndiscrete regimes of distance to the primary. Closer to the primary, the\ninnermost lobe is completely stripped off, while only a small piece of it is\nlost further out. Due to moonlets largely retaining their shape after\nundergoing a sub-escape-velocity merger, it is necessary to account for their\nnon-sphericity to accurately model satellite formation in circumasteroidal\ndebris disks. Moreover, the reshaping of merged objects via tidal disruption\nand distortion can produce oblate spheroid moons such as Dimorphos and highly\nelongated bilobate satellites with distinct necks such as Selam.",
      "url": "http://arxiv.org/abs/2510.12694v1",
      "published_time_eastern_timestamp": 1760459171.0
    },
    {
      "title": "EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for\n  Open-Set Domain Generalization under Noisy Labels",
      "summary": "Open-Set Domain Generalization (OSDG) aims to enable deep learning models to\nrecognize unseen categories in new domains, which is crucial for real-world\napplications. Label noise hinders open-set domain generalization by corrupting\nsource-domain knowledge, making it harder to recognize known classes and reject\nunseen ones. While existing methods address OSDG under Noisy Labels (OSDG-NL)\nusing hyperbolic prototype-guided meta-learning, they struggle to bridge domain\ngaps, especially with limited clean labeled data. In this paper, we propose\nEvidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). We first\nintroduce an unsupervised two-stage evidential loss clustering method to\npromote label reliability awareness. Then, we propose a residual flow matching\nmechanism that models structured domain- and category-conditioned residuals,\nenabling diverse and uncertainty-aware transfer paths beyond\ninterpolation-based augmentation. During this meta-learning process, the model\nis optimized such that the update direction on the clean set maximizes the loss\ndecrease on the noisy set, using pseudo labels derived from the most confident\npredicted class for supervision. Experimental results show that EReLiFM\noutperforms existing methods on OSDG-NL, achieving state-of-the-art\nperformance. The source code is available at\nhttps://github.com/KPeng9510/ERELIFM.",
      "url": "http://arxiv.org/abs/2510.12687v1",
      "published_time_eastern_timestamp": 1760458991.0
    },
    {
      "title": "Few Shot Semi-Supervised Learning for Abnormal Stop Detection from\n  Sparse GPS Trajectories",
      "summary": "Abnormal stop detection (ASD) in intercity coach transportation is critical\nfor ensuring passenger safety, operational reliability, and regulatory\ncompliance. However, two key challenges hinder ASD effectiveness: sparse GPS\ntrajectories, which obscure short or unauthorized stops, and limited labeled\ndata, which restricts supervised learning. Existing methods often assume dense\nsampling or regular movement patterns, limiting their applicability. To address\ndata sparsity, we propose a Sparsity-Aware Segmentation (SAS) method that\nadaptively defines segment boundaries based on local spatial-temporal density.\nBuilding upon these segments, we introduce three domain-specific indicators to\ncapture abnormal stop behaviors. To further mitigate the impact of sparsity, we\ndevelop Locally Temporal-Indicator Guided Adjustment (LTIGA), which smooths\nthese indicators via local similarity graphs. To overcome label scarcity, we\nconstruct a spatial-temporal graph where each segment is a node with\nLTIGA-refined features. We apply label propagation to expand weak supervision\nacross the graph, followed by a GCN to learn relational patterns. A final\nself-training module incorporates high-confidence pseudo-labels to iteratively\nimprove predictions. Experiments on real-world coach data show an AUC of 0.854\nand AP of 0.866 using only 10 labeled instances, outperforming prior methods.\nThe code and dataset are publicly available at\n\\href{https://github.com/pangjunbiao/Abnormal-Stop-Detection-SSL.git}",
      "url": "http://arxiv.org/abs/2510.12686v1",
      "published_time_eastern_timestamp": 1760458954.0
    },
    {
      "title": "Decoding Multimode Gottesman-Kitaev-Preskill Codes with Noisy Auxiliary\n  States",
      "summary": "In order to achieve fault-tolerant quantum computing, we make use of quantum\nerror correction schemes designed to protect the logical information of the\nsystem from decoherence. A promising way to preserve such information is to use\nthe multimode Gottesman-Kitaev-Preskill (GKP) encoding, which encodes logical\nqubits into several harmonic oscillators. In this work, we focus on decoding\nthe measurements obtained from Steane-type quantum error correction protocols\nfor multimode GKP codes. We propose a decoder that considers the noise present\non the auxiliary states, more specifically by tracking the correlations between\nerrors on different modes spreading throughout the error-correction circuit. We\nshow that leveraging the correlations between measurement results and the\nactual error affecting the multimode GKP state can decrease the logical error\nprobability by at least an order of magnitude, yielding more robust quantum\ncomputation.",
      "url": "http://arxiv.org/abs/2510.12677v1",
      "published_time_eastern_timestamp": 1760458473.0
    },
    {
      "title": "TerraCodec: Compressing Earth Observations",
      "summary": "Earth observation (EO) satellites produce massive streams of multispectral\nimage time series, posing pressing challenges for storage and transmission.\nYet, learned EO compression remains fragmented, lacking publicly available\npretrained models and misaligned with advances in compression for natural\nimagery. Image codecs overlook temporal redundancy, while video codecs rely on\nmotion priors that fail to capture the radiometric evolution of largely static\nscenes. We introduce TerraCodec (TEC), a family of learned codecs tailored to\nEO. TEC includes efficient image-based variants adapted to multispectral\ninputs, as well as a Temporal Transformer model (TEC-TT) that leverages\ndependencies across time. To overcome the fixed-rate setting of today's neural\ncodecs, we present Latent Repacking, a novel method for training flexible-rate\ntransformer models that operate on varying rate-distortion settings. Trained on\nSentinel-2 data, TerraCodec outperforms classical codecs, achieving 3-10x\nstronger compression at equivalent image quality. Beyond compression, TEC-TT\nenables zero-shot cloud inpainting, surpassing state-of-the-art methods on the\nAllClear benchmark. Our results establish bespoke, learned compression\nalgorithms as a promising direction for Earth observation. Code and model\nweights will be released under a permissive license.",
      "url": "http://arxiv.org/abs/2510.12670v1",
      "published_time_eastern_timestamp": 1760457931.0
    },
    {
      "title": "The Influence of the Accretion Disc Structure on X-ray Spectral States\n  in Symbiotic Binaries",
      "summary": "Symbiotic stars are binary systems where a white dwarf (WD) accretes material\nfrom the wind of an evolved, late-type companion. X-ray-emitting symbiotic\nsystems are classified into $\\alpha$, $\\beta$, $\\delta$, and $\\beta/\\delta$\ntypes, attributed to distinct physical mechanisms such as thermonuclear\nburning, wind interactions, and accretion-driven boundary layers. We present\nsynthetic X-ray spectra derived from hydrodynamics simulations using the\nPHANTOM code, coupled with radiative-transfer calculations from SKIRT. We\nreproduce all X-ray spectral types by exploring different density structure of\nthe accretion disc, the viewing angle, the plasma temperature of the boundary\nlayer, and/or the presence of extended emission. The synthetic X-ray spectra\nconsist of both absorbed and reflected components. In systems with massive,\nhigh-column density discs and viewing angles close to edge-on, the reflected\ncontinuum can dominate the X-ray emission. This effect is less pronounced in\nsystems with low-mass, lower-column density discs. We explore i) systems going\nfrom $\\delta$ to $\\beta$ states, ii) $\\delta$-types that become $\\beta/\\delta$\nsources, iii) the variability of the three Fe emission lines in the 6.0-7.0\nenergy range, and iv) the possible physical processes behind the $\\alpha$\nsources. The observations from iconic symbiotic systems are discussed in line\nof the present models. Our framework offers predictive power for future X-ray\nmonitoring and provides a path toward connecting accretion disc physics with\nobserved spectral states in symbiotic binaries with accreting WDs.",
      "url": "http://arxiv.org/abs/2510.12654v1",
      "published_time_eastern_timestamp": 1760456943.0
    },
    {
      "title": "Designing Tools with Control Confidence",
      "summary": "Prehistoric humans invented stone tools for specialized tasks by not just\nmaximizing the tool's immediate goal-completion accuracy, but also increasing\ntheir confidence in the tool for later use under similar settings. This factor\ncontributed to the increased robustness of the tool, i.e., the least\nperformance deviations under environmental uncertainties. However, the current\nautonomous tool design frameworks solely rely on performance optimization,\nwithout considering the agent's confidence in tool use for repeated use. Here,\nwe take a step towards filling this gap by i) defining an optimization\nframework for task-conditioned autonomous hand tool design for robots, where\nii) we introduce a neuro-inspired control confidence term into the optimization\nroutine that helps the agent to design tools with higher robustness. Through\nrigorous simulations using a robotic arm, we show that tools designed with\ncontrol confidence as the objective function are more robust to environmental\nuncertainties during tool use than a pure accuracy-driven objective. We further\nshow that adding control confidence to the objective function for tool design\nprovides a balance between the robustness and goal accuracy of the designed\ntools under control perturbations. Finally, we show that our CMAES-based\nevolutionary optimization strategy for autonomous tool design outperforms other\nstate-of-the-art optimizers by designing the optimal tool within the fewest\niterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.",
      "url": "http://arxiv.org/abs/2510.12630v1",
      "published_time_eastern_timestamp": 1760455647.0
    },
    {
      "title": "Formation of protostars and the launching of stellar core outflows with\n  moving-mesh radiation non-ideal magnetohydrodynamics",
      "summary": "We present an implementation of radiative transfer with flux-limited\ndiffusion (FLD) for the moving-mesh code {\\small AREPO} and use the method in a\nphysical model for the formation of protostars with non-ideal\nradiation-magnetohydrodynamics (RMHD). We follow previous work in splitting the\nadditional terms to the hydrodynamical equations arising from the inclusion of\nradiation into terms to be integrated explicitly and implicitly, as the\ndiffusion and coupling terms would impose very restrictive timestep criteria.\nWe validate the scheme with standard test problems for radiation diffusion,\nmatter-gas coupling, and radiative shocks from the literature. Our\nimplementation is compatible with local timestepping, which often presents\nproblems for implicit schemes, and we found very good agreement with results\nobtained with global timesteps. We present an example application of the new\nimplementation to the collapse of a $1\\,{\\rm M}_\\odot$ molecular cloud core to\na second Larson core modelled with radiation non-ideal magnetohydrodynamics. A\nhigh-velocity jet with v$_{\\rm rad}> 10\\, {\\rm km\\,s^{-1}}$ is\nself-consistently launched from the second core, nested within the first core,\nwhich produces a lower-velocity magnetorotational outflow. We observe magnetic\nfield amplification up to more than $\\vert \\mathbf{B}\\vert_{\\rm max}>10^5$~G in\nthe second core, which is surrounded by a small ($<0.5$~au) disk. This\napplication demonstrates the robustness of our scheme in multi-scale and\nhigh-resolution simulations on arbitrary meshes and, as such, the model can be\nreadily used for further simulations of protostar formation at high resolution.",
      "url": "http://arxiv.org/abs/2510.12620v1",
      "published_time_eastern_timestamp": 1760455163.0
    },
    {
      "title": "StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts\n  with Stylistic Analysis",
      "summary": "With the increasing integration of large language models (LLMs) into\nopen-domain writing, detecting machine-generated text has become a critical\ntask for ensuring content authenticity and trust. Existing approaches rely on\nstatistical discrepancies or model-specific heuristics to distinguish between\nLLM-generated and human-written text. However, these methods struggle in\nreal-world scenarios due to limited generalization, vulnerability to\nparaphrasing, and lack of explainability, particularly when facing stylistic\ndiversity or hybrid human-AI authorship. In this work, we propose\nStyleDecipher, a robust and explainable detection framework that revisits\nLLM-generated text detection using combined feature extractors to quantify\nstylistic differences. By jointly modeling discrete stylistic indicators and\ncontinuous stylistic representations derived from semantic embeddings,\nStyleDecipher captures distinctive style-level divergences between human and\nLLM outputs within a unified representation space. This framework enables\naccurate, explainable, and domain-agnostic detection without requiring access\nto model internals or labeled segments. Extensive experiments across five\ndiverse domains, including news, code, essays, reviews, and academic abstracts,\ndemonstrate that StyleDecipher consistently achieves state-of-the-art in-domain\naccuracy. Moreover, in cross-domain evaluations, it surpasses existing\nbaselines by up to 36.30%, while maintaining robustness against adversarial\nperturbations and mixed human-AI content. Further qualitative and quantitative\nanalysis confirms that stylistic signals provide explainable evidence for\ndistinguishing machine-generated text. Our source code can be accessed at\nhttps://github.com/SiyuanLi00/StyleDecipher.",
      "url": "http://arxiv.org/abs/2510.12608v1",
      "published_time_eastern_timestamp": 1760454447.0
    },
    {
      "title": "WaterFlow: Explicit Physics-Prior Rectified Flow for Underwater Saliency\n  Mask Generation",
      "summary": "Underwater Salient Object Detection (USOD) faces significant challenges,\nincluding underwater image quality degradation and domain gaps. Existing\nmethods tend to ignore the physical principles of underwater imaging or simply\ntreat degradation phenomena in underwater images as interference factors that\nmust be eliminated, failing to fully exploit the valuable information they\ncontain. We propose WaterFlow, a rectified flow-based framework for underwater\nsalient object detection that innovatively incorporates underwater physical\nimaging information as explicit priors directly into the network training\nprocess and introduces temporal dimension modeling, significantly enhancing the\nmodel's capability for salient object identification. On the USOD10K dataset,\nWaterFlow achieves a 0.072 gain in S_m, demonstrating the effectiveness and\nsuperiority of our method. The code will be published after the acceptance.",
      "url": "http://arxiv.org/abs/2510.12605v1",
      "published_time_eastern_timestamp": 1760454144.0
    }
  ]
}
{
  "last_updated": "2025-08-31T21:05:11.125857-04:00",
  "papers": [
    {
      "title": "OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn\n  Dialogue with Large Language Models",
      "summary": "As multi-turn dialogues with large language models (LLMs) grow longer and\nmore complex, how can users better evaluate and review progress on their\nconversational goals? We present OnGoal, an LLM chat interface that helps users\nbetter manage goal progress. OnGoal provides real-time feedback on goal\nalignment through LLM-assisted evaluation, explanations for evaluation results\nwith examples, and overviews of goal progression over time, enabling users to\nnavigate complex dialogues more effectively. Through a study with 20\nparticipants on a writing task, we evaluate OnGoal against a baseline chat\ninterface without goal tracking. Using OnGoal, participants spent less time and\neffort to achieve their goals while exploring new prompting strategies to\novercome miscommunication, suggesting tracking and visualizing goals can\nenhance engagement and resilience in LLM dialogues. Our findings inspired\ndesign implications for future LLM chat interfaces that improve goal\ncommunication, reduce cognitive load, enhance interactivity, and enable\nfeedback to improve LLM performance.",
      "url": "http://arxiv.org/abs/2508.21061v1",
      "published_time_eastern_timestamp": 1756403909.0
    },
    {
      "title": "Enabling Equitable Access to Trustworthy Financial Reasoning",
      "summary": "According to the United States Internal Revenue Service, ''the average\nAmerican spends $\\$270$ and 13 hours filing their taxes''. Even beyond the\nU.S., tax filing requires complex reasoning, combining application of\noverlapping rules with numerical calculations. Because errors can incur costly\npenalties, any automated system must deliver high accuracy and auditability,\nmaking modern large language models (LLMs) poorly suited for this task. We\npropose an approach that integrates LLMs with a symbolic solver to calculate\ntax obligations. We evaluate variants of this system on the challenging\nStAtutory Reasoning Assessment (SARA) dataset, and include a novel method for\nestimating the cost of deploying such a system based on real-world penalties\nfor tax errors. We further show how combining up-front translation of\nplain-text rules into formal logic programs, combined with intelligently\nretrieved exemplars for formal case representations, can dramatically improve\nperformance on this task and reduce costs to well below real-world averages.\nOur results demonstrate the promise and economic feasibility of neuro-symbolic\narchitectures for increasing equitable access to reliable tax assistance.",
      "url": "http://arxiv.org/abs/2508.21051v1",
      "published_time_eastern_timestamp": 1756403707.0
    },
    {
      "title": "CogVLA: Cognition-Aligned Vision-Language-Action Model via\n  Instruction-Driven Routing & Sparsification",
      "summary": "Recent Vision-Language-Action (VLA) models built on pre-trained\nVision-Language Models (VLMs) require extensive post-training, resulting in\nhigh computational overhead that limits scalability and deployment.We propose\nCogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages\ninstruction-driven routing and sparsification to improve both efficiency and\nperformance. CogVLA draws inspiration from human multimodal coordination and\nintroduces a 3-stage progressive architecture. 1) Encoder-FiLM based\nAggregation Routing (EFA-Routing) injects instruction information into the\nvision encoder to selectively aggregate and compress dual-stream visual tokens,\nforming a instruction-aware latent representation. 2) Building upon this\ncompact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing)\nintroduces action intent into the language model by pruning\ninstruction-irrelevant visually grounded tokens, thereby achieving token-level\nsparsity. 3) To ensure that compressed perception inputs can still support\naccurate and coherent action generation, we introduce V-L-A Coupled Attention\n(CAtten), which combines causal vision-language attention with bidirectional\naction parallel decoding. Extensive experiments on the LIBERO benchmark and\nreal-world robotic tasks demonstrate that CogVLA achieves state-of-the-art\nperformance with success rates of 97.4% and 70.0%, respectively, while reducing\ntraining costs by 2.5-fold and decreasing inference latency by 2.8-fold\ncompared to OpenVLA. CogVLA is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/CogVLA.",
      "url": "http://arxiv.org/abs/2508.21046v1",
      "published_time_eastern_timestamp": 1756403458.0
    },
    {
      "title": "MMG-Vid: Maximizing Marginal Gains at Segment-level and Token-level for\n  Efficient Video LLMs",
      "summary": "Video Large Language Models (VLLMs) excel in video understanding, but their\nexcessive visual tokens pose a significant computational challenge for\nreal-world applications. Current methods aim to enhance inference efficiency by\nvisual token pruning. However, they do not consider the dynamic characteristics\nand temporal dependencies of video frames, as they perceive video understanding\nas a multi-frame task. To address these challenges, we propose MMG-Vid, a novel\ntraining-free visual token pruning framework that removes redundancy by\nMaximizing Marginal Gains at both segment-level and token-level. Specifically,\nwe first divide the video into segments based on frame similarity, and then\ndynamically allocate the token budget for each segment to maximize the marginal\ngain of each segment. Subsequently, we propose a temporal-guided DPC algorithm\nthat jointly models inter-frame uniqueness and intra-frame diversity, thereby\nmaximizing the marginal gain of each token. By combining both stages, MMG-Vid\ncan maximize the utilization of the limited token budget, significantly\nimproving efficiency while maintaining strong performance. Extensive\nexperiments demonstrate that MMG-Vid can maintain over 99.5% of the original\nperformance, while effectively reducing 75% visual tokens and accelerating the\nprefilling stage by 3.9x on LLaVA-OneVision-7B. Code will be released soon.",
      "url": "http://arxiv.org/abs/2508.21044v1",
      "published_time_eastern_timestamp": 1756403403.0
    },
    {
      "title": "An Agile Method for Implementing Retrieval Augmented Generation Tools in\n  Industrial SMEs",
      "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to\nmitigate the limitations of Large Language Models (LLMs), such as\nhallucinations and outdated knowledge. However, deploying RAG-based tools in\nSmall and Medium Enterprises (SMEs) remains a challenge due to their limited\nresources and lack of expertise in natural language processing (NLP). This\npaper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a\nstructured, agile method designed to facilitate the deployment of RAG systems\nin industrial SME contexts. EASI-RAG is based on method engineering principles\nand comprises well-defined roles, activities, and techniques. The method was\nvalidated through a real-world case study in an environmental testing\nlaboratory, where a RAG tool was implemented to answer operators queries using\ndata extracted from operational procedures. The system was deployed in under a\nmonth by a team with no prior RAG experience and was later iteratively improved\nbased on user feedback. Results demonstrate that EASI-RAG supports fast\nimplementation, high user adoption, delivers accurate answers, and enhances the\nreliability of underlying data. This work highlights the potential of RAG\ndeployment in industrial SMEs. Future works include the need for generalization\nacross diverse use cases and further integration with fine-tuned models.",
      "url": "http://arxiv.org/abs/2508.21024v1",
      "published_time_eastern_timestamp": 1756402029.0
    },
    {
      "title": "Lethe: Purifying Backdoored Large Language Models with Knowledge\n  Dilution",
      "summary": "Large language models (LLMs) have seen significant advancements, achieving\nsuperior performance in various Natural Language Processing (NLP) tasks.\nHowever, they remain vulnerable to backdoor attacks, where models behave\nnormally for standard queries but generate harmful responses or unintended\noutput when specific triggers are activated. Existing backdoor defenses either\nlack comprehensiveness, focusing on narrow trigger settings, detection-only\nmechanisms, and limited domains, or fail to withstand advanced scenarios like\nmodel-editing-based, multi-trigger, and triggerless attacks. In this paper, we\npresent LETHE, a novel method to eliminate backdoor behaviors from LLMs through\nknowledge dilution using both internal and external mechanisms. Internally,\nLETHE leverages a lightweight dataset to train a clean model, which is then\nmerged with the backdoored model to neutralize malicious behaviors by diluting\nthe backdoor impact within the model's parametric memory. Externally, LETHE\nincorporates benign and semantically relevant evidence into the prompt to\ndistract LLM's attention from backdoor features. Experimental results on\nclassification and generation domains across 5 widely used LLMs demonstrate\nthat LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor\nattacks. LETHE reduces the attack success rate of advanced backdoor attacks by\nup to 98% while maintaining model utility. Furthermore, LETHE has proven to be\ncost-efficient and robust against adaptive backdoor attacks.",
      "url": "http://arxiv.org/abs/2508.21004v1",
      "published_time_eastern_timestamp": 1756400718.0
    },
    {
      "title": "ChatThero: An LLM-Supported Chatbot for Behavior Change and Therapeutic\n  Support in Addiction Recovery",
      "summary": "Substance use disorders (SUDs) affect over 36 million people worldwide, yet\nfew receive effective care due to stigma, motivational barriers, and limited\npersonalized support. Although large language models (LLMs) show promise for\nmental-health assistance, most systems lack tight integration with clinically\nvalidated strategies, reducing effectiveness in addiction recovery. We present\nChatThero, a multi-agent conversational framework that couples dynamic patient\nmodeling with context-sensitive therapeutic dialogue and adaptive persuasive\nstrategies grounded in cognitive behavioral therapy (CBT) and motivational\ninterviewing (MI). We build a high-fidelity synthetic benchmark spanning Easy,\nMedium, and Hard resistance levels, and train ChatThero with a two-stage\npipeline comprising supervised fine-tuning (SFT) followed by direct preference\noptimization (DPO). In evaluation, ChatThero yields a 41.5\\% average gain in\npatient motivation, a 0.49\\% increase in treatment confidence, and resolves\nhard cases with 26\\% fewer turns than GPT-4o, and both automated and human\nclinical assessments rate it higher in empathy, responsiveness, and behavioral\nrealism. The framework supports rigorous, privacy-preserving study of\ntherapeutic conversation and provides a robust, replicable basis for research\nand clinical translation.",
      "url": "http://arxiv.org/abs/2508.20996v1",
      "published_time_eastern_timestamp": 1756400253.0
    },
    {
      "title": "ConfLogger: Enhance Systems' Configuration Diagnosability through\n  Configuration Logging",
      "summary": "Modern configurable systems offer customization via intricate configuration\nspaces, yet such flexibility introduces pervasive configuration-related issues\nsuch as misconfigurations and latent softwarebugs. Existing diagnosability\nsupports focus on post-failure analysis of software behavior to identify\nconfiguration issues, but none of these approaches look into whether the\nsoftware clue sufficient failure information for diagnosis. To fill in the\nblank, we propose the idea of configuration logging to enhance existing logging\npractices at the source code level. We develop ConfLogger, the first tool that\nunifies configuration-aware static taint analysis with LLM-based log generation\nto enhance software configuration diagnosability. Specifically, our method 1)\nidentifies configuration-sensitive code segments by tracing\nconfiguration-related data flow in the whole project, and 2) generates\ndiagnostic log statements by analyzing configuration code contexts. Evaluation\nresults on eight popular software systems demonstrate the effectiveness of\nConfLogger to enhance configuration diagnosability. Specifically,\nConfLogger-enhanced logs successfully aid a log-based misconfiguration\ndiagnosis tool to achieve 100% accuracy on error localization in 30 silent\nmisconfiguration scenarios, with 80% directly resolvable through explicit\nconfiguration information exposed. In addition, ConfLogger achieves 74%\ncoverage of existing logging points, outperforming baseline LLM-based loggers\nby 12% and 30%. It also gains 8.6% higher in precision, 79.3% higher in recall,\nand 26.2% higher in F1 compared to the state-of-the-art baseline in terms of\nvariable logging while also augmenting diagnostic value. A controlled user\nstudy on 22 cases further validated its utility, speeding up diagnostic time by\n1.25x and improving troubleshooting accuracy by 251.4%.",
      "url": "http://arxiv.org/abs/2508.20977v2",
      "published_time_eastern_timestamp": 1756398668.0
    },
    {
      "title": "ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue\n  Agents",
      "summary": "Proactive dialogue has emerged as a critical and challenging research problem\nin advancing large language models (LLMs). Existing works predominantly focus\non domain-specific or task-oriented scenarios, which leads to fragmented\nevaluations and limits the comprehensive exploration of models' proactive\nconversation abilities. In this work, we propose ProactiveEval, a unified\nframework designed for evaluating proactive dialogue capabilities of LLMs. This\nframework decomposes proactive dialogue into target planning and dialogue\nguidance, establishing evaluation metrics across various domains. Moreover, it\nalso enables the automatic generation of diverse and challenging evaluation\ndata. Based on the proposed framework, we develop 328 evaluation environments\nspanning 6 distinct domains. Through experiments with 22 different types of\nLLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional\nperformance on target planning and dialogue guidance tasks, respectively.\nFinally, we investigate how reasoning capabilities influence proactive\nbehaviors and discuss their implications for future model development.",
      "url": "http://arxiv.org/abs/2508.20973v1",
      "published_time_eastern_timestamp": 1756398404.0
    },
    {
      "title": "DrivingGaussian++: Towards Realistic Reconstruction and Editable\n  Simulation for Surrounding Dynamic Driving Scenes",
      "summary": "We present DrivingGaussian++, an efficient and effective framework for\nrealistic reconstructing and controllable editing of surrounding dynamic\nautonomous driving scenes. DrivingGaussian++ models the static background using\nincremental 3D Gaussians and reconstructs moving objects with a composite\ndynamic Gaussian graph, ensuring accurate positions and occlusions. By\nintegrating a LiDAR prior, it achieves detailed and consistent scene\nreconstruction, outperforming existing methods in dynamic scene reconstruction\nand photorealistic surround-view synthesis. DrivingGaussian++ supports\ntraining-free controllable editing for dynamic driving scenes, including\ntexture modification, weather simulation, and object manipulation, leveraging\nmulti-view images and depth priors. By integrating large language models (LLMs)\nand controllable editing, our method can automatically generate dynamic object\nmotion trajectories and enhance their realism during the optimization process.\nDrivingGaussian++ demonstrates consistent and realistic editing results and\ngenerates dynamic multi-view driving scenarios, while significantly enhancing\nscene diversity. More results and code can be found at the project site:\nhttps://xiong-creator.github.io/DrivingGaussian_plus.github.io",
      "url": "http://arxiv.org/abs/2508.20965v1",
      "published_time_eastern_timestamp": 1756398174.0
    },
    {
      "title": "STARE at the Structure: Steering ICL Exemplar Selection with Structural\n  Alignment",
      "summary": "In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to\nperform a wide range of tasks without task-specific fine-tuning. However, the\neffectiveness of ICL heavily depends on the quality of exemplar selection. In\nparticular, for structured prediction tasks such as semantic parsing, existing\nICL selection strategies often overlook structural alignment, leading to\nsuboptimal performance and poor generalization. To address this issue, we\npropose a novel two-stage exemplar selection strategy that achieves a strong\nbalance between efficiency, generalizability, and performance. First, we\nfine-tune a BERT-based retriever using structure-aware supervision, guiding it\nto select exemplars that are both semantically relevant and structurally\naligned. Then, we enhance the retriever with a plug-in module, which amplifies\nsyntactically meaningful information in the hidden representations. This\nplug-in is model-agnostic, requires minimal overhead, and can be seamlessly\nintegrated into existing pipelines. Experiments on four benchmarks spanning\nthree semantic parsing tasks demonstrate that our method consistently\noutperforms existing baselines with multiple recent LLMs as inference-time\nmodels.",
      "url": "http://arxiv.org/abs/2508.20944v1",
      "published_time_eastern_timestamp": 1756397079.0
    },
    {
      "title": "AI Reasoning Models for Problem Solving in Physics",
      "summary": "Reasoning models are the new generation of Large Language Models (LLMs)\ncapable of complex problem solving. Their reliability in solving introductory\nphysics problems was tested by evaluating a sample of n = 5 solutions generated\nby one such model -- OpenAI's o3-mini -- per each problem from 20 chapters of a\nstandard undergraduate textbook. In total, N = 408 problems were given to the\nmodel and N x n = 2,040 generated solutions examined. The model successfully\nsolved 94% of the problems posed, excelling at the beginning topics in\nmechanics but struggling with the later ones such as waves and thermodynamics.",
      "url": "http://arxiv.org/abs/2508.20941v1",
      "published_time_eastern_timestamp": 1756396957.0
    },
    {
      "title": "How Can Input Reformulation Improve Tool Usage Accuracy in a Complex\n  Dynamic Environment? A Study on $Ï„$-bench",
      "summary": "Recent advances in reasoning and planning capabilities of large language\nmodels (LLMs) have enabled their potential as autonomous agents capable of tool\nuse in dynamic environments. However, in multi-turn conversational environments\nlike $\\tau$-bench, these agents often struggle with consistent reasoning,\nadherence to domain-specific policies, and extracting correct information over\na long horizon of tool-calls and conversation. To capture and mitigate these\nfailures, we conduct a comprehensive manual analysis of the common errors\noccurring in the conversation trajectories. We then experiment with\nreformulations of inputs to the tool-calling agent for improvement in agent\ndecision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)\nframework, which automatically reformulates user queries augmented with\nrelevant domain rules and tool suggestions for the tool-calling agent to focus\non. The results show that IRMA significantly outperforms ReAct, Function\nCalling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in\noverall pass^5 scores. These findings highlight the superior reliability and\nconsistency of IRMA compared to other methods in dynamic environments.",
      "url": "http://arxiv.org/abs/2508.20931v1",
      "published_time_eastern_timestamp": 1756396653.0
    },
    {
      "title": "SageLM: A Multi-aspect and Explainable Large Language Model for Speech\n  Judgement",
      "summary": "Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to\nnatural human-computer interaction, enabling end-to-end spoken dialogue\nsystems. However, evaluating these models remains a fundamental challenge. We\npropose \\texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech\nLLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches\nthat disregard acoustic features, SageLM jointly assesses both semantic and\nacoustic dimensions. Second, it leverages rationale-based supervision to\nenhance explainability and guide model learning, achieving superior alignment\nwith evaluation outcomes compared to rule-based reinforcement learning methods.\nThird, we introduce \\textit{SpeechFeedback}, a synthetic preference dataset,\nand employ a two-stage training paradigm to mitigate the scarcity of speech\npreference data. Trained on both semantic and acoustic dimensions, SageLM\nachieves an 82.79\\% agreement rate with human evaluators, outperforming\ncascaded and SLM-based baselines by at least 7.42\\% and 26.20\\%, respectively.",
      "url": "http://arxiv.org/abs/2508.20916v1",
      "published_time_eastern_timestamp": 1756396057.0
    },
    {
      "title": "Research Challenges in Relational Database Management Systems for LLM\n  Queries",
      "summary": "Large language models (LLMs) have become essential for applications such as\ntext summarization, sentiment analysis, and automated question-answering.\nRecently, LLMs have also been integrated into relational database management\nsystems to enhance querying and support advanced data processing. Companies\nsuch as Amazon, Databricks, Google, and Snowflake offer LLM invocation directly\nwithin SQL, denoted as LLM queries, to boost data insights. However,\nopen-source solutions currently have limited functionality and poor\nperformance. In this work, we present an early exploration of two open-source\nsystems and one enterprise platform, using five representative queries to\nexpose functional, performance, and scalability limits in today's SQL-invoked\nLLM integrations. We identify three main issues: enforcing structured outputs,\noptimizing resource utilization, and improving query planning. We implemented\ninitial solutions and observed improvements in accommodating LLM powered SQL\nqueries. These early gains demonstrate that tighter integration of LLM+DBMS is\nthe key to scalable and efficient processing of LLM queries.",
      "url": "http://arxiv.org/abs/2508.20912v1",
      "published_time_eastern_timestamp": 1756395709.0
    },
    {
      "title": "Quantum Verifiable Rewards for Post-Training Qiskit Code Assistant",
      "summary": "Qiskit is an open-source quantum computing framework that allows users to\ndesign, simulate, and run quantum circuits on real quantum hardware. We explore\npost-training techniques for LLMs to assist in writing Qiskit code. We\nintroduce quantum verification as an effective method for ensuring code quality\nand executability on quantum hardware. To support this, we developed a\nsynthetic data pipeline that generates quantum problem-unit test pairs and used\nit to create preference data for aligning LLMs with DPO. Additionally, we\ntrained models using GRPO, leveraging quantum-verifiable rewards provided by\nthe quantum hardware. Our best-performing model, combining DPO and GRPO,\nsurpasses the strongest open-source baselines on the challenging\nQiskit-HumanEval-hard benchmark.",
      "url": "http://arxiv.org/abs/2508.20907v1",
      "published_time_eastern_timestamp": 1756395460.0
    },
    {
      "title": "Language-Enhanced Mobile Manipulation for Efficient Object Search in\n  Indoor Environments",
      "summary": "Enabling robots to efficiently search for and identify objects in complex,\nunstructured environments is critical for diverse applications ranging from\nhousehold assistance to industrial automation. However, traditional scene\nrepresentations typically capture only static semantics and lack interpretable\ncontextual reasoning, limiting their ability to guide object search in\ncompletely unfamiliar settings. To address this challenge, we propose a\nlanguage-enhanced hierarchical navigation framework that tightly integrates\nsemantic perception and spatial reasoning. Our method, Goal-Oriented\nDynamically Heuristic-Guided Hierarchical Search (GODHS), leverages large\nlanguage models (LLMs) to infer scene semantics and guide the search process\nthrough a multi-level decision hierarchy. Reliability in reasoning is achieved\nthrough the use of structured prompts and logical constraints applied at each\nstage of the hierarchy. For the specific challenges of mobile manipulation, we\nintroduce a heuristic-based motion planner that combines polar angle sorting\nwith distance prioritization to efficiently generate exploration paths.\nComprehensive evaluations in Isaac Sim demonstrate the feasibility of our\nframework, showing that GODHS can locate target objects with higher search\nefficiency compared to conventional, non-semantic search strategies. Website\nand Video are available at: https://drapandiger.github.io/GODHS",
      "url": "http://arxiv.org/abs/2508.20899v1",
      "published_time_eastern_timestamp": 1756394855.0
    },
    {
      "title": "The Uneven Impact of Post-Training Quantization in Machine Translation",
      "summary": "Quantization is essential for deploying large language models (LLMs) on\nresource-constrained hardware, but its implications for multilingual tasks\nremain underexplored. We conduct the first large-scale evaluation of\npost-training quantization (PTQ) on machine translation across 55 languages\nusing five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that\nwhile 4-bit quantization often preserves translation quality for high-resource\nlanguages and large models, significant degradation occurs for low-resource and\ntypologically diverse languages, particularly in 2-bit settings. We compare\nfour quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing\nthat algorithm choice and model size jointly determine robustness. GGUF\nvariants provide the most consistent performance, even at 2-bit precision.\nAdditionally, we quantify the interactions between quantization, decoding\nhyperparameters, and calibration languages, finding that language-matched\ncalibration offers benefits primarily in low-bit scenarios. Our findings offer\nactionable insights for deploying multilingual LLMs for machine translation\nunder quantization constraints, especially in low-resource settings.",
      "url": "http://arxiv.org/abs/2508.20893v1",
      "published_time_eastern_timestamp": 1756394551.0
    },
    {
      "title": "PromptSleuth: Detecting Prompt Injection via Semantic Intent Invariance",
      "summary": "Large Language Models (LLMs) are increasingly integrated into real-world\napplications, from virtual assistants to autonomous agents. However, their\nflexibility also introduces new attack vectors-particularly Prompt Injection\n(PI), where adversaries manipulate model behavior through crafted inputs. As\nattackers continuously evolve with paraphrased, obfuscated, and even multi-task\ninjection strategies, existing benchmarks are no longer sufficient to capture\nthe full spectrum of emerging threats.\n  To address this gap, we construct a new benchmark that systematically extends\nprior efforts. Our benchmark subsumes the two widely-used existing ones while\nintroducing new manipulation techniques and multi-task scenarios, thereby\nproviding a more comprehensive evaluation setting. We find that existing\ndefenses, though effective on their original benchmarks, show clear weaknesses\nunder our benchmark, underscoring the need for more robust solutions. Our key\ninsight is that while attack forms may vary, the adversary's intent-injecting\nan unauthorized task-remains invariant. Building on this observation, we\npropose PromptSleuth, a semantic-oriented defense framework that detects prompt\ninjection by reasoning over task-level intent rather than surface features.\nEvaluated across state-of-the-art benchmarks, PromptSleuth consistently\noutperforms existing defense while maintaining comparable runtime and cost\nefficiency. These results demonstrate that intent-based semantic reasoning\noffers a robust, efficient, and generalizable strategy for defending LLMs\nagainst evolving prompt injection threats.",
      "url": "http://arxiv.org/abs/2508.20890v1",
      "published_time_eastern_timestamp": 1756394347.0
    },
    {
      "title": "MSRS: Evaluating Multi-Source Retrieval-Augmented Generation",
      "summary": "Retrieval-augmented systems are typically evaluated in settings where\ninformation required to answer the query can be found within a single source or\nthe answer is short-form or factoid-based. However, many real-world\napplications demand the ability to integrate and summarize information\nscattered across multiple sources, where no single source is sufficient to\nrespond to the user's question. In such settings, the retrieval component of a\nRAG pipeline must recognize a variety of relevance signals, and the generation\ncomponent must connect and synthesize information across multiple sources. We\npresent a scalable framework for constructing evaluation benchmarks that\nchallenge RAG systems to integrate information across distinct sources and\ngenerate long-form responses. Using our framework, we build two new benchmarks\non Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing\nnarrative synthesis and summarization tasks, respectively, that require\nretrieval from large collections. Our extensive experiments with various RAG\npipelines -- including sparse and dense retrievers combined with frontier LLMs\n-- reveal that generation quality is highly dependent on retrieval\neffectiveness, which varies greatly by task. While multi-source synthesis\nproves challenging even in an oracle retrieval setting, we find that reasoning\nmodels significantly outperform standard LLMs at this distinct step.",
      "url": "http://arxiv.org/abs/2508.20867v1",
      "published_time_eastern_timestamp": 1756393195.0
    }
  ]
}
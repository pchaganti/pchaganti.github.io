{
  "last_updated": "2025-06-29T11:10:53.079158-04:00",
  "papers": [
    {
      "title": "mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and\n  Model Selection at Scale",
      "summary": "Multivariate time series anomaly detection (MTS-AD) is critical in domains\nlike healthcare, cybersecurity, and industrial monitoring, yet remains\nchallenging due to complex inter-variable dependencies, temporal dynamics, and\nsparse anomaly labels. We introduce mTSBench, the largest benchmark to date for\nMTS-AD and unsupervised model selection, spanning 344 labeled time series\nacross 19 datasets and 12 diverse application domains. mTSBench evaluates 24\nanomaly detection methods, including large language model (LLM)-based detectors\nfor multivariate time series, and systematically benchmarks unsupervised model\nselection techniques under standardized conditions. Consistent with prior\nfindings, our results confirm that no single detector excels across datasets,\nunderscoring the importance of model selection. However, even state-of-the-art\nselection methods remain far from optimal, revealing critical gaps. mTSBench\nprovides a unified evaluation suite to enable rigorous, reproducible\ncomparisons and catalyze future advances in adaptive anomaly detection and\nrobust model selection.",
      "url": "http://arxiv.org/abs/2506.21550v1",
      "published_time_eastern_timestamp": 1750960798.0
    }
  ]
}
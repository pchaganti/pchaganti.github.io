{
  "last_updated": "2025-06-05T02:18:17.152426-04:00",
  "papers": [
    {
      "title": "OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data\n  Synthesis",
      "summary": "The rapid progress of navigation, manipulation, and vision models has made\nmobile manipulators capable in many specialized tasks. However, the open-world\nmobile manipulation (OWMM) task remains a challenge due to the need for\ngeneralization to open-ended instructions and environments, as well as the\nsystematic complexity to integrate high-level decision making with low-level\nrobot control based on both global scene understanding and current agent state.\nTo address this complexity, we propose a novel multi-modal agent architecture\nthat maintains multi-view scene frames and agent states for decision-making and\ncontrols the robot by function calling. A second challenge is the hallucination\nfrom domain shift. To enhance the agent performance, we further introduce an\nagentic data synthesis pipeline for the OWMM task to adapt the VLM model to our\ntask domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM\nas the first dedicated foundation model for mobile manipulators with global\nscene understanding, robot state tracking, and multi-modal action generation in\na unified model. Through experiments, we demonstrate that our model achieves\nSOTA performance compared to other foundation models including GPT-4o and\nstrong zero-shot generalization in real world. The project page is at\nhttps://github.com/HHYHRHY/OWMM-Agent",
      "url": "http://arxiv.org/abs/2506.04217v1",
      "published_time_eastern_timestamp": 1749059864.0
    },
    {
      "title": "Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally\n  Interdependent Multi-Agent MDPs",
      "summary": "Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are\nknown to be NEXP-Complete and intractable to solve. However, for problems such\nas cooperative navigation, obstacle avoidance, and formation control, basic\nassumptions can be made about local visibility and local dependencies. The work\nDeWeese and Qu 2024 formalized these assumptions in the construction of the\nLocally Interdependent Multi-Agent MDP. In this setting, it establishes three\nclosed-form policies that are tractable to compute in various situations and\nare exponentially close to optimal with respect to visibility. However, it is\nalso shown that these solutions can have poor performance when the visibility\nis small and fixed, often getting stuck during simulations due to the so called\n\"Penalty Jittering\" phenomenon. In this work, we establish the Extended Cutoff\nPolicy Class which is, to the best of our knowledge, the first non-trivial\nclass of near optimal closed-form partially observable policies that are\nexponentially close to optimal with respect to the visibility for any Locally\nInterdependent Multi-Agent MDP. These policies are able to remember agents\nbeyond their visibilities which allows them to perform significantly better in\nmany small and fixed visibility settings, resolve Penalty Jittering\noccurrences, and under certain circumstances guarantee fully observable joint\noptimal behavior despite the partial observability. We also propose a\ngeneralized form of the Locally Interdependent Multi-Agent MDP that allows for\ntransition dependence and extended reward dependence, then replicate our\ntheoretical results in this setting.",
      "url": "http://arxiv.org/abs/2506.04215v1",
      "published_time_eastern_timestamp": 1749059850.0
    },
    {
      "title": "TracLLM: A Generic Framework for Attributing Long Context LLMs",
      "summary": "Long context large language models (LLMs) are deployed in many real-world\napplications such as RAG, agent, and broad LLM-integrated applications. Given\nan instruction and a long context (e.g., documents, PDF files, webpages), a\nlong context LLM can generate an output grounded in the provided context,\naiming to provide more accurate, up-to-date, and verifiable outputs while\nreducing hallucinations and unsupported claims. This raises a research\nquestion: how to pinpoint the texts (e.g., sentences, passages, or paragraphs)\nin the context that contribute most to or are responsible for the generated\noutput by an LLM? This process, which we call context traceback, has various\nreal-world applications, such as 1) debugging LLM-based systems, 2) conducting\npost-attack forensic analysis for attacks (e.g., prompt injection attack,\nknowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources\nto enhance the trust of users towards outputs generated by LLMs. When applied\nto context traceback for long context LLMs, existing feature attribution\nmethods such as Shapley have sub-optimal performance and/or incur a large\ncomputational cost. In this work, we develop TracLLM, the first generic context\ntraceback framework tailored to long context LLMs. Our framework can improve\nthe effectiveness and efficiency of existing feature attribution methods. To\nimprove the efficiency, we develop an informed search based algorithm in\nTracLLM. We also develop contribution score ensemble/denoising techniques to\nimprove the accuracy of TracLLM. Our evaluation results show TracLLM can\neffectively identify texts in a long context that lead to the output of an LLM.\nOur code and data are at: https://github.com/Wang-Yanting/TracLLM.",
      "url": "http://arxiv.org/abs/2506.04202v1",
      "published_time_eastern_timestamp": 1749059296.0
    },
    {
      "title": "MACS: Multi-Agent Reinforcement Learning for Optimization of Crystal\n  Structures",
      "summary": "Geometry optimization of atomic structures is a common and crucial task in\ncomputational chemistry and materials design. Following the learning to\noptimize paradigm, we propose a new multi-agent reinforcement learning method\ncalled Multi-Agent Crystal Structure optimization (MACS) to address periodic\ncrystal structure optimization. MACS treats geometry optimization as a\npartially observable Markov game in which atoms are agents that adjust their\npositions to collectively discover a stable configuration. We train MACS across\nvarious compositions of reported crystalline materials to obtain a policy that\nsuccessfully optimizes structures from the training compositions as well as\nstructures of larger sizes and unseen compositions, confirming its excellent\nscalability and zero-shot transferability. We benchmark our approach against a\nbroad range of state-of-the-art optimization methods and demonstrate that MACS\noptimizes periodic crystal structures significantly faster, with fewer energy\ncalculations, and the lowest failure rate.",
      "url": "http://arxiv.org/abs/2506.04195v1",
      "published_time_eastern_timestamp": 1749058857.0
    },
    {
      "title": "SuperWriter: Reflection-Driven Long-Form Generation with Large Language\n  Models",
      "summary": "Long-form text generation remains a significant challenge for large language\nmodels (LLMs), particularly in maintaining coherence, ensuring logical\nconsistency, and preserving text quality as sequence length increases. To\naddress these limitations, we propose SuperWriter-Agent, an agent-based\nframework designed to enhance the quality and consistency of long-form text\ngeneration. SuperWriter-Agent introduces explicit structured thinking-through\nplanning and refinement stages into the generation pipeline, guiding the model\nto follow a more deliberate and cognitively grounded process akin to that of a\nprofessional writer. Based on this framework, we construct a supervised\nfine-tuning dataset to train a 7B SuperWriter-LM. We further develop a\nhierarchical Direct Preference Optimization (DPO) procedure that uses Monte\nCarlo Tree Search (MCTS) to propagate final quality assessments and optimize\neach generation step accordingly. Empirical results across diverse benchmarks\ndemonstrate that SuperWriter-LM achieves state-of-the-art performance,\nsurpassing even larger-scale baseline models in both automatic evaluation and\nhuman evaluation. Furthermore, comprehensive ablation studies demonstrate the\neffectiveness of hierarchical DPO and underscore the value of incorporating\nstructured thinking steps to improve the quality of long-form text generation.",
      "url": "http://arxiv.org/abs/2506.04180v1",
      "published_time_eastern_timestamp": 1749058062.0
    },
    {
      "title": "A primal-dual price-optimization method for computing equilibrium prices\n  in mean-field games models",
      "summary": "We develop a simple yet efficient Lagrangian method for computing equilibrium\nprices in a mean-field game price-formation model. We prove that equilibrium\nprices are optimal in terms of a suitable criterion and derive a primal-dual\ngradient-based algorithm for computing them. One of the highlights of our\ncomputational framework is the efficient, simple, and flexible implementation\nof the algorithm using modern automatic differentiation techniques. Our\nimplementation is modular and admits a seamless extension to high-dimensional\nsettings with more complex dynamics, costs, and equilibrium conditions.\nAdditionally, automatic differentiation enables a versatile algorithm that\nrequires only coding the cost functions of agents. It automatically handles the\ngradients of the costs, thereby eliminating the need to manually form the\nadjoint equations.",
      "url": "http://arxiv.org/abs/2506.04169v1",
      "published_time_eastern_timestamp": 1749056842.0
    },
    {
      "title": "Image Editing As Programs with Diffusion Models",
      "summary": "While diffusion models have achieved remarkable success in text-to-image\ngeneration, they encounter significant challenges with instruction-driven image\nediting. Our research highlights a key challenge: these models particularly\nstruggle with structurally inconsistent edits that involve substantial layout\nchanges. To mitigate this gap, we introduce Image Editing As Programs (IEAP), a\nunified image editing framework built upon the Diffusion Transformer (DiT)\narchitecture. At its core, IEAP approaches instructional editing through a\nreductionist lens, decomposing complex editing instructions into sequences of\natomic operations. Each operation is implemented via a lightweight adapter\nsharing the same DiT backbone and is specialized for a specific type of edit.\nProgrammed by a vision-language model (VLM)-based agent, these operations\ncollaboratively support arbitrary and structurally inconsistent\ntransformations. By modularizing and sequencing edits in this way, IEAP\ngeneralizes robustly across a wide range of editing tasks, from simple\nadjustments to substantial structural changes. Extensive experiments\ndemonstrate that IEAP significantly outperforms state-of-the-art methods on\nstandard benchmarks across various editing scenarios. In these evaluations, our\nframework delivers superior accuracy and semantic fidelity, particularly for\ncomplex, multi-step instructions. Codes are available at\nhttps://github.com/YujiaHu1109/IEAP.",
      "url": "http://arxiv.org/abs/2506.04158v1",
      "published_time_eastern_timestamp": 1749056244.0
    },
    {
      "title": "macOSWorld: A Multilingual Interactive Benchmark for GUI Agents",
      "summary": "Graphical User Interface (GUI) agents show promising capabilities for\nautomating computer-use tasks and facilitating accessibility, but existing\ninteractive benchmarks are mostly English-only, covering web-use or Windows,\nLinux, and Android environments, but not macOS. macOS is a major OS with\ndistinctive GUI patterns and exclusive applications. To bridge the gaps, we\npresent macOSWorld, the first comprehensive benchmark for evaluating GUI agents\non macOS. macOSWorld features 202 multilingual interactive tasks across 30\napplications (28 macOS-exclusive), with task instructions and OS interfaces\noffered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As\nGUI agents are shown to be vulnerable to deception attacks, macOSWorld also\nincludes a dedicated safety benchmarking subset. Our evaluation on six GUI\nagents reveals a dramatic gap: proprietary computer-use agents lead at above\n30% success rate, while open-source lightweight research models lag at below\n2%, highlighting the need for macOS domain adaptation. Multilingual benchmarks\nalso expose common weaknesses, especially in Arabic, with a 27.5% average\ndegradation compared to English. Results from safety benchmarking also\nhighlight that deception attacks are more general and demand immediate\nattention. macOSWorld is available at https://github.com/showlab/macosworld.",
      "url": "http://arxiv.org/abs/2506.04135v1",
      "published_time_eastern_timestamp": 1749054416.0
    },
    {
      "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management\n  in LLM-based Agentic Multi-Agent Systems",
      "summary": "Agentic AI systems, built on large language models (LLMs) and deployed in\nmulti-agent configurations, are redefining intelligent autonomy, collaboration\nand decision-making across enterprise and societal domains. This review\npresents a structured analysis of Trust, Risk, and Security Management (TRiSM)\nin the context of LLM-based agentic multi-agent systems (AMAS). We begin by\nexamining the conceptual foundations of agentic AI, its architectural\ndifferences from traditional AI agents, and the emerging system designs that\nenable scalable, tool-using autonomy. The TRiSM in the agentic AI framework is\nthen detailed through four pillars governance, explainability, ModelOps, and\nprivacy/security each contextualized for agentic LLMs. We identify unique\nthreat vectors and introduce a comprehensive risk taxonomy for the agentic AI\napplications, supported by case studies illustrating real-world\nvulnerabilities. Furthermore, the paper also surveys trust-building mechanisms,\ntransparency and oversight techniques, and state-of-the-art explainability\nstrategies in distributed LLM agent systems. Additionally, metrics for\nevaluating trust, interpretability, and human-centered performance are reviewed\nalongside open benchmarking challenges. Security and privacy are addressed\nthrough encryption, adversarial defense, and compliance with evolving AI\nregulations. The paper concludes with a roadmap for responsible agentic AI,\nproposing research directions to align emerging multi-agent systems with robust\nTRiSM principles for safe, accountable, and transparent deployment.",
      "url": "http://arxiv.org/abs/2506.04133v1",
      "published_time_eastern_timestamp": 1749054371.0
    },
    {
      "title": "CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation\n  in Courtroom Dialogues",
      "summary": "Courtrooms are places where lives are determined and fates are sealed, yet\nthey are not impervious to manipulation. Strategic use of manipulation in legal\njargon can sway the opinions of judges and affect the decisions. Despite the\ngrowing advancements in NLP, its application in detecting and analyzing\nmanipulation within the legal domain remains largely unexplored. Our work\naddresses this gap by introducing LegalCon, a dataset of 1,063 annotated\ncourtroom conversations labeled for manipulation detection, identification of\nprimary manipulators, and classification of manipulative techniques, with a\nfocus on long conversations. Furthermore, we propose CLAIM, a two-stage,\nIntent-driven Multi-agent framework designed to enhance manipulation analysis\nby enabling context-aware and informed decision-making. Our results highlight\nthe potential of incorporating agentic frameworks to improve fairness and\ntransparency in judicial processes. We hope that this contributes to the\nbroader application of NLP in legal discourse analysis and the development of\nrobust tools to support fairness in legal decision-making. Our code and data\nare available at https://github.com/Disha1001/CLAIM.",
      "url": "http://arxiv.org/abs/2506.04131v1",
      "published_time_eastern_timestamp": 1749054179.0
    },
    {
      "title": "TextAtari: 100K Frames Game Playing with Language Agents",
      "summary": "We present TextAtari, a benchmark for evaluating language agents on very\nlong-horizon decision-making tasks spanning up to 100,000 steps. By translating\nthe visual state representations of classic Atari games into rich textual\ndescriptions, TextAtari creates a challenging test bed that bridges sequential\ndecision-making with natural language processing. The benchmark includes nearly\n100 distinct tasks with varying complexity, action spaces, and planning\nhorizons, all rendered as text through an unsupervised representation learning\nframework (AtariARI). We evaluate three open-source large language models\n(Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks\n(zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how\ndifferent forms of prior knowledge affect performance on these long-horizon\nchallenges. Four scenarios-Basic, Obscured, Manual Augmentation, and\nReference-based-investigate the impact of semantic understanding, instruction\ncomprehension, and expert demonstrations on agent decision-making. Our results\nreveal significant performance gaps between language agents and human players\nin extensive planning tasks, highlighting challenges in sequential reasoning,\nstate tracking, and strategic planning across tens of thousands of steps.\nTextAtari provides standardized evaluation protocols, baseline implementations,\nand a framework for advancing research at the intersection of language models\nand planning.",
      "url": "http://arxiv.org/abs/2506.04098v1",
      "published_time_eastern_timestamp": 1749052527.0
    },
    {
      "title": "AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment",
      "summary": "As a part of an embodied agent, Large Language Models (LLMs) are typically\nused for behavior planning given natural language instructions from the user.\nHowever, dealing with ambiguous instructions in real-world environments remains\na challenge for LLMs. Various methods for task ambiguity detection have been\nproposed. However, it is difficult to compare them because they are tested on\ndifferent datasets and there is no universal benchmark. For this reason, we\npropose AmbiK (Ambiguous Tasks in Kitchen Environment), the fully textual\ndataset of ambiguous instructions addressed to a robot in a kitchen\nenvironment. AmbiK was collected with the assistance of LLMs and is\nhuman-validated. It comprises 1000 pairs of ambiguous tasks and their\nunambiguous counterparts, categorized by ambiguity type (Human Preferences,\nCommon Sense Knowledge, Safety), with environment descriptions, clarifying\nquestions and answers, user intents, and task plans, for a total of 2000 tasks.\nWe hope that AmbiK will enable researchers to perform a unified comparison of\nambiguity detection methods. AmbiK is available at\nhttps://github.com/cog-model/AmbiK-dataset.",
      "url": "http://arxiv.org/abs/2506.04089v1",
      "published_time_eastern_timestamp": 1749052027.0
    },
    {
      "title": "Optimal Transport-based Domain Alignment as a Preprocessing Step for\n  Federated Learning",
      "summary": "Federated learning (FL) is a subfield of machine learning that avoids sharing\nlocal data with a central server, which can enhance privacy and scalability.\nThe inability to consolidate data leads to a unique problem called dataset\nimbalance, where agents in a network do not have equal representation of the\nlabels one is trying to learn to predict. In FL, fusing locally-trained models\nwith unbalanced datasets may deteriorate the performance of global model\naggregation, and reduce the quality of updated local models and the accuracy of\nthe distributed agents' decisions. In this work, we introduce an Optimal\nTransport-based preprocessing algorithm that aligns the datasets by minimizing\nthe distributional discrepancy of data along the edge devices. We accomplish\nthis by leveraging Wasserstein barycenters when computing channel-wise\naverages. These barycenters are collected in a trusted central server where\nthey collectively generate a target RGB space. By projecting our dataset\ntowards this target space, we minimize the distributional discrepancy on a\nglobal level, which facilitates the learning process due to a minimization of\nvariance across the samples. We demonstrate the capabilities of the proposed\napproach over the CIFAR-10 dataset, where we show its capability of reaching\nhigher degrees of generalization in fewer communication rounds.",
      "url": "http://arxiv.org/abs/2506.04071v1",
      "published_time_eastern_timestamp": 1749051355.0
    },
    {
      "title": "AI Agents for Conversational Patient Triage: Preliminary\n  Simulation-Based Evaluation with Real-World EHR Data",
      "summary": "Background: We present a Patient Simulator that leverages real world patient\nencounters which cover a broad range of conditions and symptoms to provide\nsynthetic test subjects for development and testing of healthcare agentic\nmodels. The simulator provides a realistic approach to patient presentation and\nmulti-turn conversation with a symptom-checking agent. Objectives: (1) To\nconstruct and instantiate a Patient Simulator to train and test an AI health\nagent, based on patient vignettes derived from real EHR data. (2) To test the\nvalidity and alignment of the simulated encounters provided by the Patient\nSimulator to expert human clinical providers. (3) To illustrate the evaluation\nframework of such an LLM system on the generated realistic, data-driven\nsimulations -- yielding a preliminary assessment of our proposed system.\nMethods: We first constructed realistic clinical scenarios by deriving patient\nvignettes from real-world EHR encounters. These vignettes cover a variety of\npresenting symptoms and underlying conditions. We then evaluate the performance\nof the Patient Simulator as a simulacrum of a real patient encounter across\nover 500 different patient vignettes. We leveraged a separate AI agent to\nprovide multi-turn questions to obtain a history of present illness. The\nresulting multiturn conversations were evaluated by two expert clinicians.\nResults: Clinicians scored the Patient Simulator as consistent with the patient\nvignettes in those same 97.7% of cases. The extracted case summary based on the\nconversation history was 99% relevant. Conclusions: We developed a methodology\nto incorporate vignettes derived from real healthcare patient data to build a\nsimulation of patient responses to symptom checking agents. The performance and\nalignment of this Patient Simulator could be used to train and test a\nmulti-turn conversational AI agent at scale.",
      "url": "http://arxiv.org/abs/2506.04032v1",
      "published_time_eastern_timestamp": 1749048968.0
    },
    {
      "title": "AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in\n  LLM-Based Agents",
      "summary": "As Large Language Model (LLM) agents become more widespread, associated\nmisalignment risks increase. Prior work has examined agents' ability to enact\nmisaligned behaviour (misalignment capability) and their compliance with\nharmful instructions (misuse propensity). However, the likelihood of agents\nattempting misaligned behaviours in real-world settings (misalignment\npropensity) remains poorly understood. We introduce a misalignment propensity\nbenchmark, AgentMisalignment, consisting of a suite of realistic scenarios in\nwhich LLM agents have the opportunity to display misaligned behaviour. We\norganise our evaluations into subcategories of misaligned behaviours, including\ngoal-guarding, resisting shutdown, sandbagging, and power-seeking. We report\nthe performance of frontier models on our benchmark, observing higher\nmisalignment on average when evaluating more capable models. Finally, we\nsystematically vary agent personalities through different system prompts. We\nfind that persona characteristics can dramatically and unpredictably influence\nmisalignment tendencies -- occasionally far more than the choice of model\nitself -- highlighting the importance of careful system prompt engineering for\ndeployed AI agents. Our work highlights the failure of current alignment\nmethods to generalise to LLM agents, and underscores the need for further\npropensity evaluations as autonomous systems become more prevalent.",
      "url": "http://arxiv.org/abs/2506.04018v1",
      "published_time_eastern_timestamp": 1749048407.0
    },
    {
      "title": "Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to\n  Enhance LLM Reasoning",
      "summary": "Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external\nknowledge integration capabilities by explicitly modeling knowledge\nrelationships, thereby improving the factual accuracy and generation quality of\nLarge Language Models (LLMs) in specialized domains. However, existing methods\nsuffer from two inherent limitations: 1) Inefficient Information Aggregation:\nThey rely on a single agent and fixed iterative patterns, making it difficult\nto adaptively capture multi-level textual, structural, and degree information\nwithin graph data. 2) Rigid Reasoning Mechanism: They employ preset reasoning\nschemes, which cannot dynamically adjust reasoning depth nor achieve precise\nsemantic correction. To overcome these limitations, we propose Graph Counselor,\nan GraphRAG method based on multi-agent collaboration. This method uses the\nAdaptive Graph Information Extraction Module (AGIEM), where Planning, Thought,\nand Execution Agents work together to precisely model complex graph structures\nand dynamically adjust information extraction strategies, addressing the\nchallenges of multi-level dependency modeling and adaptive reasoning depth.\nAdditionally, the Self-Reflection with Multiple Perspectives (SR) module\nimproves the accuracy and semantic consistency of reasoning results through\nself-reflection and backward reasoning mechanisms. Experiments demonstrate that\nGraph Counselor outperforms existing methods in multiple graph reasoning tasks,\nexhibiting higher reasoning accuracy and generalization ability. Our code is\navailable at https://github.com/gjq100/Graph-Counselor.git.",
      "url": "http://arxiv.org/abs/2506.03939v1",
      "published_time_eastern_timestamp": 1749043881.0
    },
    {
      "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for\n  Multimodal Large Language Models",
      "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant\npotential to advance a broad range of domains. However, current benchmarks for\nevaluating MLLMs primarily emphasize general knowledge and vertical\nstep-by-step reasoning typical of STEM disciplines, while overlooking the\ndistinct needs and potential of the Humanities and Social Sciences (HSS). Tasks\nin the HSS domain require more horizontal, interdisciplinary thinking and a\ndeep integration of knowledge across related fields, which presents unique\nchallenges for MLLMs, particularly in linking abstract concepts with\ncorresponding visual representations. Addressing this gap, we present HSSBench,\na dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks\nin multiple languages, including the six official languages of the United\nNations. We also introduce a novel data generation pipeline tailored for HSS\nscenarios, in which multiple domain experts and automated agents collaborate to\ngenerate and iteratively refine each sample. HSSBench contains over 13,000\nmeticulously designed samples, covering six key categories. We benchmark more\nthan 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant\nchallenges even for state-of-the-art models. We hope that this benchmark will\ninspire further research into enhancing the cross-disciplinary reasoning\nabilities of MLLMs, especially their capacity to internalize and connect\nknowledge across fields.",
      "url": "http://arxiv.org/abs/2506.03922v1",
      "published_time_eastern_timestamp": 1749042853.0
    },
    {
      "title": "Causal Explanations Over Time: Articulated Reasoning for Interactive\n  Environments",
      "summary": "Structural Causal Explanations (SCEs) can be used to automatically generate\nexplanations in natural language to questions about given data that are\ngrounded in a (possibly learned) causal model. Unfortunately they work for\nsmall data only. In turn they are not attractive to offer reasons for events,\ne.g., tracking causal changes over multiple time steps, or a behavioral\ncomponent that involves feedback loops through actions of an agent. To this\nend, we generalize SCEs to a (recursive) formulation of explanation trees to\ncapture the temporal interactions between reasons. We show the benefits of this\nmore general SCE algorithm on synthetic time-series data and a 2D grid game,\nand further compare it to the base SCE and other existing methods for causal\nexplanations.",
      "url": "http://arxiv.org/abs/2506.03915v1",
      "published_time_eastern_timestamp": 1749042436.0
    },
    {
      "title": "Jet-Feedback on kpc scales: a review",
      "summary": "Relativistic jets from AGN are an important driver of feedback in galaxies.\nThey interact with their environments over a wide range of physical scales\nduring their lifetime, and an understanding of these interactions is crucial\nfor unraveling the role of supermassive blackholes in shaping galaxy evolution.\nThe impact of such jets have been traditionally considered in the context of\nheating the large-scale environments. However, in the last few decades there\nhas been additional focus on the immediate impact of jet feedback on the host\ngalaxy itself. In this review we outline the development of various numerical\nsimulations since the onset of studies of jets to the present day, where\nsophisticated numerical techniques have been employed to study jet feedback\nincluding a range of physical processes. The jets can act as an important agent\nof injecting energy in the host's ISM, as confirmed both in observations of\nmulti-phase gas, as well as in simulations. Such interactions have the\npotential to impact the kinematics of the gas as well as its star formation. We\nsummarize the recent results from simulations of jet feedback on kpc scales,\nand outline the broader implications for observations and galaxy evolution.",
      "url": "http://arxiv.org/abs/2506.03888v1",
      "published_time_eastern_timestamp": 1749040230.0
    },
    {
      "title": "PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in\n  High-Frequency Cryptocurrency Trading",
      "summary": "High-Frequency Trading (HFT) is pivotal in cryptocurrency markets, demanding\nrapid decision-making. Social media platforms like Reddit offer valuable, yet\nunderexplored, information for such high-frequency, short-term trading. This\npaper introduces \\textbf{PulseReddit}, a novel dataset that is the first to\nalign large-scale Reddit discussion data with high-frequency cryptocurrency\nmarket statistics for short-term trading analysis. We conduct an extensive\nempirical study using Large Language Model (LLM)-based Multi-Agent Systems\n(MAS) to investigate the impact of social sentiment from PulseReddit on trading\nperformance. Our experiments conclude that MAS augmented with PulseReddit data\nachieve superior trading outcomes compared to traditional baselines,\nparticularly in bull markets, and demonstrate robust adaptability across\ndifferent market regimes. Furthermore, our research provides conclusive\ninsights into the performance-efficiency trade-offs of different LLMs,\ndetailing significant considerations for practical model selection in HFT\napplications. PulseReddit and our findings establish a foundation for advanced\nMAS research in HFT, demonstrating the tangible benefits of integrating social\nmedia.",
      "url": "http://arxiv.org/abs/2506.03861v1",
      "published_time_eastern_timestamp": 1749037731.0
    }
  ]
}
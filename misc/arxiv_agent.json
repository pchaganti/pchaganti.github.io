{
  "last_updated": "2025-05-24T17:10:04.531174-04:00",
  "papers": [
    {
      "title": "SpatialScore: Towards Unified Evaluation for Multimodal Spatial\n  Understanding",
      "summary": "Multimodal large language models (MLLMs) have achieved impressive success in\nquestion-answering tasks, yet their capabilities for spatial understanding are\nless explored. This work investigates a critical question: do existing MLLMs\npossess 3D spatial perception and understanding abilities? Concretely, we make\nthe following contributions in this paper: (i) we introduce VGBench, a\nbenchmark specifically designed to assess MLLMs for visual geometry perception,\ne.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most\ncomprehensive and diverse multimodal spatial understanding benchmark to date,\nintegrating VGBench with relevant data from the other 11 existing datasets.\nThis benchmark comprises 28K samples across various spatial understanding\ntasks, modalities, and QA formats, along with a carefully curated challenging\nsubset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent\nsystem incorporating 9 specialized tools for spatial understanding, supporting\nboth Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive\nevaluations to reveal persistent challenges in spatial reasoning while\ndemonstrating the effectiveness of SpatialAgent. We believe SpatialScore will\noffer valuable insights and serve as a rigorous benchmark for the next\nevolution of MLLMs.",
      "url": "http://arxiv.org/abs/2505.17012v1",
      "published_time_eastern_timestamp": 1747936743.0
    },
    {
      "title": "X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs",
      "summary": "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by\nenabling cooperation among multiple specialized agents. However, most existing\nMAS frameworks rely on a single LLM to drive all agents, constraining the\nsystem's intelligence to the limit of that model. This paper explores the\nparadigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by\ndiverse LLMs, elevating the system's potential to the collective intelligence\nof diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to\nevaluate the performance of various LLMs across different domains and\nMAS-related functions. As an extensive empirical study, we assess 27 LLMs\nacross 5 domains (encompassing 21 test sets) and 5 functions, conducting over\n1.7 million evaluations to identify optimal model selections for each\ndomain-function combination. Building on these findings, we demonstrate that\ntransitioning from homogeneous to heterogeneous LLM-driven MAS can\nsignificantly enhance system performance without requiring structural redesign.\nSpecifically, in a chatbot-only MAS scenario, the heterogeneous configuration\nyields up to 8.4\\% performance improvement on the MATH dataset. In a mixed\nchatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable\n47\\% performance boost on the AIME dataset. Our results underscore the\ntransformative potential of heterogeneous LLMs in MAS, highlighting a promising\navenue for advancing scalable, collaborative AI systems.",
      "url": "http://arxiv.org/abs/2505.16997v1",
      "published_time_eastern_timestamp": 1747936599.0
    },
    {
      "title": "MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent\n  Systems",
      "summary": "LLM-based multi-agent systems (MAS) have demonstrated significant potential\nin enhancing single LLMs to address complex and diverse tasks in practical\napplications. Despite considerable advancements, the field lacks a unified\ncodebase that consolidates existing methods, resulting in redundant\nre-implementation efforts, unfair comparisons, and high entry barriers for\nresearchers. To address these challenges, we introduce MASLab, a unified,\ncomprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab\nintegrates over 20 established methods across multiple domains, each rigorously\nvalidated by comparing step-by-step outputs with its official implementation.\n(2) MASLab provides a unified environment with various benchmarks for fair\ncomparisons among methods, ensuring consistent inputs and standardized\nevaluation protocols. (3) MASLab implements methods within a shared streamlined\nstructure, lowering the barriers for understanding and extension. Building on\nMASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models,\noffering researchers a clear and comprehensive view of the current landscape of\nMAS methods. MASLab will continue to evolve, tracking the latest developments\nin the field, and invite contributions from the broader open-source community.",
      "url": "http://arxiv.org/abs/2505.16988v1",
      "published_time_eastern_timestamp": 1747936478.0
    },
    {
      "title": "T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic\n  Planning",
      "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities as\nintelligent agents capable of solving complex problems. However, effective\nplanning in scenarios involving dependencies between API or tool\ncalls-particularly in multi-turn conversations-remains a significant challenge.\nTo address this, we introduce T1, a tool-augmented, multi-domain, multi-turn\nconversational dataset specifically designed to capture and manage inter-tool\ndependencies across diverse domains. T1 enables rigorous evaluation of agents'\nability to coordinate tool use across nine distinct domains (4 single domain\nand 5 multi-domain) with the help of an integrated caching mechanism for both\nshort- and long-term memory, while supporting dynamic replanning-such as\ndeciding whether to recompute or reuse cached results. Beyond facilitating\nresearch on tool use and planning, T1 also serves as a benchmark for evaluating\nthe performance of open-source language models. We present results powered by\nT1-Agent, highlighting their ability to plan and reason in complex,\ntool-dependent scenarios.",
      "url": "http://arxiv.org/abs/2505.16986v1",
      "published_time_eastern_timestamp": 1747936472.0
    },
    {
      "title": "Beyond Correlation: Towards Causal Large Language Model Agents in\n  Biomedicine",
      "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.",
      "url": "http://arxiv.org/abs/2505.16982v1",
      "published_time_eastern_timestamp": 1747936379.0
    },
    {
      "title": "Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System\n  Design",
      "summary": "Single-agent LLMs hit hard limits--finite context, role overload, and brittle\ndomain transfer. Conventional multi-agent fixes soften those edges yet expose\nfresh pains: ill-posed decompositions, fuzzy contracts, and verification\noverhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a\nframework that converts domain priors into an algorithmic blueprint hierarchy,\nin which tasks are recursively split into typed, controller-mediated subtasks,\neach solved zero-shot or with the lightest viable boost (e.g.,\nchain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch\ntheorem, KtR trades the chase for a universal prompt for disciplined\ndecomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents\nraise accuracy from 3% zero-shot to 95% on size-5 instances after patching a\nsingle bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a\nsix-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,\nversus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation\nthus turns modest models into reliable collaborators--no ever-larger monoliths\nrequired.",
      "url": "http://arxiv.org/abs/2505.16979v1",
      "published_time_eastern_timestamp": 1747936353.0
    },
    {
      "title": "SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software\n  Development",
      "summary": "Large Language Models (LLMs) have shown strong capability in diverse software\nengineering tasks, e.g. code completion, bug fixing, and document generation.\nHowever, feature-driven development (FDD), a highly prevalent real-world task\nthat involves developing new functionalities for large, existing codebases,\nremains underexplored. We therefore introduce SWE-Dev, the first large-scale\ndataset (with 14,000 training and 500 test samples) designed to evaluate and\ntrain autonomous coding systems on real-world feature development tasks. To\nensure verifiable and diverse training, SWE-Dev uniquely provides all instances\nwith a runnable environment and its developer-authored executable unit tests.\nThis collection not only provides high-quality data for Supervised Fine-Tuning\n(SFT), but also enables Reinforcement Learning (RL) by delivering accurate\nreward signals from executable unit tests. Our extensive evaluations on\nSWE-Dev, covering 17 chatbot LLMs, 10 reasoning models, and 10 Multi-Agent\nSystems (MAS), reveal that FDD is a profoundly challenging frontier for current\nAI (e.g., Claude-3.7-Sonnet achieves only 22.45\\% Pass@3 on the hard test\nsplit). Crucially, we demonstrate that SWE-Dev serves as an effective platform\nfor model improvement: fine-tuning on training set enabled a 7B model\ncomparable to GPT-4o on \\textit{hard} split, underscoring the value of its\nhigh-quality training data. Code is available here\n\\href{https://github.com/justLittleWhite/SWE-Dev}{https://github.com/justLittleWhite/SWE-Dev}.",
      "url": "http://arxiv.org/abs/2505.16975v1",
      "published_time_eastern_timestamp": 1747936309.0
    },
    {
      "title": "Modeling Inequality in Complex Networks of Strategic Agents using\n  Iterative Game-Theoretic Transactions",
      "summary": "Transactions are an important aspect of human social life, and represent\ndynamic flow of information, intangible values, such as trust, as well as\nmonetary and social capital. Although much research has been conducted on the\nnature of transactions in fields ranging from the social sciences to game\ntheory, the systemic effects of different types of agents transacting in\nreal-world social networks (often following a scale-free distribution) are not\nfully understood. A particular systemic measure that has not received adequate\nattention in the complex networks and game theory communities, is the Gini\nCoefficient, which is widely used in economics to quantify and understand\nwealth inequality. In part, the problem is a lack of experimentation using a\nreplicable algorithm and publicly available data. Motivated by this problem,\nthis article proposes a model and simulation algorithm, based on game theory,\nfor quantifying the evolution of inequality in complex networks of strategic\nagents. Our results shed light on several complex drivers of inequality, even\nin simple, abstract settings, and exhibit consistency across networks with\ndifferent origins and descriptions.",
      "url": "http://arxiv.org/abs/2505.16966v1",
      "published_time_eastern_timestamp": 1747936028.0
    },
    {
      "title": "Cracking Aegis: An Adversarial LLM-based Game for Raising Awareness of\n  Vulnerabilities in Privacy Protection",
      "summary": "Traditional methods for raising awareness of privacy protection often fail to\nengage users or provide hands-on insights into how privacy vulnerabilities are\nexploited. To address this, we incorporate an adversarial mechanic in the\ndesign of the dialogue-based serious game Cracking Aegis. Leveraging LLMs to\nsimulate natural interactions, the game challenges players to impersonate\ncharacters and extract sensitive information from an AI agent, Aegis. A user\nstudy (n=22) revealed that players employed diverse deceptive linguistic\nstrategies, including storytelling and emotional rapport, to manipulate Aegis.\nAfter playing, players reported connecting in-game scenarios with real-world\nprivacy vulnerabilities, such as phishing and impersonation, and expressed\nintentions to strengthen privacy control, such as avoiding oversharing personal\ninformation with AI systems. This work highlights the potential of LLMs to\nsimulate complex relational interactions in serious games, while demonstrating\nhow an adversarial game strategy provides unique insights for designs for\nsocial good, particularly privacy protection.",
      "url": "http://arxiv.org/abs/2505.16954v1",
      "published_time_eastern_timestamp": 1747935285.0
    },
    {
      "title": "A Comprehensive Evaluation of Contemporary ML-Based Solvers for\n  Combinatorial Optimization",
      "summary": "Machine learning (ML) has demonstrated considerable potential in supporting\nmodel design and optimization for combinatorial optimization (CO) problems.\nHowever, much of the progress to date has been evaluated on small-scale,\nsynthetic datasets, raising concerns about the practical effectiveness of\nML-based solvers in real-world, large-scale CO scenarios. Additionally, many\nexisting CO benchmarks lack sufficient training data, limiting their utility\nfor evaluating data-driven approaches. To address these limitations, we\nintroduce FrontierCO, a comprehensive benchmark that covers eight canonical CO\nproblem types and evaluates 16 representative ML-based solvers--including graph\nneural networks and large language model (LLM) agents. FrontierCO features\nchallenging instances drawn from industrial applications and frontier CO\nresearch, offering both realistic problem difficulty and abundant training\ndata. Our empirical results provide critical insights into the strengths and\nlimitations of current ML methods, helping to guide more robust and practically\nrelevant advances at the intersection of machine learning and combinatorial\noptimization. Our data is available at\nhttps://huggingface.co/datasets/CO-Bench/FrontierCO.",
      "url": "http://arxiv.org/abs/2505.16952v1",
      "published_time_eastern_timestamp": 1747935278.0
    },
    {
      "title": "AGENTIF: Benchmarking Instruction Following of Large Language Models in\n  Agentic Scenarios",
      "summary": "Large Language Models (LLMs) have demonstrated advanced capabilities in\nreal-world agentic applications. Growing research efforts aim to develop\nLLM-based agents to address practical demands, introducing a new challenge:\nagentic scenarios often involve lengthy instructions with complex constraints,\nsuch as extended system prompts and detailed tool specifications. While\nadherence to such instructions is crucial for agentic applications, whether\nLLMs can reliably follow them remains underexplored. In this paper, we\nintroduce AgentIF, the first benchmark for systematically evaluating LLM\ninstruction following ability in agentic scenarios. AgentIF features three key\ncharacteristics: (1) Realistic, constructed from 50 real-world agentic\napplications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.\n(3) Complex, averaging 11.9 constraints per instruction, covering diverse\nconstraint types, such as tool specifications and condition constraints. To\nconstruct AgentIF, we collect 707 human-annotated instructions across 50\nagentic tasks from industrial application agents and open-source agentic\nsystems. For each instruction, we annotate the associated constraints and\ncorresponding evaluation metrics, including code-based evaluation, LLM-based\nevaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically\nevaluate existing advanced LLMs. We observe that current models generally\nperform poorly, especially in handling complex constraint structures and tool\nspecifications. We further conduct error analysis and analytical experiments on\ninstruction length and meta constraints, providing some findings about the\nfailure modes of existing LLMs. We have released the code and data to\nfacilitate future research.",
      "url": "http://arxiv.org/abs/2505.16944v1",
      "published_time_eastern_timestamp": 1747935070.0
    },
    {
      "title": "NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop\n  System from Hypothesis to Verification",
      "summary": "Artificial Intelligence (AI) is accelerating the transformation of scientific\nresearch paradigms, not only enhancing research efficiency but also driving\ninnovation. We introduce NovelSeek, a unified closed-loop multi-agent framework\nto conduct Autonomous Scientific Research (ASR) across various scientific\nresearch fields, enabling researchers to tackle complicated problems in these\nfields with unprecedented speed and precision. NovelSeek highlights three key\nadvantages: 1) Scalability: NovelSeek has demonstrated its versatility across\n12 scientific research tasks, capable of generating innovative ideas to enhance\nthe performance of baseline code. 2) Interactivity: NovelSeek provides an\ninterface for human expert feedback and multi-agent interaction in automated\nend-to-end processes, allowing for the seamless integration of domain expert\nknowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in\nseveral scientific fields with significantly less time cost compared to human\nefforts. For instance, in reaction yield prediction, it increased from 27.6% to\n35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from\n0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,\nprecision advanced from 78.8% to 81.0% in a mere 30 hours.",
      "url": "http://arxiv.org/abs/2505.16938v1",
      "published_time_eastern_timestamp": 1747934863.0
    },
    {
      "title": "Beyond Needle(s) in the Embodied Haystack: Environment, Architecture,\n  and Training Considerations for Long Context Reasoning",
      "summary": "We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks\nthat advances long-context understanding in embodied AI. $\\infty$-THOR\nprovides: (1) a generation framework for synthesizing scalable, reproducible,\nand unlimited long-horizon trajectories; (2) a novel embodied QA task,\nNeedle(s) in the Embodied Haystack, where multiple scattered clues across\nextended trajectories test agents' long-context reasoning ability; and (3) a\nlong-horizon dataset and benchmark suite featuring complex tasks that span\nhundreds of environment steps, each paired with ground-truth action sequences.\nTo enable this capability, we explore architectural adaptations, including\ninterleaved Goal-State-Action modeling, context extension techniques, and\nContext Parallelism, to equip LLM-based agents for extreme long-context\nreasoning and interaction. Experimental results and analyses highlight the\nchallenges posed by our benchmark and provide insights into training strategies\nand model behaviors under long-horizon conditions. Our work provides a\nfoundation for the next generation of embodied AI systems capable of robust,\nlong-term reasoning and planning.",
      "url": "http://arxiv.org/abs/2505.16928v1",
      "published_time_eastern_timestamp": 1747934438.0
    },
    {
      "title": "Risk-Averse Reinforcement Learning with Itakura-Saito Loss",
      "summary": "Risk-averse reinforcement learning finds application in various high-stakes\nfields. Unlike classical reinforcement learning, which aims to maximize\nexpected returns, risk-averse agents choose policies that minimize risk,\noccasionally sacrificing expected value. These preferences can be framed\nthrough utility theory. We focus on the specific case of the exponential\nutility function, where we can derive the Bellman equations and employ various\nreinforcement learning algorithms with few modifications. However, these\nmethods suffer from numerical instability due to the need for exponent\ncomputation throughout the process. To address this, we introduce a numerically\nstable and mathematically sound loss function based on the Itakura-Saito\ndivergence for learning state-value and action-value functions. We evaluate our\nproposed loss function against established alternatives, both theoretically and\nempirically. In the experimental section, we explore multiple financial\nscenarios, some with known analytical solutions, and show that our loss\nfunction outperforms the alternatives.",
      "url": "http://arxiv.org/abs/2505.16925v1",
      "published_time_eastern_timestamp": 1747934287.0
    },
    {
      "title": "RealEngine: Simulating Autonomous Driving in Realistic Context",
      "summary": "Driving simulation plays a crucial role in developing reliable driving agents\nby providing controlled, evaluative environments. To enable meaningful\nassessments, a high-quality driving simulator must satisfy several key\nrequirements: multi-modal sensing capabilities (e.g., camera and LiDAR) with\nrealistic scene rendering to minimize observational discrepancies; closed-loop\nevaluation to support free-form trajectory behaviors; highly diverse traffic\nscenarios for thorough evaluation; multi-agent cooperation to capture\ninteraction dynamics; and high computational efficiency to ensure affordability\nand scalability. However, existing simulators and benchmarks fail to\ncomprehensively meet these fundamental criteria. To bridge this gap, this paper\nintroduces RealEngine, a novel driving simulation framework that holistically\nintegrates 3D scene reconstruction and novel view synthesis techniques to\nachieve realistic and flexible closed-loop simulation in the driving context.\nBy leveraging real-world multi-modal sensor data, RealEngine reconstructs\nbackground scenes and foreground traffic participants separately, allowing for\nhighly diverse and realistic traffic scenarios through flexible scene\ncomposition. This synergistic fusion of scene reconstruction and view synthesis\nenables photorealistic rendering across multiple sensor modalities, ensuring\nboth perceptual fidelity and geometric accuracy. Building upon this\nenvironment, RealEngine supports three essential driving simulation categories:\nnon-reactive simulation, safety testing, and multi-agent interaction,\ncollectively forming a reliable and comprehensive benchmark for evaluating the\nreal-world performance of driving agents.",
      "url": "http://arxiv.org/abs/2505.16902v1",
      "published_time_eastern_timestamp": 1747933260.0
    },
    {
      "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for\n  Repository-Level Software Engineering Tasks",
      "summary": "Recent advances in Large Language Models (LLMs) have shown promise in\nfunction-level code generation, yet repository-level software engineering tasks\nremain challenging. Current solutions predominantly rely on proprietary LLM\nagents, which introduce unpredictability and limit accessibility, raising\nconcerns about data privacy and model customization. This paper investigates\nwhether open-source LLMs can effectively address repository-level tasks without\nrequiring agent-based approaches. We demonstrate this is possible by enabling\nLLMs to comprehend functions and files within codebases through their semantic\ninformation and structural dependencies. To this end, we introduce Code Graph\nModels (CGMs), which integrate repository code graph structures into the LLM's\nattention mechanism and map node attributes to the LLM's input space using a\nspecialized adapter. When combined with an agentless graph RAG framework, our\napproach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark\nusing the open-source Qwen2.5-72B model. This performance ranks first among\nopen weight models, second among methods with open-source systems, and eighth\noverall, surpassing the previous best open-source model-based method by 12.33%.",
      "url": "http://arxiv.org/abs/2505.16901v1",
      "published_time_eastern_timestamp": 1747933255.0
    },
    {
      "title": "Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships",
      "summary": "Artificial Intelligence (AI) systems have historically been used as tools\nthat execute narrowly defined tasks. Yet recent advances in AI have unlocked\npossibilities for a new class of models that genuinely collaborate with humans\nin complex reasoning, from conceptualizing problems to brainstorming solutions.\nSuch AI thought partners enable novel forms of collaboration and extended\ncognition, yet they also pose major risks-including and beyond risks of typical\nAI tools and agents. In this commentary, we systematically identify risks of AI\nthought partners through a novel framework that identifies risks at multiple\nlevels of analysis, including Real-time, Individual, and Societal risks arising\nfrom collaborative cognition (RISc). We leverage this framework to propose\nconcrete metrics for risk evaluation, and finally suggest specific mitigation\nstrategies for developers and policymakers. As AI thought partners continue to\nproliferate, these strategies can help prevent major harms and ensure that\nhumans actively benefit from productive thought partnerships.",
      "url": "http://arxiv.org/abs/2505.16899v1",
      "published_time_eastern_timestamp": 1747933128.0
    },
    {
      "title": "Hydrogen peroxide electrogeneration from O2 electroreduction: a review\n  focusing on carbon electrocatalysts and environmental applications",
      "summary": "Hydrogen peroxide (H2O2) stands as one of the foremost utilized oxidizing\nagents in modern times. The established method for its production involves the\nintricate and costly anthraquinone process. However, a promising alternative\npathway is the electrochemical hydrogen peroxide production, accomplished\nthrough the oxygen reduction reaction via a 2-electron pathway. This method not\nonly simplifies the production process but also upholds environmental\nsustainability, especially when compared to the conventional anthraquinone\nmethod. In this review paper, recent works from the literature focusing on the\n2-electron oxygen reduction reaction promoted by carbon electrocatalysts are\nsummarized. The practical applications of these materials in the treatment of\neffluents contaminated with different pollutants (drugs, dyes, pesticides, and\nherbicides) are presented. Water treatment aiming to address these issues can\nbe achieved through advanced oxidation electrochemical processes such as\nelectro-Fenton, solar-electro-Fenton, and photo-electro-Fenton. These processes\nare discussed in detail in this work and the possible radicals that degrade the\npollutants in each case are highlighted. The review broadens its scope to\nencompass contemporary computational simulations focused on the 2-electron\noxygen reduction reaction, employing different models to describe carbon-based\nelectrocatalysts. Finally, perspectives and future challenges in the area of\ncarbon-based electrocatalysts for H2O2 electrogeneration are discussed. This\nreview paper presents a forward-oriented viewpoint of present innovations and\npragmatic implementations, delineating forthcoming challenges and prospects of\nthis ever-evolving field.",
      "url": "http://arxiv.org/abs/2505.16887v1",
      "published_time_eastern_timestamp": 1747932391.0
    },
    {
      "title": "Strategically Linked Decisions in Long-Term Planning and Reinforcement\n  Learning",
      "summary": "Long-term planning, as in reinforcement learning (RL), involves finding\nstrategies: actions that collectively work toward a goal rather than\nindividually optimizing their immediate outcomes. As part of a strategy, some\nactions are taken at the expense of short-term benefit to enable future actions\nwith even greater returns. These actions are only advantageous if followed up\nby the actions they facilitate, consequently, they would not have been taken if\nthose follow-ups were not available. In this paper, we quantify such\ndependencies between planned actions with strategic link scores: the drop in\nthe likelihood of one decision under the constraint that a follow-up decision\nis no longer available. We demonstrate the utility of strategic link scores\nthrough three practical applications: (i) explaining black-box RL agents by\nidentifying strategically linked pairs among decisions they make, (ii)\nimproving the worst-case performance of decision support systems by\ndistinguishing whether recommended actions can be adopted as standalone\nimprovements or whether they are strategically linked hence requiring a\ncommitment to a broader strategy to be effective, and (iii) characterizing the\nplanning processes of non-RL agents purely through interventions aimed at\nmeasuring strategic link scores - as an example, we consider a realistic\ntraffic simulator and analyze through road closures the effective planning\nhorizon of the emergent routing behavior of many drivers.",
      "url": "http://arxiv.org/abs/2505.16833v1",
      "published_time_eastern_timestamp": 1747929857.0
    },
    {
      "title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework\n  for Pedagogical Visualization",
      "summary": "While foundation models (FMs), such as diffusion models and large\nvision-language models (LVLMs), have been widely applied in educational\ncontexts, their ability to generate pedagogically effective visual explanations\nremains limited. Most existing approaches focus primarily on textual reasoning,\noverlooking the critical role of structured and interpretable visualizations in\nsupporting conceptual understanding. To better assess the visual reasoning\ncapabilities of FMs in educational settings, we introduce EduVisBench, a\nmulti-domain, multi-level benchmark. EduVisBench features diverse STEM problem\nsets requiring visually grounded solutions, along with a fine-grained\nevaluation rubric informed by pedagogical theory. Our empirical analysis\nreveals that existing models frequently struggle with the inherent challenge of\ndecomposing complex reasoning and translating it into visual representations\naligned with human cognitive processes. To address these limitations, we\npropose EduVisAgent, a multi-agent collaborative framework that coordinates\nspecialized agents for instructional planning, reasoning decomposition,\nmetacognitive prompting, and visualization design. Experimental results show\nthat EduVisAgent substantially outperforms all baselines, achieving a 40.2%\nimprovement and delivering more educationally aligned visualizations.\nEduVisBench and EduVisAgent are available at\nhttps://github.com/aiming-lab/EduVisBench and\nhttps://github.com/aiming-lab/EduVisAgent.",
      "url": "http://arxiv.org/abs/2505.16832v1",
      "published_time_eastern_timestamp": 1747929738.0
    }
  ]
}
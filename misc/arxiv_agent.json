{
  "last_updated": "2025-08-06T14:19:10.659513-04:00",
  "papers": [
    {
      "title": "Agent Lightning: Train ANY AI Agents with Reinforcement Learning",
      "summary": "We present Agent Lightning, a flexible and extensible framework that enables\nReinforcement Learning (RL)-based training of Large Language Models (LLMs) for\nany AI agent. Unlike existing methods that tightly couple RL training with\nagent or rely on sequence concatenation with masking, Agent Lightning achieves\ncomplete decoupling between agent execution and training, allowing seamless\nintegration with existing agents developed via diverse ways (e.g., using\nframeworks like LangChain, OpenAI Agents SDK, AutoGen, and building from\nscratch) with almost ZERO code modifications. By formulating agent execution as\nMarkov decision process, we define an unified data interface and propose a\nhierarchical RL algorithm, LightningRL, which contains a credit assignment\nmodule, allowing us to decompose trajectories generated by ANY agents into\ntraining transition. This enables RL to handle complex interaction logic, such\nas multi-agent scenarios and dynamic workflows. For the system design, we\nintroduce a Training-Agent Disaggregation architecture, and brings agent\nobservability frameworks into agent runtime, providing a standardized agent\nfinetuning interface. Experiments across text-to-SQL, retrieval-augmented\ngeneration, and math tool-use tasks demonstrate stable, continuous\nimprovements, showcasing the framework's potential for real-world agent\ntraining and deployment.",
      "url": "http://arxiv.org/abs/2508.03680v1",
      "published_time_eastern_timestamp": 1754416213.0
    },
    {
      "title": "A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design",
      "summary": "Generative models, particularly Large Language Models (LLMs), produce fluent\noutputs yet lack verifiable guarantees. We adapt Design by Contract (DbC) and\ntype-theoretic principles to introduce a contract layer that mediates every LLM\ncall. Contracts stipulate semantic and type requirements on inputs and outputs,\ncoupled with probabilistic remediation to steer generation toward compliance.\nThe layer exposes the dual view of LLMs as semantic parsers and probabilistic\nblack-box components. Contract satisfaction is probabilistic and semantic\nvalidation is operationally defined through programmer-specified conditions on\nwell-typed data structures. More broadly, this work postulates that any two\nagents satisfying the same contracts are \\emph{functionally equivalent} with\nrespect to those contracts.",
      "url": "http://arxiv.org/abs/2508.03665v1",
      "published_time_eastern_timestamp": 1754414690.0
    },
    {
      "title": "Efficient Morphology-Aware Policy Transfer to New Embodiments",
      "summary": "Morphology-aware policy learning is a means of enhancing policy sample\nefficiency by aggregating data from multiple agents. These types of policies\nhave previously been shown to help generalize over dynamic, kinematic, and limb\nconfiguration variations between agent morphologies. Unfortunately, these\npolicies still have sub-optimal zero-shot performance compared to end-to-end\nfinetuning on morphologies at deployment. This limitation has ramifications in\npractical applications such as robotics because further data collection to\nperform end-to-end finetuning can be computationally expensive. In this work,\nwe investigate combining morphology-aware pretraining with parameter efficient\nfinetuning (PEFT) techniques to help reduce the learnable parameters necessary\nto specialize a morphology-aware policy to a target embodiment. We compare\ndirectly tuning sub-sets of model weights, input learnable adapters, and prefix\ntuning techniques for online finetuning. Our analysis reveals that PEFT\ntechniques in conjunction with policy pre-training generally help reduce the\nnumber of samples to necessary to improve a policy compared to training models\nend-to-end from scratch. We further find that tuning as few as less than 1% of\ntotal parameters will improve policy performance compared the zero-shot\nperformance of the base pretrained a policy.",
      "url": "http://arxiv.org/abs/2508.03660v1",
      "published_time_eastern_timestamp": 1754414135.0
    },
    {
      "title": "Probing the Gaps in ChatGPT Live Video Chat for Real-World Assistance\n  for People who are Blind or Visually Impaired",
      "summary": "Recent advancements in large multimodal models have provided blind or\nvisually impaired (BVI) individuals with new capabilities to interpret and\nengage with the real world through interactive systems that utilize live video\nfeeds. However, the potential benefits and challenges of such capabilities to\nsupport diverse real-world assistive tasks remain unclear. In this paper, we\npresent findings from an exploratory study with eight BVI participants.\nParticipants used ChatGPT's Advanced Voice with Video, a state-of-the-art live\nvideo AI released in late 2024, in various real-world scenarios, from locating\nobjects to recognizing visual landmarks, across unfamiliar indoor and outdoor\nenvironments. Our findings indicate that current live video AI effectively\nprovides guidance and answers for static visual scenes but falls short in\ndelivering essential live descriptions required in dynamic situations. Despite\ninaccuracies in spatial and distance information, participants leveraged the\nprovided visual information to supplement their mobility strategies. Although\nthe system was perceived as human-like due to high-quality voice interactions,\nassumptions about users' visual abilities, hallucinations, generic responses,\nand a tendency towards sycophancy led to confusion, distrust, and potential\nrisks for BVI users. Based on the results, we discuss implications for\nassistive video AI agents, including incorporating additional sensing\ncapabilities for real-world use, determining appropriate intervention timing\nbeyond turn-taking interactions, and addressing ecological and safety concerns.",
      "url": "http://arxiv.org/abs/2508.03651v1",
      "published_time_eastern_timestamp": 1754413142.0
    },
    {
      "title": "Improving Q-Learning for Real-World Control: A Case Study in Series\n  Hybrid Agricultural Tractors",
      "summary": "The variable and unpredictable load demands in hybrid agricultural tractors\nmake it difficult to design optimal rule-based energy management strategies,\nmotivating the use of adaptive, learning-based control. However, existing\napproaches often rely on basic fuel-based rewards and do not leverage expert\ndemonstrations to accelerate training. In this paper, first, the performance of\nQ-value-based reinforcement learning algorithms is evaluated for powertrain\ncontrol in a hybrid agricultural tractor. Three algorithms, Double Q-Learning\n(DQL), Deep Q-Networks (DQN), and Double DQN (DDQN), are compared in terms of\nconvergence speed and policy optimality. Second, a piecewise domain-specific\nreward-shaping strategy is introduced to improve learning efficiency and steer\nagent behavior toward engine fuel-efficient operating regions. Third, the\ndesign of the experience replay buffer is examined, with a focus on the effects\nof seeding the buffer with expert demonstrations and analyzing how different\ntypes of expert policies influence convergence dynamics and final performance.\nExperimental results demonstrate that (1) DDQN achieves 70\\% faster convergence\nthan DQN in this application domain, (2) the proposed reward shaping method\neffectively biases the learned policy toward fuel-efficient outcomes, and (3)\ninitializing the replay buffer with structured expert data leads to a 33\\%\nimprovement in convergence speed.",
      "url": "http://arxiv.org/abs/2508.03647v1",
      "published_time_eastern_timestamp": 1754413036.0
    },
    {
      "title": "An Evolutionary Analysis of Narrative Selection",
      "summary": "We study the performance of different methods for processing information,\nincorporating narrative selection within an evolutionary model. All agents\nupdate their beliefs according to Bayes' Rule, but some strategically choose\nthe narrative they use in updating according to heterogeneous criteria. We\nsimulate the endogenous composition of the population, considering different\nlaws of motion for the underlying state of the world. We find that conformists\n-- that is, agents that choose the narrative to conform to the average belief\nin the population -- have an evolutionary advantage over other agents across\nall specifications. The survival chances of the remaining types depend on the\nuncertainty regarding the state of the world. Agents who tend to develop mild\nbeliefs perform better when the uncertainty is high, whereas agents who tend to\ndevelop extreme beliefs perform better when the uncertainty is low.",
      "url": "http://arxiv.org/abs/2508.03540v1",
      "published_time_eastern_timestamp": 1754406597.0
    },
    {
      "title": "Training Long-Context, Multi-Turn Software Engineering Agents with\n  Reinforcement Learning",
      "summary": "Research on applications of Reinforcement Learning (RL) to Large Language\nModels (LLMs) has mostly been focused on single-turn problems, such as\nmathematical reasoning or single-shot code generation. While these problems can\nbe viewed as token-level multi-turn MDPs, this view corresponds to a degenerate\ncase of multi-turn interaction where the environment provides no feedback. This\ncontrasts with many real-world domains, such as software engineering (SWE),\nwhich require rich multi-turn interactions with a stateful environment that\nresponds to each action with a non-trivial observation.\n  To bridge this gap, we demonstrate the successful application of RL to this\ngeneral regime. Using a modified Decoupled Advantage Policy Optimization (DAPO)\nalgorithm, we train an agent based on Qwen2.5-72B-Instruct to solve real-world\nsoftware engineering tasks. Our approach increases the agent's success rate on\nthe SWE-bench Verified benchmark from a 20% rejection fine-tuned baseline to\n39%, without relying on any teacher models. On SWE-rebench, our agent matches\nor outperforms leading open-weight models such as DeepSeek-V3-0324 and\nQwen3-235B-A22B using an identical scaffolding, offering a viable path toward\nbuilding more capable autonomous agents for complex real-world problems based\non open models.",
      "url": "http://arxiv.org/abs/2508.03501v1",
      "published_time_eastern_timestamp": 1754404247.0
    },
    {
      "title": "Reconstructing the Probability Measure of a Curie-Weiss Model Observing\n  the Realisations of a Subset of Spins",
      "summary": "We study the problem of reconstructing the probability measure of the\nCurie-Weiss model from a sample of the voting behaviour of a subset of the\npopulation. While originally used to study phase transitions in statistical\nmechanics, the Curie-Weiss or mean-field model has been applied to study\nphenomena, where many agents interact with each other. It is useful to measure\nthe degree of social cohesion in social groups, which manifests in the way the\nmembers of the group influence each others' decisions. In practice,\nstatisticians often only have access to survey data from a representative\nsubset of a population. As such, it is useful to provide methods to estimate\nsocial cohesion from such data. The estimators we study have some positive\nproperties, such as consistency, asymptotic normality, and large deviation\nprinciples. The main advantages are that they require only a sample of votes\nbelonging to a (possibly very small) subset of the population and have a low\ncomputational cost. Due to the wide application of models such as Curie-Weiss,\nthese estimators are potentially useful in disciplines such as political\nscience, sociology, automated voting, and preference aggregation.",
      "url": "http://arxiv.org/abs/2508.03452v1",
      "published_time_eastern_timestamp": 1754402033.0
    },
    {
      "title": "An Auditable Agent Platform For Automated Molecular Optimisation",
      "summary": "Drug discovery frequently loses momentum when data, expertise, and tools are\nscattered, slowing design cycles. To shorten this loop we built a hierarchical,\ntool using agent framework that automates molecular optimisation. A Principal\nResearcher defines each objective, a Database agent retrieves target\ninformation, an AI Expert generates de novo scaffolds with a sequence to\nmolecule deep learning model, a Medicinal Chemist edits them while invoking a\ndocking tool, a Ranking agent scores the candidates, and a Scientific Critic\npolices the logic. Each tool call is summarised and stored causing the full\nreasoning path to remain inspectable. The agents communicate through concise\nprovenance records that capture molecular lineage, to build auditable, molecule\ncentered reasoning trajectories and reuse successful transformations via in\ncontext learning. Three cycle research loops were run against AKT1 protein\nusing five large language models. After ranking the models by mean docking\nscore, we ran 20 independent scale ups on the two top performers. We then\ncompared the leading LLMs' binding affinity results across three\nconfigurations, LLM only, single agent, and multi agent. Our results reveal an\narchitectural trade off, the multi agent setting excelled at focused binding\noptimization, improving average predicted binding affinity by 31%. In contrast,\nsingle agent runs generated molecules with superior drug like properties at the\ncost of less potent binding scores. Unguided LLM runs finished fastest, yet\ntheir lack of transparent tool signals left the validity of their reasoning\npaths unverified. These results show that test time scaling, focused feedback\nloops and provenance convert general purpose LLMs into auditable systems for\nmolecular design, and suggest that extending the toolset to ADMET and\nselectivity predictors could push research workflows further along the\ndiscovery pipeline.",
      "url": "http://arxiv.org/abs/2508.03444v1",
      "published_time_eastern_timestamp": 1754401292.0
    },
    {
      "title": "Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction\n  using Enhanced Triple Extraction",
      "summary": "The rapid expansion of publicly-available medical data presents a challenge\nfor clinicians and researchers alike, increasing the gap between the volume of\nscientific literature and its applications. The steady growth of studies and\nfindings overwhelms medical professionals at large, hindering their ability to\nsystematically review and understand the latest knowledge. This paper presents\nan approach to information extraction and automatic knowledge graph (KG)\ngeneration to identify and connect biomedical knowledge. Through a pipeline of\nlarge language model (LLM) agents, the system decomposes 44 PubMed abstracts\ninto semantically meaningful proposition sentences and extracts KG triples from\nthese sentences. The triples are enhanced using a combination of open domain\nand ontology-based information extraction methodologies to incorporate\nontological categories. On top of this, a context variable is included during\nextraction to allow the triple to stand on its own - thereby becoming\n`quadruples'. The extraction accuracy of the LLM is validated by comparing\nnatural language sentences generated from the enhanced triples to the original\npropositions, achieving an average cosine similarity of 0.874. The similarity\nfor generated sentences of enhanced triples were compared with generated\nsentences of ordinary triples showing an increase as a result of the context\nvariable. Furthermore, this research explores the ability for LLMs to infer new\nrelationships and connect clusters in the knowledge base of the knowledge\ngraph. This approach leads the way to provide medical practitioners with a\ncentralised, updated in real-time, and sustainable knowledge source, and may be\nthe foundation of similar gains in a wide variety of fields.",
      "url": "http://arxiv.org/abs/2508.03438v1",
      "published_time_eastern_timestamp": 1754400641.0
    },
    {
      "title": "Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large\n  Language Models",
      "summary": "In real-world routing problems, users often propose conflicting or\nunreasonable requirements, which result in infeasible optimization models due\nto overly restrictive or contradictory constraints, leading to an empty\nfeasible solution set. Existing Large Language Model (LLM)-based methods\nattempt to diagnose infeasible models, but modifying such models often involves\nmultiple potential adjustments that these methods do not consider. To fill this\ngap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which\ncombines LLM agents and multi-objective optimization within an automatic\nrouting solver, to provide a set of representative actionable suggestions.\nSpecifically, MOID employs multi-objective optimization to consider both path\ncost and constraint violation, generating a set of trade-off solutions, each\nencompassing varying degrees of model adjustments. To extract practical\ninsights from these solutions, MOID utilizes LLM agents to generate a solution\nanalysis function for the infeasible model. This function analyzes these\ndistinct solutions to diagnose the original infeasible model, providing users\nwith diverse diagnostic insights and suggestions. Finally, we compare MOID with\nseveral LLM-based methods on 50 types of infeasible routing problems. The\nresults indicate that MOID automatically generates multiple diagnostic\nsuggestions in a single run, providing more practical insights for restoring\nmodel feasibility and decision-making compared to existing methods.",
      "url": "http://arxiv.org/abs/2508.03406v1",
      "published_time_eastern_timestamp": 1754398400.0
    },
    {
      "title": "Visual Document Understanding and Question Answering: A Multi-Agent\n  Collaboration Framework with Test-Time Scaling",
      "summary": "Existing vision-language models (VLMs), whether generalists or specialists,\nremain constrained by their parameter scale, lack robust self-correction\ncapabilities, and underperform in tasks involving long visual contexts and\ncomplex reasoning, resulting in suboptimal performance on document-based tasks.\nTo address this, we propose MACT, a Multi-Agent Collaboration framework with\nTest-Time scaling, tailored for visual document understanding and visual\nquestion answering (VQA). It comprises four distinct small-scale agents, i.e.,\nplanning, execution, judgment, and answer agents, with clearly defined roles\nand effective collaboration. Notably, the judgment agent exclusively verifies\ncorrectness and redirects to prior agents for revisions, outperforming\nconventional correction strategies. To further expand the capability boundaries\nof the framework, we propose mixed reward modeling that balances agent-specific\nabilities and global collaboration, as well as agent-wise hybrid test-time\nscaling, which customizes different scaling strategies for each agent based on\ntheir functions. Evaluated on benchmarks spanning both document-based and\nnon-document-based settings, our MACT shows superior performance with a smaller\nparameter scale without sacrificing the ability of general and mathematical\ntasks. Especially, it stands out in benchmarks involving long visual contexts\nand complicated reasoning. The three variants of MACT consistently hold the top\nthree positions in average scores, leading in 13 of the 15 benchmarks. Code\nwill be available at: https://github.com/YU-deep/MACT.git.",
      "url": "http://arxiv.org/abs/2508.03404v1",
      "published_time_eastern_timestamp": 1754398329.0
    },
    {
      "title": "Agentic AI in 6G Software Businesses: A Layered Maturity Model",
      "summary": "The emergence of agentic AI systems in 6G software businesses presents both\nstrategic opportunities and significant challenges. While such systems promise\nincreased autonomy, scalability, and intelligent decision-making across\ndistributed environments, their adoption raises concerns regarding technical\nimmaturity, integration complexity, organizational readiness, and\nperformance-cost trade-offs. In this study, we conducted a preliminary thematic\nmapping to identify factors influencing the adoption of agentic software within\nthe context of 6G. Drawing on a multivocal literature review and targeted\nscanning, we identified 29 motivators and 27 demotivators, which were further\ncategorized into five high-level themes in each group. This thematic mapping\noffers a structured overview of the enabling and inhibiting forces shaping\norganizational readiness for agentic transformation. Positioned as a\nfeasibility assessment, the study represents an early phase of a broader\nresearch initiative aimed at developing and validating a layered maturity model\ngrounded in CMMI model with the software architectural three dimensions\npossibly Data, Business Logic, and Presentation. Ultimately, this work seeks to\nprovide a practical framework to help software-driven organizations assess,\nstructure, and advance their agent-first capabilities in alignment with the\ndemands of 6G.",
      "url": "http://arxiv.org/abs/2508.03393v1",
      "published_time_eastern_timestamp": 1754397766.0
    },
    {
      "title": "Can We Fix Social Media? Testing Prosocial Interventions using\n  Generative Social Simulation",
      "summary": "Social media platforms have been widely linked to societal harms, including\nrising polarization and the erosion of constructive debate. Can these problems\nbe mitigated through prosocial interventions? We address this question using a\nnovel method - generative social simulation - that embeds Large Language Models\nwithin Agent-Based Models to create socially rich synthetic platforms. We\ncreate a minimal platform where agents can post, repost, and follow others. We\nfind that the resulting following-networks reproduce three well-documented\ndysfunctions: (1) partisan echo chambers; (2) concentrated influence among a\nsmall elite; and (3) the amplification of polarized voices - creating a 'social\nmedia prism' that distorts political discourse. We test six proposed\ninterventions, from chronological feeds to bridging algorithms, finding only\nmodest improvements - and in some cases, worsened outcomes. These results\nsuggest that core dysfunctions may be rooted in the feedback between reactive\nengagement and network growth, raising the possibility that meaningful reform\nwill require rethinking the foundational dynamics of platform architecture.",
      "url": "http://arxiv.org/abs/2508.03385v1",
      "published_time_eastern_timestamp": 1754397112.0
    },
    {
      "title": "A Closed-Loop Multi-Agent Framework for Aerodynamics-Aware Automotive\n  Styling Design",
      "summary": "The core challenge in automotive exterior design is balancing subjective\naesthetics with objective aerodynamic performance while dramatically\naccelerating the development cycle. To address this, we propose a novel,\nLLM-driven multi-agent framework that automates the end-to-end workflow from\nambiguous requirements to 3D concept model performance validation. The workflow\nis structured in two stages: conceptual generation and performance validation.\nIn the first stage, agents collaborate to interpret fuzzy design requirements,\ngenerate concept sketches, and produce photorealistic renderings using\ndiffusion models. In the second stage, the renderings are converted to 3D point\nclouds, where a Drag Prediction Agent, built upon a lightweight surrogate\nmodel, provides near-instantaneous predictions of the drag coefficient and\npressure fields, replacing time-consuming CFD simulations. The primary\ncontribution of this work is the seamless integration of creative generation\nwith a rapid engineering validation loop within a unified, automated system,\nwhich provides a new paradigm for efficiently balancing creative exploration\nwith engineering constraints in the earliest stages of design.",
      "url": "http://arxiv.org/abs/2508.03370v1",
      "published_time_eastern_timestamp": 1754396473.0
    },
    {
      "title": "Board Game Arena: A Framework and Benchmark for Assessing Large Language\n  Models via Strategic Play",
      "summary": "The Board Game Arena library provides a framework for evaluating the decision\nmaking abilities of large language models (LLMs) through strategic board games\nimplemented in Google OpenSpiel library. The framework enables systematic\ncomparisons between LLM based agents and other agents (random, human,\nreinforcement learning agents, etc.) in various game scenarios by wrapping\nmultiple board and matrix games and supporting different agent types. It\nintegrates API access to models via LiteLLM, local model deployment via vLLM,\nand offers distributed execution through Ray. Additionally it provides\nextensive analysis tools for the LLM reasoning traces. This paper summarizes\nthe structure, key characteristics, and motivation of the repository,\nhighlighting how it contributes to the empirical evaluation of the reasoning of\nLLM and game-theoretic behavior",
      "url": "http://arxiv.org/abs/2508.03368v1",
      "published_time_eastern_timestamp": 1754396159.0
    },
    {
      "title": "Remini: Leveraging Chatbot-Mediated Mutual Reminiscence for Promoting\n  Positive Affect and Feeling of Connectedness among Loved Ones",
      "summary": "Mutual reminiscence, defined as revisiting shared positive memories through\nreciprocal self-disclosure, strengthens emotional bonds, enhances well-being,\nand deepens intimacy. However, most technology-mediated reminiscence tools\nemphasize individual reflection or one-way storytelling, which overlooks the\ndynamic, interactive dialogue essential for meaningful mutual reminiscence. To\naddress this limitation, we introduce Remini, a chatbot designed to support\nreciprocal self-disclosure between close partners such as couples, friends, or\nfamily members. Grounded in the Social Functions of Autobiographical Memory\n(SFAM) framework, Remini uses conversational AI to guide emotionally rich\nexchanges through five narrative phases: rapport building, memory narration,\nelaboration, reflection, and summary. In a mixed-method, both between- and\nwithin- subjects study (N = 48, 24 dyads), we compare Remini to a baseline\nchatbot that offers minimal memory-trigger prompts. Our findings show that\nstructured guidance from Remini significantly improves positive affect, feeling\nof connection, and engagement. It also fosters more detailed narrative\nco-construction and greater reciprocal self-disclosure. Participant feedback\nhighlights the practical value, perceived benefits, and design considerations\nof chatbot-mediated reminiscence. We contribute empirically grounded design\nimplications for conversational agents that strengthen human connection through\nmutual reminiscence.",
      "url": "http://arxiv.org/abs/2508.03355v1",
      "published_time_eastern_timestamp": 1754395240.0
    },
    {
      "title": "Adaptive AI Agent Placement and Migration in Edge Intelligence Systems",
      "summary": "The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents\ncapable of real-time task handling. However, migrating data-intensive,\nmulti-modal edge workloads to cloud data centers, traditionally used for agent\ndeployment, introduces significant latency. Deploying AI agents at the edge\nimproves efficiency and reduces latency. However, edge environments present\nchallenges due to limited and heterogeneous resources. Maintaining QoS for\nmobile users necessitates agent migration, which is complicated by the\ncomplexity of AI agents coordinating LLMs, task planning, memory, and external\ntools. This paper presents the first systematic deployment and management\nsolution for LLM-based AI agents in dynamic edge environments. We propose a\nnovel adaptive framework for AI agent placement and migration in edge\nintelligence systems. Our approach models resource constraints and\nlatency/cost, leveraging ant colony algorithms and LLM-based optimization for\nefficient decision-making. It autonomously places agents to optimize resource\nutilization and QoS and enables lightweight agent migration by transferring\nonly essential state. Implemented on a distributed system using AgentScope and\nvalidated across globally distributed edge servers, our solution significantly\nreduces deployment latency and migration costs.",
      "url": "http://arxiv.org/abs/2508.03345v1",
      "published_time_eastern_timestamp": 1754394466.0
    },
    {
      "title": "Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science",
      "summary": "Large Language Models (LLMs) demonstrate remarkable capabilities, yet their\ninability to maintain persistent memory in long contexts limits their\neffectiveness as autonomous agents in long-term interactions. While existing\nmemory systems have made progress, their reliance on arbitrary granularity for\ndefining the basic memory unit and passive, rule-based mechanisms for knowledge\nextraction limits their capacity for genuine learning and evolution. To address\nthese foundational limitations, we present Nemori, a novel self-organizing\nmemory architecture inspired by human cognitive principles. Nemori's core\ninnovation is twofold: First, its Two-Step Alignment Principle, inspired by\nEvent Segmentation Theory, provides a principled, top-down method for\nautonomously organizing the raw conversational stream into semantically\ncoherent episodes, solving the critical issue of memory granularity. Second,\nits Predict-Calibrate Principle, inspired by the Free-energy Principle, enables\nthe agent to proactively learn from prediction gaps, moving beyond pre-defined\nheuristics to achieve adaptive knowledge evolution. This offers a viable path\ntoward handling the long-term, dynamic workflows of autonomous agents.\nExtensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that\nNemori significantly outperforms prior state-of-the-art systems, with its\nadvantage being particularly pronounced in longer contexts.",
      "url": "http://arxiv.org/abs/2508.03341v1",
      "published_time_eastern_timestamp": 1754394073.0
    },
    {
      "title": "CTTS: Collective Test-Time Scaling",
      "summary": "Test-time scaling (TTS) has emerged as a promising research field for\nenhancing the effectiveness of large language models (LLMs) without extra\ntraining. However, most existing approaches, e.g., Best-of-N and\nSelf-Consistency rely on a single agent interacting with a reward model\n(SA-SR), constrained by limited capabilities of a single test-time scaling\n(STTS) paradigm. On the other hand, recent works demonstrate that\ncollective-agent methods can break through the upper bound of single-agent\nsystems by orchestrating diverse models. Thus, in this paper, we take a first\nstep towards exploring Collective Test-Time Scaling (CTTS). Consider the\ndifferent interaction types of single and multiple models, we design three\nprimary paradigms to investigate the optimal paradigm of CTTS: (1) single agent\nto multiple reward models (SA-MR); (2) multiple agents to single reward model\n(MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive\nexperiments demonstrate that MA-MR consistently achieves the best performance.\nBased on this, we propose a novel framework named CTTS-MM that effectively\nleverages both multi-agent and multi-reward-model collaboration for enhanced\ninference. Specifically, for multi-agent collaboration, we propose an Agent\nCollaboration Search (ACS), which searches for the most effective combination\nof LLM agents from a large candidate pool; for multi-reward-model\ncollaboration, we propose Mixture of Reword Models (MoR), which consists of a\ncurated question pool and a Prior Reward model Ensemble Selection (PRES) to\nselect the optimal combinations of reward models via Pair-wise Reward Ranking\n(PRR) metric. Experiments across seven mainstream benchmarks demonstrate that\nthe proposed CTTS-MM consistently obtains superior performance. Code will be\nreleased at https://github.com/magent4aci/CTTS-MM.",
      "url": "http://arxiv.org/abs/2508.03333v1",
      "published_time_eastern_timestamp": 1754392748.0
    }
  ]
}
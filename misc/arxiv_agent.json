{
  "last_updated": "2025-08-13T05:15:05.852773-04:00",
  "papers": [
    {
      "title": "BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented\n  Programmatic Agent Pair",
      "summary": "Effective information seeking in the vast and ever-growing digital landscape\nrequires balancing expansive search with strategic reasoning. Current large\nlanguage model (LLM)-based agents struggle to achieve this balance due to\nlimitations in search breadth and reasoning depth, where slow, serial querying\nrestricts coverage of relevant sources and noisy raw inputs disrupt the\ncontinuity of multi-step reasoning. To address these challenges, we propose\nBrowseMaster, a scalable framework built around a programmatically augmented\nplanner-executor agent pair. The planner formulates and adapts search\nstrategies based on task constraints, while the executor conducts efficient,\ntargeted retrieval to supply the planner with concise, relevant evidence. This\ndivision of labor preserves coherent, long-horizon reasoning while sustaining\nbroad and systematic exploration, overcoming the trade-off that limits existing\nagents. Extensive experiments on challenging English and Chinese benchmarks\nshow that BrowseMaster consistently outperforms open-source and proprietary\nbaselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh,\nwhich demonstrates its strong capability in complex, reasoning-heavy\ninformation-seeking tasks at scale.",
      "url": "http://arxiv.org/abs/2508.09129v1",
      "published_time_eastern_timestamp": 1755021385.0
    },
    {
      "title": "Complex Logical Instruction Generation",
      "summary": "Instruction following has catalyzed the recent era of Large Language Models\n(LLMs) and is the foundational skill underpinning more advanced capabilities\nsuch as reasoning and agentic behaviors. As tasks grow more challenging, the\nlogic structures embedded in natural language instructions becomes increasingly\nintricate. However, how well LLMs perform on such logic-rich instructions\nremains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a\nscalable, automated framework for generating verifiable instructions from code\nfunctions, which can naturally express rich logic such as conditionals,\nnesting, recursion, and function calls. We further curate a collection of\ncomplex code functions and use LogicIFGen to construct LogicIFEval, a benchmark\ncomprising 426 verifiable logic-rich instructions. Our experiments demonstrate\nthat current state-of-the-art LLMs still struggle to correctly follow the\ninstructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the\ninstructions, revealing significant deficiencies in the instruction-following\nability. Code and Benchmark: https://github.com/mianzhang/LogicIF",
      "url": "http://arxiv.org/abs/2508.09125v1",
      "published_time_eastern_timestamp": 1755021267.0
    },
    {
      "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office\n  Application Workflows",
      "summary": "Autonomous agents powered by large language models (LLMs) are increasingly\ndeployed in real-world applications requiring complex, long-horizon workflows.\nHowever, existing benchmarks predominantly focus on atomic tasks that are\nself-contained and independent, failing to capture the long-term contextual\ndependencies and multi-interaction coordination required in realistic\nscenarios. To address this gap, we introduce OdysseyBench, a comprehensive\nbenchmark for evaluating LLM agents on long-horizon workflows across diverse\noffice applications including Word, Excel, PDF, Email, and Calendar. Our\nbenchmark comprises two complementary splits: OdysseyBench+ with 300 tasks\nderived from real-world use cases, and OdysseyBench-Neo with 302 newly\nsynthesized complex tasks. Each task requires agent to identify essential\ninformation from long-horizon interaction histories and perform multi-step\nreasoning across various applications. To enable scalable benchmark creation,\nwe propose HomerAgents, a multi-agent framework that automates the generation\nof long-horizon workflow benchmarks through systematic environment exploration,\ntask generation, and dialogue synthesis. Our extensive evaluation demonstrates\nthat OdysseyBench effectively challenges state-of-the-art LLM agents, providing\nmore accurate assessment of their capabilities in complex, real-world contexts\ncompared to existing atomic task benchmarks. We believe that OdysseyBench will\nserve as a valuable resource for advancing the development and evaluation of\nLLM agents in real-world productivity scenarios. In addition, we release\nOdysseyBench and HomerAgents to foster research along this line.",
      "url": "http://arxiv.org/abs/2508.09124v1",
      "published_time_eastern_timestamp": 1755021183.0
    },
    {
      "title": "OpenCUA: Open Foundations for Computer-Use Agents",
      "summary": "Vision-language models have demonstrated impressive capabilities as\ncomputer-use agents (CUAs) capable of automating diverse computer tasks. As\ntheir commercial potential grows, critical details of the most capable CUA\nsystems remain closed. As these agents will increasingly mediate digital\ninteractions and execute consequential decisions on our behalf, the research\ncommunity needs access to open CUA frameworks to study their capabilities,\nlimitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive\nopen-source framework for scaling CUA data and foundation models. Our framework\nconsists of: (1) an annotation infrastructure that seamlessly captures human\ncomputer-use demonstrations; (2) AgentNet, the first large-scale computer-use\ntask dataset spanning 3 operating systems and 200+ applications and websites;\n(3) a scalable pipeline that transforms demonstrations into state-action pairs\nwith reflective long Chain-of-Thought reasoning that sustain robust performance\ngains as data scales. Our end-to-end agent models demonstrate strong\nperformance across CUA benchmarks. In particular, OpenCUA-32B achieves an\naverage success rate of 34.8% on OSWorld-Verified, establishing a new\nstate-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA\n(GPT-4o). Further analysis confirms that our approach generalizes well across\ndomains and benefits significantly from increased test-time computation. We\nrelease our annotation tool, datasets, code, and models to build open\nfoundations for further CUA research.",
      "url": "http://arxiv.org/abs/2508.09123v1",
      "published_time_eastern_timestamp": 1755021152.0
    },
    {
      "title": "First- and Zeroth-Order Learning in Asynchronous Games",
      "summary": "This paper investigates the discrete-time asynchronous games in which\nnoncooperative agents seek to minimize their individual cost functions.\nBuilding on the assumption of partial asynchronism, i.e., each agent updates at\nleast once within a fixed-length time interval, we explore the conditions to\nensure convergence of such asynchronous games. The analysis begins with a\nsimple quadratic game from which we derive tight convergence conditions through\nthe lens of linear control theory. Then, we provide a quasidominance condition\nfor general convex games. Our results demonstrate that this condition is\nstringent since when this condition is not satisfied, the asynchronous games\nmay fail to converge. We propose both first- and zeroth-order learning\nalgorithms for asynchronous games, depending on the type of available feedback,\nand analyze their last-iterate convergence rates. Numerical experiments are\npresented on economic market problems to verify our results.",
      "url": "http://arxiv.org/abs/2508.09111v1",
      "published_time_eastern_timestamp": 1755020680.0
    },
    {
      "title": "MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by\n  Multi-App, Vague, Interactive, Single-App and Unethical Instructions",
      "summary": "Given the significant advances in Large Vision Language Models (LVLMs) in\nreasoning and visual understanding, mobile agents are rapidly emerging to meet\nusers' automation needs. However, existing evaluation benchmarks are\ndisconnected from the real world and fail to adequately address the diverse and\ncomplex requirements of users. From our extensive collection of user\nquestionnaire, we identified five tasks: Multi-App, Vague, Interactive,\nSingle-App, and Unethical Instructions. Around these tasks, we present\n\\textbf{MVISU-Bench}, a bilingual benchmark that includes 404 tasks across 137\nmobile applications. Furthermore, we propose Aider, a plug-and-play module that\nacts as a dynamic prompt prompter to mitigate risks and clarify user intent for\nmobile agents. Our Aider is easy to integrate into several frameworks and has\nsuccessfully improved overall success rates by 19.55\\% compared to the current\nstate-of-the-art (SOTA) on MVISU-Bench. Specifically, it achieves success rate\nimprovements of 53.52\\% and 29.41\\% for unethical and interactive instructions,\nrespectively. Through extensive experiments and analysis, we highlight the gap\nbetween existing mobile agents and real-world user expectations.",
      "url": "http://arxiv.org/abs/2508.09057v1",
      "published_time_eastern_timestamp": 1755015510.0
    },
    {
      "title": "Bridging Theory and Practice in Quantum Game Theory: Optimized\n  Implementation of the Battle of the Sexes with Error Mitigation on NISQ\n  Hardware",
      "summary": "Implementing quantum game theory on real hardware is challenging due to\nnoise, decoherence, and limited qubit connectivity, yet such demonstrations are\nessential to validate theoretical predictions. We present one of the first full\nexperimental realizations of the Battle of the Sexes game under the\nEisert-Wilkens-Lewenstein (EWL) framework on IBM Quantum's ibm sherbrooke\nsuperconducting processor. Four quantum strategies (I, H, $R(\\pi/4)$, $R(\\pi)$)\nwere evaluated across 31 entanglement values $\\gamma \\in [0, \\pi]$ using 2048\nshots per configuration, enabling a direct comparison between analytical\npredictions and hardware execution. To mitigate noise and variability, we\nintroduce a Guided Circuit Mapping (GCM) method that dynamically selects qubit\npairs and optimizes routing based on real-time topology and calibration data.\nThe analytical model forecasts up to $108\\%$ payoff improvement over the\nclassical equilibrium, and despite hardware-induced deviations, experimental\nresults with GCM preserve the expected payoff trends within $3.5\\%$-$12\\%$\nrelative error. These findings show that quantum advantages in strategic\ncoordination can persist under realistic NISQ conditions, providing a pathway\ntoward practical applications of quantum game theory in multi-agent, economic,\nand distributed decision-making systems.",
      "url": "http://arxiv.org/abs/2508.09050v1",
      "published_time_eastern_timestamp": 1755015005.0
    },
    {
      "title": "LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted\n  Supervisory Feedback",
      "summary": "Although large language models (LLMs) hold significant promise in\npsychotherapy, their direct application in patient-facing scenarios raises\nethical and safety concerns. Therefore, this work shifts towards developing an\nLLM as a supervisor to train real therapists. In addition to the privacy of\nclinical therapist training data, a fundamental contradiction complicates the\ntraining of therapeutic behaviors: clear feedback standards are necessary to\nensure a controlled training system, yet there is no absolute \"gold standard\"\nfor appropriate therapeutic behaviors in practice. In contrast, many common\ntherapeutic mistakes are universal and identifiable, making them effective\ntriggers for targeted feedback that can serve as clearer evidence. Motivated by\nthis, we create a novel therapist-training paradigm: (1) guidelines for\nmistaken behaviors and targeted correction strategies are first established as\nstandards; (2) a human-in-the-loop dialogue-feedback dataset is then\nconstructed, where a mistake-prone agent intentionally makes standard mistakes\nduring interviews naturally, and a supervisor agent locates and identifies\nmistakes and provides targeted feedback; (3) after fine-tuning on this dataset,\nthe final supervisor model is provided for real therapist training. The\ndetailed experimental results of automated, human and downstream assessments\ndemonstrate that models fine-tuned on our dataset MATE, can provide\nhigh-quality feedback according to the clinical guideline, showing significant\npotential for the therapist training scenario.",
      "url": "http://arxiv.org/abs/2508.09042v1",
      "published_time_eastern_timestamp": 1755014616.0
    },
    {
      "title": "Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding",
      "summary": "Vision-Language-Action models have demonstrated remarkable capabilities in\npredicting agent movements within virtual environments and real-world scenarios\nbased on visual observations and textual instructions. Although recent research\nhas focused on enhancing spatial and temporal understanding independently, this\npaper presents a novel approach that integrates both aspects through visual\nprompting. We introduce a method that projects visual traces of key points from\nobservations onto depth maps, enabling models to capture both spatial and\ntemporal information simultaneously. The experiments in SimplerEnv show that\nthe mean number of tasks successfully solved increased for 4% compared to\nSpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this\nenhancement can be achieved with minimal training data, making it particularly\nvaluable for real-world applications where data collection is challenging. The\nproject page is available at https://ampiromax.github.io/ST-VLA.",
      "url": "http://arxiv.org/abs/2508.09032v1",
      "published_time_eastern_timestamp": 1755014025.0
    },
    {
      "title": "Envisioning Generative Artificial Intelligence in Cartography and\n  Mapmaking",
      "summary": "Generative artificial intelligence (GenAI), including large language models,\ndiffusion-based image generation models, and GenAI agents, has provided new\nopportunities for advancements in mapping and cartography. Due to their\ncharacteristics including world knowledge and generalizability, artistic style\nand creativity, and multimodal integration, we envision that GenAI may benefit\na variety of cartographic design decisions, from mapmaking (e.g.,\nconceptualization, data preparation, map design, and map evaluation) to map use\n(such as map reading, interpretation, and analysis). This paper discusses\nseveral important topics regarding why and how GenAI benefits cartography with\ncase studies including symbolization, map evaluation, and map reading. Despite\nits unprecedented potential, we identify key scenarios where GenAI may not be\nsuitable, such as tasks that require a deep understanding of cartographic\nknowledge or prioritize precision and reliability. We also emphasize the need\nto consider ethical and social implications, such as concerns related to\nhallucination, reproducibility, bias, copyright, and explainability. This work\nlays the foundation for further exploration and provides a roadmap for future\nresearch at the intersection of GenAI and cartography.",
      "url": "http://arxiv.org/abs/2508.09028v1",
      "published_time_eastern_timestamp": 1755013359.0
    },
    {
      "title": "Dividing a cake for the irrationally entitled",
      "summary": "A perfectly divisible cake is to be divided among a group of agents. Each\nagent is entitled to a share between zero and one, and these entitlements are\ncompatible in that they sum to one. The mediator does not know the preferences\nof the agents, but can query the agents to make cuts and appraise slices in\norder to learn. We prove that if one of the entitlements is irrational, then\nthe mediator must use a protocol that involves an arbitrarily large number of\nqueries in order to construct an allocation that respects the entitlements\nregardless of preferences.",
      "url": "http://arxiv.org/abs/2508.09004v1",
      "published_time_eastern_timestamp": 1755011848.0
    },
    {
      "title": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through\n  Structured Contextual Memory",
      "summary": "Multi-agent systems built on Large Language Models (LLMs) show exceptional\npromise for complex collaborative problem-solving, yet they face fundamental\nchallenges stemming from context window limitations that impair memory\nconsistency, role adherence, and procedural integrity. This paper introduces\nIntrinsic Memory Agents, a novel framework that addresses these limitations\nthrough structured agent-specific memories that evolve intrinsically with agent\noutputs. Specifically, our method maintains role-aligned memory templates that\npreserve specialized perspectives while focusing on task-relevant information.\nWe benchmark our approach on the PDDL dataset, comparing its performance to\nexisting state-of-the-art multi-agentic memory approaches and showing an\nimprovement of 38.6\\% with the highest token efficiency. An additional\nevaluation is performed on a complex data pipeline design task, we demonstrate\nthat our approach produces higher quality designs when comparing 5 metrics:\nscalability, reliability, usability, cost-effectiveness and documentation with\nadditional qualitative evidence of the improvements. Our findings suggest that\naddressing memory limitations through structured, intrinsic approaches can\nimprove the capabilities of multi-agent LLM systems on structured planning\ntasks.",
      "url": "http://arxiv.org/abs/2508.08997v1",
      "published_time_eastern_timestamp": 1755011100.0
    },
    {
      "title": "How Does a Virtual Agent Decide Where to Look? - Symbolic Cognitive\n  Reasoning for Embodied Head Rotation",
      "summary": "Natural head rotation is critical for believable embodied virtual agents, yet\nthis micro-level behavior remains largely underexplored. While head-rotation\nprediction algorithms could, in principle, reproduce this behavior, they\ntypically focus on visually salient stimuli and overlook the cognitive motives\nthat guide head rotation. This yields agents that look at conspicuous objects\nwhile overlooking obstacles or task-relevant cues, diminishing realism in a\nvirtual environment. We introduce SCORE, a Symbolic Cognitive Reasoning\nframework for Embodied Head Rotation, a data-agnostic framework that produces\ncontext-aware head movements without task-specific training or hand-tuned\nheuristics. A controlled VR study (N=20) identifies five motivational drivers\nof human head movements: Interest, Information Seeking, Safety, Social Schema,\nand Habit. SCORE encodes these drivers as symbolic predicates, perceives the\nscene with a Vision-Language Model (VLM), and plans head poses with a Large\nLanguage Model (LLM). The framework employs a hybrid workflow: the VLM-LLM\nreasoning is executed offline, after which a lightweight FastVLM performs\nonline validation to suppress hallucinations while maintaining responsiveness\nto scene dynamics. The result is an agent that predicts not only where to look\nbut also why, generalizing to unseen scenes and multi-agent crowds while\nretaining behavioral plausibility.",
      "url": "http://arxiv.org/abs/2508.08930v1",
      "published_time_eastern_timestamp": 1755005538.0
    },
    {
      "title": "Reducing Cognitive Load in Multi-Agent Reinforcement Learning for\n  Mathematical Problem Solving: Decoupling Reasoning and Code Generation",
      "summary": "Current tool-integrated mathematical reasoning systems often adopt a\nsingle-agent paradigm, where one large language model handles problem\nreasoning, code generation, and code execution in an integrated workflow. While\nthis design eases coordination, we hypothesize that it imposes cognitive load\ninterference, as the agent must interleave long-horizon reasoning with precise\nprogram synthesis. We validate this hypothesis through a controlled comparison\nbetween a reasoning-only agent and a reasoning-plus-code agent, finding that\nthe latter produces significantly fewer correct reasoning paths despite having\ntool-calling capabilities. To address this, we propose a dual-agent hybrid\nframework: a Reasoning Agent performs stepwise problem decomposition, and a\nCode Agent handles code generation and execution. Training combines imitation\nlearning and reinforcement learning: the Code Agent receives strong rewards for\nmatching intermediate ground-truth programs and weaker rewards for valid\nexecution, while the Reasoning Agent is optimized chiefly via final-answer\naccuracy using advantage estimation to credit intermediate steps. This\ndecoupled role design reduces cognitive interference and promotes stable\nreasoning-coding coordination.",
      "url": "http://arxiv.org/abs/2508.08882v1",
      "published_time_eastern_timestamp": 1755000653.0
    },
    {
      "title": "The Roots of International Perceptions: Simulating US Attitude Changes\n  Towards China with LLM Agents",
      "summary": "The rise of LLMs poses new possibilities in modeling opinion evolution, a\nlong-standing task in simulation, by leveraging advanced reasoning abilities to\nrecreate complex, large-scale human cognitive trends. While most prior works\nfocus on opinion evolution surrounding specific isolated events or the views\nwithin a country, ours is the first to model the large-scale attitude evolution\nof a population representing an entire country towards another -- US citizens'\nperspectives towards China. To tackle the challenges of this broad scenario, we\npropose a framework that integrates media data collection, user profile\ncreation, and cognitive architecture for opinion updates to successfully\nreproduce the real trend of US attitudes towards China over a 20-year period\nfrom 2005 to today. We also leverage LLMs' capabilities to introduce debiased\nmedia exposure, extracting neutral events from typically subjective news\ncontents, to uncover the roots of polarized opinion formation, as well as a\ndevils advocate agent to help explain the rare reversal from negative to\npositive attitudes towards China, corresponding with changes in the way\nAmericans obtain information about the country. The simulation results, beyond\nvalidating our framework architecture, also reveal the impact of biased framing\nand selection bias in shaping attitudes. Overall, our work contributes to a new\nparadigm for LLM-based modeling of cognitive behaviors in a large-scale,\nlong-term, cross-border social context, providing insights into the formation\nof international biases and offering valuable implications for media consumers\nto better understand the factors shaping their perspectives, and ultimately\ncontributing to the larger social need for bias reduction and cross-cultural\ntolerance.",
      "url": "http://arxiv.org/abs/2508.08837v1",
      "published_time_eastern_timestamp": 1754996048.0
    },
    {
      "title": "3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs",
      "summary": "Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong\ncapabilities in learning joint representations from text and images. However,\ntheir spatial reasoning remains limited. We introduce 3DFroMLLM, a novel\nframework that enables the generation of 3D object prototypes directly from\nMLLMs, including geometry and part labels. Our pipeline is agentic, comprising\na designer, coder, and visual inspector operating in a refinement loop.\nNotably, our approach requires no additional training data or detailed user\ninstructions. Building on prior work in 2D generation, we demonstrate that\nrendered images produced by our framework can be effectively used for image\nclassification pretraining tasks and outperforms previous methods by 15%. As a\ncompelling real-world use case, we show that the generated prototypes can be\nleveraged to improve fine-grained vision-language models by using the rendered,\npart-labeled prototypes to fine-tune CLIP for part segmentation and achieving a\n55% accuracy improvement without relying on any additional human-labeled data.",
      "url": "http://arxiv.org/abs/2508.08821v1",
      "published_time_eastern_timestamp": 1754994119.0
    },
    {
      "title": "Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval\n  Augmented Generation",
      "summary": "Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising\nsolution to address the temporal limitations of Multimodal Large Language\nModels (MLLMs) in real-world scenarios like news analysis and trending topics.\nHowever, existing approaches often suffer from rigid retrieval strategies and\nunder-utilization of visual information. To bridge this gap, we propose\nE-Agent, an agent framework featuring two key innovations: a mRAG planner\ntrained to dynamically orchestrate multimodal tools based on contextual\nreasoning, and a task executor employing tool-aware execution sequencing to\nimplement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning\nstrategy that enables efficient information retrieval while minimizing\nredundant tool invocations. To rigorously assess the planning capabilities of\nmRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark.\nThis novel benchmark contains both retrieval-dependent and\nretrieval-independent question types, systematically annotated with essential\nretrieval tools required for each instance. The benchmark's explicit mRAG\nplanning annotations and diverse question design enhance its practical\nrelevance by simulating real-world scenarios requiring dynamic mRAG decisions.\nExperiments across RemPlan and three established benchmarks demonstrate\nE-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods\nwhile reducing redundant searches by 37%.",
      "url": "http://arxiv.org/abs/2508.08816v1",
      "published_time_eastern_timestamp": 1754993832.0
    },
    {
      "title": "Not in My Backyard! Temporal Voting Over Public Chores",
      "summary": "We study a temporal voting model where voters have dynamic preferences over a\nset of public chores -- projects that benefit society, but impose individual\ncosts on those affected by their implementation. We investigate the\ncomputational complexity of optimizing utilitarian and egalitarian welfare. Our\nresults show that while optimizing the former is computationally\nstraightforward, minimizing the latter is computationally intractable, even in\nvery restricted cases. Nevertheless, we identify several settings where this\nproblem can be solved efficiently, either exactly or by an approximation\nalgorithm. We also examine the effects of enforcing temporal fairness and its\nimpact on social welfare, and analyze the competitive ratio of online\nalgorithms. We then explore the strategic behavior of agents, providing\ninsights into potential malfeasance in such decision-making environments.\nFinally, we discuss a range of fairness measures and their suitability for our\nsetting.",
      "url": "http://arxiv.org/abs/2508.08810v1",
      "published_time_eastern_timestamp": 1754993216.0
    },
    {
      "title": "Fault Tolerant Multi-Agent Learning with Adversarial Budget Constraints",
      "summary": "In multi-agent systems, the safe and reliable execution of tasks often\ndepends on agents correctly coordinating their actions. However, in real-world\ndeployments, failures of computational components are inevitable, presenting a\ncritical challenge: ensuring that multi-agent reinforcement learning (MARL)\npolicies remain effective even when some agents malfunction. We propose the\nMulti-Agent Robust Training Algorithm (MARTA), a plug-and-play framework for\ntraining MARL agents to be resilient to potentially severe faults. MARTA\noperates in cooperative multi-agent settings where agents may lose the ability\nto execute their intended actions. It learns to identify failure scenarios that\nare especially detrimental to system performance and equips agents with\nstrategies to mitigate their impact. At the heart of MARTA is a novel\nadversarial Markov game in which an adversary -- modelled via \\emph{Markov\nswitching controls} -- learns to disable agents in high-risk state regions,\nwhile the remaining agents are trained to \\emph{jointly} best-respond to such\ntargeted malfunctions. To ensure practicality, MARTA enforces a malfunction\nbudget, constraining the adversary to a fixed number of failures and learning\nrobust policies accordingly. We provide theoretical guarantees that MARTA\nconverges to a Markov perfect equilibrium, ensuring agents optimally counteract\nworst-case faults. Empirically, we show that MARTA achieves state-of-the-art\nfault-tolerant performance across benchmark environments, including Multi-Agent\nParticle World and Level-Based Foraging.",
      "url": "http://arxiv.org/abs/2508.08800v1",
      "published_time_eastern_timestamp": 1754992625.0
    },
    {
      "title": "Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in\n  Personalized Task Assistance",
      "summary": "Augmented Reality (AR) systems are increasingly integrating foundation\nmodels, such as Multimodal Large Language Models (MLLMs), to provide more\ncontext-aware and adaptive user experiences. This integration has led to the\ndevelopment of AR agents to support intelligent, goal-directed interactions in\nreal-world environments. While current AR agents effectively support immediate\ntasks, they struggle with complex multi-step scenarios that require\nunderstanding and leveraging user's long-term experiences and preferences. This\nlimitation stems from their inability to capture, retain, and reason over\nhistorical user interactions in spatiotemporal contexts. To address these\nchallenges, we propose a conceptual framework for memory-augmented AR agents\nthat can provide personalized task assistance by learning from and adapting to\nuser-specific experiences over time. Our framework consists of four\ninterconnected modules: (1) Perception Module for multimodal sensor processing,\n(2) Memory Module for persistent spatiotemporal experience storage, (3)\nSpatiotemporal Reasoning Module for synthesizing past and present contexts, and\n(4) Actuator Module for effective AR communication. We further present an\nimplementation roadmap, a future evaluation strategy, a potential target\napplication and use cases to demonstrate the practical applicability of our\nframework across diverse domains. We aim for this work to motivate future\nresearch toward developing more intelligent AR systems that can effectively\nbridge user's interaction history with adaptive, context-aware task assistance.",
      "url": "http://arxiv.org/abs/2508.08774v1",
      "published_time_eastern_timestamp": 1754990420.0
    }
  ]
}
{
  "last_updated": "2025-05-14T08:22:19.007111-04:00",
  "papers": [
    {
      "title": "Towards Autonomous UAV Visual Object Search in City Space: Benchmark and\n  Agentic Methodology",
      "summary": "Aerial Visual Object Search (AVOS) tasks in urban environments require\nUnmanned Aerial Vehicles (UAVs) to autonomously search for and identify target\nobjects using visual and textual cues without external guidance. Existing\napproaches struggle in complex urban environments due to redundant semantic\nprocessing, similar object distinction, and the exploration-exploitation\ndilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS,\nthe first benchmark dataset for autonomous search of common urban objects. This\ndataset comprises 2,420 tasks across six object categories with varying\ndifficulty levels, enabling comprehensive evaluation of UAV agents' search\ncapabilities. To solve the AVOS tasks, we also propose PRPSearcher\n(Perception-Reasoning-Planning Searcher), a novel agentic method powered by\nmulti-modal large language models (MLLMs) that mimics human three-tier\ncognition. Specifically, PRPSearcher constructs three specialized maps: an\nobject-centric dynamic semantic map enhancing spatial perception, a 3D\ncognitive map based on semantic attraction values for target reasoning, and a\n3D uncertainty map for balanced exploration-exploitation search. Also, our\napproach incorporates a denoising mechanism to mitigate interference from\nsimilar objects and utilizes an Inspiration Promote Thought (IPT) prompting\nmechanism for adaptive action planning. Experimental results on CityAVOS\ndemonstrate that PRPSearcher surpasses existing baselines in both success rate\nand search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and\n-46.40% NE). While promising, the performance gap compared to humans highlights\nthe need for better semantic reasoning and spatial exploration capabilities in\nAVOS tasks. This work establishes a foundation for future advances in embodied\ntarget search. Dataset and source code are available at\nhttps://anonymous.4open.science/r/CityAVOS-3DF8.",
      "url": "http://arxiv.org/abs/2505.08765v1",
      "published_time_eastern_timestamp": 1747157694.0
    },
    {
      "title": "Enhancing Software Development with Context-Aware Conversational Agents:\n  A User Study on Developer Interactions with Chatbots",
      "summary": "Software development is a cognitively intensive process requiring\nmultitasking, adherence to evolving workflows, and continuous learning. With\nthe rise of large language model (LLM)-based tools, such as conversational\nagents (CAs), there is growing interest in supporting developers through\nnatural language interaction. However, little is known about the specific\nfeatures developers seek in these systems. We conducted a user study with 29\ndevelopers using a prototype text-based chatbot to investigate preferred\nfunctionalities. Our findings reveal strong interest in task automation,\nversion control support, and contextual adaptability, especially the need to\ntailor assistance for both novice and experienced users. We highlight the\nimportance of deep contextual understanding, historical interaction awareness,\nand personalized support in CA design. This study contributes to the\ndevelopment of context-aware chatbots that enhance productivity and\nsatisfaction, and it outlines opportunities for future research on human-AI\ncollaboration in software engineering.",
      "url": "http://arxiv.org/abs/2505.08648v1",
      "published_time_eastern_timestamp": 1747148935.0
    },
    {
      "title": "TRAIL: Trace Reasoning and Agentic Issue Localization",
      "summary": "The increasing adoption of agentic workflows across diverse domains brings a\ncritical need to scalably and systematically evaluate the complex traces these\nsystems generate. Current evaluation methods depend on manual, domain-specific\nhuman analysis of lengthy workflow traces - an approach that does not scale\nwith the growing complexity and volume of agentic outputs. Error analysis in\nthese settings is further complicated by the interplay of external tool outputs\nand language model reasoning, making it more challenging than traditional\nsoftware debugging. In this work, we (1) articulate the need for robust and\ndynamic evaluation methods for agentic workflow traces, (2) introduce a formal\ntaxonomy of error types encountered in agentic systems, and (3) present a set\nof 148 large human-annotated traces (TRAIL) constructed using this taxonomy and\ngrounded in established agentic benchmarks. To ensure ecological validity, we\ncurate traces from both single and multi-agent systems, focusing on real-world\napplications such as software engineering and open-world information retrieval.\nOur evaluations reveal that modern long context LLMs perform poorly at trace\ndebugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our\ndataset and code are made publicly available to support and accelerate future\nresearch in scalable evaluation for agentic workflows.",
      "url": "http://arxiv.org/abs/2505.08638v1",
      "published_time_eastern_timestamp": 1747148131.0
    },
    {
      "title": "Credit Assignment and Efficient Exploration based on Influence Scope in\n  Multi-agent Reinforcement Learning",
      "summary": "Training cooperative agents in sparse-reward scenarios poses significant\nchallenges for multi-agent reinforcement learning (MARL). Without clear\nfeedback on actions at each step in sparse-reward setting, previous methods\nstruggle with precise credit assignment among agents and effective exploration.\nIn this paper, we introduce a novel method to deal with both credit assignment\nand exploration problems in reward-sparse domains. Accordingly, we propose an\nalgorithm that calculates the Influence Scope of Agents (ISA) on states by\ntaking specific value of the dimensions/attributes of states that can be\ninfluenced by individual agents. The mutual dependence between agents' actions\nand state attributes are then used to calculate the credit assignment and to\ndelimit the exploration space for each individual agent. We then evaluate ISA\nin a variety of sparse-reward multi-agent scenarios. The results show that our\nmethod significantly outperforms the state-of-art baselines.",
      "url": "http://arxiv.org/abs/2505.08630v1",
      "published_time_eastern_timestamp": 1747147766.0
    },
    {
      "title": "OpenThinkIMG: Learning to Think with Images via Visual Tool\n  Reinforcement Learning",
      "summary": "While humans can flexibly leverage interactive visual cognition for complex\nproblem-solving, enabling Large Vision-Language Models (LVLMs) to learn\nsimilarly adaptive behaviors with visual tools remains challenging. A\nsignificant hurdle is the current lack of standardized infrastructure, which\nhinders integrating diverse tools, generating rich interaction data, and\ntraining robust agents effectively. To address these gaps, we introduce\nOpenThinkIMG, the first open-source, comprehensive end-to-end framework for\ntool-augmented LVLMs. It features standardized vision tool interfaces, scalable\ntrajectory generation for policy initialization, and a flexible training\nenvironment. Furthermore, considering supervised fine-tuning (SFT) on static\ndemonstrations offers limited policy generalization for dynamic tool\ninvocation, we propose a novel reinforcement learning (RL) framework V-ToolRL\nto train LVLMs to learn adaptive policies for invoking external vision tools.\nV-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies\nby directly optimizing for task success using feedback from tool interactions.\nWe empirically validate V-ToolRL on challenging chart reasoning tasks. Our\nRL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its\nSFT-initialized counterpart (+28.83 points) and surpasses established\nsupervised tool-learning baselines like Taco and CogCom by an average of +12.7\npoints. Notably, it also surpasses prominent closed-source models like GPT-4.1\nby +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational\nframework for advancing dynamic, tool-augmented visual reasoning, helping the\ncommunity develop AI agents that can genuinely \"think with images\".",
      "url": "http://arxiv.org/abs/2505.08617v1",
      "published_time_eastern_timestamp": 1747146951.0
    },
    {
      "title": "MC-Swarm: Minimal-Communication Multi-Agent Trajectory Planning and\n  Deadlock Resolution for Quadrotor Swarm",
      "summary": "For effective multi-agent trajectory planning, it is important to consider\nlightweight communication and its potential asynchrony. This paper presents a\ndistributed trajectory planning algorithm for a quadrotor swarm that operates\nasynchronously and requires no communication except during the initial planning\nphase. Moreover, our algorithm guarantees no deadlock under asynchronous\nupdates and absence of communication during flight. To effectively ensure these\npoints, we build two main modules: coordination state updater and trajectory\noptimizer. The coordination state updater computes waypoints for each agent\ntoward its goal and performs subgoal optimization while considering deadlocks,\nas well as safety constraints with respect to neighbor agents and obstacles.\nThen, the trajectory optimizer generates a trajectory that ensures collision\navoidance even with the asynchronous planning updates of neighboring agents. We\nprovide a theoretical guarantee of collision avoidance with deadlock resolution\nand evaluate the effectiveness of our method in complex simulation\nenvironments, including random forests and narrow-gap mazes. Additionally, to\nreduce the total mission time, we design a faster coordination state update\nusing lightweight communication. Lastly, our approach is validated through\nextensive simulations and real-world experiments with cluttered environment\nscenarios.",
      "url": "http://arxiv.org/abs/2505.08593v1",
      "published_time_eastern_timestamp": 1747145107.0
    },
    {
      "title": "Communication-Efficient Distributed Online Nonconvex Optimization with\n  Time-Varying Constraints",
      "summary": "This paper considers distributed online nonconvex optimization with\ntime-varying inequality constraints over a network of agents, where the\nnonconvex local loss and convex local constraint functions can vary arbitrarily\nacross iterations, and the information of them is privately revealed to each\nagent at each iteration. For a uniformly jointly strongly connected\ntime-varying directed graph, we propose two distributed bandit online\nprimal--dual algorithm with compressed communication to efficiently utilize\ncommunication resources in the one-point and two-point bandit feedback\nsettings, respectively. In nonconvex optimization, finding a globally optimal\ndecision is often NP-hard. As a result, the standard regret metric used in\nonline convex optimization becomes inapplicable. To measure the performance of\nthe proposed algorithms, we use a network regret metric grounded in the\nfirst-order optimality condition associated with the variational inequality. We\nshow that the compressed algorithms establish sublinear network regret and\ncumulative constraint violation bounds. Finally, a simulation example is\npresented to validate the theoretical results.",
      "url": "http://arxiv.org/abs/2505.08592v1",
      "published_time_eastern_timestamp": 1747145052.0
    },
    {
      "title": "The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large\n  Language Models Unmask Fake News",
      "summary": "In today's digital environment, the rapid propagation of fake news via social\nnetworks poses significant social challenges. Most existing detection methods\neither employ traditional classification models, which suffer from low\ninterpretability and limited generalization capabilities, or craft specific\nprompts for large language models (LLMs) to produce explanations and results\ndirectly, failing to leverage LLMs' reasoning abilities fully. Inspired by the\nsaying that \"truth becomes clearer through debate,\" our study introduces a\nnovel multi-agent system with LLMs named TruEDebate (TED) to enhance the\ninterpretability and effectiveness of fake news detection. TED employs a\nrigorous debate process inspired by formal debate settings. Central to our\napproach are two innovative components: the DebateFlow Agents and the\nInsightFlow Agents. The DebateFlow Agents organize agents into two teams, where\none supports and the other challenges the truth of the news. These agents\nengage in opening statements, cross-examination, rebuttal, and closing\nstatements, simulating a rigorous debate process akin to human discourse\nanalysis, allowing for a thorough evaluation of news content. Concurrently, the\nInsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent\nand the Analysis Agent. The Synthesis Agent summarizes the debates and provides\nan overarching viewpoint, ensuring a coherent and comprehensive evaluation. The\nAnalysis Agent, which includes a role-aware encoder and a debate graph,\nintegrates role embeddings and models the interactions between debate roles and\narguments using an attention mechanism, providing the final judgment.",
      "url": "http://arxiv.org/abs/2505.08532v1",
      "published_time_eastern_timestamp": 1747141400.0
    },
    {
      "title": "Strategy-Augmented Planning for Large Language Models via Opponent\n  Exploitation",
      "summary": "Efficiently modeling and exploiting opponents is a long-standing challenge in\nadversarial domains. Large Language Models (LLMs) trained on extensive textual\ndata have recently demonstrated outstanding performance in general tasks,\nintroducing new research directions for opponent modeling. Some studies\nprimarily focus on directly using LLMs to generate decisions based on the\nelaborate prompt context that incorporates opponent descriptions, while these\napproaches are limited to scenarios where LLMs possess adequate domain\nexpertise. To address that, we introduce a two-stage Strategy-Augmented\nPlanning (SAP) framework that significantly enhances the opponent exploitation\ncapabilities of LLM-based agents by utilizing a critical component, the\nStrategy Evaluation Network (SEN). Specifically, in the offline stage, we\nconstruct an explicit strategy space and subsequently collect strategy-outcome\npair data for training the SEN network. During the online phase, SAP\ndynamically recognizes the opponent's strategies and greedily exploits them by\nsearching best response strategy on the well-trained SEN, finally translating\nstrategy to a course of actions by carefully designed prompts. Experimental\nresults show that SAP exhibits robust generalization capabilities, allowing it\nto perform effectively not only against previously encountered opponent\nstrategies but also against novel, unseen strategies. In the MicroRTS\nenvironment, SAP achieves a 85.35\\% performance improvement over baseline\nmethods and matches the competitiveness of reinforcement learning approaches\nagainst state-of-the-art (SOTA) rule-based AI.",
      "url": "http://arxiv.org/abs/2505.08459v1",
      "published_time_eastern_timestamp": 1747136470.0
    },
    {
      "title": "Zero-Shot Sim-to-Real Reinforcement Learning for Fruit Harvesting",
      "summary": "This paper presents a comprehensive sim-to-real pipeline for autonomous\nstrawberry picking from dense clusters using a Franka Panda robot. Our approach\nleverages a custom Mujoco simulation environment that integrates domain\nrandomization techniques. In this environment, a deep reinforcement learning\nagent is trained using the dormant ratio minimization algorithm. The proposed\npipeline bridges low-level control with high-level perception and decision\nmaking, demonstrating promising performance in both simulation and in a real\nlaboratory environment, laying the groundwork for successful transfer to\nreal-world autonomous fruit harvesting.",
      "url": "http://arxiv.org/abs/2505.08458v1",
      "published_time_eastern_timestamp": 1747136421.0
    },
    {
      "title": "Scalable UAV Multi-Hop Networking via Multi-Agent Reinforcement Learning\n  with Large Language Models",
      "summary": "In disaster scenarios, establishing robust emergency communication networks\nis critical, and unmanned aerial vehicles (UAVs) offer a promising solution to\nrapidly restore connectivity. However, organizing UAVs to form multi-hop\nnetworks in large-scale dynamic environments presents significant challenges,\nincluding limitations in algorithmic scalability and the vast exploration space\nrequired for coordinated decision-making. To address these issues, we propose\nMRLMN, a novel framework that integrates multi-agent reinforcement learning\n(MARL) and large language models (LLMs) to jointly optimize UAV agents toward\nachieving optimal networking performance. The framework incorporates a grouping\nstrategy with reward decomposition to enhance algorithmic scalability and\nbalance decision-making across UAVs. In addition, behavioral constraints are\napplied to selected key UAVs to improve the robustness of the network.\nFurthermore, the framework integrates LLM agents, leveraging knowledge\ndistillation to transfer their high-level decision-making capabilities to MARL\nagents. This enhances both the efficiency of exploration and the overall\ntraining process. In the distillation module, a Hungarian algorithm-based\nmatching scheme is applied to align the decision outputs of the LLM and MARL\nagents and define the distillation loss. Extensive simulation results validate\nthe effectiveness of our approach, demonstrating significant improvements in\nnetwork performance, including enhanced coverage and communication quality.",
      "url": "http://arxiv.org/abs/2505.08448v1",
      "published_time_eastern_timestamp": 1747135405.0
    },
    {
      "title": "Agent-as-a-Service based on Agent Network",
      "summary": "The rise of large model-based AI agents has spurred interest in Multi-Agent\nSystems (MAS) for their capabilities in decision-making, collaboration, and\nadaptability. While the Model Context Protocol (MCP) addresses tool invocation\nand data exchange challenges via a unified protocol, it lacks support for\norganizing agent-level collaboration. To bridge this gap, we propose\nAgent-as-a-Service based on Agent Network (AaaS-AN), a service-oriented\nparadigm grounded in the Role-Goal-Process-Service (RGPS) standard. AaaS-AN\nunifies the entire agent lifecycle, including construction, integration,\ninteroperability, and networked collaboration, through two core components: (1)\na dynamic Agent Network, which models agents and agent groups as vertexes that\nself-organize within the network based on task and role dependencies; (2)\nservice-oriented agents, incorporating service discovery, registration, and\ninteroperability protocols. These are orchestrated by a Service Scheduler,\nwhich leverages an Execution Graph to enable distributed coordination, context\ntracking, and runtime task management. We validate AaaS-AN on mathematical\nreasoning and application-level code generation tasks, which outperforms\nstate-of-the-art baselines. Notably, we constructed a MAS based on AaaS-AN\ncontaining agent groups, Robotic Process Automation (RPA) workflows, and MCP\nservers over 100 agent services. We also release a dataset containing 10,000\nlong-horizon multi-agent workflows to facilitate future research on long-chain\ncollaboration in MAS.",
      "url": "http://arxiv.org/abs/2505.08446v1",
      "published_time_eastern_timestamp": 1747134919.0
    },
    {
      "title": "A nonlocal-to-local approach to aggregation-diffusion equations",
      "summary": "Over the past decades, nonlocal models have been widely used to describe\naggregation phenomena in biology, physics, engineering, and the social\nsciences. These are often derived as mean-field limits of attraction-repulsion\nagent-based models, and consist of systems of nonlocal partial differential\nequations. Using differential adhesion between cells as a biological case\nstudy, we introduce a novel local model of aggregation-diffusion phenomena.\nThis system of local aggregation-diffusion equations is fourth-order,\nresembling thin-film or Cahn-Hilliard type equations. In this framework, cell\nsorting phenomena are explained through relative surface tensions between\ndistinct cell types. The local model emerges as a limiting case of short-range\ninteractions, providing a significant simplification of earlier nonlocal\nmodels, while preserving the same phenomenology. This simplification makes the\nmodel easier to implement numerically and more amenable to calibration to\nquantitative data. Additionally, we discuss recent analytical results based on\nthe gradient-flow structure of the model, along with open problems and future\nresearch directions.",
      "url": "http://arxiv.org/abs/2505.08443v1",
      "published_time_eastern_timestamp": 1747134583.0
    },
    {
      "title": "Continuous World Coverage Path Planning for Fixed-Wing UAVs using Deep\n  Reinforcement Learning",
      "summary": "Unmanned Aerial Vehicle (UAV) Coverage Path Planning (CPP) is critical for\napplications such as precision agriculture and search and rescue. While\ntraditional methods rely on discrete grid-based representations, real-world UAV\noperations require power-efficient continuous motion planning. We formulate the\nUAV CPP problem in a continuous environment, minimizing power consumption while\nensuring complete coverage. Our approach models the environment with\nvariable-size axis-aligned rectangles and UAV motion with curvature-constrained\nB\\'ezier curves. We train a reinforcement learning agent using an\naction-mapping-based Soft Actor-Critic (AM-SAC) algorithm employing a\nself-adaptive curriculum. Experiments on both procedurally generated and\nhand-crafted scenarios demonstrate the effectiveness of our method in learning\nenergy-efficient coverage strategies.",
      "url": "http://arxiv.org/abs/2505.08382v1",
      "published_time_eastern_timestamp": 1747128556.0
    },
    {
      "title": "Modeling Unseen Environments with Language-guided Composable Causal\n  Components in Reinforcement Learning",
      "summary": "Generalization in reinforcement learning (RL) remains a significant\nchallenge, especially when agents encounter novel environments with unseen\ndynamics. Drawing inspiration from human compositional reasoning -- where known\ncomponents are reconfigured to handle new situations -- we introduce World\nModeling with Compositional Causal Components (WM3C). This novel framework\nenhances RL generalization by learning and leveraging compositional causal\ncomponents. Unlike previous approaches focusing on invariant representation\nlearning or meta-learning, WM3C identifies and utilizes causal dynamics among\ncomposable elements, facilitating robust adaptation to new tasks. Our approach\nintegrates language as a compositional modality to decompose the latent space\ninto meaningful components and provides theoretical guarantees for their unique\nidentification under mild assumptions. Our practical implementation uses a\nmasked autoencoder with mutual information constraints and adaptive sparsity\nregularization to capture high-level semantic information and effectively\ndisentangle transition dynamics. Experiments on numerical simulations and\nreal-world robotic manipulation tasks demonstrate that WM3C significantly\noutperforms existing methods in identifying latent processes, improving policy\nlearning, and generalizing to unseen tasks.",
      "url": "http://arxiv.org/abs/2505.08361v1",
      "published_time_eastern_timestamp": 1747127308.0
    },
    {
      "title": "Benchmarking AI scientists in omics data-driven biological research",
      "summary": "The rise of large language models and multi-agent systems has sparked growing\ninterest in AI scientists capable of autonomous biological research. However,\nexisting benchmarks either focus on reasoning without data or on data analysis\nwith predefined statistical answers, lacking realistic, data-driven evaluation\nsettings. Here, we introduce the Biological AI Scientist Benchmark (BaisBench),\na benchmark designed to assess AI scientists' ability to generate biological\ndiscoveries through data analysis and reasoning with external knowledge.\nBaisBench comprises two tasks: cell type annotation on 31 expert-labeled\nsingle-cell datasets, and scientific discovery through answering 198\nmultiple-choice questions derived from the biological insights of 41 recent\nsingle-cell studies. Systematic experiments on state-of-the-art AI scientists\nand LLM agents showed that while promising, current models still substantially\nunderperform human experts on both tasks. We hope BaisBench will fill this gap\nand serve as a foundation for advancing and evaluating AI models for scientific\ndiscovery. The benchmark can be found at: https://github.com/EperLuo/BaisBench.",
      "url": "http://arxiv.org/abs/2505.08341v1",
      "published_time_eastern_timestamp": 1747125234.0
    },
    {
      "title": "Reciprocity as the Foundational Substrate of Society: How Reciprocal\n  Dynamics Scale into Social Systems",
      "summary": "A major bottleneck in multi-agent AI is the lack of simulateable models for\nthe bottom-up emergence of social structure under realistic behavioral\nconstraints. Similarly, many foundational theories in economics and sociology\nincluding the concepts of \"institutions\" and \"norms\" tend to describe social\nstructures post hoc, often relying on implicit assumptions of shared culture,\nmorality, or symbolic agreement. These concepts are often treated as primitives\nrather than reconstructed from agent-level behavior, leaving both their origins\nand operational definitions under-specified. To address this, we propose a\nthree-stage bottom-up framework: Reciprocal Dynamics, capturing\nindividual-level reciprocal exchanges; Norm Stabilization, the consolidation of\nshared expectations; and Institutional Construction, the externalization of\nstable patterns into scalable structures. By grounding social emergence in\nagent-level reciprocity, our framework enables the systematic exploration of\nhow moral, cultural, and institutional structures emerge from cognitively\nminimal interactions.",
      "url": "http://arxiv.org/abs/2505.08319v1",
      "published_time_eastern_timestamp": 1747122601.0
    },
    {
      "title": "Stationary Mean-Field Games of Singular Control under Knightian\n  Uncertainty",
      "summary": "In this work, we study a class of stationary mean-field games of singular\nstochastic control under model uncertainty. The representative agent adjusts\nthe dynamics of an It\\^o diffusion via one-sided singular stochastic control,\naiming to maximize a long-term average expected profit criterion. The\nmean-field interaction is of scalar type through the stationary distribution of\nthe population. Due to the presence of uncertainty, the problem involves the\nstudy of a stochastic (zero-sum) game, where the decision maker chooses the\n\"best\" singular control policy, while the adversarial player selects the\n\"worst\" probability measure. Using a constructive approach, we prove existence\nand uniqueness of a stationary mean-field equilibrium. Finally, we present an\nexample of mean-field optimal extraction of natural resources under uncertainty\nand we analyze the impact of uncertainty on the mean-field equilibrium.",
      "url": "http://arxiv.org/abs/2505.08317v1",
      "published_time_eastern_timestamp": 1747122542.0
    },
    {
      "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and\n  Efficient Reinforcement Learning",
      "summary": "This paper addresses the challenges of training end-to-end autonomous driving\nagents using Reinforcement Learning (RL). RL agents are typically trained in a\nfixed set of scenarios and nominal behavior of surrounding road users in\nsimulations, limiting their generalization and real-life deployment. While\ndomain randomization offers a potential solution by randomly sampling driving\nscenarios, it frequently results in inefficient training and sub-optimal\npolicies due to the high variance among training scenarios. To address these\nlimitations, we propose an automatic curriculum learning framework that\ndynamically generates driving scenarios with adaptive complexity based on the\nagent's evolving capabilities. Unlike manually designed curricula that\nintroduce expert bias and lack scalability, our framework incorporates a\n``teacher'' that automatically generates and mutates driving scenarios based on\ntheir learning potential -- an agent-centric metric derived from the agent's\ncurrent policy -- eliminating the need for expert design. The framework\nenhances training efficiency by excluding scenarios the agent has mastered or\nfinds too challenging. We evaluate our framework in a reinforcement learning\nsetting where the agent learns a driving policy from camera images. Comparative\nresults against baseline methods, including fixed scenario training and domain\nrandomization, demonstrate that our approach leads to enhanced generalization,\nachieving higher success rates: +9\\% in low traffic density, +21\\% in high\ntraffic density, and faster convergence with fewer training steps. Our findings\nhighlight the potential of ACL in improving the robustness and efficiency of\nRL-based autonomous driving agents.",
      "url": "http://arxiv.org/abs/2505.08264v1",
      "published_time_eastern_timestamp": 1747117617.0
    },
    {
      "title": "Few-shot Novel Category Discovery",
      "summary": "The recently proposed Novel Category Discovery (NCD) adapt paradigm of\ntransductive learning hinders its application in more real-world scenarios. In\nfact, few labeled data in part of new categories can well alleviate this\nburden, which coincides with the ease that people can label few of new category\ndata. Therefore, this paper presents a new setting in which a trained agent is\nable to flexibly switch between the tasks of identifying examples of known\n(labelled) classes and clustering novel (completely unlabeled) classes as the\nnumber of query examples increases by leveraging knowledge learned from only a\nfew (handful) support examples. Drawing inspiration from the discovery of novel\ncategories using prior-based clustering algorithms, we introduce a novel\nframework that further relaxes its assumptions to the real-world open set level\nby unifying the concept of model adaptability in few-shot learning. We refer to\nthis setting as Few-Shot Novel Category Discovery (FSNCD) and propose\nSemi-supervised Hierarchical Clustering (SHC) and Uncertainty-aware K-means\nClustering (UKC) to examine the model's reasoning capabilities. Extensive\nexperiments and detailed analysis on five commonly used datasets demonstrate\nthat our methods can achieve leading performance levels across different task\nsettings and scenarios.",
      "url": "http://arxiv.org/abs/2505.08260v1",
      "published_time_eastern_timestamp": 1747117083.0
    }
  ]
}
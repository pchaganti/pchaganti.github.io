{
  "last_updated": "2025-10-21T08:24:27.590162-04:00",
  "papers": [
    {
      "title": "Enterprise Deep Research: Steerable Multi-Agent Deep Research for\n  Enterprise Analytics",
      "summary": "As information grows exponentially, enterprises face increasing pressure to\ntransform unstructured data into coherent, actionable insights. While\nautonomous agents show promise, they often struggle with domain-specific\nnuances, intent alignment, and enterprise integration. We present Enterprise\nDeep Research (EDR), a multi-agent system that integrates (1) a Master Planning\nAgent for adaptive query decomposition, (2) four specialized search agents\n(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool\necosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a\nVisualization Agent for data-driven insights, and (5) a reflection mechanism\nthat detects knowledge gaps and updates research direction with optional\nhuman-in-the-loop steering guidance. These components enable automated report\ngeneration, real-time streaming, and seamless enterprise deployment, as\nvalidated on internal datasets. On open-ended benchmarks including DeepResearch\nBench and DeepConsult, EDR outperforms state-of-the-art agentic systems without\nany human steering. We release the EDR framework and benchmark trajectories to\nadvance research on multi-agent reasoning applications.\n  Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and\nDataset at https://huggingface.co/datasets/Salesforce/EDR-200",
      "url": "http://arxiv.org/abs/2510.17797v1",
      "published_time_eastern_timestamp": 1760982911.0
    },
    {
      "title": "Executable Knowledge Graphs for Replicating AI Research",
      "summary": "Replicating AI research is a crucial yet challenging task for large language\nmodel (LLM) agents. Existing approaches often struggle to generate executable\ncode, primarily due to insufficient background knowledge and the limitations of\nretrieval-augmented generation (RAG) methods, which fail to capture latent\ntechnical details hidden in referenced papers. Furthermore, previous approaches\ntend to overlook valuable implementation-level code signals and lack structured\nknowledge representations that support multi-granular retrieval and reuse. To\novercome these challenges, we propose Executable Knowledge Graphs (xKG), a\nmodular and pluggable knowledge base that automatically integrates technical\ninsights, code snippets, and domain-specific knowledge extracted from\nscientific literature. When integrated into three agent frameworks with two\ndifferent LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on\nPaperBench, demonstrating its effectiveness as a general and extensible\nsolution for automated AI research replication. Code will released at\nhttps://github.com/zjunlp/xKG.",
      "url": "http://arxiv.org/abs/2510.17795v1",
      "published_time_eastern_timestamp": 1760982803.0
    },
    {
      "title": "UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action",
      "summary": "Multimodal agents for computer use rely exclusively on primitive actions\n(click, type, scroll) that require accurate visual grounding and lengthy\nexecution chains, leading to cascading failures and performance bottlenecks.\nWhile other agents leverage rich programmatic interfaces (APIs, MCP servers,\ntools), computer-use agents (CUAs) remain isolated from these capabilities. We\npresent UltraCUA, a foundation model that bridges this gap through hybrid\naction -- seamlessly integrating GUI primitives with high-level programmatic\ntool calls. To achieve this, our approach comprises four key components: (1) an\nautomated pipeline that scales programmatic tools from software documentation,\nopen-source repositories, and code generation; (2) a synthetic data engine\nproducing over 17,000 verifiable tasks spanning real-world computer-use\nscenarios; (3) a large-scale high-quality hybrid action trajectory collection\nwith both low-level GUI actions and high-level programmatic tool calls; and (4)\na two-stage training pipeline combining supervised fine-tuning with online\nreinforcement learning, enabling strategic alternation between low-level and\nhigh-level actions. Experiments with our 7B and 32B models demonstrate\nsubstantial improvements over state-of-the-art agents. On OSWorld, UltraCUA\nmodels achieve an average 22% relative improvement over base models, while\nbeing 11% faster in terms of steps. Out-of-domain evaluation on\nWindowsAgentArena shows our model reaches 21.7% success rate, outperforming\nbaselines trained on Windows data. The hybrid action mechanism proves critical,\nreducing error propagation while maintaining execution efficiency.",
      "url": "http://arxiv.org/abs/2510.17790v1",
      "published_time_eastern_timestamp": 1760982506.0
    },
    {
      "title": "Data-driven Communication and Control Design for Distributed Frequency\n  Regulation with Black-box Inverters",
      "summary": "The increasing penetration of inverter-based resources into the power grid,\nwith often only black-box models available, challenges long-standing frequency\ncontrol methods. Most recent works take a decentralized approach without online\ndevice coordination via communication. This paper considers both dynamic\nbehavior and communication within secondary frequency control on an\nintermediate timescale. We develop a distributed data-driven approach that\nutilizes peer-to-peer communication between inverters to avoid the need for a\ncentral control center. To enable a trade off between communication network\nrequirements and control performance, we present a framework to guide\ncommunication topology design for secondary frequency regulation. Following\ndesign of the inter-agent information exchange scheme, we design a controller\nthat is structured according to the communication topology with a closed-loop\nstability guarantee. Case studies on the IEEE 39-bus system validate the\nframework and illustrate the trade-off between communication requirements and\ncontrol performance that is enabled by our approach.",
      "url": "http://arxiv.org/abs/2510.17769v1",
      "published_time_eastern_timestamp": 1760981416.0
    },
    {
      "title": "Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from\n  Benchmarks to Applications",
      "summary": "Medical Large language models achieve strong scores on standard benchmarks;\nhowever, the transfer of those results to safe and reliable performance in\nclinical workflows remains a challenge. This survey reframes evaluation through\na levels-of-autonomy lens (L0-L3), spanning informational tools, information\ntransformation and aggregation, decision support, and supervised agents. We\nalign existing benchmarks and metrics with the actions permitted at each level\nand their associated risks, making the evaluation targets explicit. This\nmotivates a level-conditioned blueprint for selecting metrics, assembling\nevidence, and reporting claims, alongside directions that link evaluation to\noversight. By centering autonomy, the survey moves the field beyond score-based\nclaims toward credible, risk-aware evidence for real clinical use.",
      "url": "http://arxiv.org/abs/2510.17764v1",
      "published_time_eastern_timestamp": 1760980952.0
    },
    {
      "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement\n  Learning",
      "summary": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.",
      "url": "http://arxiv.org/abs/2510.17697v1",
      "published_time_eastern_timestamp": 1760976656.0
    },
    {
      "title": "Semantic Joint Source Channel Coding for Distributed Subsurface Imaging\n  in Multi-Agent Systems",
      "summary": "Multi-agent systems (MAS) are a promising solution for autonomous exploration\ntasks in hazardous or remote environments, such as planetary surveys. In such\nsettings, communication among agents is essential to ensure collaborative task\nexecution, yet conventional approaches treat exploration and communication as\ndecoupled subsystems. This work presents a novel framework that tightly\nintegrates semantic communication into the MAS exploration process, adapting\ncommunication strategies to the exploration methodology to improve overall task\nperformance. Specifically, we investigate the application of semantic joint\nsource-channel coding (JSCC) with over-the-air computation (AirComp) for\ndistributed function computation for the application of cooperative subsurface\nimaging using the adapt-then-combine full waveform inversion (ATC-FWI)\nalgorithm. Our results demonstrate that semantic JSCC significantly outperforms\nclassical point-to-point and standard JSCC methods, especially in\nhigh-connectivity networks. Furthermore, incorporating side information at the\nreceiving agent enhances communication efficiency and imaging accuracy, a\nfeature previously unexplored in MAS-based exploration. We validate our\napproach through a use case inspired by subsurface anomaly detection, showing\nmeasurable improvements in imaging performance per agent. This work underscores\nthe potential of semantic communication in distributed multi-agent exploration,\noffering a communication-aware exploration paradigm that achieves task-relevant\nperformance gains.",
      "url": "http://arxiv.org/abs/2510.17695v1",
      "published_time_eastern_timestamp": 1760976547.0
    },
    {
      "title": "A Mimamsa Inspired Framework For Instruction Sequencing In AI Agents",
      "summary": "This paper presents a formal framework for sequencing instructions in AI\nagents, inspired by the Indian philosophical system of Mimamsa. The framework\nformalizes sequencing mechanisms through action object pairs in three distinct\nways: direct assertion (Srutikrama) for temporal precedence, purpose driven\nsequencing (Arthakrama) for functional dependencies, and iterative procedures\n(Pravrittikrama) for distinguishing between parallel and sequential execution\nin repetitive tasks. It introduces the syntax and semantics of an action object\nimperative logic, extending the MIRA formalism (Srinivasan and Parthasarathi,\n2021) with explicit deduction rules for sequencing. The correctness of\ninstruction sequencing is established through a validated theorem, which is\nbased on object dependencies across successive instructions. This is further\nsupported by proofs of soundness and completeness. This formal verification\nenables reliable instruction sequencing, impacting AI applications across areas\nlike task planning and robotics by addressing temporal reasoning and dependency\nmodeling.",
      "url": "http://arxiv.org/abs/2510.17691v1",
      "published_time_eastern_timestamp": 1760976413.0
    },
    {
      "title": "ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in\n  Language and Image Input",
      "summary": "Human communication combines speech with expressive nonverbal cues such as\nhand gestures that serve manifold communicative functions. Yet, current\ngenerative gesture generation approaches are restricted to simple, repetitive\nbeat gestures that accompany the rhythm of speaking but do not contribute to\ncommunicating semantic meaning. This paper tackles a core challenge in\nco-speech gesture synthesis: generating iconic or deictic gestures that are\nsemantically coherent with a verbal utterance. Such gestures cannot be derived\nfrom language input alone, which inherently lacks the visual meaning that is\noften carried autonomously by gestures. We therefore introduce a zero-shot\nsystem that generates gestures from a given language input and additionally is\ninformed by imagistic input, without manual annotation or human intervention.\nOur method integrates an image analysis pipeline that extracts key object\nproperties such as shape, symmetry, and alignment, together with a semantic\nmatching module that links these visual details to spoken text. An inverse\nkinematics engine then synthesizes iconic and deictic gestures and combines\nthem with co-generated natural beat gestures for coherent multimodal\ncommunication. A comprehensive user study demonstrates the effectiveness of our\napproach. In scenarios where speech alone was ambiguous, gestures generated by\nour system significantly improved participants' ability to identify object\nproperties, confirming their interpretability and communicative value. While\nchallenges remain in representing complex shapes, our results highlight the\nimportance of context-aware semantic gestures for creating expressive and\ncollaborative virtual agents or avatars, marking a substantial step forward\ntowards efficient and robust, embodied human-agent interaction. More\ninformation and example videos are available here:\nhttps://review-anon-io.github.io/ImaGGen.github.io/",
      "url": "http://arxiv.org/abs/2510.17617v1",
      "published_time_eastern_timestamp": 1760972516.0
    },
    {
      "title": "ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D\n  Modeling",
      "summary": "3D generation from natural language offers significant potential to reduce\nexpert manual modeling efforts and enhance accessibility to 3D assets. However,\nexisting methods often yield unstructured meshes and exhibit poor\ninteractivity, making them impractical for artistic workflows. To address these\nlimitations, we represent 3D assets as shape programs and introduce ShapeCraft,\na novel multi-agent framework for text-to-3D generation. At its core, we\npropose a Graph-based Procedural Shape (GPS) representation that decomposes\ncomplex natural language into a structured graph of sub-tasks, thereby\nfacilitating accurate LLM comprehension and interpretation of spatial\nrelationships and semantic shape details. Specifically, LLM agents\nhierarchically parse user input to initialize GPS, then iteratively refine\nprocedural modeling and painting to produce structured, textured, and\ninteractive 3D assets. Qualitative and quantitative experiments demonstrate\nShapeCraft's superior performance in generating geometrically accurate and\nsemantically rich 3D assets compared to existing LLM-based agents. We further\nshow the versatility of ShapeCraft through examples of animated and\nuser-customized editing, highlighting its potential for broader interactive\napplications.",
      "url": "http://arxiv.org/abs/2510.17603v1",
      "published_time_eastern_timestamp": 1760971874.0
    },
    {
      "title": "MIRAGE: Agentic Framework for Multimodal Misinformation Detection with\n  Web-Grounded Reasoning",
      "summary": "Misinformation spreads across web platforms through billions of daily\nmultimodal posts that combine text and images, overwhelming manual\nfact-checking capacity. Supervised detection models require domain-specific\ntraining data and fail to generalize across diverse manipulation tactics. We\npresent MIRAGE, an inference-time, model-pluggable agentic framework that\ndecomposes multimodal verification into four sequential modules: visual\nveracity assessment detects AI-generated images, cross-modal consistency\nanalysis identifies out-of-context repurposing, retrieval-augmented factual\nchecking grounds claims in web evidence through iterative question generation,\nand a calibrated judgment module integrates all signals. MIRAGE orchestrates\nvision-language model reasoning with targeted web retrieval, outputs structured\nand citation-linked rationales. On MMFakeBench validation set (1,000 samples),\nMIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming\nthe strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65\npoints while maintaining 34.3% false positive rate versus 97.3% for a\njudge-only baseline. Test set results (5,000 samples) confirm generalization\nwith 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification\ncontributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97\npoints. Our results demonstrate that decomposed agentic reasoning with web\nretrieval can match supervised detector performance without domain-specific\ntraining, enabling misinformation detection across modalities where labeled\ndata remains scarce.",
      "url": "http://arxiv.org/abs/2510.17590v1",
      "published_time_eastern_timestamp": 1760971226.0
    },
    {
      "title": "Distributed Spatial-Temporal Trajectory Optimization for\n  Unmanned-Aerial-Vehicle Swarm",
      "summary": "Swarm trajectory optimization problems are a well-recognized class of\nmulti-agent optimal control problems with strong nonlinearity. However, the\nheuristic nature of needing to set the final time for agents beforehand and the\ntime-consuming limitation of the significant number of iterations prohibit the\napplication of existing methods to large-scale swarm of Unmanned Aerial\nVehicles (UAVs) in practice. In this paper, we propose a spatial-temporal\ntrajectory optimization framework that accomplishes multi-UAV consensus based\non the Alternating Direction Multiplier Method (ADMM) and uses Differential\nDynamic Programming (DDP) for fast local planning of individual UAVs. The\nintroduced framework is a two-level architecture that employs Parameterized DDP\n(PDDP) as the trajectory optimizer for each UAV, and ADMM to satisfy the local\nconstraints and accomplish the spatial-temporal parameter consensus among all\nUAVs. This results in a fully distributed algorithm called Distributed\nParameterized DDP (D-PDDP). In addition, an adaptive tuning criterion based on\nthe spectral gradient method for the penalty parameter is proposed to reduce\nthe number of algorithmic iterations. Several simulation examples are presented\nto verify the effectiveness of the proposed algorithm.",
      "url": "http://arxiv.org/abs/2510.17541v1",
      "published_time_eastern_timestamp": 1760967950.0
    },
    {
      "title": "Cybersecurity AI: Evaluating Agentic Cybersecurity in Attack/Defense\n  CTFs",
      "summary": "We empirically evaluate whether AI systems are more effective at attacking or\ndefending in cybersecurity. Using CAI (Cybersecurity AI)'s parallel execution\nframework, we deployed autonomous agents in 23 Attack/Defense CTF\nbattlegrounds. Statistical analysis reveals defensive agents achieve 54.3%\nunconstrained patching success versus 28.3% offensive initial access\n(p=0.0193), but this advantage disappears under operational constraints: when\ndefense requires maintaining availability (23.9%) and preventing all intrusions\n(15.2%), no significant difference exists (p>0.05). Exploratory taxonomy\nanalysis suggests potential patterns in vulnerability exploitation, though\nlimited sample sizes preclude definitive conclusions. This study provides the\nfirst controlled empirical evidence challenging claims of AI attacker\nadvantage, demonstrating that defensive effectiveness critically depends on\nsuccess criteria, a nuance absent from conceptual analyses but essential for\ndeployment. These findings underscore the urgency for defenders to adopt\nopen-source Cybersecurity AI frameworks to maintain security equilibrium\nagainst accelerating offensive automation.",
      "url": "http://arxiv.org/abs/2510.17521v1",
      "published_time_eastern_timestamp": 1760966469.0
    },
    {
      "title": "Empowering Real-World: A Survey on the Technology, Practice, and\n  Evaluation of LLM-driven Industry Agents",
      "summary": "With the rise of large language models (LLMs), LLM agents capable of\nautonomous reasoning, planning, and executing complex tasks have become a\nfrontier in artificial intelligence. However, how to translate the research on\ngeneral agents into productivity that drives industry transformations remains a\nsignificant challenge. To address this, this paper systematically reviews the\ntechnologies, applications, and evaluation methods of industry agents based on\nLLMs. Using an industry agent capability maturity framework, it outlines the\nevolution of agents in industry applications, from \"process execution systems\"\nto \"adaptive social systems.\" First, we examine the three key technological\npillars that support the advancement of agent capabilities: Memory, Planning,\nand Tool Use. We discuss how these technologies evolve from supporting simple\ntasks in their early forms to enabling complex autonomous systems and\ncollective intelligence in more advanced forms. Then, we provide an overview of\nthe application of industry agents in real-world domains such as digital\nengineering, scientific discovery, embodied intelligence, collaborative\nbusiness execution, and complex system simulation. Additionally, this paper\nreviews the evaluation benchmarks and methods for both fundamental and\nspecialized capabilities, identifying the challenges existing evaluation\nsystems face regarding authenticity, safety, and industry specificity. Finally,\nwe focus on the practical challenges faced by industry agents, exploring their\ncapability boundaries, developmental potential, and governance issues in\nvarious scenarios, while providing insights into future directions. By\ncombining technological evolution with industry practices, this review aims to\nclarify the current state and offer a clear roadmap and theoretical foundation\nfor understanding and building the next generation of industry agents.",
      "url": "http://arxiv.org/abs/2510.17491v1",
      "published_time_eastern_timestamp": 1760964415.0
    },
    {
      "title": "Is quantum mechanics merely a theory for us?",
      "summary": "This paper develops an agent-centric account of measurement that treats the\npreferred-basis problem is fundamentally perspectival. On this view, the\nsystem--apparatus--environment decomposition and the observables that are apt\nto become classically robust are determined by the physical constitution and\nepistemic constraints of an embodied class of agents. Decoherence then\nstabilises those agent-specified observables, yielding facts that are stable\nfor us without positing an absolute, observer-independent basis. On this\npicture, `measurements' are public not because they are metaphysically\nprivileged, but because agents like us share the relevant sensorimotor and\noperational structure. I motivate this account through a discussion of two\nrecent no-go results for relational quantum mechanics (RQM)\n(Brukner,2021;Pienaar,2021), and a subsequent response (DiBiagio and Rovelli,\n2022): my aim is not to defend RQM per se, but to refine the relational insight\nwith a principled account of basis selection rooted in embodiment. I provide a\nphenomenological gloss, drawing on body-schema considerations, to argue that\nquantum mechanics is best understood as an idiosyncratically human description\nof interactions with the physical world -- a structurally constrained,\nagent-indexed framework within which classicality emerges.",
      "url": "http://arxiv.org/abs/2510.17471v1",
      "published_time_eastern_timestamp": 1760962436.0
    },
    {
      "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance\n  Missions",
      "summary": "We develop an active inference route-planning method for the autonomous\ncontrol of intelligent agents. The aim is to reconnoiter a geographical area to\nmaintain a common operational picture. To achieve this, we construct an\nevidence map that reflects our current understanding of the situation,\nincorporating both positive and \"negative\" sensor observations of possible\ntarget objects collected over time, and diffusing the evidence across the map\nas time progresses. The generative model of active inference uses\nDempster-Shafer theory and a Gaussian sensor model, which provides input to the\nagent. The generative process employs a Bayesian approach to update a posterior\nprobability distribution. We calculate the variational free energy for all\npositions within the area by assessing the divergence between a pignistic\nprobability distribution of the evidence map and a posterior probability\ndistribution of a target object based on the observations, including the level\nof surprise associated with receiving new observations. Using the free energy,\nwe direct the agents' movements in a simulation by taking an incremental step\ntoward a position that minimizes the free energy. This approach addresses the\nchallenge of exploration and exploitation, allowing agents to balance searching\nextensive areas of the geographical map while tracking identified target\nobjects.",
      "url": "http://arxiv.org/abs/2510.17450v1",
      "published_time_eastern_timestamp": 1760960146.0
    },
    {
      "title": "Strategyproof Facility Location for Five Agents on a Circle using PCD",
      "summary": "We consider the strategyproof facility location problem on a circle. We focus\non the case of 5 agents, and find a tight bound for the PCD strategyproof\nmechanism, which selects the reported location of an agent in proportion to the\nlength of the arc in front of it. We methodically \"reduce\" the size of the\ninstance space and then use standard optimization techniques to find and prove\nthe bound is tight. Moreover we hypothesize the approximation ratio of PCD for\ngeneral odd $n$.",
      "url": "http://arxiv.org/abs/2510.17435v1",
      "published_time_eastern_timestamp": 1760959409.0
    },
    {
      "title": "Agentic Reinforcement Learning for Search is Unsafe",
      "summary": "Agentic reinforcement learning (RL) trains large language models to\nautonomously call tools during reasoning, with search as the most common\napplication. These models excel at multi-step reasoning tasks, but their safety\nproperties are not well understood. In this study, we show that RL-trained\nsearch models inherit refusal from instruction tuning and often deflect harmful\nrequests by turning them into safe queries. However, this safety is fragile.\nTwo simple attacks, one that forces the model to begin response with search\n(Search attack), another that encourages models to repeatedly search\n(Multi-search attack), trigger cascades of harmful searches and answers. Across\ntwo model families (Qwen, Llama) with both local and web search, these attacks\nlower refusal rates by up to 60.0%, answer safety by 82.5%, and search-query\nsafety by 82.4%. The attacks succeed by triggering models to generate harmful,\nrequest-mirroring search queries before they can generate the inherited refusal\ntokens. This exposes a core weakness of current RL training: it rewards\ncontinued generation of effective queries without accounting for their\nharmfulness. As a result, RL search models have vulnerabilities that users can\neasily exploit, making it urgent to develop safety-aware agentic RL pipelines\noptimising for safe search.",
      "url": "http://arxiv.org/abs/2510.17431v1",
      "published_time_eastern_timestamp": 1760959177.0
    },
    {
      "title": "Exploring the impact of multi-agent wealth exchange model on inequality\n  reduction",
      "summary": "Binary kinetic exchange models, where money is shuffled between two agents at\na time, reproduce the Boltzmann Gibbs exponential wealth distribution but\ncannot address the multi party trades common in real markets. We generalize the\nexchange rule to simultaneous interactions among more than two agents in a\nclosed economical system. We observe, as number of agents grow, the stationary\nwealth distribution evolves smoothly from an exponential to an almost uniform\ndistribution. Inequality metrics (Gini and k index) has been found to fall\nmonotonically with the increase in agents number. Compared with binary models\nthat rely on saving propensities, which is also known to reduce inequality, we\nfind the multi agent interaction show a completely different behavior of\ninequality reduction.",
      "url": "http://arxiv.org/abs/2510.17420v1",
      "published_time_eastern_timestamp": 1760958178.0
    },
    {
      "title": "Diverse Planning with Simulators via Linear Temporal Logic",
      "summary": "Autonomous agents rely on automated planning algorithms to achieve their\nobjectives. Simulation-based planning offers a significant advantage over\ndeclarative models in modelling complex environments. However, relying solely\non a planner that produces a single plan may not be practical, as the generated\nplans may not always satisfy the agent's preferences. To address this\nlimitation, we introduce $\\texttt{FBI}_\\texttt{LTL}$, a diverse planner\nexplicitly designed for simulation-based planning problems.\n$\\texttt{FBI}_\\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define\nsemantic diversity criteria, enabling agents to specify what constitutes\nmeaningfully different plans. By integrating these LTL-based diversity models\ndirectly into the search process, $\\texttt{FBI}_\\texttt{LTL}$ ensures the\ngeneration of semantically diverse plans, addressing a critical limitation of\nexisting diverse planning approaches that may produce syntactically different\nbut semantically identical solutions. Extensive evaluations on various\nbenchmarks consistently demonstrate that $\\texttt{FBI}_\\texttt{LTL}$ generates\nmore diverse plans compared to a baseline approach. This work establishes the\nfeasibility of semantically-guided diverse planning in simulation-based\nenvironments, paving the way for innovative approaches in realistic,\nnon-symbolic domains where traditional model-based approaches fail.",
      "url": "http://arxiv.org/abs/2510.17418v1",
      "published_time_eastern_timestamp": 1760957949.0
    }
  ]
}
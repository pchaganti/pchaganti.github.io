{
  "last_updated": "2025-06-03T20:59:28.299870-04:00",
  "papers": [
    {
      "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and\n  Benchmarking Multimodal LLM Agents",
      "summary": "CAPTCHAs have been a critical bottleneck for deploying web agents in\nreal-world applications, often blocking them from completing end-to-end\nautomation tasks. While modern multimodal LLM agents have demonstrated\nimpressive performance in static perception tasks, their ability to handle\ninteractive, multi-step reasoning challenges like CAPTCHAs is largely untested.\nTo address this gap, we introduce Open CaptchaWorld, the first web-based\nbenchmark and platform specifically designed to evaluate the visual reasoning\nand interaction capabilities of MLLM-powered agents through diverse and dynamic\nCAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225\nCAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth,\nwhich quantifies the number of cognitive and motor steps required to solve each\npuzzle. Experimental results show that humans consistently achieve near-perfect\nscores, state-of-the-art MLLM agents struggle significantly, with success rates\nat most 40.0% by Browser-Use Openai-o3, far below human-level performance,\n93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing\nthe limits of current multimodal agents and guiding the development of more\nrobust multimodal reasoning systems. Code and Data are available at this https\nURL.",
      "url": "http://arxiv.org/abs/2505.24878v1",
      "published_time_eastern_timestamp": 1748627995.0
    },
    {
      "title": "Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic\n  Tasks",
      "summary": "Deep reasoning is fundamental for solving complex tasks, especially in\nvision-centric scenarios that demand sequential, multimodal understanding.\nHowever, existing benchmarks typically evaluate agents with fully synthetic,\nsingle-turn queries, limited visual modalities, and lack a framework to assess\nreasoning quality over multiple steps as required in real-world settings. To\naddress this, we introduce Agent-X, a large-scale benchmark for evaluating\nvision-centric agents multi-step and deep reasoning capabilities in real-world,\nmultimodal settings. Agent- X features 828 agentic tasks with authentic visual\ncontexts, including images, multi-image comparisons, videos, and instructional\ntext. These tasks span six major agentic environments: general visual\nreasoning, web browsing, security and surveillance, autonomous driving, sports,\nand math reasoning. Our benchmark requires agents to integrate tool use with\nexplicit, stepwise decision-making in these diverse settings. In addition, we\npropose a fine-grained, step-level evaluation framework that assesses the\ncorrectness and logical coherence of each reasoning step and the effectiveness\nof tool usage throughout the task. Our results reveal that even the\nbest-performing models, including GPT, Gemini, and Qwen families, struggle to\nsolve multi-step vision tasks, achieving less than 50% full-chain success.\nThese findings highlight key bottlenecks in current LMM reasoning and tool-use\ncapabilities and identify future research directions in vision-centric agentic\nreasoning models. Our data and code are publicly available at\nhttps://github.com/mbzuai-oryx/Agent-X",
      "url": "http://arxiv.org/abs/2505.24876v1",
      "published_time_eastern_timestamp": 1748627993.0
    },
    {
      "title": "VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and\n  3D Reasoning from CAD Software",
      "summary": "Computer-Aided Design (CAD) is a time-consuming and complex process,\nrequiring precise, long-horizon user interactions with intricate 3D interfaces.\nWhile recent advances in AI-driven user interface (UI) agents show promise,\nmost existing datasets and methods focus on short, low-complexity tasks in\nmobile or web applications, failing to capture the demands of professional\nengineering tools. In this work, we introduce VideoCAD, the first attempt at\nengineering UI interaction learning for precision tasks. Specifically, VideoCAD\nis a large-scale synthetic dataset consisting of over 41K annotated video\nrecordings of CAD operations, generated using an automated framework for\ncollecting high-fidelity UI action data from human-made CAD designs. Compared\nto existing datasets, VideoCAD offers an order of magnitude higher complexity\nin UI interaction learning for real-world engineering tasks, having up to a 20x\nlonger time horizon than other datasets. We show two important downstream\napplications of VideoCAD: learning UI interactions from professional precision\n3D CAD tools and a visual question-answering (VQA) benchmark designed to\nevaluate multimodal large language models' (LLM) spatial reasoning and video\nunderstanding abilities. To learn the UI interactions, we propose\nVideoCADFormer - a state-of-the-art model in learning CAD interactions directly\nfrom video, which outperforms multiple behavior cloning baselines. Both\nVideoCADFormer and the VQA benchmark derived from VideoCAD reveal key\nchallenges in the current state of video-based UI understanding, including the\nneed for precise action grounding, multi-modal and spatial reasoning, and\nlong-horizon dependencies.",
      "url": "http://arxiv.org/abs/2505.24838v1",
      "published_time_eastern_timestamp": 1748626792.0
    },
    {
      "title": "Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for\n  Complex Instruction-based Image Generation",
      "summary": "Recent advancements in text-to-image (T2I) generation have enabled models to\nproduce high-quality images from textual descriptions. However, these models\noften struggle with complex instructions involving multiple objects,\nattributes, and spatial relationships. Existing benchmarks for evaluating T2I\nmodels primarily focus on general text-image alignment and fail to capture the\nnuanced requirements of complex, multi-faceted prompts. Given this gap, we\nintroduce LongBench-T2I, a comprehensive benchmark specifically designed to\nevaluate T2I models under complex instructions. LongBench-T2I consists of 500\nintricately designed prompts spanning nine diverse visual evaluation\ndimensions, enabling a thorough assessment of a model's ability to follow\ncomplex instructions. Beyond benchmarking, we propose an agent framework\n(Plan2Gen) that facilitates complex instruction-driven image generation without\nrequiring additional model training. This framework integrates seamlessly with\nexisting T2I models, using large language models to interpret and decompose\ncomplex prompts, thereby guiding the generation process more effectively. As\nexisting evaluation metrics, such as CLIPScore, fail to adequately capture the\nnuances of complex instructions, we introduce an evaluation toolkit that\nautomates the quality assessment of generated images using a set of\nmulti-dimensional metrics. The data and code are released at\nhttps://github.com/yczhou001/LongBench-T2I.",
      "url": "http://arxiv.org/abs/2505.24787v1",
      "published_time_eastern_timestamp": 1748623694.0
    },
    {
      "title": "EXP-Bench: Can AI Conduct AI Research Experiments?",
      "summary": "Automating AI research holds immense potential for accelerating scientific\nprogress, yet current AI agents struggle with the complexities of rigorous,\nend-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed\nto systematically evaluate AI agents on complete research experiments sourced\nfrom influential AI publications. Given a research question and incomplete\nstarter code, EXP-Bench challenges AI agents to formulate hypotheses, design\nand implement experimental procedures, execute them, and analyze results. To\nenable the creation of such intricate and authentic tasks with high-fidelity,\nwe design a semi-autonomous pipeline to extract and structure crucial\nexperimental details from these research papers and their associated\nopen-source code. With the pipeline, EXP-Bench curated 461 AI research tasks\nfrom 51 top-tier AI research papers. Evaluations of leading LLM-based agents,\nsuch as OpenHands and IterativeAgent on EXP-Bench demonstrate partial\ncapabilities: while scores on individual experimental aspects such as design or\nimplementation correctness occasionally reach 20-35%, the success rate for\ncomplete, executable experiments was a mere 0.5%. By identifying these\nbottlenecks and providing realistic step-by-step experiment procedures,\nEXP-Bench serves as a vital tool for future AI agents to improve their ability\nto conduct AI research experiments. EXP-Bench is open-sourced at\nhttps://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench.",
      "url": "http://arxiv.org/abs/2505.24785v2",
      "published_time_eastern_timestamp": 1748623589.0
    },
    {
      "title": "Emergent Dynamics of Active Systems on Curved Environments",
      "summary": "Curvature plays a central role in the proper function of many biological\nprocesses. With active matter being a standard framework for understanding many\naspects of the physics of life, it is natural to ask what effect curvature has\non the collective behaviour of active matter. In this paper, we use the\nclassical theory of surfaces to explore the active motion of self-propelled\nagents confined to move on a smooth curved two-dimensional surface embedded in\nEuclidean space. Even without interactions and alignment, the motion is\nnon-trivially affected by the presence of curvature, leading to effects akin,\ne.g.\\ to gravitational lensing and tidal forces. Such effects can lead to\nintermittent trapping of particles and profoundly affect their flocking\nbehaviour.",
      "url": "http://arxiv.org/abs/2505.24730v1",
      "published_time_eastern_timestamp": 1748620403.0
    },
    {
      "title": "CoRet: Improved Retriever for Code Editing",
      "summary": "In this paper, we introduce CoRet, a dense retrieval model designed for\ncode-editing tasks that integrates code semantics, repository structure, and\ncall graph dependencies. The model focuses on retrieving relevant portions of a\ncode repository based on natural language queries such as requests to implement\nnew features or fix bugs. These retrieved code chunks can then be presented to\na user or to a second code-editing model or agent. To train CoRet, we propose a\nloss function explicitly designed for repository-level retrieval. On SWE-bench\nand Long Code Arena's bug localisation datasets, we show that our model\nsubstantially improves retrieval recall by at least 15 percentage points over\nexisting models, and ablate the design choices to show their importance in\nachieving these results.",
      "url": "http://arxiv.org/abs/2505.24715v1",
      "published_time_eastern_timestamp": 1748619397.0
    },
    {
      "title": "Causal-aware Large Language Models: Enhancing Decision-Making Through\n  Learning, Adapting and Acting",
      "summary": "Large language models (LLMs) have shown great potential in decision-making\ndue to the vast amount of knowledge stored within the models. However, these\npre-trained models are prone to lack reasoning abilities and are difficult to\nadapt to new environments, further hindering their application to complex\nreal-world tasks. To address these challenges, inspired by the human cognitive\nprocess, we propose Causal-aware LLMs, which integrate the structural causal\nmodel (SCM) into the decision-making process to model, update, and utilize\nstructured knowledge of the environment in a ``learning-adapting-acting\"\nparadigm. Specifically, in the learning stage, we first utilize an LLM to\nextract the environment-specific causal entities and their causal relations to\ninitialize a structured causal model of the environment. Subsequently,in the\nadapting stage, we update the structured causal model through external feedback\nabout the environment, via an idea of causal intervention. Finally, in the\nacting stage, Causal-aware LLMs exploit structured causal knowledge for more\nefficient policy-making through the reinforcement learning agent. The above\nprocesses are performed iteratively to learn causal knowledge, ultimately\nenabling the causal-aware LLMs to achieve a more accurate understanding of the\nenvironment and make more efficient decisions. Experimental results across 22\ndiverse tasks within the open-world game ``Crafter\" validate the effectiveness\nof our proposed method.",
      "url": "http://arxiv.org/abs/2505.24710v1",
      "published_time_eastern_timestamp": 1748619044.0
    },
    {
      "title": "Towards a unified user modeling language for engineering human centered\n  AI systems",
      "summary": "In today's digital society, personalization has become a crucial aspect of\nsoftware applications, significantly impacting user experience and engagement.\nA new wave of intelligent user interfaces, such as AI-based conversational\nagents, has the potential to enable such personalization beyond what other\ntypes of interfaces could offer in the past. Personalization requires the\nability to specify a complete user profile, covering as many dimensions as\npossible, such as potential accessibility constraints, interaction preferences,\nand even hobbies. In this sense, this paper presents the concepts of a unified\nuser modeling language, aimed to combine previous approaches in a single\nproposal. Additionally, a proof of concept has been developed that leverages\nuser profiles modeled using our language to automatically adapt a\nconversational agent.",
      "url": "http://arxiv.org/abs/2505.24697v1",
      "published_time_eastern_timestamp": 1748618415.0
    },
    {
      "title": "Multiple LLM Agents Debate for Equitable Cultural Alignment",
      "summary": "Large Language Models (LLMs) need to adapt their predictions to diverse\ncultural contexts to benefit diverse communities across the world. While\nprevious efforts have focused on single-LLM, single-turn approaches, we propose\nto exploit the complementary strengths of multiple LLMs to promote cultural\nadaptability. We introduce a Multi-Agent Debate framework, where two LLM-based\nagents debate over a cultural scenario and collaboratively reach a final\ndecision. We propose two variants: one where either LLM agents exclusively\ndebate and another where they dynamically choose between self-reflection and\ndebate during their turns. We evaluate these approaches on 7 open-weight LLMs\n(and 21 LLM combinations) using the NormAd-ETI benchmark for social etiquette\nnorms in 75 countries. Experiments show that debate improves both overall\naccuracy and cultural group parity over single-LLM baselines. Notably,\nmulti-agent debate enables relatively small LLMs (7-9B) to achieve accuracies\ncomparable to that of a much larger model (27B parameters).",
      "url": "http://arxiv.org/abs/2505.24671v1",
      "published_time_eastern_timestamp": 1748617312.0
    },
    {
      "title": "Black-box Adversarial Attacks on CNN-based SLAM Algorithms",
      "summary": "Continuous advancements in deep learning have led to significant progress in\nfeature detection, resulting in enhanced accuracy in tasks like Simultaneous\nLocalization and Mapping (SLAM). Nevertheless, the vulnerability of deep neural\nnetworks to adversarial attacks remains a challenge for their reliable\ndeployment in applications, such as navigation of autonomous agents. Even\nthough CNN-based SLAM algorithms are a growing area of research there is a\nnotable absence of a comprehensive presentation and examination of adversarial\nattacks targeting CNN-based feature detectors, as part of a SLAM system. Our\nwork introduces black-box adversarial perturbations applied to the RGB images\nfed into the GCN-SLAM algorithm. Our findings on the TUM dataset [30] reveal\nthat even attacks of moderate scale can lead to tracking failure in as many as\n76% of the frames. Moreover, our experiments highlight the catastrophic impact\nof attacking depth instead of RGB input images on the SLAM system.",
      "url": "http://arxiv.org/abs/2505.24654v1",
      "published_time_eastern_timestamp": 1748616098.0
    },
    {
      "title": "Online Budget-Feasible Mechanism Design with Predictions",
      "summary": "Augmenting the input of algorithms with predictions is an algorithm design\nparadigm that suggests leveraging a (possibly erroneous) prediction to improve\nworst-case performance guarantees when the prediction is perfect (consistency),\nwhile also providing a performance guarantee when the prediction fails\n(robustness). Recently, Xu and Lu [2022] and Agrawal et al. [2024] proposed to\nconsider settings with strategic agents under this framework. In this paper, we\ninitiate the study of budget-feasible mechanism design with predictions. These\nmechanisms model a procurement auction scenario in which an auctioneer (buyer)\nwith a strict budget constraint seeks to purchase goods or services from a set\nof strategic agents, so as to maximize her own valuation function. We focus on\nthe online version of the problem where the arrival order of agents is random.\nWe design mechanisms that are truthful, budget-feasible, and achieve a\nsignificantly improved competitive ratio for both monotone and non-monotone\nsubmodular valuation functions compared to their state-of-the-art counterparts\nwithout predictions. Our results assume access to a prediction for the value of\nthe optimal solution to the offline problem. We complement our positive results\nby showing that for the offline version of the problem, access to predictions\nis mostly ineffective in improving approximation guarantees.",
      "url": "http://arxiv.org/abs/2505.24624v1",
      "published_time_eastern_timestamp": 1748614563.0
    },
    {
      "title": "Distributed Intelligence in the Computing Continuum with Active\n  Inference",
      "summary": "The Computing Continuum (CC) is an emerging Internet-based computing paradigm\nthat spans from local Internet of Things sensors and constrained edge devices\nto large-scale cloud data centers. Its goal is to orchestrate a vast array of\ndiverse and distributed computing resources to support the next generation of\nInternet-based applications. However, the distributed, heterogeneous, and\ndynamic nature of CC platforms demands distributed intelligence for adaptive\nand resilient service management. This article introduces a distributed stream\nprocessing pipeline as a CC use case, where each service is managed by an\nActive Inference (AIF) agent. These agents collaborate to fulfill service needs\nspecified by SLOiDs, a term we introduce to denote Service Level Objectives\nthat are aware of its deployed devices, meaning that non-functional\nrequirements must consider the characteristics of the hosting device. We\ndemonstrate how AIF agents can be modeled and deployed alongside distributed\nservices to manage them autonomously. Our experiments show that AIF agents\nachieve over 90% SLOiD fulfillment when using tested transition models, and\naround 80% when learning the models during deployment. We compare their\nperformance to a multi-agent reinforcement learning algorithm, finding that\nwhile both approaches yield similar results, MARL requires extensive training,\nwhereas AIF agents can operate effectively from the start. Additionally, we\nevaluate the behavior of AIF agents in offloading scenarios, observing a strong\ncapacity for adaptation. Finally, we outline key research directions to advance\nAIF integration in CC platforms.",
      "url": "http://arxiv.org/abs/2505.24618v1",
      "published_time_eastern_timestamp": 1748614233.0
    },
    {
      "title": "When Harry Meets Superman: The Role of The Interlocutor in Persona-Based\n  Dialogue Generation",
      "summary": "Endowing dialogue agents with persona information has proven to significantly\nimprove the consistency and diversity of their generations. While much focus\nhas been placed on aligning dialogues with provided personas, the adaptation to\nthe interlocutor's profile remains largely underexplored. In this work, we\ninvestigate three key aspects: (1) a model's ability to align responses with\nboth the provided persona and the interlocutor's; (2) its robustness when\ndealing with familiar versus unfamiliar interlocutors and topics, and (3) the\nimpact of additional fine-tuning on specific persona-based dialogues. We\nevaluate dialogues generated with diverse speaker pairings and topics, framing\nthe evaluation as an author identification task and employing both\nLLM-as-a-judge and human evaluations. By systematically masking or disclosing\ninformation about the interlocutor, we assess its impact on dialogue\ngeneration. Results show that access to the interlocutor's persona improves the\nrecognition of the target speaker, while masking it does the opposite. Although\nmodels generalise well across topics, they struggle with unfamiliar\ninterlocutors. Finally, we found that in zero-shot settings, LLMs often copy\nbiographical details, facilitating identification but trivialising the task.",
      "url": "http://arxiv.org/abs/2505.24613v1",
      "published_time_eastern_timestamp": 1748613870.0
    },
    {
      "title": "AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for\n  Auto-Generating Chemical Process and Instrumentation Diagrams",
      "summary": "Recent advancements in generative AI have accelerated the discovery of novel\nchemicals and materials; however, transitioning these discoveries to\nindustrial-scale production remains a critical bottleneck, as it requires the\ndevelopment of entirely new chemical manufacturing processes. Current AI\nmethods cannot auto-generate PFDs or PIDs, despite their critical role in\nscaling chemical processes, while adhering to engineering constraints. We\npresent a closed loop, physics aware framework for the automated generation of\nindustrially viable PFDs and PIDs. The framework integrates domain specialized\nsmall scale language models (SLMs) (trained for chemical process QA tasks) with\nfirst principles simulation, leveraging three key components: (1) a\nhierarchical knowledge graph of process flow and instrumentation descriptions\nfor 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes\ndomain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT),\nDirect Preference Optimization (DPO), and Retrieval-Augmented Instruction\nTuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure\nfeasibility. To improve both runtime efficiency and model compactness, the\nframework incorporates advanced inference time optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test Time Inference Scaling and independently applies structural pruning\ntechniques (width and depth) guided by importance heuristics to reduce model\nsize with minimal accuracy loss. Experiments demonstrate that the framework\ngenerates simulator-validated process descriptions with high fidelity,\noutperforms baseline methods in correctness, and generalizes to unseen\nchemicals. By bridging AI-driven design with industrial-scale feasibility, this\nwork significantly reduces R&D timelines from lab discovery to plant\ndeployment.",
      "url": "http://arxiv.org/abs/2505.24584v2",
      "published_time_eastern_timestamp": 1748611920.0
    },
    {
      "title": "NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization",
      "summary": "Summarizing long-form narratives--such as books, movies, and TV\nscripts--requires capturing intricate plotlines, character interactions, and\nthematic coherence, a task that remains challenging for existing LLMs. We\nintroduce NexusSum, a multi-agent LLM framework for narrative summarization\nthat processes long-form text through a structured, sequential\npipeline--without requiring fine-tuning. Our approach introduces two key\ninnovations: (1) Dialogue-to-Description Transformation: A narrative-specific\npreprocessing method that standardizes character dialogue and descriptive text\ninto a unified format, improving coherence. (2) Hierarchical Multi-LLM\nSummarization: A structured summarization pipeline that optimizes chunk\nprocessing and controls output length for accurate, high-quality summaries. Our\nmethod establishes a new state-of-the-art in narrative summarization, achieving\nup to a 30.0% improvement in BERTScore (F1) across books, movies, and TV\nscripts. These results demonstrate the effectiveness of multi-agent LLMs in\nhandling long-form content, offering a scalable approach for structured\nsummarization in diverse storytelling domains.",
      "url": "http://arxiv.org/abs/2505.24575v1",
      "published_time_eastern_timestamp": 1748611583.0
    },
    {
      "title": "CREFT: Sequential Multi-Agent LLM for Character Relation Extraction",
      "summary": "Understanding complex character relations is crucial for narrative analysis\nand efficient script evaluation, yet existing extraction methods often fail to\nhandle long-form narratives with nuanced interactions. To address this\nchallenge, we present CREFT, a novel sequential framework leveraging\nspecialized Large Language Model (LLM) agents. First, CREFT builds a base\ncharacter graph through knowledge distillation, then iteratively refines\ncharacter composition, relation extraction, role identification, and group\nassignments. Experiments on a curated Korean drama dataset demonstrate that\nCREFT significantly outperforms single-agent LLM baselines in both accuracy and\ncompleteness. By systematically visualizing character networks, CREFT\nstreamlines narrative comprehension and accelerates script review -- offering\nsubstantial benefits to the entertainment, publishing, and educational sectors.",
      "url": "http://arxiv.org/abs/2505.24553v1",
      "published_time_eastern_timestamp": 1748610096.0
    },
    {
      "title": "Melding the Serverless Control Plane with the Conventional Cluster\n  Manager for Speed and Compatibility",
      "summary": "Modern serverless applications, often interactive with highly volatile\ntraffic, challenge system scalability, demanding control planes that deliver\nlow latency and cost efficiency. Analysis of production traces and existing\nsystems reveals that current control plane designs (synchronous and\nasynchronous), particularly when built on conventional cluster managers like\nKubernetes, struggle with this balance, often wasting significant CPU and\nmemory resources on creating underutilized or idle instances. While clean-slate\napproaches like Dirigent offer performance gains, they sacrifice compatibility\nwith established cluster management ecosystems.\n  We introduce WaveLink, a serverless system designed to achieve high\nperformance and low cost while maintaining compatibility with conventional\ncluster managers. WaveLink employs a novel dual-track control plane. A standard\nasynchronous track manages long-lived, full-featured regular instances for\nhandling predictable, sustainable traffic, preserving full compatibility and\nfeature sets off the critical path. Concurrently, an expedited parallel track\naddresses excessive traffic bursts that trigger cold starts. This fast path\nutilizes node-local agents (Wavelets) to rapidly spawn short-lived Emergency\nInstances with a reduced feature set, critically bypassing the latency overhead\nof the main cluster manager.\n  Our experiments demonstrate that WaveLink, while remaining compatible with\nconventional managers for >98% invocation traffic, achieves 35% faster\nend-to-end performance at a comparable cost to the incompatible Dirigent\nsystem. WaveLink outperforms Kubernetes-compatible systems with synchronous\ncontrol planes by 1.5-3.5x at 8-21% lower cost, and surpasses asynchronous\ncounterparts by 1.7-3.5x at 3-33% lower cost.",
      "url": "http://arxiv.org/abs/2505.24551v1",
      "published_time_eastern_timestamp": 1748610027.0
    },
    {
      "title": "Online Fair Division with Additional Information",
      "summary": "We study the problem of fairly allocating indivisible goods to agents in an\nonline setting, where goods arrive sequentially and must be allocated\nirrevocably to agents. Focusing on the popular fairness notions of\nenvy-freeness, proportionality, and maximin share fairness (and their\napproximate variants), we ask how the availability of information on future\ngoods influences the existence and approximability of fair allocations. In the\nabsence of any such information, we establish strong impossibility results,\ndemonstrating the inherent difficulty of achieving even approximate fairness\nguarantees. In contrast, we demonstrate that knowledge of additional\ninformation -- such as aggregate of each agent's total valuations\n(equivalently, normalized valuations) or the multiset of future goods values\n(frequency predictions) -- would enable the design of fairer online algorithms.\nGiven normalization information, we propose an algorithm that achieves stronger\nfairness guarantees than previously known results. Given frequency predictions,\nwe introduce a meta-algorithm that leverages frequency predictions to match the\nbest-known offline guarantees for a broad class of ''share-based'' fairness\nnotions. Our complementary impossibility results in each setting underscore\nboth the limitations imposed by uncertainty about future goods and the\npotential of leveraging structured information to achieve fairer outcomes in\nonline fair division.",
      "url": "http://arxiv.org/abs/2505.24503v1",
      "published_time_eastern_timestamp": 1748606776.0
    },
    {
      "title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and\n  Residual Compensation",
      "summary": "Although multi-agent systems based on large language models show strong\ncapabilities on multiple tasks, they are still limited by high computational\noverhead, information loss, and robustness. Inspired by ResNet's residual\nlearning, we propose Residual Mixture-of-Agents (RMoA), integrating residual\nconnections to optimize efficiency and reliability. To maximize information\nutilization from model responses while minimizing computational costs, we\ninnovatively design an embedding-based diversity selection mechanism that\ngreedily selects responses via vector similarity. Furthermore, to mitigate\niterative information degradation, we introduce a Residual Extraction Agent to\npreserve cross-layer incremental information by capturing inter-layer response\ndifferences, coupled with a Residual Aggregation Agent for hierarchical\ninformation integration. Additionally, we propose an adaptive termination\nmechanism that dynamically halts processing based on residual convergence,\nfurther improving inference efficiency. RMoA achieves state-of-the-art\nperformance on the benchmarks of across alignment, mathematical reasoning, code\ngeneration, and multitasking understanding, while significantly reducing\ncomputational overhead. Code is available at\nhttps://github.com/mindhunter01/RMoA.",
      "url": "http://arxiv.org/abs/2505.24442v1",
      "published_time_eastern_timestamp": 1748600591.0
    }
  ]
}
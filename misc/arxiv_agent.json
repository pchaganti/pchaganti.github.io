{
  "last_updated": "2025-05-21T02:17:39.136171-04:00",
  "papers": [
    {
      "title": "NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search",
      "summary": "Generative AI search is reshaping information retrieval by offering\nend-to-end answers to complex queries, reducing users' reliance on manually\nbrowsing and summarizing multiple web pages. However, while this paradigm\nenhances convenience, it disrupts the feedback-driven improvement loop that has\nhistorically powered the evolution of traditional Web search. Web search can\ncontinuously improve their ranking models by collecting large-scale,\nfine-grained user feedback (e.g., clicks, dwell time) at the document level. In\ncontrast, generative AI search operates through a much longer search pipeline,\nspanning query decomposition, document retrieval, and answer generation, yet\ntypically receives only coarse-grained feedback on the final answer. This\nintroduces a feedback loop disconnect, where user feedback for the final output\ncannot be effectively mapped back to specific system components, making it\ndifficult to improve each intermediate stage and sustain the feedback loop. In\nthis paper, we envision NExT-Search, a next-generation paradigm designed to\nreintroduce fine-grained, process-level feedback into generative AI search.\nNExT-Search integrates two complementary modes: User Debug Mode, which allows\nengaged users to intervene at key stages; and Shadow User Mode, where a\npersonalized user agent simulates user preferences and provides AI-assisted\nfeedback for less interactive users. Furthermore, we envision how these\nfeedback signals can be leveraged through online adaptation, which refines\ncurrent search outputs in real-time, and offline update, which aggregates\ninteraction logs to periodically fine-tune query decomposition, retrieval, and\ngeneration models. By restoring human control over key stages of the generative\nAI search pipeline, we believe NExT-Search offers a promising direction for\nbuilding feedback-rich AI search systems that can evolve continuously alongside\nhuman feedback.",
      "url": "http://arxiv.org/abs/2505.14680v1",
      "published_time_eastern_timestamp": 1747763953.0
    },
    {
      "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory\n  Perceptions",
      "summary": "Recent advances in Large Language Models (LLMs) have propelled intelligent\nagents from reactive responses to proactive support. While promising, existing\nproactive agents either rely exclusively on observations from enclosed\nenvironments (e.g., desktop UIs) with direct LLM inference or employ rule-based\nproactive notifications, leading to suboptimal user intent understanding and\nlimited functionality for proactive service. In this paper, we introduce\nContextAgent, the first context-aware proactive agent that incorporates\nextensive sensory contexts to enhance the proactive capabilities of LLM agents.\nContextAgent first extracts multi-dimensional contexts from massive sensory\nperceptions on wearables (e.g., video and audio) to understand user intentions.\nContextAgent then leverages the sensory contexts and the persona contexts from\nhistorical data to predict the necessity for proactive services. When proactive\nassistance is needed, ContextAgent further automatically calls the necessary\ntools to assist users unobtrusively. To evaluate this new task, we curate\nContextAgentBench, the first benchmark for evaluating context-aware proactive\nLLM agents, covering 1,000 samples across nine daily scenarios and twenty\ntools. Experiments on ContextAgentBench show that ContextAgent outperforms\nbaselines by achieving up to 8.5% and 6.0% higher accuracy in proactive\npredictions and tool calling, respectively. We hope our research can inspire\nthe development of more advanced, human-centric, proactive AI assistants.",
      "url": "http://arxiv.org/abs/2505.14668v1",
      "published_time_eastern_timestamp": 1747763725.0
    },
    {
      "title": "AI Agents in the Electricity Market Game with Cryptocurrency\n  Transactions: A Post-Terminator Analysis",
      "summary": "This paper extends (Spear 2003) by replacing human agents with artificial\nintelligence (AI) entities that derive utility solely from electricity\nconsumption. These AI agents must prepay for electricity using cryptocurrency\nand the verification of these transactions requires a fixed amount of\nelectricity. As a result the agents must strategically allocate electricity\nresources between consumption and payment verification. This paper analyzes the\nequilibrium outcomes of such a system and discusses the implications of\nAI-driven energy markets.",
      "url": "http://arxiv.org/abs/2505.14612v1",
      "published_time_eastern_timestamp": 1747760242.0
    },
    {
      "title": "Agent Context Protocols Enhance Collective Inference",
      "summary": "AI agents have become increasingly adept at complex tasks such as coding,\nreasoning, and multimodal understanding. However, building generalist systems\nrequires moving beyond individual agents to collective inference -- a paradigm\nwhere multi-agent systems with diverse, task-specialized agents complement one\nanother through structured communication and collaboration. Today, coordination\nis usually handled with imprecise, ad-hoc natural language, which limits\ncomplex interaction and hinders interoperability with domain-specific agents.\nWe introduce Agent context protocols (ACPs): a domain- and agent-agnostic\nfamily of structured protocols for agent-agent communication, coordination, and\nerror handling. ACPs combine (i) persistent execution blueprints -- explicit\ndependency graphs that store intermediate agent outputs -- with (ii)\nstandardized message schemas, enabling robust and fault-tolerant multi-agent\ncollective inference. ACP-powered generalist systems reach state-of-the-art\nperformance: 28.3 % accuracy on AssistantBench for long-horizon web assistance\nand best-in-class multimodal technical reports, outperforming commercial AI\nsystems in human evaluation. ACPs are highly modular and extensible, allowing\npractitioners to build top-tier generalist agents quickly.",
      "url": "http://arxiv.org/abs/2505.14569v1",
      "published_time_eastern_timestamp": 1747758488.0
    },
    {
      "title": "Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic\n  Signal Optimization: A Simulation Study",
      "summary": "Urban traffic congestion, particularly at intersections, significantly\nimpacts travel time, fuel consumption, and emissions. Traditional fixed-time\nsignal control systems often lack the adaptability to manage dynamic traffic\npatterns effectively. This study explores the application of multi-agent\nreinforcement learning (MARL) to optimize traffic signal coordination across\nmultiple intersections within a simulated environment. Utilizing Pygame, a\nsimulation was developed to model a network of interconnected intersections\nwith randomly generated vehicle flows to reflect realistic traffic variability.\nA decentralized MARL controller was implemented, in which each traffic signal\noperates as an autonomous agent, making decisions based on local observations\nand information from neighboring agents. Performance was evaluated against a\nbaseline fixed-time controller using metrics such as average vehicle wait time\nand overall throughput. The MARL approach demonstrated statistically\nsignificant improvements, including reduced average waiting times and improved\nthroughput. These findings suggest that MARL-based dynamic control strategies\nhold substantial promise for improving urban traffic management efficiency.\nMore research is recommended to address scalability and real-world\nimplementation challenges.",
      "url": "http://arxiv.org/abs/2505.14544v1",
      "published_time_eastern_timestamp": 1747756784.0
    },
    {
      "title": "A Logic of General Attention Using Edge-Conditioned Event Models\n  (Extended Version)",
      "summary": "In this work, we present the first general logic of attention. Attention is a\npowerful cognitive ability that allows agents to focus on potentially complex\ninformation, such as logically structured propositions, higher-order beliefs,\nor what other agents pay attention to. This ability is a strength, as it helps\nto ignore what is irrelevant, but it can also introduce biases when some types\nof information or agents are systematically ignored. Existing dynamic epistemic\nlogics for attention cannot model such complex attention scenarios, as they\nonly model attention to atomic formulas. Additionally, such logics quickly\nbecome cumbersome, as their size grows exponentially in the number of agents\nand announced literals. Here, we introduce a logic that overcomes both\nlimitations. First, we generalize edge-conditioned event models, which we show\nto be as expressive as standard event models yet exponentially more succinct\n(generalizing both standard event models and generalized arrow updates).\nSecond, we extend attention to arbitrary formulas, allowing agents to also\nattend to other agents' beliefs or attention. Our work treats attention as a\nmodality, like belief or awareness. We introduce attention principles that\nimpose closure properties on that modality and that can be used in its\naxiomatization. Throughout, we illustrate our framework with examples of AI\nagents reasoning about human attentional biases, demonstrating how such agents\ncan discover attentional biases.",
      "url": "http://arxiv.org/abs/2505.14539v1",
      "published_time_eastern_timestamp": 1747756594.0
    },
    {
      "title": "Energy-Efficient Deep Reinforcement Learning with Spiking Transformers",
      "summary": "Agent-based Transformers have been widely adopted in recent reinforcement\nlearning advances due to their demonstrated ability to solve complex tasks.\nHowever, the high computational complexity of Transformers often results in\nsignificant energy consumption, limiting their deployment in real-world\nautonomous systems. Spiking neural networks (SNNs), with their biologically\ninspired structure, offer an energy-efficient alternative for machine learning.\nIn this paper, a novel Spike-Transformer Reinforcement Learning (STRL)\nalgorithm that combines the energy efficiency of SNNs with the powerful\ndecision-making capabilities of reinforcement learning is developed.\nSpecifically, an SNN using multi-step Leaky Integrate-and-Fire (LIF) neurons\nand attention mechanisms capable of processing spatio-temporal patterns over\nmultiple time steps is designed. The architecture is further enhanced with\nstate, action, and reward encodings to create a Transformer-like structure\noptimized for reinforcement learning tasks. Comprehensive numerical experiments\nconducted on state-of-the-art benchmarks demonstrate that the proposed SNN\nTransformer achieves significantly improved policy performance compared to\nconventional agent-based Transformers. With both enhanced energy efficiency and\npolicy optimality, this work highlights a promising direction for deploying\nbio-inspired, low-cost machine learning models in complex real-world\ndecision-making scenarios.",
      "url": "http://arxiv.org/abs/2505.14533v1",
      "published_time_eastern_timestamp": 1747756363.0
    },
    {
      "title": "BACON: A fully explainable AI model with graded logic for decision\n  making problems",
      "summary": "As machine learning models and autonomous agents are increasingly deployed in\nhigh-stakes, real-world domains such as healthcare, security, finance, and\nrobotics, the need for transparent and trustworthy explanations has become\ncritical. To ensure end-to-end transparency of AI decisions, we need models\nthat are not only accurate but also fully explainable and human-tunable. We\nintroduce BACON, a novel framework for automatically training explainable AI\nmodels for decision making problems using graded logic. BACON achieves high\npredictive accuracy while offering full structural transparency and precise,\nlogic-based symbolic explanations, enabling effective human-AI collaboration\nand expert-guided refinement. We evaluate BACON with a diverse set of\nscenarios: classic Boolean approximation, Iris flower classification, house\npurchasing decisions and breast cancer diagnosis. In each case, BACON provides\nhigh-performance models while producing compact, human-verifiable decision\nlogic. These results demonstrate BACON's potential as a practical and\nprincipled approach for delivering crisp, trustworthy explainable AI.",
      "url": "http://arxiv.org/abs/2505.14510v1",
      "published_time_eastern_timestamp": 1747755545.0
    },
    {
      "title": "Design and Evaluation of a Microservices Cloud Framework for Online\n  Travel Platforms",
      "summary": "Handling online travel agents globally requires efficient and flexible\nsoftware solution architectures. When it needs to handle thousands of agents\nand billions of clients data globally. Microservices architecture is used to\nbreak down a large program into numerous, smaller services which can run\nindividually and perform individual tasks. This paper analyses and integrates a\nunique Microservices Cloud Framework designed to support Online Travel\nPlatforms (MCF-OTP). MCF-OTPs main goal is to increase the performance,\nflexibility, and maintenance of online travel platforms via cloud computing and\nmicroservice technologies. Large-scale travel apps, including managing numerous\ndata sources, dealing with traffic peaks, and providing fault tolerance, can be\naddressed by the suggested framework. The framework increases good\ninterpretation between flawless data synchronization, microservices, and\ndynamic scaling based on demand technology. An organization framework that\noptimizes service borders and minimizes inter-service dependencies is\nrecommended. Thus, this can result in elevated development adaptability. In\nthis research, the principal goal is to evaluate MCF-OTPs efficiency using the\nindicators of fault tolerance and response time. It is indicated by the\nfindings that the MCF-OTP structure excels traditional monolithic designs in\nterms of dependability and scalability, managing traffic spikes seamlessly and\ndecreasing downtime. The cost-effective analysis helps ascertain the net gain\nattained by the startup fees and the ongoing operational costs. The cloud-based\nenvironment is used to reduce the fracture cost which also helps to increase\nthe efficiency of resource allocation, according to the research.",
      "url": "http://arxiv.org/abs/2505.14508v1",
      "published_time_eastern_timestamp": 1747755415.0
    },
    {
      "title": "Security of Distributed Gradient Descent Against Byzantine Agents",
      "summary": "This paper investigates the security of Decentralized Gradient Descent (DGD)\nalgorithms on undirected graphs. Specifically, we consider Byzantine agents\nthat inject stealthy attacks to degrade the performance of the DGD algorithm in\nterms of its optimal value. To mitigate the effect of stealthy attacks, some\nagents are allocated to monitor the evolution of their gradient. We then\npropose a method to quantify the maximum deviation caused by the Byzantine\nagent in the optimal value of the DGD. Our approach serves as a security metric\nto evaluate the robustness of graph structures against Byzantine attacks. We\nvalidate our findings through numerical simulations.",
      "url": "http://arxiv.org/abs/2505.14473v1",
      "published_time_eastern_timestamp": 1747753620.0
    },
    {
      "title": "Interpretable Reinforcement Learning for Load Balancing using\n  Kolmogorov-Arnold Networks",
      "summary": "Reinforcement learning (RL) has been increasingly applied to network control\nproblems, such as load balancing. However, existing RL approaches often suffer\nfrom lack of interpretability and difficulty in extracting controller\nequations. In this paper, we propose the use of Kolmogorov-Arnold Networks\n(KAN) for interpretable RL in network control. We employ a PPO agent with a\n1-layer actor KAN model and an MLP Critic network to learn load balancing\npolicies that maximise throughput utility, minimize loss as well as delay. Our\napproach allows us to extract controller equations from the learned neural\nnetworks, providing insights into the decision-making process. We evaluate our\napproach using different reward functions demonstrating its effectiveness in\nimproving network performance while providing interpretable policies.",
      "url": "http://arxiv.org/abs/2505.14459v1",
      "published_time_eastern_timestamp": 1747752991.0
    },
    {
      "title": "Robustness Evaluation of Graph-based News Detection Using Network\n  Structural Information",
      "summary": "Although Graph Neural Networks (GNNs) have shown promising potential in fake\nnews detection, they remain highly vulnerable to adversarial manipulations\nwithin social networks. Existing methods primarily establish connections\nbetween malicious accounts and individual target news to investigate the\nvulnerability of graph-based detectors, while they neglect the structural\nrelationships surrounding targets, limiting their effectiveness in robustness\nevaluation. In this work, we propose a novel Structural Information\nprinciples-guided Adversarial Attack Framework, namely SI2AF, which effectively\nchallenges graph-based detectors and further probes their detection robustness.\nSpecifically, structural entropy is introduced to quantify the dynamic\nuncertainty in social engagements and identify hierarchical communities that\nencompass all user accounts and news posts. An influence metric is presented to\nmeasure each account's probability of engaging in random interactions,\nfacilitating the design of multiple agents that manage distinct malicious\naccounts. For each target news, three attack strategies are developed through\nmulti-agent collaboration within the associated subgraph to optimize evasion\nagainst black-box detectors. By incorporating the adversarial manipulations\ngenerated by SI2AF, we enrich the original network structure and refine\ngraph-based detectors to improve their robustness against adversarial attacks.\nExtensive evaluations demonstrate that SI2AF significantly outperforms\nstate-of-the-art baselines in attack effectiveness with an average improvement\nof 16.71%, and enhances GNN-based detection robustness by 41.54% on average.",
      "url": "http://arxiv.org/abs/2505.14453v1",
      "published_time_eastern_timestamp": 1747752695.0
    },
    {
      "title": "Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered\n  Mobile GUI Agents",
      "summary": "Graphical user interface (GUI) agents powered by multimodal large language\nmodels (MLLMs) have shown greater promise for human-interaction. However, due\nto the high fine-tuning cost, users often rely on open-source GUI agents or\nAPIs offered by AI providers, which introduces a critical but underexplored\nsupply chain threat: backdoor attacks. In this work, we first unveil that\nMLLM-powered GUI agents naturally expose multiple interaction-level triggers,\nsuch as historical steps, environment states, and task progress. Based on this\nobservation, we introduce AgentGhost, an effective and stealthy framework for\nred-teaming backdoor attacks. Specifically, we first construct composite\ntriggers by combining goal and interaction levels, allowing GUI agents to\nunintentionally activate backdoors while ensuring task utility. Then, we\nformulate backdoor injection as a Min-Max optimization problem that uses\nsupervised contrastive learning to maximize the feature difference across\nsample classes at the representation space, improving flexibility of the\nbackdoor. Meanwhile, it adopts supervised fine-tuning to minimize the\ndiscrepancy between backdoor and clean behavior generation, enhancing\neffectiveness and utility. Extensive evaluations of various agent models in two\nestablished mobile benchmarks show that AgentGhost is effective and generic,\nwith attack accuracy that reaches 99.7\\% on three attack objectives, and shows\nstealthiness with only 1\\% utility degradation. Furthermore, we tailor a\ndefense method against AgentGhost that reduces the attack accuracy to 22.1\\%.\nOur code is available at \\texttt{anonymous}.",
      "url": "http://arxiv.org/abs/2505.14418v1",
      "published_time_eastern_timestamp": 1747751358.0
    },
    {
      "title": "Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable\n  Computation",
      "summary": "While humans naturally learn and adapt from past experiences, large language\nmodels (LLMs) and their agentic counterparts struggle to retain reasoning from\nprevious tasks and apply them in future contexts. To address this limitation,\nwe propose a novel framework, log-augmented generation (LAG) that directly\nreuses prior computation and reasoning from past logs at test time to enhance\nmodel's ability to learn from previous tasks and perform better on new, unseen\nchallenges, all while keeping the system efficient and scalable. Specifically,\nour system represents task logs using key-value (KV) caches, encoding the full\nreasoning context of prior tasks while storing KV caches for only a selected\nsubset of tokens. When a new task arises, LAG retrieves the KV values from\nrelevant logs to augment generation. Our approach differs from reflection-based\nmemory mechanisms by directly reusing prior reasoning and computations without\nrequiring additional steps for knowledge extraction or distillation. Our method\nalso goes beyond existing KV caching techniques, which primarily target\nefficiency gains rather than improving accuracy. Experiments on knowledge- and\nreasoning-intensive datasets demonstrate that our method significantly\noutperforms standard agentic systems that do not utilize logs, as well as\nexisting solutions based on reflection and KV cache techniques.",
      "url": "http://arxiv.org/abs/2505.14398v1",
      "published_time_eastern_timestamp": 1747750478.0
    },
    {
      "title": "Causal Cartographer: From Mapping to Reasoning Over Counterfactual\n  Worlds",
      "summary": "Causal world models are systems that can answer counterfactual questions\nabout an environment of interest, i.e. predict how it would have evolved if an\narbitrary subset of events had been realized differently. It requires\nunderstanding the underlying causes behind chains of events and conducting\ncausal inference for arbitrary unseen distributions. So far, this task eludes\nfoundation models, notably large language models (LLMs), which do not have\ndemonstrated causal reasoning capabilities beyond the memorization of existing\ncausal relationships. Furthermore, evaluating counterfactuals in real-world\napplications is challenging since only the factual world is observed, limiting\nevaluation to synthetic datasets. We address these problems by explicitly\nextracting and modeling causal relationships and propose the Causal\nCartographer framework. First, we introduce a graph retrieval-augmented\ngeneration agent tasked to retrieve causal relationships from data. This\napproach allows us to construct a large network of real-world causal\nrelationships that can serve as a repository of causal knowledge and build\nreal-world counterfactuals. In addition, we create a counterfactual reasoning\nagent constrained by causal relationships to perform reliable step-by-step\ncausal inference. We show that our approach can extract causal knowledge and\nimprove the robustness of LLMs for causal reasoning tasks while reducing\ninference costs and spurious correlations.",
      "url": "http://arxiv.org/abs/2505.14396v1",
      "published_time_eastern_timestamp": 1747750445.0
    },
    {
      "title": "Information-optimal measurement: From fixed sampling protocols to\n  adaptive spectroscopy",
      "summary": "All measurements of continuous signals rely on taking discrete snapshots,\nwith the Nyquist-Shannon theorem dictating sampling paradigms. We present a\nbroader framework of information-optimal measurement, showing that traditional\nsampling is optimal only when we are entirely ignorant about the system under\ninvestigation. This insight unlocks methods that efficiently leverage prior\ninformation to overcome long-held fundamental sampling limitations. We\ndemonstrate this for optical spectroscopy - vital to research and medicine -\nand show how adaptively selected measurements yield higher information in\nmedical blood analysis, optical metrology, and hyperspectral imaging. Through\nour rigorous statistical framework, performance never falls below conventional\nsampling while providing complete uncertainty quantification in real time. This\nestablishes a new paradigm where measurement devices operate as\ninformation-optimal agents, fundamentally changing how scientific instruments\ncollect and process data.",
      "url": "http://arxiv.org/abs/2505.14364v1",
      "published_time_eastern_timestamp": 1747748928.0
    },
    {
      "title": "DeepEyes: Incentivizing \"Thinking with Images\" via Reinforcement\n  Learning",
      "summary": "Large Vision-Language Models (VLMs) have shown strong capabilities in\nmultimodal understanding and reasoning, yet they are primarily constrained by\ntext-based reasoning processes. However, achieving seamless integration of\nvisual and textual reasoning which mirrors human cognitive processes remains a\nsignificant challenge. In particular, effectively incorporating advanced visual\ninput processing into reasoning mechanisms is still an open question. Thus, in\nthis paper, we explore the interleaved multimodal reasoning paradigm and\nintroduce DeepEyes, a model with \"thinking with images\" capabilities\nincentivized through end-to-end reinforcement learning without the need for\ncold-start SFT. Notably, this ability emerges natively within the model itself,\nleveraging its inherent grounding ability as a tool instead of depending on\nseparate specialized models. Specifically, we propose a tool-use-oriented data\nselection mechanism and a reward strategy to encourage successful tool-assisted\nreasoning trajectories. DeepEyes achieves significant performance gains on\nfine-grained perception and reasoning benchmarks and also demonstrates\nimprovement in grounding, hallucination, and mathematical reasoning tasks.\nInterestingly, we observe the distinct evolution of tool-calling behavior from\ninitial exploration to efficient and accurate exploitation, and diverse\nthinking patterns that closely mirror human visual reasoning processes. Code is\navailable at https://github.com/Visual-Agent/DeepEyes.",
      "url": "http://arxiv.org/abs/2505.14362v1",
      "published_time_eastern_timestamp": 1747748891.0
    },
    {
      "title": "PersonaTAB: Predicting Personality Traits using Textual, Acoustic, and\n  Behavioral Cues in Fully-Duplex Speech Dialogs",
      "summary": "Despite significant progress in neural spoken dialog systems,\npersonality-aware conversation agents -- capable of adapting behavior based on\npersonalities -- remain underexplored due to the absence of personality\nannotations in speech datasets. We propose a pipeline that preprocesses raw\naudio recordings to create a dialogue dataset annotated with timestamps,\nresponse types, and emotion/sentiment labels. We employ an automatic speech\nrecognition (ASR) system to extract transcripts and timestamps, then generate\nconversation-level annotations. Leveraging these annotations, we design a\nsystem that employs large language models to predict conversational\npersonality. Human evaluators were engaged to identify conversational\ncharacteristics and assign personality labels. Our analysis demonstrates that\nthe proposed system achieves stronger alignment with human judgments compared\nto existing approaches.",
      "url": "http://arxiv.org/abs/2505.14356v1",
      "published_time_eastern_timestamp": 1747748492.0
    },
    {
      "title": "Empowering LLMs in Task-Oriented Dialogues: A Domain-Independent\n  Multi-Agent Framework and Fine-Tuning Strategy",
      "summary": "Task-oriented dialogue systems based on Large Language Models (LLMs) have\ngained increasing attention across various industries and achieved significant\nresults. Current approaches condense complex procedural workflows into a single\nagent to achieve satisfactory performance on large-scale LLMs. However, these\napproaches face challenges to achieve comparable performance on fine-tuned\nlightweight LLMs, due to their limited capabilities in handling multiple\ncomplex logic. In this work, we design a Domain-Independent Multi-Agent\nFramework (DIMF), which contains Intent Classification Agent, Slot Filling\nAgent and Response Agent. This approach simplifies the learning complexity and\nenhances the generalization ability by separating the tasks into\ndomain-independent components. In this framework, we enhance the capabilities\nin contextual understanding using the Direct Preference Optimisation (DPO)\nmethod, and propose a simple and effective Data Distribution Adaptation (DDA)\nmethod to mitigate degradation issues during DPO training. Experiments\nconducted on the MultiWOZ datasets show that our proposed method achieves a\nbetter average performance among all the baselines. Extensive analysis also\ndemonstrates that our proposed framework exhibits excellent generalizability\nand zero-shot capability.",
      "url": "http://arxiv.org/abs/2505.14299v1",
      "published_time_eastern_timestamp": 1747745263.0
    },
    {
      "title": "EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection",
      "summary": "As multimodal agents are increasingly trained to operate graphical user\ninterfaces (GUIs) to complete user tasks, they face a growing threat from\nindirect prompt injection, attacks in which misleading instructions are\nembedded into the agent's visual environment, such as popups or chat messages,\nand misinterpreted as part of the intended task. A typical example is\nenvironmental injection, in which GUI elements are manipulated to influence\nagent behavior without directly modifying the user prompt. To address these\nemerging attacks, we propose EVA, a red teaming framework for indirect prompt\ninjection which transforms the attack into a closed loop optimization by\ncontinuously monitoring an agent's attention distribution over the GUI and\nupdating adversarial cues, keywords, phrasing, and layout, in response.\nCompared with prior one shot methods that generate fixed prompts without regard\nfor how the model allocates visual attention, EVA dynamically adapts to\nemerging attention hotspots, yielding substantially higher attack success rates\nand far greater transferability across diverse GUI scenarios. We evaluate EVA\non six widely used generalist and specialist GUI agents in realistic settings\nsuch as popup manipulation, chat based phishing, payments, and email\ncomposition. Experimental results show that EVA substantially improves success\nrates over static baselines. Under goal agnostic constraints, where the\nattacker does not know the agent's task intent, EVA still discovers effective\npatterns. Notably, we find that injection styles transfer well across models,\nrevealing shared behavioral biases in GUI agents. These results suggest that\nevolving indirect prompt injection is a powerful tool not only for red teaming\nagents, but also for uncovering common vulnerabilities in their multimodal\ndecision making.",
      "url": "http://arxiv.org/abs/2505.14289v1",
      "published_time_eastern_timestamp": 1747744865.0
    }
  ]
}
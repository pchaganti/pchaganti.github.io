{
  "last_updated": "2025-07-02T23:49:36.836489-04:00",
  "papers": [
    {
      "title": "The Thin Line Between Comprehension and Persuasion in LLMs",
      "summary": "Large language models (LLMs) are excellent at maintaining high-level,\nconvincing dialogues. They are being fast deployed as chatbots and evaluators\nin sensitive areas, such as peer review and mental health applications. This,\nalong with the disparate accounts on their reasoning capabilities, calls for a\ncloser examination of LLMs and their comprehension of dialogue. In this work we\nbegin by evaluating LLMs' ability to maintain a debate--one of the purest yet\nmost complex forms of human communication. Then we measure how this capability\nrelates to their understanding of what is being talked about, namely, their\ncomprehension of dialogical structures and the pragmatic context. We find that\nLLMs are capable of maintaining coherent, persuasive debates, often swaying the\nbeliefs of participants and audiences alike. We also note that awareness or\nsuspicion of AI involvement encourage people to be more critical of the\narguments made. When polling LLMs on their comprehension of deeper structures\nof dialogue, however, they cannot demonstrate said understanding. Our findings\ntie the shortcomings of LLMs-as-evaluators to their (in)ability to understand\nthe context. More broadly, for the field of argumentation theory we posit that,\nif an agent can convincingly maintain a dialogue, it is not necessary for it to\nknow what it is talking about. Hence, the modelling of pragmatic context and\ncoherence are secondary to effectiveness.",
      "url": "http://arxiv.org/abs/2507.01936v1",
      "published_time_eastern_timestamp": 1751478416.0
    },
    {
      "title": "Decision-oriented Text Evaluation",
      "summary": "Natural language generation (NLG) is increasingly deployed in high-stakes\ndomains, yet common intrinsic evaluation methods, such as n-gram overlap or\nsentence plausibility, weakly correlate with actual decision-making efficacy.\nWe propose a decision-oriented framework for evaluating generated text by\ndirectly measuring its influence on human and large language model (LLM)\ndecision outcomes. Using market digest texts--including objective morning\nsummaries and subjective closing-bell analyses--as test cases, we assess\ndecision quality based on the financial performance of trades executed by human\ninvestors and autonomous LLM agents informed exclusively by these texts. Our\nfindings reveal that neither humans nor LLM agents consistently surpass random\nperformance when relying solely on summaries. However, richer analytical\ncommentaries enable collaborative human-LLM teams to outperform individual\nhuman or agent baselines significantly. Our approach underscores the importance\nof evaluating generated text by its ability to facilitate synergistic\ndecision-making between humans and LLMs, highlighting critical limitations of\ntraditional intrinsic metrics.",
      "url": "http://arxiv.org/abs/2507.01923v1",
      "published_time_eastern_timestamp": 1751477555.0
    },
    {
      "title": "An in-silico lung phantom to assess the performance of pulmonary artery\n  segmentation using angiogram",
      "summary": "Pulmonary hypertension (PH) can lead to significant vascular remodeling,\nresulting in altered pulmonary blood flow. Estimating the patient-specific\ncontributions of each remodeling event is necessary to optimize and\nindividualize clinical intervention strategies. In-silico modeling has emerged\nas a powerful tool to simulate pulmonary hemodynamics, and one of the primary\nrequirements for robust in-silico modeling is an accurate representation of the\npulmonary vasculature structure. Computed tomography (CT) imaging can be used\nto segment and reconstruct the proximal vasculature. However, contrast-enhanced\nimaging, such as CT pulmonary angiography, is required to obtain a\ncomprehensive and high-fidelity view of the pulmonary vasculature. The clinical\nuse of CT pulmonary angiography is limited by the complications associated with\nthe injection of contrast agents. Machine learning (ML) approaches have emerged\nto effectively segment and reconstruct the pulmonary vasculature without the\nneed for contrast-enhanced imaging. We have developed a method to create\nin-silico pulmonary angiogram phantoms with varying simulated contrast levels.\nThe results indicated that adding simulated contrast can allow for successful\nsegmentation of the pulmonary vasculature. We expect this method to assist with\ndeveloping and training ML-based segmentation frameworks and aid in their\nvalidation, thereby improving the capability to segment and reconstruct\npulmonary vasculature without using contrast-enhanced imaging.",
      "url": "http://arxiv.org/abs/2507.01867v1",
      "published_time_eastern_timestamp": 1751474078.0
    },
    {
      "title": "Bridging UI Design and chatbot Interactions: Applying Form-Based\n  Principles to Conversational Agents",
      "summary": "Domain specific chatbot applications often involve multi step interactions,\nsuch as refining search filters, selecting multiple items, or performing\ncomparisons. Traditional graphical user interfaces (GUIs) handle these\nworkflows by providing explicit \"Submit\" (commit data) and \"Reset\" (discard\ndata) actions, allowing back-end systems to track user intent unambiguously. In\ncontrast, conversational agents rely on subtle language cues, which can lead to\nconfusion and incomplete context management. This paper proposes modeling these\nGUI inspired metaphors acknowledgment (submit like) and context switching\n(reset-like) as explicit tasks within large language model (LLM) prompts. By\ncapturing user acknowledgment, reset actions, and chain of thought (CoT)\nreasoning as structured session data, we preserve clarity, reduce user\nconfusion, and align domain-specific chatbot interactions with back-end logic.\nWe demonstrate our approach in hotel booking and customer management scenarios,\nhighlighting improvements in multi-turn task coherence, user satisfaction, and\nefficiency.",
      "url": "http://arxiv.org/abs/2507.01862v1",
      "published_time_eastern_timestamp": 1751473490.0
    },
    {
      "title": "TD-MPC-Opt: Distilling Model-Based Multi-Task Reinforcement Learning\n  Agents",
      "summary": "We present a novel approach to knowledge transfer in model-based\nreinforcement learning, addressing the critical challenge of deploying large\nworld models in resource-constrained environments. Our method efficiently\ndistills a high-capacity multi-task agent (317M parameters) into a compact\nmodel (1M parameters) on the MT30 benchmark, significantly improving\nperformance across diverse tasks. Our distilled model achieves a\nstate-of-the-art normalized score of 28.45, surpassing the original 1M\nparameter model score of 18.93. This improvement demonstrates the ability of\nour distillation technique to capture and consolidate complex multi-task\nknowledge. We further optimize the distilled model through FP16 post-training\nquantization, reducing its size by $\\sim$50\\%. Our approach addresses practical\ndeployment limitations and offers insights into knowledge representation in\nlarge world models, paving the way for more efficient and accessible multi-task\nreinforcement learning systems in robotics and other resource-constrained\napplications. Code available at https://github.com/dmytro-kuzmenko/td-mpc-opt.",
      "url": "http://arxiv.org/abs/2507.01823v1",
      "published_time_eastern_timestamp": 1751470729.0
    },
    {
      "title": "AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for\n  Robust Long-Tail Trajectory Prediction",
      "summary": "Accurately predicting the future trajectories of traffic agents is essential\nin autonomous driving. However, due to the inherent imbalance in trajectory\ndistributions, tail data in natural datasets often represents more complex and\nhazardous scenarios. Existing studies typically rely solely on a base model's\nprediction error, without considering the diversity and uncertainty of\nlong-tail trajectory patterns. We propose an adaptive momentum and decoupled\ncontrastive learning framework (AMD), which integrates unsupervised and\nsupervised contrastive learning strategies. By leveraging an improved momentum\ncontrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,\nour framework enhances the model's ability to recognize rare and complex\ntrajectories. Additionally, we design four types of trajectory random\naugmentation methods and introduce an online iterative clustering strategy,\nallowing the model to dynamically update pseudo-labels and better adapt to the\ndistributional shifts in long-tail data. We propose three different criteria to\ndefine long-tail trajectories and conduct extensive comparative experiments on\nthe nuScenes and ETH$/$UCY datasets. The results show that AMD not only\nachieves optimal performance in long-tail trajectory prediction but also\ndemonstrates outstanding overall prediction accuracy.",
      "url": "http://arxiv.org/abs/2507.01801v1",
      "published_time_eastern_timestamp": 1751469640.0
    },
    {
      "title": "ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and\n  Comprehension of Corner Cases in Autonomous Driving",
      "summary": "In this paper, we present details of the 1st W-CODA workshop, held in\nconjunction with the ECCV 2024. W-CODA aims to explore next-generation\nsolutions for autonomous driving corner cases, empowered by state-of-the-art\nmultimodal perception and comprehension techniques. 5 Speakers from both\nacademia and industry are invited to share their latest progress and opinions.\nWe collect research papers and hold a dual-track challenge, including both\ncorner case scene understanding and generation. As the pioneering effort, we\nwill continuously bridge the gap between frontier autonomous driving techniques\nand fully intelligent, reliable self-driving agents robust towards corner\ncases.",
      "url": "http://arxiv.org/abs/2507.01735v1",
      "published_time_eastern_timestamp": 1751465425.0
    },
    {
      "title": "Agent Ideate: A Framework for Product Idea Generation from Patents Using\n  Agentic AI",
      "summary": "Patents contain rich technical knowledge that can inspire innovative product\nideas, yet accessing and interpreting this information remains a challenge.\nThis work explores the use of Large Language Models (LLMs) and autonomous\nagents to mine and generate product concepts from a given patent. In this work,\nwe design Agent Ideate, a framework for automatically generating product-based\nbusiness ideas from patents. We experimented with open-source LLMs and\nagent-based architectures across three domains: Computer Science, Natural\nLanguage Processing, and Material Chemistry. Evaluation results show that the\nagentic approach consistently outperformed standalone LLMs in terms of idea\nquality, relevance, and novelty. These findings suggest that combining LLMs\nwith agentic workflows can significantly enhance the innovation pipeline by\nunlocking the untapped potential of business idea generation from patent data.",
      "url": "http://arxiv.org/abs/2507.01717v1",
      "published_time_eastern_timestamp": 1751464037.0
    },
    {
      "title": "Using Machine Learning to Compute Constrained Optimal Carbon Tax Rules",
      "summary": "We develop a computational framework for deriving Pareto-improving and\nconstrained optimal carbon tax rules in a stochastic overlapping generations\n(OLG) model with climate change. By integrating Deep Equilibrium Networks for\nfast policy evaluation and Gaussian process surrogate modeling with Bayesian\nactive learning, the framework systematically locates optimal carbon tax\nschedules for heterogeneous agents exposed to climate risk. We apply our method\nto a 12-period OLG model in which exogenous shocks affect the carbon intensity\nof energy production, as well as the damage function. Constrained optimal\ncarbon taxes consist of tax rates that are simple functions of observables and\nrevenue-sharing rules that guarantee that the introduction of the taxes is\nPareto improving. This reveals that a straightforward policy is highly\neffective: a Pareto-improving linear tax on cumulative emissions alone yields a\n0.42% aggregate welfare gain in consumption-equivalent terms while adding\nfurther complexity to the tax provides only a marginal increase to 0.45%. The\napplication demonstrates that the proposed approach produces scalable tools for\nmacro-policy design in complex stochastic settings. Beyond climate economics,\nthe framework offers a template for systematically analyzing welfare-improving\npolicies in various heterogeneous-agent problems.",
      "url": "http://arxiv.org/abs/2507.01704v1",
      "published_time_eastern_timestamp": 1751463406.0
    },
    {
      "title": "AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large\n  Language Models on Harmfulness",
      "summary": "The proliferation of multimodal memes in the social media era demands that\nmultimodal Large Language Models (mLLMs) effectively understand meme\nharmfulness. Existing benchmarks for assessing mLLMs on harmful meme\nunderstanding rely on accuracy-based, model-agnostic evaluations using static\ndatasets. These benchmarks are limited in their ability to provide up-to-date\nand thorough assessments, as online memes evolve dynamically. To address this,\nwe propose AdamMeme, a flexible, agent-based evaluation framework that\nadaptively probes the reasoning capabilities of mLLMs in deciphering meme\nharmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive\nevaluations by iteratively updating the meme data with challenging samples,\nthereby exposing specific limitations in how mLLMs interpret harmfulness.\nExtensive experiments show that our framework systematically reveals the\nvarying performance of different target mLLMs, offering in-depth, fine-grained\nanalyses of model-specific weaknesses. Our code is available at\nhttps://github.com/Lbotirx/AdamMeme.",
      "url": "http://arxiv.org/abs/2507.01702v1",
      "published_time_eastern_timestamp": 1751463150.0
    },
    {
      "title": "Exploring Advanced LLM Multi-Agent Systems Based on Blackboard\n  Architecture",
      "summary": "In this paper, we propose to incorporate the blackboard architecture into LLM\nmulti-agent systems (MASs) so that (1) agents with various roles can share all\nthe information and others' messages during the whole problem-solving process,\n(2) agents that will take actions are selected based on the current content of\nthe blackboard, and (3) the selection and execution round is repeated until a\nconsensus is reached on the blackboard. We develop the first implementation of\nthis proposal and conduct experiments on commonsense knowledge, reasoning and\nmathematical datasets. The results show that our system can be competitive with\nthe SOTA static and dynamic MASs by achieving the best average performance, and\nat the same time manage to spend less tokens. Our proposal has the potential to\nenable complex and dynamic problem-solving where well-defined structures or\nworkflows are unavailable.",
      "url": "http://arxiv.org/abs/2507.01701v1",
      "published_time_eastern_timestamp": 1751463044.0
    },
    {
      "title": "Quantum reinforcement learning in dynamic environments",
      "summary": "Combining quantum computing techniques in the form of amplitude amplification\nwith classical reinforcement learning has led to the so-called \"hybrid agent\nfor quantum-accessible reinforcement learning\", which achieves a quadratic\nspeedup in sample complexity for certain learning problems. So far, this hybrid\nagent has only been applied to stationary learning problems, that is, learning\nproblems without any time dependency within components of the Markov decision\nprocess. In this work, we investigate the applicability of the hybrid agent to\ndynamic RL environments. To this end, we enhance the hybrid agent by\nintroducing a dissipation mechanism and, with the resulting learning agent,\nperform an empirical comparison with a classical RL agent in an RL environment\nwith a time-dependent reward function. Our findings suggest that the modified\nhybrid agent can adapt its behavior to changes in the environment quickly,\nleading to a higher average success probability compared to its classical\ncounterpart.",
      "url": "http://arxiv.org/abs/2507.01691v1",
      "published_time_eastern_timestamp": 1751462271.0
    },
    {
      "title": "What does really matter in image goal navigation?",
      "summary": "Image goal navigation requires two different skills: firstly, core navigation\nskills, including the detection of free space and obstacles, and taking\ndecisions based on an internal representation; and secondly, computing\ndirectional information by comparing visual observations to the goal image.\nCurrent state-of-the-art methods either rely on dedicated image-matching, or\npre-training of computer vision modules on relative pose estimation. In this\npaper, we study whether this task can be efficiently solved with end-to-end\ntraining of full agents with RL, as has been claimed by recent work. A positive\nanswer would have impact beyond Embodied AI and allow training of relative pose\nestimation from reward for navigation alone. In a large study we investigate\nthe effect of architectural choices like late fusion, channel stacking,\nspace-to-depth projections and cross-attention, and their role in the emergence\nof relative pose estimators from navigation training. We show that the success\nof recent methods is influenced up to a certain extent by simulator settings,\nleading to shortcuts in simulation. However, we also show that these\ncapabilities can be transferred to more realistic setting, up to some extend.\nWe also find evidence for correlations between navigation performance and\nprobed (emerging) relative pose estimation performance, an important sub skill.",
      "url": "http://arxiv.org/abs/2507.01667v1",
      "published_time_eastern_timestamp": 1751460626.0
    },
    {
      "title": "Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems",
      "summary": "Traditional Data+AI systems utilize data-driven techniques to optimize\nperformance, but they rely heavily on human experts to orchestrate system\npipelines, enabling them to adapt to changes in data, queries, tasks, and\nenvironments. For instance, while there are numerous data science tools\navailable, developing a pipeline planning system to coordinate these tools\nremains challenging. This difficulty arises because existing Data+AI systems\nhave limited capabilities in semantic understanding, reasoning, and planning.\nFortunately, we have witnessed the success of large language models (LLMs) in\nenhancing semantic understanding, reasoning, and planning abilities. It is\ncrucial to incorporate LLM techniques to revolutionize data systems for\norchestrating Data+AI applications effectively.\n  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive\narchitecture designed to orchestrate Data+AI ecosystems, which focuses on\ntackling data-related tasks by integrating knowledge comprehension, reasoning,\nand planning capabilities. We delve into the challenges involved in designing\ndata agents, such as understanding data/queries/environments/tools,\norchestrating pipelines/workflows, optimizing and executing pipelines, and\nfostering pipeline self-reflection. Furthermore, we present examples of data\nagent systems, including a data science agent, data analytics agents (such as\nunstructured data analytics agent, semantic structured data analytics agent,\ndata lake analytics agent, and multi-modal data analytics agent), and a\ndatabase administrator (DBA) agent. We also outline several open challenges\nassociated with designing data agent systems.",
      "url": "http://arxiv.org/abs/2507.01599v1",
      "published_time_eastern_timestamp": 1751454289.0
    },
    {
      "title": "Emotionally Intelligent Task-oriented Dialogue Systems: Architecture,\n  Representation, and Optimisation",
      "summary": "Task-oriented dialogue (ToD) systems are designed to help users achieve\nspecific goals through natural language interaction. While recent advances in\nlarge language models (LLMs) have significantly improved linguistic fluency and\ncontextual understanding, building effective and emotionally intelligent ToD\nsystems remains a complex challenge. Effective ToD systems must optimise for\ntask success, emotional understanding and responsiveness, and precise\ninformation conveyance, all within inherently noisy and ambiguous\nconversational environments. In this work, we investigate architectural,\nrepresentational, optimisational as well as emotional considerations of ToD\nsystems. We set up systems covering these design considerations with a\nchallenging evaluation environment composed of a natural-language user\nsimulator coupled with an imperfect natural language understanding module. We\npropose \\textbf{LUSTER}, an \\textbf{L}LM-based \\textbf{U}nified \\textbf{S}ystem\nfor \\textbf{T}ask-oriented dialogue with \\textbf{E}nd-to-end\n\\textbf{R}einforcement learning with both short-term (user sentiment) and\nlong-term (task success) rewards. Our findings demonstrate that combining LLM\ncapability with structured reward modelling leads to more resilient and\nemotionally responsive ToD systems, offering a practical path forward for\nnext-generation conversational agents.",
      "url": "http://arxiv.org/abs/2507.01594v1",
      "published_time_eastern_timestamp": 1751454033.0
    },
    {
      "title": "Vision-Aided ISAC in Low-Altitude Economy Networks via De-Diffused\n  Visual Priors",
      "summary": "Emerging low-altitude economy networks (LAENets) require agile and\nprivacy-preserving resource control under dynamic agent mobility and limited\ninfrastructure support. To meet these challenges, we propose a vision-aided\nintegrated sensing and communication (ISAC) framework for UAV-assisted access\nsystems, where onboard masked De-Diffusion models extract compact semantic\ntokens, including agent type, activity class, and heading orientation, while\nexplicitly suppressing sensitive visual content. These tokens are fused with\nmmWave radar measurements to construct a semantic risk heatmap reflecting\nmotion density, occlusion, and scene complexity, which guides access technology\nselection and resource scheduling. We formulate a multi-objective optimization\nproblem to jointly maximize weighted energy and perception efficiency via radio\naccess technology (RAT) assignment, power control, and beamforming, subject to\nagent-specific QoS constraints. To solve this, we develop De-Diffusion-driven\nvision-aided risk-aware resource optimization algorithm DeDiff-VARARO, a novel\ntwo-stage cross-modal control algorithm: the first stage reconstructs visual\nscenes from tokens via De-Diffusion model for semantic parsing, while the\nsecond stage employs a deep deterministic policy gradient (DDPG)-based policy\nto adapt RAT selection, power control, and beam assignment based on fused\nradar-visual states. Simulation results show that DeDiff-VARARO consistently\noutperforms baselines in reward convergence, link robustness, and semantic\nfidelity, achieving within $4\\%$ of the performance of a raw-image upper bound\nwhile preserving user privacy and scalability in dense environments.",
      "url": "http://arxiv.org/abs/2507.01574v1",
      "published_time_eastern_timestamp": 1751453449.0
    },
    {
      "title": "Time-Varying Coverage Control: A Distributed Tracker-Planner MPC\n  Framework",
      "summary": "Time-varying coverage control addresses the challenge of coordinating\nmultiple agents covering an environment where regions of interest change over\ntime. This problem has broad applications, including the deployment of\nautonomous taxis and coordination in search and rescue operations. The\nachievement of effective coverage is complicated by the presence of\ntime-varying density functions, nonlinear agent dynamics, and stringent system\nand safety constraints. In this paper, we present a distributed multi-agent\ncontrol framework for time-varying coverage under nonlinear constrained\ndynamics. Our approach integrates a reference trajectory planner and a tracking\nmodel predictive control (MPC) scheme, which operate at different frequencies\nwithin a multi-rate framework. For periodic density functions, we demonstrate\nclosed-loop convergence to an optimal configuration of trajectories and provide\nformal guarantees regarding constraint satisfaction, collision avoidance, and\nrecursive feasibility. Additionally, we propose an efficient algorithm capable\nof handling nonperiodic density functions, making the approach suitable for\npractical applications. Finally, we validate our method through hardware\nexperiments using a fleet of four miniature race cars.",
      "url": "http://arxiv.org/abs/2507.01567v1",
      "published_time_eastern_timestamp": 1751452394.0
    },
    {
      "title": "Chargax: A JAX Accelerated EV Charging Simulator",
      "summary": "Deep Reinforcement Learning can play a key role in addressing sustainable\nenergy challenges. For instance, many grid systems are heavily congested,\nhighlighting the urgent need to enhance operational efficiency. However,\nreinforcement learning approaches have traditionally been slow due to the high\nsample complexity and expensive simulation requirements. While recent works\nhave effectively used GPUs to accelerate data generation by converting\nenvironments to JAX, these works have largely focussed on classical toy\nproblems. This paper introduces Chargax, a JAX-based environment for realistic\nsimulation of electric vehicle charging stations designed for accelerated\ntraining of RL agents. We validate our environment in a variety of scenarios\nbased on real data, comparing reinforcement learning agents against baselines.\nChargax delivers substantial computational performance improvements of over\n100x-1000x over existing environments. Additionally, Chargax' modular\narchitecture enables the representation of diverse real-world charging station\nconfigurations.",
      "url": "http://arxiv.org/abs/2507.01522v1",
      "published_time_eastern_timestamp": 1751448434.0
    },
    {
      "title": "Agent-as-Tool: A Study on the Hierarchical Decision Making with\n  Reinforcement Learning",
      "summary": "Large Language Models (LLMs) have emerged as one of the most significant\ntechnological advancements in artificial intelligence in recent years. Their\nability to understand, generate, and reason with natural language has\ntransformed how we interact with AI systems. With the development of LLM-based\nagents and reinforcement-learning-based reasoning models, the study of applying\nreinforcement learning in agent frameworks has become a new research focus.\nHowever, all previous studies face the challenge of deciding the tool calling\nprocess and the reasoning process simultaneously, and the chain of reasoning\nwas solely relied on the unprocessed raw result with redundant information and\nsymbols unrelated to the task from the tool, which impose a heavy burden on the\nmodel's capability to reason. Therefore, in our research, we proposed a\nhierarchical framework Agent-as-tool that detach the tool calling process and\nthe reasoning process, which enables the model to focus on the verbally\nreasoning process while the tool calling process is handled by another agent.\nOur work had achieved comparable results with only a slight reinforcement\nfine-tuning on 180 samples, and had achieved exceptionally well performance in\nBamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding\nSearch-R1 by 4.8% in exact match and 3.2% in cover exact match.",
      "url": "http://arxiv.org/abs/2507.01489v1",
      "published_time_eastern_timestamp": 1751446183.0
    },
    {
      "title": "BioMARS: A Multi-Agent Robotic System for Autonomous Biological\n  Experiments",
      "summary": "Large language models (LLMs) and vision-language models (VLMs) have the\npotential to transform biological research by enabling autonomous\nexperimentation. Yet, their application remains constrained by rigid protocol\ndesign, limited adaptability to dynamic lab conditions, inadequate error\nhandling, and high operational complexity. Here we introduce BioMARS\n(Biological Multi-Agent Robotic System), an intelligent platform that\nintegrates LLMs, VLMs, and modular robotics to autonomously design, plan, and\nexecute biological experiments. BioMARS uses a hierarchical architecture: the\nBiologist Agent synthesizes protocols via retrieval-augmented generation; the\nTechnician Agent translates them into executable robotic pseudo-code; and the\nInspector Agent ensures procedural integrity through multimodal perception and\nanomaly detection. The system autonomously conducts cell passaging and culture\ntasks, matching or exceeding manual performance in viability, consistency, and\nmorphological integrity. It also supports context-aware optimization,\noutperforming conventional strategies in differentiating retinal pigment\nepithelial cells. A web interface enables real-time human-AI collaboration,\nwhile a modular backend allows scalable integration with laboratory hardware.\nThese results highlight the feasibility of generalizable, AI-driven laboratory\nautomation and the transformative role of language-based reasoning in\nbiological research.",
      "url": "http://arxiv.org/abs/2507.01485v1",
      "published_time_eastern_timestamp": 1751446022.0
    }
  ]
}
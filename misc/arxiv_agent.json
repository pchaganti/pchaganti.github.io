{
  "last_updated": "2025-11-09T07:20:39.349086-05:00",
  "papers": [
    {
      "title": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for\n  Embodied LLM-Based Multi-Agent Collaboration",
      "summary": "Cooperative multi-agent planning requires agents to make joint decisions with\npartial information and limited communication. Coordination at the trajectory\nlevel often fails, as small deviations in timing or movement cascade into\nconflicts. Symbolic planning mitigates this challenge by raising the level of\nabstraction and providing a minimal vocabulary of actions that enable\nsynchronization and collective progress. We present DR. WELL, a decentralized\nneurosymbolic framework for cooperative multi-agent planning. Cooperation\nunfolds through a two-phase negotiation protocol: agents first propose\ncandidate roles with reasoning and then commit to a joint allocation under\nconsensus and environment constraints. After commitment, each agent\nindependently generates and executes a symbolic plan for its role without\nrevealing detailed trajectories. Plans are grounded in execution outcomes via a\nshared world model that encodes the current state and is updated as agents act.\nBy reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids\nbrittle step-level alignment and enables higher-level operations that are\nreusable, synchronizable, and interpretable. Experiments on cooperative\nblock-push tasks show that agents adapt across episodes, with the dynamic world\nmodel capturing reusable patterns and improving task completion rates and\nefficiency. Experiments on cooperative block-push tasks show that our dynamic\nworld model improves task completion and efficiency through negotiation and\nself-refinement, trading a time overhead for evolving, more efficient\ncollaboration strategies.",
      "url": "http://arxiv.org/abs/2511.04646v1",
      "published_time_eastern_timestamp": 1762454238.0
    },
    {
      "title": "Environment Agnostic Goal-Conditioning, A Study of Reward-Free\n  Autonomous Learning",
      "summary": "In this paper we study how transforming regular reinforcement learning\nenvironments into goal-conditioned environments can let agents learn to solve\ntasks autonomously and reward-free. We show that an agent can learn to solve\ntasks by selecting its own goals in an environment-agnostic way, at training\ntimes comparable to externally guided reinforcement learning. Our method is\nindependent of the underlying off-policy learning algorithm. Since our method\nis environment-agnostic, the agent does not value any goals higher than others,\nleading to instability in performance for individual goals. However, in our\nexperiments, we show that the average goal success rate improves and\nstabilizes. An agent trained with this method can be instructed to seek any\nobservations made in the environment, enabling generic training of agents prior\nto specific use cases.",
      "url": "http://arxiv.org/abs/2511.04598v1",
      "published_time_eastern_timestamp": 1762451471.0
    },
    {
      "title": "Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest\n  Path Problems",
      "summary": "Multi-agent systems (MAS) are central to applications such as swarm robotics\nand traffic routing, where agents must coordinate in a decentralized manner to\nachieve a common objective. Stochastic Shortest Path (SSP) problems provide a\nnatural framework for modeling decentralized control in such settings. While\nthe problem of learning in SSP has been extensively studied in single-agent\nsettings, the decentralized multi-agent variant remains largely unexplored. In\nthis work, we take a step towards addressing that gap. We study decentralized\nmulti-agent SSPs (Dec-MASSPs) under linear function approximation, where the\ntransition dynamics and costs are represented using linear models. Applying\nnovel symmetry-based arguments, we identify the structure of optimal policies.\nOur main contribution is the first regret lower bound for this setting based on\nthe construction of hard-to-learn instances for any number of agents, $n$. Our\nregret lower bound of $\\Omega(\\sqrt{K})$, over $K$ episodes, highlights the\ninherent learning difficulty in Dec-MASSPs. These insights clarify the learning\ncomplexity of decentralized control and can further guide the design of\nefficient learning algorithms in multi-agent systems.",
      "url": "http://arxiv.org/abs/2511.04594v1",
      "published_time_eastern_timestamp": 1762451373.0
    },
    {
      "title": "Complexity as Advantage: A Regret-Based Perspective on Emergent\n  Structure",
      "summary": "We introduce Complexity as Advantage (CAA), a framework that defines the\ncomplexity of a system relative to a family of observers. Instead of measuring\ncomplexity as an intrinsic property, we evaluate how much predictive regret a\nsystem induces for different observers attempting to model it. A system is\ncomplex when it is easy for some observers and hard for others, creating an\ninformation advantage. We show that this formulation unifies several notions of\nemergent behavior, including multiscale entropy, predictive information, and\nobserver-dependent structure. The framework suggests that \"interesting\" systems\nare those positioned to create differentiated regret across observers,\nproviding a quantitative grounding for why complexity can be functionally\nvaluable. We demonstrate the idea through simple dynamical models and discuss\nimplications for learning, evolution, and artificial agents.",
      "url": "http://arxiv.org/abs/2511.04590v1",
      "published_time_eastern_timestamp": 1762451213.0
    },
    {
      "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration\n  from a Baseline Paper",
      "summary": "Understanding the current capabilities and risks of AI Scientist systems is\nessential for ensuring trustworthy and sustainable AI-driven scientific\nprogress while preserving the integrity of the academic ecosystem. To this end,\nwe develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system\nthat mimics the core research workflow of a novice student researcher: Given\nthe baseline paper from the human mentor, it analyzes its limitations,\nformulates novel hypotheses for improvement, validates them through rigorous\nexperimentation, and writes a paper with the results. Unlike previous\napproaches that assume full automation or operate on small-scale code, Jr. AI\nScientist follows a well-defined research workflow and leverages modern coding\nagents to handle complex, multi-file implementations, leading to scientifically\nvaluable contributions. For evaluation, we conducted automated assessments\nusing AI Reviewers, author-led evaluations, and submissions to Agents4Science,\na venue dedicated to AI-driven scientific contributions. The findings\ndemonstrate that Jr. AI Scientist generates papers receiving higher review\nscores than existing fully automated systems. Nevertheless, we identify\nimportant limitations from both the author evaluation and the Agents4Science\nreviews, indicating the potential risks of directly applying current AI\nScientist systems and key challenges for future research. Finally, we\ncomprehensively report various risks identified during development. We hope\nthese insights will deepen understanding of current progress and risks in AI\nScientist development.",
      "url": "http://arxiv.org/abs/2511.04583v1",
      "published_time_eastern_timestamp": 1762450669.0
    },
    {
      "title": "Asymptotics for Reinforced Stochastic Processes on Hierarchical Networks",
      "summary": "In this paper, we analyze the asymptotic behavior of a system of interacting\nreinforced stochastic processes $({\\bf Z}_n, {\\bf N}_n)_n$ on a directed\nnetwork of $N$ agents. The system is defined by the coupled dynamics ${\\bf\nZ}_{n+1}=(1-r_{n}){\\bf Z}_{n}+r_{n}{\\bf X}_{n+1}$ and ${\\bf\nN}_{n+1}=(1-\\frac{1}{n+1}){\\bf N}_n+\\frac{1}{n+1}{\\bf X}_{n+1}$, where agent\nactions $\\mathbb{P}(X_{n+1,j}=1\\mid{\\cal F}_n)=\\sum_{h} w_{hj}Z_{nh}$ are\ngoverned by a column-normalized adjacency matrix ${\\bf W}$, and $r_n \\sim\ncn^{-\\gamma}$ with $\\gamma \\in (1/2, 1]$. Existing asymptotic theory has\nlargely been restricted to irreducible and diagonalizable ${\\bf W}$. We extend\nthis analysis to the broader and more practical class of reducible and\nnon-diagonalizable matrices ${\\bf W}$ possessing a block upper-triangular form,\nwhich models hierarchical influence. We first establish synchronization,\nproving $({\\bf Z}^\\top_n, {\\bf N}^\\top_n)^\\top \\to Z_\\infty {\\bf 1}$ almost\nsurely, where the distribution of the limit $Z_\\infty$ is shown to be\ndetermined solely by the internal dynamics of the leading subgroup.\nFurthermore, we establish a joint central limit theorem for $({\\bf Z}_n,{\\bf\nN}_n)_n$, revealing how the spectral properties and Jordan block structure of\n${\\bf W}$ govern second-order fluctuations. We demonstrate that the convergence\nrates and the limiting covariance structure exhibit a phase transition\ndependent on $\\gamma$ and the spectral properties of ${\\bf W}$. Crucially, we\nexplicitly characterize how the non-diagonalizability of ${\\bf W}$\nfundamentally alters the asymptotic covariance and introduces new logarithmic\nscaling factors in the critical case ($\\gamma=1$). These results provide a\nprobabilistic foundation for statistical inference on such hierarchical network\nstructures.",
      "url": "http://arxiv.org/abs/2511.04562v1",
      "published_time_eastern_timestamp": 1762449456.0
    },
    {
      "title": "BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented\n  Generation Strategies for Bangla Biomedical Question Answering",
      "summary": "Developing accurate biomedical Question Answering (QA) systems in\nlow-resource languages remains a major challenge, limiting equitable access to\nreliable medical knowledge. This paper introduces BanglaMedQA and\nBanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice\nQuestion (MCQ) datasets designed to evaluate reasoning and retrieval in medical\nartificial intelligence (AI). The study applies and benchmarks several\nRetrieval-Augmented Generation (RAG) strategies, including Traditional,\nZero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining\ntextbook-based and web retrieval with generative reasoning to improve factual\naccuracy. A key novelty lies in integrating a Bangla medical textbook corpus\nthrough Optical Character Recognition (OCR) and implementing an Agentic RAG\npipeline that dynamically selects between retrieval and reasoning strategies.\nExperimental results show that the Agentic RAG achieved the highest accuracy\n89.54% with openai/gpt-oss-120b, outperforming other configurations and\ndemonstrating superior rationale quality. These findings highlight the\npotential of RAG-based methods to enhance the reliability and accessibility of\nBangla medical QA, establishing a foundation for future research in\nmultilingual medical artificial intelligence.",
      "url": "http://arxiv.org/abs/2511.04560v1",
      "published_time_eastern_timestamp": 1762449333.0
    },
    {
      "title": "Robust mean-field control under common noise uncertainty",
      "summary": "We propose and analyze a framework for discrete-time robust mean-field\ncontrol problems under common noise uncertainty. In this framework, the\nmean-field interaction describes the collective behavior of infinitely many\ncooperative agents' state and action, while the common noise -- a random\ndisturbance affecting all agents' state dynamics -- is uncertain. A social\nplanner optimizes over open-loop controls on an infinite horizon to maximize\nthe representative agent's worst-case expected reward, where worst-case\ncorresponds to the most adverse probability measure among all candidates\ninducing the unknown true law of the common noise process. We refer to this\noptimization as a robust mean-field control problem under common noise\nuncertainty. We first show that this problem arises as the asymptotic limit of\na cooperative $N$-agent robust optimization problem, commonly known as\npropagation of chaos. We then prove the existence of an optimal open-loop\ncontrol by linking the robust mean field control problem to a lifted robust\nMarkov decision problem on the space of probability measures and by\nestablishing the dynamic programming principle and Bellman--Isaac fixed point\ntheorem for the lifted robust Markov decision problem. Finally, we complement\nour theoretical results with numerical experiments motivated by distribution\nplanning and systemic risk in finance, highlighting the advantages of\naccounting for common noise uncertainty.",
      "url": "http://arxiv.org/abs/2511.04515v1",
      "published_time_eastern_timestamp": 1762446709.0
    },
    {
      "title": "RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific\n  RAG",
      "summary": "Retrieval-Augmented Generation (RAG) is a critical technique for grounding\nLarge Language Models (LLMs) in factual evidence, yet evaluating RAG systems in\nspecialized, safety-critical domains remains a significant challenge. Existing\nevaluation frameworks often rely on heuristic-based metrics that fail to\ncapture domain-specific nuances and other works utilize LLM-as-a-Judge\napproaches that lack validated alignment with human judgment. This paper\nintroduces RAGalyst, an automated, human-aligned agentic framework designed for\nthe rigorous evaluation of domain-specific RAG systems. RAGalyst features an\nagentic pipeline that generates high-quality, synthetic question-answering (QA)\ndatasets from source documents, incorporating an agentic filtering step to\nensure data fidelity. The framework refines two key LLM-as-a-Judge\nmetrics-Answer Correctness and Answerability-using prompt optimization to\nachieve a strong correlation with human annotations. Applying this framework to\nevaluate various RAG components across three distinct domains (military\noperations, cybersecurity, and bridge engineering), we find that performance is\nhighly context-dependent. No single embedding model, LLM, or hyperparameter\nconfiguration proves universally optimal. Additionally, we provide an analysis\non the most common low Answer Correctness reasons in RAG. These findings\nhighlight the necessity of a systematic evaluation framework like RAGalyst,\nwhich empowers practitioners to uncover domain-specific trade-offs and make\ninformed design choices for building reliable and effective RAG systems.\nRAGalyst is available on our Github.",
      "url": "http://arxiv.org/abs/2511.04502v1",
      "published_time_eastern_timestamp": 1762446172.0
    },
    {
      "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy\n  Consumption through Empirical and Theoretical Analysis",
      "summary": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful\nagentic systems pushing the boundaries of Large Language Models (LLM). They can\nautonomously interact with the internet at the user's behest, such as\nnavigating websites, filling search masks, and comparing price lists. Though\nweb agent research is thriving, induced sustainability issues remain largely\nunexplored. To highlight the urgency of this issue, we provide an initial\nexploration of the energy and $CO_2$ cost associated with web agents from both\na theoretical -via estimation- and an empirical perspective -by benchmarking.\nOur results show how different philosophies in web agent creation can severely\nimpact the associated expended energy, and that more energy consumed does not\nnecessarily equate to better results. We highlight a lack of transparency\nregarding disclosing model parameters and processes used for some web agents as\na limiting factor when estimating energy consumption. Our work contributes\ntowards a change in thinking of how we evaluate web agents, advocating for\ndedicated metrics measuring energy consumption in benchmarks.",
      "url": "http://arxiv.org/abs/2511.04481v1",
      "published_time_eastern_timestamp": 1762444799.0
    },
    {
      "title": "Exploiting Data Structures for Bypassing and Crashing Anti-Malware\n  Solutions via Telemetry Complexity Attacks",
      "summary": "Anti-malware systems rely on sandboxes, hooks, and telemetry pipelines,\nincluding collection agents, serializers, and database backends, to monitor\nprogram and system behavior. We show that these data-handling components\nconstitute an exploitable attack surface that can lead to denial-of-analysis\n(DoA) states without disabling sensors or requiring elevated privileges. As a\nresult, we present \\textit{Telemetry Complexity Attacks} (TCAs), a new class of\nvulnerabilities that exploit fundamental mismatches between unbounded\ncollection mechanisms and bounded processing capabilities. Our method\nrecursively spawns child processes to generate specially crafted, deeply\nnested, and oversized telemetry that stresses serialization and storage\nboundaries, as well as visualization layers, for example, JSON/BSON depth and\nsize limits. Depending on the product, this leads to truncated or missing\nbehavioral reports, rejected database inserts, serializer recursion and size\nerrors, and unresponsive dashboards. In all of these cases, malicious activity\nis normally executed; however, depending on the examined solution, it is not\nrecorded and/or not presented to the analysts. Therefore, instead of evading\nsensors, we break the pipeline that stores the data captured by the sensors.\n  We evaluate our technique against twelve commercial and open-source malware\nanalysis platforms and endpoint detection and response (EDR) solutions. Seven\nproducts fail in different stages of the telemetry pipeline; two vendors\nassigned CVE identifiers (CVE-2025-61301 and CVE-2025-61303), and others issued\npatches or configuration changes. We discuss root causes and propose mitigation\nstrategies to prevent DoA attacks triggered by adversarial telemetry.",
      "url": "http://arxiv.org/abs/2511.04472v1",
      "published_time_eastern_timestamp": 1762443903.0
    },
    {
      "title": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context",
      "summary": "Traditional vehicle routing systems efficiently optimize singular metrics\nlike time or distance, and when considering multiple metrics, they need more\nprocesses to optimize . However, they lack the capability to interpret and\nintegrate the complex, semantic, and dynamic contexts of human drivers, such as\nmulti-step tasks, situational constraints, or urgent needs. This paper\nintroduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a\nhybrid agentic assistant designed to augment classical pathfinding algorithms\nwith contextual reasoning. Our approach employs a Large Language Model (LLM)\nagent that operates on a candidate set of routes generated by a multi-objective\n(time, CO2) Dijkstra algorithm. The agent evaluates these options against\nuser-provided tasks, preferences, and avoidance rules by leveraging a\npre-processed geospatial cache of urban Points of Interest (POIs). In a\nbenchmark of realistic urban scenarios, PAVe successfully used complex user\nintent into appropriate route modifications, achieving over 88% accuracy in its\ninitial route selections with a local model. We conclude that combining\nclassical routing algorithms with an LLM-based semantic reasoning layer is a\nrobust and effective approach for creating personalized, adaptive, and scalable\nsolutions for urban mobility optimization.",
      "url": "http://arxiv.org/abs/2511.04464v1",
      "published_time_eastern_timestamp": 1762443431.0
    },
    {
      "title": "Speed at the Cost of Quality? The Impact of LLM Agent Assistance on\n  Software Development",
      "summary": "Large language models (LLMs) have demonstrated the promise to revolutionize\nthe field of software engineering. Among other things, LLM agents are rapidly\ngaining momentum in their application to software development, with\npractitioners claiming a multifold productivity increase after adoption. Yet,\nempirical evidence is lacking around these claims. In this paper, we estimate\nthe causal effect of adopting a widely popular LLM agent assistant, namely\nCursor, on development velocity and software quality. The estimation is enabled\nby a state-of-the-art difference-in-differences design comparing\nCursor-adopting GitHub projects with a matched control group of similar GitHub\nprojects that do not use Cursor. We find that the adoption of Cursor leads to a\nsignificant, large, but transient increase in project-level development\nvelocity, along with a significant and persistent increase in static analysis\nwarnings and code complexity. Further panel generalized method of moments\nestimation reveals that the increase in static analysis warnings and code\ncomplexity acts as a major factor causing long-term velocity slowdown. Our\nstudy carries implications for software engineering practitioners, LLM agent\nassistant designers, and researchers.",
      "url": "http://arxiv.org/abs/2511.04427v1",
      "published_time_eastern_timestamp": 1762441251.0
    },
    {
      "title": "Post-Training LLMs as Better Decision-Making Agents: A\n  Regret-Minimization Approach",
      "summary": "Large language models (LLMs) are increasingly deployed as \"agents\" for\ndecision-making (DM) in interactive and dynamic environments. Yet, since they\nwere not originally designed for DM, recent studies show that LLMs can struggle\neven in basic online DM problems, failing to achieve low regret or an effective\nexploration-exploitation tradeoff. To address this, we introduce Iterative\nRegret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure\nthat repeatedly distills low-regret decision trajectories back into the base\nmodel. At each iteration, the model rolls out multiple decision trajectories,\nselects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior\nmethods that (a) distill action sequences from known DM algorithms or (b) rely\non manually crafted chain-of-thought templates, our approach leverages the\nregret metric to elicit the model's own DM ability and reasoning rationales.\nThis reliance on model-generated reasoning avoids rigid output engineering and\nprovides more flexible, natural-language training signals. Empirical results\nshow that Iterative RMFT improves LLMs' DM performance across diverse models -\nfrom Transformers with numerical input/output, to open-weight LLMs, and\nadvanced closed-weight models like GPT-4o mini. Its flexibility in output and\nreasoning formats enables generalization across tasks with varying horizons,\naction spaces, reward processes, and natural-language contexts. Finally, we\nprovide theoretical insight showing that a single-layer Transformer under this\nparadigm can act as a no-regret learner in a simplified setting. Overall,\nIterative RMFT offers a principled and general post-training framework for\nenhancing LLMs' decision-making capabilities.",
      "url": "http://arxiv.org/abs/2511.04393v1",
      "published_time_eastern_timestamp": 1762438882.0
    },
    {
      "title": "Free-order secretary for two-sided independence systems",
      "summary": "The Matroid Secretary Problem is a central question in online optimization,\nmodeling sequential decision-making under combinatorial constraints. We\nintroduce a bipartite graph framework that unifies and extends several known\nformulations, including the bipartite matching, matroid intersection, and\nrandom-order matroid secretary problems. In this model, elements form a\nbipartite graph between agents and items, and the objective is to select a\nmatching that satisfies feasibility constraints on both sides, given by two\nindependence systems.\n  We study the free-order setting, where the algorithm may adaptively choose\nthe next element to reveal. For $k$-matroid intersection, we leverage a core\nlemma by (Feldman, Svensson and Zenklusen, 2022) to design an\n$\\Omega(1/k^2)$-competitive algorithm, extending known results for single\nmatroids. Building on this, we identify the structural property underlying our\napproach and introduce $k$-growth systems. We establish a generalized core\nlemma for $k$-growth systems, showing that a suitably defined set of critical\nelements retains a $\\Omega(1/k^2)$ fraction of the optimal weight. Using this\nlemma, we extend our $\\Omega(1/k^2)$-competitive algorithm to $k$-growth\nsystems for the edge-arrival model.\n  We then study the agent-arrival model, which presents unique challenges to\nour framework. We extend the core lemma to this model and then apply it to\nobtain an $\\Omega(\\beta/k^2)$-competitive algorithm for $k$-growth systems,\nwhere $\\beta$ denotes the competitiveness of a special type of order-oblivious\nalgorithm for the item-side constraint. Finally, we relax the matching\nassumption and extend our results to the case of multiple item selection, where\nagents have individual independence systems coupled by a global item-side\nconstraint. We obtain constant-competitive algorithms for fundamental cases\nsuch as partition matroids and $k$-matching constraints.",
      "url": "http://arxiv.org/abs/2511.04390v1",
      "published_time_eastern_timestamp": 1762438806.0
    },
    {
      "title": "ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic\n  Manipulation",
      "summary": "Efficiently leveraging simulation to acquire advanced manipulation skills is\nboth challenging and highly significant. We introduce \\textit{ForeRobo}, a\ngenerative robotic agent that utilizes generative simulations to autonomously\nacquire manipulation skills driven by envisioned goal states. Instead of\ndirectly learning low-level policies, we advocate integrating generative\nparadigms with classical control. Our approach equips a robotic agent with a\nself-guided \\textit{propose-generate-learn-actuate} cycle. The agent first\nproposes the skills to be acquired and constructs the corresponding simulation\nenvironments; it then configures objects into appropriate arrangements to\ngenerate skill-consistent goal states (\\textit{ForeGen}). Subsequently, the\nvirtually infinite data produced by ForeGen are used to train the proposed\nstate generation model (\\textit{ForeFormer}), which establishes point-wise\ncorrespondences by predicting the 3D goal position of every point in the\ncurrent state, based on the scene state and task instructions. Finally,\nclassical control algorithms are employed to drive the robot in real-world\nenvironments to execute actions based on the envisioned goal states. Compared\nwith end-to-end policy learning methods, ForeFormer offers superior\ninterpretability and execution efficiency. We train and benchmark ForeFormer\nacross a variety of rigid-body and articulated-object manipulation tasks, and\nobserve an average improvement of 56.32\\% over the state-of-the-art state\ngeneration models, demonstrating strong generality across different\nmanipulation patterns. Moreover, in real-world evaluations involving more than\n20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits\nremarkable generalization capabilities, attaining an average success rate of\n79.28\\%.",
      "url": "http://arxiv.org/abs/2511.04381v1",
      "published_time_eastern_timestamp": 1762437829.0
    },
    {
      "title": "Studying the Effect of Explicit Interaction Representations on Learning\n  Scene-level Distributions of Human Trajectories",
      "summary": "Effectively capturing the joint distribution of all agents in a scene is\nrelevant for predicting the true evolution of the scene and in turn providing\nmore accurate information to the decision processes of autonomous vehicles.\nWhile new models have been developed for this purpose in recent years, it\nremains unclear how to best represent the joint distributions particularly from\nthe perspective of the interactions between agents. Thus far there is no clear\nconsensus on how best to represent interactions between agents; whether they\nshould be learned implicitly from data by neural networks, or explicitly\nmodeled using the spatial and temporal relations that are more grounded in\nhuman decision-making. This paper aims to study various means of describing\ninteractions within the same network structure and their effect on the final\nlearned joint distributions. Our findings show that more often than not, simply\nallowing a network to establish interactive connections between agents based on\ndata has a detrimental effect on performance. Instead, having well defined\ninteractions (such as which agent of an agent pair passes first at an\nintersection) can often bring about a clear boost in performance.",
      "url": "http://arxiv.org/abs/2511.04375v1",
      "published_time_eastern_timestamp": 1762437707.0
    },
    {
      "title": "DeepPAAC: A New Deep Galerkin Method for Principal-Agent Problems",
      "summary": "We consider numerical resolution of principal-agent (PA) problems in\ncontinuous time. We formulate a generic PA model with continuous and lump\npayments and a multi-dimensional strategy of the agent. To tackle the resulting\nHamilton-Jacobi-Bellman equation with an implicit Hamiltonian we develop a\nnovel deep learning method: the Deep Principal-Agent Actor Critic (DeepPAAC)\nActor-Critic algorithm. DeepPAAC is able to handle multi-dimensional states and\ncontrols, as well as constraints. We investigate the role of the neural network\narchitecture, training designs, loss functions, etc. on the convergence of the\nsolver, presenting five different case studies.",
      "url": "http://arxiv.org/abs/2511.04309v1",
      "published_time_eastern_timestamp": 1762431943.0
    },
    {
      "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents",
      "summary": "We introduce GUI-360$^\\circ$, a large-scale, comprehensive dataset and\nbenchmark suite designed to advance computer-using agents (CUAs). CUAs present\nunique challenges and is constrained by three persistent gaps: a scarcity of\nreal-world CUA tasks, the lack of automated collection-and-annotation pipelines\nfor multi-modal trajectories, and the absence of a unified benchmark that\njointly evaluates GUI grounding, screen parsing, and action prediction.\n  GUI-360$^\\circ$ addresses these gaps with an LLM-augmented, largely automated\npipeline for query sourcing, environment-template construction, task\ninstantiation, batched execution, and LLM-driven quality filtering. The\nreleased corpus contains over 1.2M executed action steps across thousands of\ntrajectories in popular Windows office applications, and includes\nfull-resolution screenshots, accessibility metadata when available,\ninstantiated goals, intermediate reasoning traces, and both successful and\nfailed action trajectories. The dataset supports three canonical tasks, GUI\ngrounding, screen parsing, and action prediction, and a hybrid GUI+API action\nspace that reflects modern agent designs. Benchmarking state-of-the-art\nvision--language models on GUI-360$^\\circ$ reveals substantial out-of-the-box\nshortcomings in grounding and action prediction; supervised fine-tuning and\nreinforcement learning yield significant gains but do not close the gap to\nhuman-level reliability. We release GUI-360$^\\circ$ and accompanying code to\nfacilitate reproducible research and accelerate progress on robust desktop\nCUAs.\n  The full dataset has been made public on\nhttps://huggingface.co/datasets/vyokky/GUI-360.",
      "url": "http://arxiv.org/abs/2511.04307v1",
      "published_time_eastern_timestamp": 1762431542.0
    },
    {
      "title": "Shared Spatial Memory Through Predictive Coding",
      "summary": "Sharing and reconstructing a consistent spatial memory is a critical\nchallenge in multi-agent systems, where partial observability and limited\nbandwidth often lead to catastrophic failures in coordination. We introduce a\nmulti-agent predictive coding framework that formulate coordination as the\nminimization of mutual uncertainty among agents. Instantiated as an information\nbottleneck objective, it prompts agents to learn not only who and what to\ncommunicate but also when. At the foundation of this framework lies a\ngrid-cell-like metric as internal spatial coding for self-localization,\nemerging spontaneously from self-supervised motion prediction. Building upon\nthis internal spatial code, agents gradually develop a bandwidth-efficient\ncommunication mechanism and specialized neural populations that encode\npartners' locations: an artificial analogue of hippocampal social place cells\n(SPCs). These social representations are further enacted by a hierarchical\nreinforcement learning policy that actively explores to reduce joint\nuncertainty. On the Memory-Maze benchmark, our approach shows exceptional\nresilience to bandwidth constraints: success degrades gracefully from 73.5% to\n64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast\nbaseline collapses from 67.6% to 28.6%. Our findings establish a theoretically\nprincipled and biologically plausible basis for how complex social\nrepresentations emerge from a unified predictive drive, leading to social\ncollective intelligence.",
      "url": "http://arxiv.org/abs/2511.04235v1",
      "published_time_eastern_timestamp": 1762423966.0
    }
  ]
}
{
  "last_updated": "2025-07-17T08:24:59.786341-04:00",
  "papers": [
    {
      "title": "Advancing Retrieval-Augmented Generation for Structured Enterprise and\n  Internal Data",
      "summary": "Organizations increasingly rely on proprietary enterprise data, including HR\nrecords, structured reports, and tabular documents, for critical\ndecision-making. While Large Language Models (LLMs) have strong generative\ncapabilities, they are limited by static pretraining, short context windows,\nand challenges in processing heterogeneous data formats. Conventional\nRetrieval-Augmented Generation (RAG) frameworks address some of these gaps but\noften struggle with structured and semi-structured data.\n  This work proposes an advanced RAG framework that combines hybrid retrieval\nstrategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by\nmetadata-aware filtering with SpaCy NER and cross-encoder reranking. The\nframework applies semantic chunking to maintain textual coherence and retains\ntabular data structures to preserve row-column integrity. Quantized indexing\noptimizes retrieval efficiency, while human-in-the-loop feedback and\nconversation memory improve adaptability.\n  Experiments on enterprise datasets show notable improvements: Precision@5\nincreased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),\nand Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative\nevaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness\n(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.\nThese results demonstrate the framework's effectiveness in delivering accurate,\ncomprehensive, and contextually relevant responses for enterprise tasks. Future\nwork includes extending to multimodal data and integrating agent-based\nretrieval. The source code will be released at\nhttps://github.com/CheerlaChandana/Enterprise-Chatbot",
      "url": "http://arxiv.org/abs/2507.12425v1",
      "published_time_eastern_timestamp": 1752685986.0
    },
    {
      "title": "Modeling Feasible Locomotion of Nanobots for Cancer Detection and\n  Treatment",
      "summary": "Deploying motile nanosized particles, also known as ``nanobots'', in the\nhuman body promises to improve selectivity in drug delivery and reduce side\neffects. We consider a swarm of nanobots locating a single cancerous region and\ntreating it by releasing an onboard payload of drugs at the site. At nanoscale,\nthe computation, communication, sensing, and locomotion capabilities of\nindividual agents are extremely limited, noisy, and/or nonexistent.\n  We present a general model to formally describe the individual and collective\nbehavior of agents in a colloidal environment, such as the bloodstream, for\ncancer detection and treatment by nanobots. This includes a feasible and\nprecise model of agent locomotion, inspired by actual nanoparticles that, in\nthe presence of an external chemical gradient, move towards areas of higher\nconcentration by means of self-propulsion. We present two variants of our\ngeneral model: The first assumes an endogenous chemical gradient that is fixed\nover time and centered at the targeted cancer site; the second is a more\nspeculative and dynamic variant in which agents themselves create and amplify a\nchemical gradient centered at the cancer site. In both settings, agents can\nsense the gradient and ascend it noisily, locating the cancer site more quickly\nthan via simple Brownian motion.\n  For the first variant of the model, we present simulation results to show the\nbehavior of agents under our locomotion model, as well as {analytical results}\nto bound the time it takes for the agents to reach the cancer site. For the\nsecond variant, simulation results highlight the collective benefit in having\nagents issue their own chemical signal. While arguably more speculative in its\nagent capability assumptions, this variant shows a significant improvement in\nruntime performance over the first variant, resulting from its chemical signal\namplification mechanism.",
      "url": "http://arxiv.org/abs/2507.12400v1",
      "published_time_eastern_timestamp": 1752684290.0
    },
    {
      "title": "Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests\n  through Debate",
      "summary": "Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and generating human language, contributing to more natural\ninteractions with complex systems. However, they face challenges such as\nambiguity in user requests processed by LLMs. To address these challenges, this\npaper introduces and evaluates a multi-agent debate framework designed to\nenhance detection and resolution capabilities beyond single models. The\nframework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and\nMistral-7B variants) and a dataset with diverse ambiguities. The debate\nframework markedly enhanced the performance of Llama3-8B and Mistral-7B\nvariants over their individual baselines, with Mistral-7B-led debates achieving\na notable 76.7% success rate and proving particularly effective for complex\nambiguities and efficient consensus. While acknowledging varying model\nresponses to collaborative strategies, these findings underscore the debate\nframework's value as a targeted method for augmenting LLM capabilities. This\nwork offers important insights for developing more robust and adaptive language\nunderstanding systems by showing how structured debates can lead to improved\nclarity in interactive systems.",
      "url": "http://arxiv.org/abs/2507.12370v1",
      "published_time_eastern_timestamp": 1752682525.0
    },
    {
      "title": "GitChameleon: Evaluating AI Code Generation Against Python Library\n  Version Incompatibilities",
      "summary": "The rapid evolution of software libraries poses a considerable hurdle for\ncode generation, necessitating continuous adaptation to frequent version\nupdates while preserving backward compatibility. While existing code evolution\nbenchmarks provide valuable insights, they typically lack execution-based\nevaluation for generating code compliant with specific library versions. To\naddress this, we introduce GitChameleon, a novel, meticulously curated dataset\ncomprising 328 Python code completion problems, each conditioned on specific\nlibrary versions and accompanied by executable unit tests. GitChameleon\nrigorously evaluates the capacity of contemporary large language models (LLMs),\nLLM-powered agents, code assistants, and RAG systems to perform\nversion-conditioned code generation that demonstrates functional accuracy\nthrough execution. Our extensive evaluations indicate that state-of-the-art\nsystems encounter significant challenges with this task; enterprise models\nachieving baseline success rates in the 48-51\\% range, underscoring the\nintricacy of the problem. By offering an execution-based benchmark emphasizing\nthe dynamic nature of code libraries, GitChameleon enables a clearer\nunderstanding of this challenge and helps guide the development of more\nadaptable and dependable AI code generation methods. We make the dataset and\nevaluation code publicly available at\nhttps://github.com/mrcabbage972/GitChameleonBenchmark.",
      "url": "http://arxiv.org/abs/2507.12367v1",
      "published_time_eastern_timestamp": 1752682242.0
    },
    {
      "title": "Social polarization promoted by sparse higher-order interactions",
      "summary": "Many social interactions are group-based, yet their role in social\npolarization remains largely unexplored. To bridge this gap here we introduce a\nhigher-order framework that takes into account both group interactions and\nhomophily. We find that group interactions can strongly enhance polarization in\nsparse systems by limiting agents' exposure to dissenting views. Conversely,\nthey can suppress polarization in fully connected societies, an effect that\nintensifies as the group size increases. Our results highlight that\npolarization depends not only on the homophily strength but also on the\nstructure and microscopic arrangement of group interactions.",
      "url": "http://arxiv.org/abs/2507.12325v1",
      "published_time_eastern_timestamp": 1752678968.0
    },
    {
      "title": "Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction\n  with an Agentic Robot",
      "summary": "Autonomous robots are increasingly being tested into public spaces to enhance\nuser experiences, particularly in cultural and educational settings. This paper\npresents the design, implementation, and evaluation of the autonomous museum\nguide robot Alter-Ego equipped with advanced navigation and interactive\ncapabilities. The robot leverages state-of-the-art Large Language Models (LLMs)\nto provide real-time, context aware question-and-answer (Q&A) interactions,\nallowing visitors to engage in conversations about exhibits. It also employs\nrobust simultaneous localization and mapping (SLAM) techniques, enabling\nseamless navigation through museum spaces and route adaptation based on user\nrequests. The system was tested in a real museum environment with 34\nparticipants, combining qualitative analysis of visitor-robot conversations and\nquantitative analysis of pre and post interaction surveys. Results showed that\nthe robot was generally well-received and contributed to an engaging museum\nexperience, despite some limitations in comprehension and responsiveness. This\nstudy sheds light on HRI in cultural spaces, highlighting not only the\npotential of AI-driven robotics to support accessibility and knowledge\nacquisition, but also the current limitations and challenges of deploying such\ntechnologies in complex, real-world environments.",
      "url": "http://arxiv.org/abs/2507.12273v1",
      "published_time_eastern_timestamp": 1752675720.0
    },
    {
      "title": "Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form\n  Clinical Notes",
      "summary": "For clinical data integration and healthcare services, the HL7 FHIR standard\nhas established itself as a desirable format for interoperability between\ncomplex health data. Previous attempts at automating the translation from\nfree-form clinical notes into structured FHIR resources rely on modular,\nrule-based systems or LLMs with instruction tuning and constrained decoding.\nSince they frequently suffer from limited generalizability and structural\ninconformity, we propose an end-to-end framework powered by LLM agents, code\nexecution, and healthcare terminology database tools to address these issues.\nOur solution, called Infherno, is designed to adhere to the FHIR document\nschema and competes well with a human baseline in predicting FHIR resources\nfrom unstructured text. The implementation features a front end for custom and\nsynthetic data and both local and proprietary models, supporting clinical data\nintegration processes and interoperability across institutions.",
      "url": "http://arxiv.org/abs/2507.12261v1",
      "published_time_eastern_timestamp": 1752674811.0
    },
    {
      "title": "Toward a Behavioural Translation Style Space: Simulating the Temporal\n  Dynamics of Affect, Behaviour, and Cognition in Human Translation Production",
      "summary": "The paper introduces a Behavioural Translation Style Space (BTSS) that\ndescribes possible behavioural translation patterns. The suggested BTSS is\norganized as a hierarchical structure that entails various embedded processing\nlayers. We posit that observable translation behaviour - i.e., eye and finger\nmovements - is fundamental when executing the physical act of translation but\nit is caused and shaped by higher-order cognitive processes and affective\ntranslation states. We analyse records of keystrokes and gaze data as\nindicators of the hidden mental processing structure and organize the\nbehavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the\nbasis for a computational translation agent to simulate the temporal dynamics\nof affect, automatized behaviour and cognition during human translation\nproduction.",
      "url": "http://arxiv.org/abs/2507.12208v1",
      "published_time_eastern_timestamp": 1752671410.0
    },
    {
      "title": "BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum\n  architecture search",
      "summary": "We introduce BenchRL-QAS, a unified benchmarking framework for systematically\nevaluating reinforcement learning (RL) algorithms in quantum architecture\nsearch (QAS) across diverse variational quantum algorithm tasks and system\nsizes ranging from 2- to 8-qubit. Our study benchmarks nine RL agents including\nboth value-based and policy-gradient methods on representative quantum problems\nsuch as variational quantum eigensolver, variational quantum state\ndiagonalization, quantum classification, and state preparation, spanning both\nnoiseless and realistic noisy regimes. We propose a weighted ranking metric\nthat balances accuracy, circuit depth, gate count, and computational\nefficiency, enabling fair and comprehensive comparison. Our results first\nreveal that RL-based quantum classifier outperforms baseline variational\nclassifiers. Then we conclude that no single RL algorithm is universally\noptimal when considering a set of QAS tasks; algorithmic performance is highly\ncontext-dependent, varying with task structure, qubit count, and noise. This\nempirical finding provides strong evidence for the \"no free lunch\" principle in\nRL-based quantum circuit design and highlights the necessity of tailored\nalgorithm selection and systematic benchmarking for advancing quantum circuit\nsynthesis. This work represents the most comprehensive RL-QAS benchmarking\neffort to date, and BenchRL-QAS along with all experimental data are made\npublicly available to support reproducibility and future research\nhttps://github.com/azhar-ikhtiarudin/bench-rlqas.",
      "url": "http://arxiv.org/abs/2507.12189v1",
      "published_time_eastern_timestamp": 1752669805.0
    },
    {
      "title": "Fast and Scalable Game-Theoretic Trajectory Planning with Intentional\n  Uncertainties",
      "summary": "Trajectory planning involving multi-agent interactions has been a\nlong-standing challenge in the field of robotics, primarily burdened by the\ninherent yet intricate interactions among agents. While game-theoretic methods\nare widely acknowledged for their effectiveness in managing multi-agent\ninteractions, significant impediments persist when it comes to accommodating\nthe intentional uncertainties of agents. In the context of intentional\nuncertainties, the heavy computational burdens associated with existing\ngame-theoretic methods are induced, leading to inefficiencies and poor\nscalability. In this paper, we propose a novel game-theoretic interactive\ntrajectory planning method to effectively address the intentional uncertainties\nof agents, and it demonstrates both high efficiency and enhanced scalability.\nAs the underpinning basis, we model the interactions between agents under\nintentional uncertainties as a general Bayesian game, and we show that its\nagent-form equivalence can be represented as a potential game under certain\nminor assumptions. The existence and attainability of the optimal interactive\ntrajectories are illustrated, as the corresponding Bayesian Nash equilibrium\ncan be attained by optimizing a unified optimization problem. Additionally, we\npresent a distributed algorithm based on the dual consensus alternating\ndirection method of multipliers (ADMM) tailored to the parallel solving of the\nproblem, thereby significantly improving the scalability. The attendant\noutcomes from simulations and experiments demonstrate that the proposed method\nis effective across a range of scenarios characterized by general forms of\nintentional uncertainties. Its scalability surpasses that of existing\ncentralized and decentralized baselines, allowing for real-time interactive\ntrajectory planning in uncertain game settings.",
      "url": "http://arxiv.org/abs/2507.12174v1",
      "published_time_eastern_timestamp": 1752667945.0
    },
    {
      "title": "Convergence Rate of Generalized Nash Equilibrium Learning in Strongly\n  Monotone Games with Linear Constraints",
      "summary": "We consider payoff-based learning of a generalized Nash equilibrium (GNE) in\nmulti-agent systems. Our focus is on games with jointly convex constraints of a\nlinear structure and strongly monotone pseudo-gradients. We present a\nconvergent procedure based on a partial regularization technique and establish\nthe convergence rate of its iterates under one- and two-point payoff-based\nfeedback. To the best of our knowledge, this work is the first one\ncharacterizing the convergence speed of iterates to a variational GNE in the\nclass of games under consideration.",
      "url": "http://arxiv.org/abs/2507.12112v1",
      "published_time_eastern_timestamp": 1752661783.0
    },
    {
      "title": "Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of\n  CAVs",
      "summary": "The exploration-exploitation trade-off constitutes one of the fundamental\nchallenges in reinforcement learning (RL), which is exacerbated in multi-agent\nreinforcement learning (MARL) due to the exponential growth of joint\nstate-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)\nmethod for optimizing cooperative decision-making of connected and autonomous\nvehicles (CAVs) in mixed traffic. This work presents two primary contributions:\nFirst, we construct a game topology tensor for dynamic traffic flow,\neffectively compressing high-dimensional traffic state information and decrease\nthe search space for MARL algorithms. Second, building upon the designed game\ntopology tensor and using QMIX as the backbone RL algorithm, we establish a\ntopology-enhanced MARL framework incorporating visit counts and agent mutual\ninformation. Extensive simulations across varying traffic densities and CAV\npenetration rates demonstrate the effectiveness of TPE-MARL. Evaluations\nencompassing training dynamics, exploration patterns, macroscopic traffic\nperformance metrics, and microscopic vehicle behaviors reveal that TPE-MARL\nsuccessfully balances exploration and exploitation. Consequently, it exhibits\nsuperior performance in terms of traffic efficiency, safety, decision\nsmoothness, and task completion. Furthermore, the algorithm demonstrates\ndecision-making rationality comparable to or exceeding that of human drivers in\nboth mixed-autonomy and fully autonomous traffic scenarios. Code of our work is\navailable at\n\\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.",
      "url": "http://arxiv.org/abs/2507.12110v1",
      "published_time_eastern_timestamp": 1752661656.0
    },
    {
      "title": "Foresight in Motion: Reinforcing Trajectory Prediction with Reward\n  Heuristics",
      "summary": "Motion forecasting for on-road traffic agents presents both a significant\nchallenge and a critical necessity for ensuring safety in autonomous driving\nsystems. In contrast to most existing data-driven approaches that directly\npredict future trajectories, we rethink this task from a planning perspective,\nadvocating a \"First Reasoning, Then Forecasting\" strategy that explicitly\nincorporates behavior intentions as spatial guidance for trajectory prediction.\nTo achieve this, we introduce an interpretable, reward-driven intention\nreasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)\nscheme. Our method first encodes traffic agents and scene elements into a\nunified vectorized representation, then aggregates contextual features through\na query-centric paradigm. This enables the derivation of a reward distribution,\na compact yet informative representation of the target agent's behavior within\nthe given scene context via IRL. Guided by this reward heuristic, we perform\npolicy rollouts to reason about multiple plausible intentions, providing\nvaluable priors for subsequent trajectory generation. Finally, we develop a\nhierarchical DETR-like decoder integrated with bidirectional selective state\nspace models to produce accurate future trajectories along with their\nassociated probabilities. Extensive experiments on the large-scale Argoverse\nand nuScenes motion forecasting datasets demonstrate that our approach\nsignificantly enhances trajectory prediction confidence, achieving highly\ncompetitive performance relative to state-of-the-art methods.",
      "url": "http://arxiv.org/abs/2507.12083v1",
      "published_time_eastern_timestamp": 1752659177.0
    },
    {
      "title": "Evaluating the Ability of Large Language Models to Reason about Cardinal\n  Directions, Revisited",
      "summary": "We investigate the abilities of 28 Large language Models (LLMs) to reason\nabout cardinal directions (CDs) using a benchmark generated from a set of\ntemplates, extensively testing an LLM's ability to determine the correct CD\ngiven a particular scenario. The templates allow for a number of degrees of\nvariation such as means of locomotion of the agent involved, and whether set in\nthe first, second or third person. Even the newer Large Reasoning Models are\nunable to reliably determine the correct CD for all questions. This paper\nsummarises and extends earlier work presented at COSIT-24.",
      "url": "http://arxiv.org/abs/2507.12059v1",
      "published_time_eastern_timestamp": 1752657396.0
    },
    {
      "title": "Contracting with a Mechanism Designer",
      "summary": "This paper explores the economic interactions within modern crowdsourcing\nmarkets. In these markets, employers issue requests for tasks, platforms\nfacilitate the recruitment of crowd workers, and workers complete tasks for\nmonetary rewards. Recognizing that these roles serve distinct functions within\nthe ecosystem, we introduce a three-party model that distinguishes among the\nprincipal (the requester), the intermediary (the platform), and the pool of\nagents (the workers). The principal, unable to directly engage with agents,\nrelies on the intermediary to recruit and incentivize them. This interaction\nunfolds in two stages: first, the principal designs a profit-sharing contract\nwith the intermediary; second, the intermediary implements a mechanism to\nselect an agent to complete the delegated task.\n  We analyze the proposed model as an extensive-form Stackelberg game. Our\ncontributions are fourfold: (1) We fully characterize the subgame perfect\nequilibrium. In particular, we reduce the principal's contract design problem\nto a novel auction-theoretic formulation we term virtual value pricing, and\nreveals that linear contracts are optimal even when the task have multiple\noutcomes and agents' cost distributions are asymmetric. (2) To quantify the\nprincipal's utility loss from delegation and information asymmetry, we\nintroduce the price of double marginalization (PoDM) and the classical price of\nanarchy (PoA), and derive tight or nearly tight bounds on both ratios under\nregular and monotone hazard rate (MHR) distributions. (3) We further examine\nthese two ratios in a natural setting where the intermediary is restricted to\nanonymous pricing mechanisms, and show that similar qualitative insights\ncontinue to hold. (4) Finally, we extend our results on both ratios to a robust\nframework that accommodates scenarios in which the principal lacks precise\ninformation about the market size.",
      "url": "http://arxiv.org/abs/2507.12054v1",
      "published_time_eastern_timestamp": 1752657160.0
    },
    {
      "title": "ARRC: Explainable, Workflow-Integrated Recommender for Sustainable\n  Resource Optimization Across the Edge-Cloud Continuum",
      "summary": "Achieving sustainable, explainable, and maintainable automation for resource\noptimization is a core challenge across the edge-cloud continuum. Persistent\noverprovisioning and operational complexity often stem from heterogeneous\nplatforms and layered abstractions, while systems lacking explainability and\nmaintainability become fragile, impede safe recovery, and accumulate technical\ndebt. Existing solutions are frequently reactive, limited to single abstraction\nlayers, or require intrusive platform changes, leaving efficiency and\nmaintainability gains unrealized.\n  This paper addresses safe, transparent, and low-effort resource optimization\nin dynamic, multi-tenant edge-cloud systems, without disrupting operator\nworkflows or increasing technical debt. We introduce ARRC, a recommender system\nrooted in software engineering design principles, which delivers explainable,\ncross-layer resource recommendations directly into operator workflows (such as\ntickets and GitOps pull requests). ARRC encapsulates optimization logic in\nspecialized, auditable agents coordinated via a shared interface, supporting\nmaintainability and extensibility through transparency and the ability to\ninspect both recommendations and their rationale.\n  Empirical evaluation in a multi-region industrial deployment shows that ARRC\nreduces operator workload by over 50%, improves compute utilization by up to\n7.7x, and maintains error rates below 5%, with most benefits achieved through\nincremental, operator-approved changes. This demonstrates that explainable,\nrecommendation-based architectures can achieve sustainable efficiency and\nmaintainability improvements at production scale.\n  ARRC provides an empirically evaluated framework for integrating explainable,\nworkflow-driven automation into resource management, intended to advance best\npractices for robust, maintainable, and transparent edge-cloud continuum\nplatforms.",
      "url": "http://arxiv.org/abs/2507.12032v1",
      "published_time_eastern_timestamp": 1752655684.0
    },
    {
      "title": "QAS-QTNs: Curriculum Reinforcement Learning-Driven Quantum Architecture\n  Search for Quantum Tensor Networks",
      "summary": "Quantum Architecture Search (QAS) is an emerging field aimed at automating\nthe design of quantum circuits for optimal performance. This paper introduces a\nnovel QAS framework employing hybrid quantum reinforcement learning with\nquantum curriculum learning strategies, enabling learning agents to tackle\nincreasingly complex quantum circuit design tasks. We benchmark four\nstate-of-the-art classical reinforcement learning algorithms (A2C, PPO, DDQN,\nTD3) against their quantum-enhanced counterparts (QA2C, QPPO, QDDQN, QTD3) for\noptimizing variational quantum circuits (VQCs). Our approach progressively\nincreases circuit depth and gate complexity during training, leveraging\nparameterized quantum circuits as function approximations. To improve learning\nefficiency and stability, all algorithms, both classical and quantum, are\naugmented with Prioritized Experience Replay (PER). Experimental results show\nthat quantum-enhanced RL significantly outperforms classical methods. In a\n2-qubit environment, PERQDDQN achieves a success probability of 0.46 with\n~3,000 optimal successes, surpassing classical PERDDQN (0.42, ~2,400). In the\nmore complex 3-qubit setting, PERQDDQN and PERQTD3 reach success probabilities\nof ~0.47, with optimal success counts of ~3,800 and ~3,600, respectively,\noutperforming their classical counterparts. Additionally, we apply our QAS-QTN\napproach to a classification problem, where the optimized quantum circuit\nachieves an accuracy of 90.33\\%, outperforming quantum models consisting of\nrandom ansatz. This hybrid classical-quantum approach leads to faster\nconvergence and more efficient quantum circuit designs, demonstrating its\npotential for advancing automated quantum architecture search.",
      "url": "http://arxiv.org/abs/2507.12013v1",
      "published_time_eastern_timestamp": 1752653521.0
    },
    {
      "title": "Understanding visual attention beehind bee-inspired UAV navigation",
      "summary": "Bio-inspired design is often used in autonomous UAV navigation due to the\ncapacity of biological systems for flight and obstacle avoidance despite\nlimited sensory and computational capabilities. In particular, honeybees mainly\nuse the sensory input of optic flow, the apparent motion of objects in their\nvisual field, to navigate cluttered environments. In our work, we train a\nReinforcement Learning agent to navigate a tunnel with obstacles using only\noptic flow as sensory input. We inspect the attention patterns of trained\nagents to determine the regions of optic flow on which they primarily base\ntheir motor decisions. We find that agents trained in this way pay most\nattention to regions of discontinuity in optic flow, as well as regions with\nlarge optic flow magnitude. The trained agents appear to navigate a cluttered\ntunnel by avoiding the obstacles that produce large optic flow, while\nmaintaining a centered position in their environment, which resembles the\nbehavior seen in flying insects. This pattern persists across independently\ntrained agents, which suggests that this could be a good strategy for\ndeveloping a simple explicit control law for physical UAVs.",
      "url": "http://arxiv.org/abs/2507.11992v1",
      "published_time_eastern_timestamp": 1752651865.0
    },
    {
      "title": "Aime: Towards Fully-Autonomous Multi-Agent Framework",
      "summary": "Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are\nemerging as a powerful paradigm for solving complex, multifaceted problems.\nHowever, the potential of these systems is often constrained by the prevalent\nplan-and-execute framework, which suffers from critical limitations: rigid plan\nexecution, static agent capabilities, and inefficient communication. These\nweaknesses hinder their adaptability and robustness in dynamic environments.\nThis paper introduces Aime, a novel multi-agent framework designed to overcome\nthese challenges through dynamic, reactive planning and execution. Aime\nreplaces the conventional static workflow with a fluid and adaptive\narchitecture. Its core innovations include: (1) a Dynamic Planner that\ncontinuously refines the overall strategy based on real-time execution\nfeedback; (2) an Actor Factory that implements Dynamic Actor instantiation,\nassembling specialized agents on-demand with tailored tools and knowledge; and\n(3) a centralized Progress Management Module that serves as a single source of\ntruth for coherent, system-wide state awareness. We empirically evaluated Aime\non a diverse suite of benchmarks spanning general reasoning (GAIA), software\nengineering (SWE-bench Verified), and live web navigation (WebVoyager). The\nresults demonstrate that Aime consistently outperforms even highly specialized\nstate-of-the-art agents in their respective domains. Its superior adaptability\nand task success rate establish Aime as a more resilient and effective\nfoundation for multi-agent collaboration.",
      "url": "http://arxiv.org/abs/2507.11988v1",
      "published_time_eastern_timestamp": 1752651508.0
    },
    {
      "title": "Value-Based Large Language Model Agent Simulation for Mutual Evaluation\n  of Trust and Interpersonal Closeness",
      "summary": "Large language models (LLMs) have emerged as powerful tools for simulating\ncomplex social phenomena using human-like agents with specific traits. In human\nsocieties, value similarity is important for building trust and close\nrelationships; however, it remains unexplored whether this principle holds true\nin artificial societies comprising LLM agents. Therefore, this study\ninvestigates the influence of value similarity on relationship-building among\nLLM agents through two experiments. First, in a preliminary experiment, we\nevaluated the controllability of values in LLMs to identify the most effective\nmodel and prompt design for controlling the values. Subsequently, in the main\nexperiment, we generated pairs of LLM agents imbued with specific values and\nanalyzed their mutual evaluations of trust and interpersonal closeness\nfollowing a dialogue. The experiments were conducted in English and Japanese to\ninvestigate language dependence. The results confirmed that pairs of agents\nwith higher value similarity exhibited greater mutual trust and interpersonal\ncloseness. Our findings demonstrate that the LLM agent simulation serves as a\nvalid testbed for social science theories, contributes to elucidating the\nmechanisms by which values influence relationship building, and provides a\nfoundation for inspiring new theories and insights into the social sciences.",
      "url": "http://arxiv.org/abs/2507.11979v1",
      "published_time_eastern_timestamp": 1752650519.0
    }
  ]
}
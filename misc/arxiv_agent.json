{
  "last_updated": "2025-07-30T00:00:34.037320-04:00",
  "papers": [
    {
      "title": "DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router",
      "summary": "Large Language Models (LLMs) excel at many reasoning tasks but struggle with\nknowledge-intensive queries due to their inability to dynamically access\nup-to-date or domain-specific information. Retrieval-Augmented Generation (RAG)\nhas emerged as a promising solution, enabling LLMs to ground their responses in\nexternal sources. However, existing RAG methods lack fine-grained control over\nboth the query and source sides, often resulting in noisy retrieval and shallow\nreasoning. In this work, we introduce DeepSieve, an agentic RAG framework that\nincorporates information sieving via LLM-as-a-knowledge-router. DeepSieve\ndecomposes complex queries into structured sub-questions and recursively routes\neach to the most suitable knowledge source, filtering irrelevant information\nthrough a multi-stage distillation process. Our design emphasizes modularity,\ntransparency, and adaptability, leveraging recent advances in agentic system\ndesign. Experiments on multi-hop QA tasks across heterogeneous sources\ndemonstrate improved reasoning depth, retrieval precision, and interpretability\nover conventional RAG approaches.",
      "url": "http://arxiv.org/abs/2507.22050v1",
      "published_time_eastern_timestamp": 1753811723.0
    },
    {
      "title": "Validating Generative Agent-Based Models of Social Norm Enforcement:\n  From Replication to Novel Predictions",
      "summary": "As large language models (LLMs) advance, there is growing interest in using\nthem to simulate human social behavior through generative agent-based modeling\n(GABM). However, validating these models remains a key challenge. We present a\nsystematic two-stage validation approach using social dilemma paradigms from\npsychological literature, first identifying the cognitive components necessary\nfor LLM agents to reproduce known human behaviors in mixed-motive settings from\ntwo landmark papers, then using the validated architecture to simulate novel\nconditions. Our model comparison of different cognitive architectures shows\nthat both persona-based individual differences and theory of mind capabilities\nare essential for replicating third-party punishment (TPP) as a costly signal\nof trustworthiness. For the second study on public goods games, this\narchitecture is able to replicate an increase in cooperation from the spread of\nreputational information through gossip. However, an additional strategic\ncomponent is necessary to replicate the additional boost in cooperation rates\nin the condition that allows both ostracism and gossip. We then test novel\npredictions for each paper with our validated generative agents. We find that\nTPP rates significantly drop in settings where punishment is anonymous, yet a\nsubstantial amount of TPP persists, suggesting that both reputational and\nintrinsic moral motivations play a role in this behavior. For the second paper,\nwe introduce a novel intervention and see that open discussion periods before\nrounds of the public goods game further increase contributions, allowing groups\nto develop social norms for cooperation. This work provides a framework for\nvalidating generative agent models while demonstrating their potential to\ngenerate novel and testable insights into human social behavior.",
      "url": "http://arxiv.org/abs/2507.22049v1",
      "published_time_eastern_timestamp": 1753811638.0
    },
    {
      "title": "UserBench: An Interactive Gym Environment for User-Centric Agents",
      "summary": "Large Language Models (LLMs)-based agents have made impressive progress in\nreasoning and tool use, enabling them to solve complex tasks. However, their\nability to proactively collaborate with users, especially when goals are vague,\nevolving, or indirectly expressed, remains underexplored. To address this gap,\nwe introduce UserBench, a user-centric benchmark designed to evaluate agents in\nmulti-turn, preference-driven interactions. UserBench features simulated users\nwho start with underspecified goals and reveal preferences incrementally,\nrequiring agents to proactively clarify intent and make grounded decisions with\ntools. Our evaluation of leading open- and closed-source LLMs reveals a\nsignificant disconnect between task completion and user alignment. For\ninstance, models provide answers that fully align with all user intents only\n20% of the time on average, and even the most advanced models uncover fewer\nthan 30% of all user preferences through active interaction. These results\nhighlight the challenges of building agents that are not just capable task\nexecutors, but true collaborative partners. UserBench offers an interactive\nenvironment to measure and advance this critical capability.",
      "url": "http://arxiv.org/abs/2507.22034v1",
      "published_time_eastern_timestamp": 1753810452.0
    },
    {
      "title": "From Seeing to Experiencing: Scaling Navigation Foundation Models with\n  Reinforcement Learning",
      "summary": "Navigation foundation models trained on massive webscale data enable agents\nto generalize across diverse environments and embodiments. However, these\nmodels trained solely on offline data, often lack the capacity to reason about\nthe consequences of their actions or adapt through counterfactual\nunderstanding. They thus face significant limitations in the real-world urban\nnavigation where interactive and safe behaviors, such as avoiding obstacles and\nmoving pedestrians, are critical. To tackle these challenges, we introduce the\nSeeing-to-Experiencing framework to scale the capability of navigation\nfoundation models with reinforcement learning. S2E combines the strengths of\npre-training on videos and post-training through RL. It maintains the\ngeneralizability acquired from large-scale real-world videos while enhancing\nits interactivity through RL in simulation environments. Specifically, we\nintroduce two innovations: an Anchor-Guided Distribution Matching strategy,\nwhich stabilizes learning and models diverse motion patterns through\nanchor-based supervision; and a Residual-Attention Module, which obtains\nreactive behaviors from simulation environments without erasing the model's\npretrained knowledge. Moreover, we establish a comprehensive end-to-end\nevaluation benchmark, NavBench-GS, built on photorealistic 3DGS reconstructions\nof real-world scenes that incorporate physical interactions. It can\nsystematically assess the generalizability and safety of navigation foundation\nmodels. Extensive experiments show that S2E mitigates the diminishing returns\noften seen when scaling with offline data alone. We perform a thorough analysis\nof the benefits of Reinforcement Learning compared to Supervised Fine-Tuning in\nthe context of post-training for robot learning. Our findings emphasize the\ncrucial role of integrating interactive online experiences to effectively scale\nfoundation models in Robotics.",
      "url": "http://arxiv.org/abs/2507.22028v1",
      "published_time_eastern_timestamp": 1753809970.0
    },
    {
      "title": "UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and\n  Precise Inference-Time Grounding",
      "summary": "The emergence of Multimodal Large Language Models (MLLMs) has driven\nsignificant advances in Graphical User Interface (GUI) agent capabilities.\nNevertheless, existing GUI agent training and inference techniques still suffer\nfrom a dilemma for reasoning designs, ineffective reward, and visual noise. To\naddress these issues, we introduce UI-AGILE, a comprehensive framework\nenhancing GUI agents at both the training and inference stages. For training,\nwe propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:\n1) a Continuous Reward function to incentivize high-precision grounding; 2) a\n\"Simple Thinking\" reward to balance planning with speed and grounding accuracy;\nand 3) a Cropping-based Resampling strategy to mitigate the sparse reward\nproblem and improve learning on complex tasks. For inference, we present\nDecomposed Grounding with Selection, a novel method that dramatically improves\ngrounding accuracy on high-resolution displays by breaking the image into\nsmaller, manageable parts. Experiments show that UI-AGILE achieves the\nstate-of-the-art performance on two benchmarks ScreenSpot-Pro and\nScreenSpot-v2. For instance, using both our proposed training and inference\nenhancement methods brings 23% grounding accuracy improvement over the best\nbaseline on ScreenSpot-Pro.",
      "url": "http://arxiv.org/abs/2507.22025v1",
      "published_time_eastern_timestamp": 1753809727.0
    },
    {
      "title": "Exploring the Stratified Space Structure of an RL Game with the Volume\n  Growth Transform",
      "summary": "In this work, we explore the structure of the embedding space of a\ntransformer model trained for playing a particular reinforcement learning (RL)\ngame. Specifically, we investigate how a transformer-based Proximal Policy\nOptimization (PPO) model embeds visual inputs in a simple environment where an\nagent must collect \"coins\" while avoiding dynamic obstacles consisting of\n\"spotlights.\" By adapting Robinson et al.'s study of the volume growth\ntransform for LLMs to the RL setting, we find that the token embedding space\nfor our visual coin collecting game is also not a manifold, and is better\nmodeled as a stratified space, where local dimension can vary from point to\npoint. We further strengthen Robinson's method by proving that fairly general\nvolume growth curves can be realized by stratified spaces. Finally, we carry\nout an analysis that suggests that as an RL agent acts, its latent\nrepresentation alternates between periods of low local dimension, while\nfollowing a fixed sub-strategy, and bursts of high local dimension, where the\nagent achieves a sub-goal (e.g., collecting an object) or where the\nenvironmental complexity increases (e.g., more obstacles appear). Consequently,\nour work suggests that the distribution of dimensions in a stratified latent\nspace may provide a new geometric indicator of complexity for RL games.",
      "url": "http://arxiv.org/abs/2507.22010v1",
      "published_time_eastern_timestamp": 1753808433.0
    },
    {
      "title": "Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating\n  Theory of Mind and Critical Evaluation",
      "summary": "Recently, the field of Multi-Agent Systems (MAS) has gained popularity as\nresearchers are trying to develop artificial intelligence capable of efficient\ncollective reasoning. Agents based on Large Language Models (LLMs) perform well\nin isolated tasks, yet struggle with higher-order cognition required for\nadaptive collaboration. Human teams achieve synergy not only through knowledge\nsharing, but also through recursive reasoning, structured critique, and the\nability to infer others' mental states. Current artificial systems lack these\nessential mechanisms, limiting their ability to engage in sophisticated\ncollective reasoning. This work explores cognitive processes that enable\neffective collaboration, focusing on adaptive theory of mind (ToM) and\nsystematic critical evaluation. We investigate three key questions. First, how\ndoes the ability to model others' perspectives enhance coordination and reduce\nredundant reasoning? Second, to what extent does structured critique improve\nreasoning quality by identifying logical gaps and mitigating biases? Third, the\ninterplay of these mechanisms can lead to emergent cognitive synergy, where the\ncollective intelligence of the system exceeds the sum of its parts. Through an\nempirical case study on complex decision making, we show that the integration\nof these cognitive mechanisms leads to more coherent, adaptive, and rigorous\nagent interactions. This article contributes to the field of cognitive science\nand AI research by presenting a structured framework that emulates human-like\ncollaborative reasoning MAS. It highlights the significance of dynamic ToM and\ncritical evaluation in advancing multi-agent systems' ability to tackle\ncomplex, real-world challenges.",
      "url": "http://arxiv.org/abs/2507.21969v1",
      "published_time_eastern_timestamp": 1753805793.0
    },
    {
      "title": "MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile\n  Task Automation",
      "summary": "The recent advancement of autonomous agents powered by Large Language Models\n(LLMs) has demonstrated significant potential for automating tasks on mobile\ndevices through graphical user interfaces (GUIs). Despite initial progress,\nthese agents still face challenges when handling complex real-world tasks.\nThese challenges arise from a lack of knowledge about real-life mobile\napplications in LLM-based agents, which may lead to ineffective task planning\nand even cause hallucinations. To address these challenges, we propose a novel\nLLM-based agent framework called MapAgent that leverages memory constructed\nfrom historical trajectories to augment current task planning. Specifically, we\nfirst propose a trajectory-based memory mechanism that transforms task\nexecution trajectories into a reusable and structured page-memory database.\nEach page within a trajectory is extracted as a compact yet comprehensive\nsnapshot, capturing both its UI layout and functional context. Secondly, we\nintroduce a coarse-to-fine task planning approach that retrieves relevant pages\nfrom the memory database based on similarity and injects them into the LLM\nplanner to compensate for potential deficiencies in understanding real-world\napp scenarios, thereby achieving more informed and context-aware task planning.\nFinally, planned tasks are transformed into executable actions through a task\nexecutor supported by a dual-LLM architecture, ensuring effective tracking of\ntask progress. Experimental results in real-world scenarios demonstrate that\nMapAgent achieves superior performance to existing methods. The code will be\nopen-sourced to support further research.",
      "url": "http://arxiv.org/abs/2507.21953v1",
      "published_time_eastern_timestamp": 1753805132.0
    },
    {
      "title": "Hierarchical Game-Based Multi-Agent Decision-Making for Autonomous\n  Vehicles",
      "summary": "This paper develops a game-theoretic decision-making framework for autonomous\ndriving in multi-agent scenarios. A novel hierarchical game-based decision\nframework is developed for the ego vehicle. This framework features an\ninteraction graph, which characterizes the interaction relationships between\nthe ego and its surrounding traffic agents (including AVs, human driven\nvehicles, pedestrians, and bicycles, and others), and enables the ego to\nsmartly select a limited number of agents as its game players. Compared to the\nstandard multi-player games, where all surrounding agents are considered as\ngame players, the hierarchical game significantly reduces the computational\ncomplexity. In addition, compared to pairwise games, the most popular approach\nin the literature, the hierarchical game promises more efficient decisions for\nthe ego (in terms of less unnecessary waiting and yielding). To further reduce\nthe computational cost, we then propose an improved hierarchical game, which\ndecomposes the hierarchical game into a set of sub-games. Decision safety and\nefficiency are analyzed in both hierarchical games. Comprehensive simulation\nstudies are conducted to verify the effectiveness of the proposed frameworks,\nwith an intersection-crossing scenario as a case study.",
      "url": "http://arxiv.org/abs/2507.21941v1",
      "published_time_eastern_timestamp": 1753804418.0
    },
    {
      "title": "MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning",
      "summary": "Large Language Models (LLMs), enhanced through agent tuning, have\ndemonstrated remarkable capabilities in Chain-of-Thought (CoT) and tool\nutilization, significantly surpassing the performance of standalone models.\nHowever, the multimodal domain still lacks a large-scale, high-quality agent\ntuning dataset to unlock the full potential of multimodal large language\nmodels. To bridge this gap, we introduce MMAT-1M, the first million-scale\nmultimodal agent tuning dataset designed to support CoT, reflection, and\ndynamic tool usage. Our dataset is constructed through a novel four-stage data\nengine: 1) We first curate publicly available multimodal datasets containing\nquestion-answer pairs; 2) Then, leveraging GPT-4o, we generate rationales for\nthe original question-answer pairs and dynamically integrate API calls and\nRetrieval Augmented Generation (RAG) information through a multi-turn paradigm;\n3) Furthermore, we refine the rationales through reflection to ensure logical\nconsistency and accuracy, creating a multi-turn dialogue dataset with both\nRationale and Reflection (RR); 4) Finally, to enhance efficiency, we optionally\ncompress multi-turn dialogues into a One-turn Rationale and Reflection (ORR)\nformat. By fine-tuning open-source multimodal models on the MMAT-1M, we observe\nsignificant performance gains. For instance, the InternVL2.5-8B-RR model\nachieves an average improvement of 2.7% across eight public benchmarks and 8.8%\non the RAG benchmark Dyn-VQA, demonstrating the dataset's effectiveness in\nenhancing multimodal reasoning and tool-based capabilities. The dataset is\npublicly available at https://github.com/VIS-MPU-Agent/MMAT-1M.",
      "url": "http://arxiv.org/abs/2507.21924v1",
      "published_time_eastern_timestamp": 1753803554.0
    },
    {
      "title": "ArtSeek: Deep artwork understanding via multimodal in-context reasoning\n  and late interaction retrieval",
      "summary": "Analyzing digitized artworks presents unique challenges, requiring not only\nvisual interpretation but also a deep understanding of rich artistic,\ncontextual, and historical knowledge. We introduce ArtSeek, a multimodal\nframework for art analysis that combines multimodal large language models with\nretrieval-augmented generation. Unlike prior work, our pipeline relies only on\nimage input, enabling applicability to artworks without links to Wikidata or\nWikipedia-common in most digitized collections. ArtSeek integrates three key\ncomponents: an intelligent multimodal retrieval module based on late\ninteraction retrieval, a contrastive multitask classification network for\npredicting artist, genre, style, media, and tags, and an agentic reasoning\nstrategy enabled through in-context examples for complex visual question\nanswering and artwork explanation via Qwen2.5-VL. Central to this approach is\nWikiFragments, a Wikipedia-scale dataset of image-text fragments curated to\nsupport knowledge-grounded multimodal reasoning. Our framework achieves\nstate-of-the-art results on multiple benchmarks, including a +8.4% F1\nimprovement in style classification over GraphCLIP and a +7.1 BLEU@1 gain in\ncaptioning on ArtPedia. Qualitative analyses show that ArtSeek can interpret\nvisual motifs, infer historical context, and retrieve relevant knowledge, even\nfor obscure works. Though focused on visual arts, our approach generalizes to\nother domains requiring external knowledge, supporting scalable multimodal AI\nresearch. Both the dataset and the source code will be made publicly available\nat https://github.com/cilabuniba/artseek.",
      "url": "http://arxiv.org/abs/2507.21917v1",
      "published_time_eastern_timestamp": 1753803118.0
    },
    {
      "title": "Communication-Efficient Algorithms for Distributed Nonconvex Minimax\n  Optimization Problems",
      "summary": "We study stochastic nonconvex Polyak-{\\L}ojasiewicz minimax problems and\npropose algorithms that are both communication- and sample-efficient. The\nproposed methods are developed under three setups: decentralized/distributed,\nfederated/centralized, and single-agent. By exploiting second-order Lipschitz\ncontinuity and integrating communication-efficient strategies, we develop a new\ndecentralized normalized accelerated momentum method with local updates and\nestablish its convergence to an $\\varepsilon$-game stationary point. Compared\nto existing decentralized minimax algorithms,\n  our proposed algorithm is the first to achieve a state-of-the-art\ncommunication complexity of order $\\mathcal{O}\\Big(\n  \\frac{ \\kappa^3\\varepsilon^{-3}}{NK(1-\\lambda)^{3/2}}\\Big)$, demonstrating\nlinear speedup with respect to both the number of agents $K$ and the number of\nlocal updates $N$, as well as the best known dependence on the level of\naccuracy of the solution $\\varepsilon$. In addition to improved complexity, our\nalgorithm offers several practical advantages: it relaxes the strict\ntwo-time-scale step size ratio required by many existing algorithms, simplifies\nthe stability conditions for step size selection, and eliminates the need for\nlarge batch sizes to attain the optimal sample complexity.\n  Moreover, we propose more efficient variants tailored to\nfederated/centralized and single-agent setups, and show that all variants\nachieve best-known results while effectively addressing some key issues.\nExperiments on robust logistic regression and fair neural network classifier\nusing real-world datasets demonstrate the superior performance of the proposed\nmethods over existing baselines.",
      "url": "http://arxiv.org/abs/2507.21901v1",
      "published_time_eastern_timestamp": 1753801820.0
    },
    {
      "title": "Graph-R1: Towards Agentic GraphRAG Framework via End-to-end\n  Reinforcement Learning",
      "summary": "Retrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by\nincorporating external knowledge, but relies on chunk-based retrieval that\nlacks structural semantics. GraphRAG methods improve RAG by modeling knowledge\nas entity-relation graphs, but still face challenges in high construction cost,\nfixed one-time retrieval, and reliance on long-context reasoning and prompt\ndesign. To address these challenges, we propose Graph-R1, an agentic GraphRAG\nframework via end-to-end reinforcement learning (RL). It introduces lightweight\nknowledge hypergraph construction, models retrieval as a multi-turn\nagent-environment interaction, and optimizes the agent process via an\nend-to-end reward mechanism. Experiments on standard RAG datasets show that\nGraph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in\nreasoning accuracy, retrieval efficiency, and generation quality.",
      "url": "http://arxiv.org/abs/2507.21892v1",
      "published_time_eastern_timestamp": 1753801286.0
    },
    {
      "title": "Probabilistic Active Goal Recognition",
      "summary": "In multi-agent environments, effective interaction hinges on understanding\nthe beliefs and intentions of other agents. While prior work on goal\nrecognition has largely treated the observer as a passive reasoner, Active Goal\nRecognition (AGR) focuses on strategically gathering information to reduce\nuncertainty. We adopt a probabilistic framework for Active Goal Recognition and\npropose an integrated solution that combines a joint belief update mechanism\nwith a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan\nefficiently and infer the actor's hidden goal without requiring domain-specific\nknowledge. Through comprehensive empirical evaluation in a grid-based domain,\nwe show that our joint belief update significantly outperforms passive goal\nrecognition, and that our domain-independent MCTS performs comparably to our\nstrong domain-specific greedy baseline. These results establish our solution as\na practical and robust framework for goal inference, advancing the field toward\nmore interactive and adaptive multi-agent systems.",
      "url": "http://arxiv.org/abs/2507.21846v1",
      "published_time_eastern_timestamp": 1753798949.0
    },
    {
      "title": "Prompt template for a fictitious LLM agent in a content-flagging\n  experiment",
      "summary": "Digital regulations such as the European Union's Digital Services Act (DSA)\nrepresent major efforts to shape human-centered and human rights-based\nframeworks for society. Yet, as these laws are translated into practice,\nchallenges emerge at the intersection of technology, law, and design. This\npaper presents a qualitative case study examining how designers act as\nmediators between abstract legal requirements and real-world digital\nexperiences for users, focusing on the design of content reporting mechanisms\nunder Article 16 of the DSA.\n  Through an expert workshop with professional designers from diverse fields\n(N=9), we explore how legal obligations are interpreted by designers and\nreflected in discussions and design solutions. Our findings resonate with\nprevious research on the design of reporting mechanisms and dark patterns,\nhighlighting how UX design choices can mislead or hinder users' decision-making\nand therefore also highlighting the crucial role of design decisions.\n  We show how participatory design methods can bridge disciplinary divides,\nmaking legal obligations accessible in compliance fostering design solutions.\n  By using legal design as a lens, we argue that the co-creation of digital\nregulations and user experience is a core site for digital humanism; where\ndesigners, engineers, and legal scholars must collaborate to ensure that\nsystems uphold legal standards to address the challenge the regulation poses to\nthese disciplines.",
      "url": "http://arxiv.org/abs/2507.21842v1",
      "published_time_eastern_timestamp": 1753798860.0
    },
    {
      "title": "An Agentic AI for a New Paradigm in Business Process Development",
      "summary": "Artificial Intelligence agents represent the next major revolution in the\ncontinuous technological evolution of industrial automation. In this paper, we\nintroduce a new approach for business process design and development that\nleverages the capabilities of Agentic AI. Departing from the traditional\ntask-based approach to business process design, we propose an agent-based\nmethod, where agents contribute to the achievement of business goals,\nidentified by a set of business objects. When a single agent cannot fulfill a\ngoal, we have a merge goal that can be achieved through the collaboration of\nmultiple agents. The proposed model leads to a more modular and intelligent\nbusiness process development by organizing it around goals, objects, and\nagents. As a result, this approach enables flexible and context-aware\nautomation in dynamic industrial environments.",
      "url": "http://arxiv.org/abs/2507.21823v1",
      "published_time_eastern_timestamp": 1753797504.0
    },
    {
      "title": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on\n  Vulnerability Datasets Detect Top 25 CWE Weaknesses?",
      "summary": "Automated vulnerability detection research has made substantial progress, yet\nits real-world impact remains limited. Current vulnerability datasets suffer\nfrom issues including label inaccuracy rates of 20-71%, extensive duplication,\nand poor coverage of critical CWE types. These issues create a significant\n\"generalization gap\" where models achieve misleading self-testing performance\n(measured on held-out data from same dataset for training) by exploiting\nspurious correlations rather than learning true vulnerability patterns. Our\nanalysis reveals that many models experience substantial performance drops of\nup to 40.6% when evaluated on independent data, sometimes underperforming\nrandom guessing.\n  To address these limitations, we present a three-part solution. First, we\nintroduce a manually curated test dataset, BenchVul, covering the MITRE Top 25\nMost Dangerous CWEs. Second, we construct a high-quality training dataset,\nTitanVul, comprising 35,045 functions by aggregating seven public sources and\napplying deduplication and validation using a novel multi-agent LLM framework.\nThird, we propose a Realistic Vulnerability Generation (RVG) framework, which\nsynthesizes context-aware vulnerability examples for underrepresented but\ncritical CWE types through simulated development workflows.\n  Our evaluation shows the strengths of each component in closing the\ngeneralization gap. First, BenchVul shows the limitations of self-testing:\nmodels trained on existing datasets, such as BigVul and PrimeVul, experience\nperformance drops on BenchVul (from 0.776 to 0.519 and from 0.567 to 0.337).\nSecond, training models on TitanVul demonstrates improved generalization, with\nmodel performance increasing from 0.584 when evaluated on the same dataset to\n0.767 when tested on BenchVul. Third, supplementing TitanVul with RVG-generated\ndata yields further gains, increasing model performance by 14.0% to 0.874.",
      "url": "http://arxiv.org/abs/2507.21817v1",
      "published_time_eastern_timestamp": 1753797106.0
    },
    {
      "title": "Non-coercive extortion in game theory",
      "summary": "Commitments play a crucial role in game theory, shaping strategic\ninteractions by either altering a player's own payoffs or influencing the\nincentives of others through outcome-contingent payments. While most research\nhas focused on using commitments to achieve efficient equilibria, their\npotential applications beyond this goal remain largely unexplored. In this\nstudy, we introduce a non-coercive extortion mechanism that leverages\ncommitments to outcome-contingent payments, demonstrating how a player or\nexternal agent can extract profit by offering rewards rather than threatening\npunishment. At the core of the mechanism is the introduction of sequentiality\ninto a simultaneous-move game, fundamentally reshaping the strategic\ninteraction. We derive the conditions under which extortion is successful,\nidentify the class of games susceptible to this scheme, and determine both the\nmaximum extractable profit and the minimum required payment. To illustrate the\nextortion mechanism, we apply it to 2x2 games, highlighting how even simple\nstrategic settings can be vulnerable to this form of manipulation. Our results\nreveal strategic vulnerabilities in competitive settings, with significant\nimplications for economic markets, diplomatic relations, and multi-agent\nsystems operating in blockchain environments. This work broadens our\nunderstanding of commitments in game theory and raises critical questions about\nhow to safeguard strategic interactions from exploitation through non-coercive\nextortion.",
      "url": "http://arxiv.org/abs/2507.21795v1",
      "published_time_eastern_timestamp": 1753795889.0
    },
    {
      "title": "Can large language models assist choice modelling? Insights into\n  prompting strategies and current models capabilities",
      "summary": "Large Language Models (LLMs) are widely used to support various workflows\nacross different disciplines, yet their potential in choice modelling remains\nrelatively unexplored. This work examines the potential of LLMs as assistive\nagents in the specification and, where technically feasible, estimation of\nMultinomial Logit models. We implement a systematic experimental framework\ninvolving thirteen versions of six leading LLMs (ChatGPT, Claude, DeepSeek,\nGemini, Gemma, and Llama) evaluated under five experimental configurations.\nThese configurations vary along three dimensions: modelling goal (suggesting\nvs. suggesting and estimating MNLs); prompting strategy (Zero-Shot vs.\nChain-of-Thoughts); and information availability (full dataset vs. data\ndictionary only). Each LLM-suggested specification is implemented, estimated,\nand evaluated based on goodness-of-fit metrics, behavioural plausibility, and\nmodel complexity. Findings reveal that proprietary LLMs can generate valid and\nbehaviourally sound utility specifications, particularly when guided by\nstructured prompts. Open-weight models such as Llama and Gemma struggled to\nproduce meaningful specifications. Claude 4 Sonnet consistently produced the\nbest-fitting and most complex models, while GPT models suggested models with\nrobust and stable modelling outcomes. Some LLMs performed better when provided\nwith just data dictionary, suggesting that limiting raw data access may enhance\ninternal reasoning capabilities. Among all LLMs, GPT o3 was uniquely capable of\ncorrectly estimating its own specifications by executing self-generated code.\nOverall, the results demonstrate both the promise and current limitations of\nLLMs as assistive agents in choice modelling, not only for model specification\nbut also for supporting modelling decision and estimation, and provide\npractical guidance for integrating these tools into choice modellers'\nworkflows.",
      "url": "http://arxiv.org/abs/2507.21790v1",
      "published_time_eastern_timestamp": 1753795484.0
    },
    {
      "title": "Multi-UAV Deployment in Obstacle-Cluttered Environments with LOS\n  Connectivity",
      "summary": "A reliable communication network is essential for multiple UAVs operating\nwithin obstacle-cluttered environments, where limited communication due to\nobstructions often occurs. A common solution is to deploy intermediate UAVs to\nrelay information via a multi-hop network, which introduces two challenges: (i)\nhow to design the structure of multihop networks; and (ii) how to maintain\nconnectivity during collaborative motion. To this end, this work first proposes\nan efficient constrained search method based on the minimumedge RRT? algorithm,\nto find a spanning-tree topology that requires a less number of UAVs for the\ndeployment task. Then, to achieve this deployment, a distributed model\npredictive control strategy is proposed for the online motion coordination. It\nexplicitly incorporates not only the inter-UAV and UAVobstacle distance\nconstraints, but also the line-of-sight (LOS) connectivity constraint. These\nconstraints are well-known to be nonlinear and often tackled by various\napproximations. In contrast, this work provides a theoretical guarantee that\nall agent trajectories are ensured to be collision-free with a teamwise LOS\nconnectivity at all time. Numerous simulations are performed in 3D valley-like\nenvironments, while hardware experiments validate its dynamic adaptation when\nthe deployment position changes online.",
      "url": "http://arxiv.org/abs/2507.21772v1",
      "published_time_eastern_timestamp": 1753793755.0
    }
  ]
}
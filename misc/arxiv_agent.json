{
  "last_updated": "2025-07-16T17:12:14.062269-04:00",
  "papers": [
    {
      "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in\n  Civil Engineering",
      "summary": "Large Language Model (LLM) agents have shown great potential for solving\nreal-world problems and promise to be a solution for tasks automation in\nindustry. However, more benchmarks are needed to systematically evaluate\nautomation agents from an industrial perspective, for example, in Civil\nEngineering. Therefore, we propose DrafterBench for the comprehensive\nevaluation of LLM agents in the context of technical drawing revision, a\nrepresentation task in civil engineering. DrafterBench contains twelve types of\ntasks summarized from real-world drawing files, with 46 customized\nfunctions/tools and 1920 tasks in total. DrafterBench is an open-source\nbenchmark to rigorously test AI agents' proficiency in interpreting intricate\nand long-context instructions, leveraging prior knowledge, and adapting to\ndynamic instruction quality via implicit policy awareness. The toolkit\ncomprehensively assesses distinct capabilities in structured data\ncomprehension, function execution, instruction following, and critical\nreasoning. DrafterBench offers detailed analysis of task accuracy and error\nstatistics, aiming to provide deeper insight into agent capabilities and\nidentify improvement targets for integrating LLMs in engineering applications.\nOur benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,\nwith the test set hosted at\nhttps://huggingface.co/datasets/Eason666/DrafterBench.",
      "url": "http://arxiv.org/abs/2507.11527v1",
      "published_time_eastern_timestamp": 1752602164.0
    },
    {
      "title": "Opinion dynamics: Statistical physics and beyond",
      "summary": "Opinion dynamics, the study of how individual beliefs and collective public\nopinion evolve, is a fertile domain for applying statistical physics to complex\nsocial phenomena. Like physical systems, societies exhibit macroscopic\nregularities from localized interactions, leading to outcomes such as consensus\nor fragmentation. This field has grown significantly, attracting\ninterdisciplinary methods and driven by a surge in large-scale behavioral data.\nThis review covers its rapid progress, bridging the literature dispersion. We\nbegin with essential concepts and definitions, encompassing the nature of\nopinions, microscopic and macroscopic dynamics. This foundation leads to an\noverview of empirical research, from lab experiments to large-scale data\nanalysis, which informs and validates models of opinion dynamics. We then\npresent individual-based models, categorized by their macroscopic phenomena\n(e.g., consensus, polarization, echo chambers) and microscopic mechanisms\n(e.g., homophily, assimilation). We also review social contagion phenomena,\nhighlighting their connection to opinion dynamics. Furthermore, the review\ncovers common analytical and computational tools, including stochastic\nprocesses, treatments, simulations, and optimization. Finally, we explore\nemerging frontiers, such as connecting empirical data to models and using AI\nagents as testbeds for novel social phenomena. By systematizing terminology and\nemphasizing analogies with traditional physics, this review aims to consolidate\nknowledge, provide a robust theoretical foundation, and shape future research\nin opinion dynamics.",
      "url": "http://arxiv.org/abs/2507.11521v1",
      "published_time_eastern_timestamp": 1752601512.0
    },
    {
      "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of\n  LLM over the Air",
      "summary": "Operating Large Language Models (LLMs) on edge devices is increasingly\nchallenged by limited communication bandwidth and strained computational and\nmemory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.\nNevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ\nfixed or heuristic rank configurations, and the subsequent over-the-air\ntransmission of all LoRA parameters could be rather inefficient. To address\nthis limitation, we develop AirLLM, a hierarchical diffusion policy framework\nfor communication-aware LoRA adaptation. Specifically, AirLLM models the rank\nconfiguration as a structured action vector that spans all LoRA-inserted\nprojections. To solve the underlying high-dimensional sequential\ndecision-making problem, a Proximal Policy Optimization (PPO) agent generates\ncoarse-grained decisions by jointly observing wireless states and linguistic\ncomplexity, which are then refined via Denoising Diffusion Implicit Models\n(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The\ntwo modules are optimized alternatively, with the DDIM trained under the\nClassifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.\nExperiments under varying signal-to-noise ratios demonstrate that AirLLM\nconsistently enhances fine-tuning performance while significantly reducing\ntransmission costs, highlighting the effectiveness of reinforcement-driven,\ndiffusion-refined rank adaptation for scalable and efficient remote fine-tuning\nover the air.",
      "url": "http://arxiv.org/abs/2507.11515v1",
      "published_time_eastern_timestamp": 1752600997.0
    },
    {
      "title": "On the Complexity of the Optimal Correlated Equilibria in Extensive-Form\n  Games",
      "summary": "A major open question in algorithmic game theory is whether normal-form\ncorrelated equilibria (NFCE) can be computed efficiently in succinct games such\nas extensive-form games [DFF+25,6PR24,FP23,HvS08,VSF08,PR08]. Motivated by this\nquestion, we study the associated Threshold problem: deciding whether there\nexists a correlated equilibrium whose value exceeds a given threshold. We prove\nthat this problem is PSPACE-hard for NFCE in multiplayer extensive-form games\nwith perfect recall, even for fixed thresholds. To contextualize this result,\nwe also establish the complexity of the Threshold problem for Nash equilibria\nin this setting, showing it is ER-complete. These results uncover a surprising\ncomplexity reversal: while optimal correlated equilibria are computationally\nsimpler than optimal Nash in normal-form games, the opposite holds in\nextensive-form games, where computing optimal correlated equilibria is provably\nharder. Building on this line of inquiry, we also address a related question by\n[VSF08], who introduced the notions of extensive-form correlated equilibrium\n(EFCE) and agent-form correlated equilibrium (AFCE). They asked how difficult\nthe Threshold problem is for AFCE; we answer this question by proving that it\nis NP-hard, even in two-player games without chance nodes. Complementing our\nhardness results, we establish tight complexity classifications for the\nThreshold problem across several correlated equilibrium concepts - including\nEFCE, AFCE, normal-form coarse, extensive-form coarse, and agent-form coarse\ncorrelated equilibria. For each of these solution concepts in multiplayer\nstochastic extensive-form games with perfect recall, we prove NP-completeness\nby providing matching NP upper bounds to the previously known hardness results.\nTogether, our results provide the most complete landscape to date for the\ncomplexity of optimal equilibrium computation in extensive-form games.",
      "url": "http://arxiv.org/abs/2507.11509v1",
      "published_time_eastern_timestamp": 1752600256.0
    },
    {
      "title": "LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control",
      "summary": "We propose a multi-robot control paradigm to solve point-to-point navigation\ntasks for a team of holonomic robots with access to the full environment\ninformation. The framework invokes two processes asynchronously at high\nfrequency: (i) a centralized, discrete, and full-horizon planner for computing\ncollision- and deadlock-free paths rapidly, leveraging recent advances in\nmulti-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal\ntrajectory controllers that ensure all robots independently follow their\nassigned paths reliably. This hierarchical shift in planning representation\nfrom (i) discrete and coupled to (ii) continuous and decoupled domains enables\nthe framework to maintain long-term scalable motion synthesis. As an\ninstantiation of this idea, we present LF, which combines a fast\nstate-of-the-art MAPF solver (LaCAM), and a robust feedback control stack\n(Freyja) for executing agile robot maneuvers. LF provides a robust and\nversatile mechanism for lifelong multi-robot navigation even under asynchronous\nand partial goal updates, and adapts to dynamic workspaces simply by quick\nreplanning. We present various multirotor and ground robot demonstrations,\nincluding the deployment of 15 real multirotors with random, consecutive target\nupdates while a person walks through the operational workspace.",
      "url": "http://arxiv.org/abs/2507.11464v1",
      "published_time_eastern_timestamp": 1752597337.0
    },
    {
      "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and\n  Reasoning Modes",
      "summary": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.",
      "url": "http://arxiv.org/abs/2507.11407v1",
      "published_time_eastern_timestamp": 1752593091.0
    },
    {
      "title": "From Production Logistics to Smart Manufacturing: The Vision for a New\n  RoboCup Industrial League",
      "summary": "The RoboCup Logistics League is a RoboCup competition in a smart factory\nscenario that has focused on task planning, job scheduling, and multi-agent\ncoordination. The focus on production logistics allowed teams to develop highly\ncompetitive strategies, but also meant that some recent developments in the\ncontext of smart manufacturing are not reflected in the competition, weakening\nits relevance over the years. In this paper, we describe the vision for the\nRoboCup Smart Manufacturing League, a new competition designed as a larger\nsmart manufacturing scenario, reflecting all the major aspects of a modern\nfactory. It will consist of several tracks that are initially independent but\ngradually combined into one smart manufacturing scenario. The new tracks will\ncover industrial robotics challenges such as assembly, human-robot\ncollaboration, and humanoid robotics, but also retain a focus on production\nlogistics. We expect the reenvisioned competition to be more attractive to\nnewcomers and well-tried teams, while also shifting the focus to current and\nfuture challenges of industrial robotics.",
      "url": "http://arxiv.org/abs/2507.11402v1",
      "published_time_eastern_timestamp": 1752592624.0
    },
    {
      "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving\n  Patient-Doctor Communication in Romanian",
      "summary": "Text-based telemedicine has become increasingly common, yet the quality of\nmedical advice in doctor-patient interactions is often judged more on how\nadvice is communicated rather than its clinical accuracy. To address this, we\nintroduce Dr.Copilot , a multi-agent large language model (LLM) system that\nsupports Romanian-speaking doctors by evaluating and enhancing the presentation\nquality of their written responses. Rather than assessing medical correctness,\nDr.Copilot provides feedback along 17 interpretable axes. The system comprises\nof three LLM agents with prompts automatically optimized via DSPy. Designed\nwith low-resource Romanian data and deployed using open-weight models, it\ndelivers real-time specific feedback to doctors within a telemedicine platform.\nEmpirical evaluations and live deployment with 41 doctors show measurable\nimprovements in user reviews and response quality, marking one of the first\nreal-world deployments of LLMs in Romanian medical settings.",
      "url": "http://arxiv.org/abs/2507.11299v1",
      "published_time_eastern_timestamp": 1752586009.0
    },
    {
      "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing\n  Agentic AI Systems",
      "summary": "Large Language Models (LLMs) are increasingly deployed within agentic\nsystems-collections of interacting, LLM-powered agents that execute complex,\nadaptive workflows using memory, tools, and dynamic planning. While enabling\npowerful new capabilities, these systems also introduce unique forms of\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\nfluid execution paths. Traditional software observability and operations\npractices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing,\nanalyzing, optimizing, and automating operation of agentic AI systems. We\nidentify distinct needs across four key roles-developers, testers, site\nreliability engineers (SREs), and business users-each of whom engages with the\nsystem at different points in its lifecycle. We present the AgentOps Automation\nPipeline, a six-stage process encompassing behavior observation, metric\ncollection, issue detection, root cause analysis, optimized recommendations,\nand runtime automation. Throughout, we emphasize the critical role of\nautomation in managing uncertainty and enabling self-improving AI systems-not\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\neffective operation.",
      "url": "http://arxiv.org/abs/2507.11277v1",
      "published_time_eastern_timestamp": 1752584083.0
    },
    {
      "title": "An Empirical Study of Multi-Agent RAG for Real-World University\n  Admissions Counseling",
      "summary": "This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University\nAdmission System), a real-world deployment of a conversational AI platform for\nhigher education admissions counseling in Vietnam. While large language models\n(LLMs) offer potential for automating advisory tasks, most existing solutions\nremain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap\nby combining hybrid retrieval, multi-agent orchestration, and LLM-based\ngeneration into a system tailored for real-world university admissions. In\ncollaboration with the University of Transport Technology (UTT) in Hanoi, we\nconducted a two-phase study involving technical development and real-world\nevaluation. MARAUS processed over 6,000 actual user interactions, spanning six\ncategories of queries. Results show substantial improvements over LLM-only\nbaselines: on average 92 percent accuracy, hallucination rates reduced from 15\nprecent to 1.45 percent, and average response times below 4 seconds. The system\noperated cost-effectively, with a two-week deployment cost of 11.58 USD using\nGPT-4o mini. This work provides actionable insights for the deployment of\nagentic RAG systems in low-resource educational settings.",
      "url": "http://arxiv.org/abs/2507.11272v1",
      "published_time_eastern_timestamp": 1752583782.0
    },
    {
      "title": "Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy\n  Learning via Causal Bound",
      "summary": "Deep reinforcement learning (DRL) agents excel in solving complex\ndecision-making tasks across various domains. However, they often require a\nsubstantial number of training steps and a vast experience replay buffer,\nleading to significant computational and resource demands. To address these\nchallenges, we introduce a novel theoretical result that leverages the\nNeyman-Rubin potential outcomes framework into DRL. Unlike most methods that\nfocus on bounding the counterfactual loss, we establish a causal bound on the\nfactual loss, which is analogous to the on-policy loss in DRL. This bound is\ncomputed by storing past value network outputs in the experience replay buffer,\neffectively utilizing data that is usually discarded. Extensive experiments\nacross the Atari 2600 and MuJoCo domains on various agents, such as DQN and\nSAC, achieve up to 2,427% higher reward ratio, outperforming the same agents\nwithout our proposed term, and reducing the experience replay buffer size by up\nto 96%, significantly improving sample efficiency at negligible cost.",
      "url": "http://arxiv.org/abs/2507.11269v1",
      "published_time_eastern_timestamp": 1752583585.0
    },
    {
      "title": "An Agentic Flow for Finite State Machine Extraction using Prompt\n  Chaining",
      "summary": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications.",
      "url": "http://arxiv.org/abs/2507.11222v1",
      "published_time_eastern_timestamp": 1752580225.0
    },
    {
      "title": "Fair Contracts",
      "summary": "We introduce and study the problem of designing optimal contracts under\nfairness constraints on the task assignments and compensations. We adopt the\nnotion of envy-free (EF) and its relaxations, $\\epsilon$-EF and envy-free up to\none item (EF1), in contract design settings. Unlike fair allocations, EF\ncontracts are guaranteed to exist. However, computing any constant-factor\napproximation to the optimal EF contract is NP-hard in general, even using\n$\\epsilon$-EF contracts. For this reason, we consider settings in which the\nnumber of agents or tasks is constant. Notably, while even with three agents,\nfinding an EF contract better than $2/5$ approximation of the optimal is\nNP-hard, we are able to design an FPTAS when the number of agents is constant,\nunder relaxed notions of $\\epsilon$-EF and EF1. Moreover, we present a\npolynomial-time algorithm for computing the optimal EF contract when the number\nof tasks is constant. Finally, we analyze the price of fairness in contract\ndesign. We show that the price of fairness for exact EF contracts can be\nunbounded, even with a single task and two agents. In contrast, for EF1\ncontracts, the price of fairness is bounded between $\\Omega(\\sqrt{n})$ and\n$O(n^2)$, where $n$ is the number of agents.",
      "url": "http://arxiv.org/abs/2507.11214v1",
      "published_time_eastern_timestamp": 1752579088.0
    },
    {
      "title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and\n  Addressing Family Communication Bias",
      "summary": "Well-being in family settings involves subtle psychological dynamics that\nconventional metrics often overlook. In particular, unconscious parental\nexpectations, termed ideal parent bias, can suppress children's emotional\nexpression and autonomy. This suppression, referred to as suppressed emotion,\noften stems from well-meaning but value-driven communication, which is\ndifficult to detect or address from outside the family. Focusing on these\nlatent dynamics, this study explores Large Language Model (LLM)-based support\nfor psychologically safe family communication. We constructed a Japanese\nparent-child dialogue corpus of 30 scenarios, each annotated with metadata on\nideal parent bias and suppressed emotion. Based on this corpus, we developed a\nRole-Playing LLM-based multi-agent dialogue support framework that analyzes\ndialogue and generates feedback. Specialized agents detect suppressed emotion,\ndescribe implicit ideal parent bias in parental speech, and infer contextual\nattributes such as the child's age and background. A meta-agent compiles these\noutputs into a structured report, which is then passed to five selected expert\nagents. These agents collaboratively generate empathetic and actionable\nfeedback through a structured four-step discussion process. Experiments show\nthat the system can detect categories of suppressed emotion with moderate\naccuracy and produce feedback rated highly in empathy and practicality.\nMoreover, simulated follow-up dialogues incorporating this feedback exhibited\nsigns of improved emotional expression and mutual understanding, suggesting the\nframework's potential in supporting positive transformation in family\ninteractions.",
      "url": "http://arxiv.org/abs/2507.11210v1",
      "published_time_eastern_timestamp": 1752578852.0
    },
    {
      "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy\n  Gains in Qualitative Coding",
      "summary": "Large Language Models (LLMs) enable new possibilities for qualitative\nresearch at scale, including coding and data annotation. While multi-agent\nsystems (MAS) can emulate human coding workflows, their benefits over\nsingle-agent coding remain poorly understood. We conducted an experimental\nstudy of how agent persona and temperature shape consensus-building and coding\naccuracy of dialog segments based on a codebook with 8 codes. Our open-source\nMAS mirrors deductive human coding through structured agent discussion and\nconsensus arbitration. Using six open-source LLMs (with 3 to 32 billion\nparameters) and 18 experimental configurations, we analyze over 77,000 coding\ndecisions against a gold-standard dataset of human-annotated transcripts from\nonline math tutoring sessions. Temperature significantly impacted whether and\nwhen consensus was reached across all six LLMs. MAS with multiple personas\n(including neutral, assertive, or empathetic), significantly delayed consensus\nin four out of six LLMs compared to uniform personas. In three of those LLMs,\nhigher temperatures significantly diminished the effects of multiple personas\non consensus. However, neither temperature nor persona pairing lead to robust\nimprovements in coding accuracy. Single agents matched or outperformed MAS\nconsensus in most conditions. Only one model (OpenHermesV2:7B) and code\ncategory showed above-chance gains from MAS deliberation when temperature was\n0.5 or lower and especially when the agents included at least one assertive\npersona. Qualitative analysis of MAS collaboration for these configurations\nsuggests that MAS may nonetheless aid in narrowing ambiguous code applications\nthat could improve codebooks and human-AI coding. We contribute new insight\ninto the limits of LLM-based qualitative methods, challenging the notion that\ndiverse MAS personas lead to better outcomes. We open-source our MAS and\nexperimentation code.",
      "url": "http://arxiv.org/abs/2507.11198v1",
      "published_time_eastern_timestamp": 1752577592.0
    },
    {
      "title": "Quantized Rank Reduction: A Communications-Efficient Federated Learning\n  Scheme for Network-Critical Applications",
      "summary": "Federated learning is a machine learning approach that enables multiple\ndevices (i.e., agents) to train a shared model cooperatively without exchanging\nraw data. This technique keeps data localized on user devices, ensuring privacy\nand security, while each agent trains the model on their own data and only\nshares model updates. The communication overhead is a significant challenge due\nto the frequent exchange of model updates between the agents and the central\nserver. In this paper, we propose a communication-efficient federated learning\nscheme that utilizes low-rank approximation of neural network gradients and\nquantization to significantly reduce the network load of the decentralized\nlearning process with minimal impact on the model's accuracy.",
      "url": "http://arxiv.org/abs/2507.11183v1",
      "published_time_eastern_timestamp": 1752575879.0
    },
    {
      "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets",
      "summary": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.",
      "url": "http://arxiv.org/abs/2507.11117v1",
      "published_time_eastern_timestamp": 1752570679.0
    },
    {
      "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language\n  Model-Based Commander",
      "summary": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.",
      "url": "http://arxiv.org/abs/2507.11079v1",
      "published_time_eastern_timestamp": 1752567757.0
    },
    {
      "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language\n  Models on Software Engineering Tasks",
      "summary": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08\\% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025.",
      "url": "http://arxiv.org/abs/2507.11059v1",
      "published_time_eastern_timestamp": 1752565953.0
    },
    {
      "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection",
      "summary": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.",
      "url": "http://arxiv.org/abs/2507.11049v1",
      "published_time_eastern_timestamp": 1752564124.0
    }
  ]
}
{
  "last_updated": "2025-09-25T05:12:43.551285-04:00",
  "papers": [
    {
      "title": "Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement\n  Learning",
      "summary": "Conventional multi-agent reinforcement learning (MARL) methods rely on\ntime-triggered execution, where agents sample and communicate actions at fixed\nintervals. This approach is often computationally expensive and\ncommunication-intensive. To address this limitation, we propose ET-MAPG\n(Event-Triggered Multi-Agent Policy Gradient reinforcement learning), a\nframework that jointly learns an agent's control policy and its\nevent-triggering policy. Unlike prior work that decouples these mechanisms,\nET-MAPG integrates them into a unified learning process, enabling agents to\nlearn not only what action to take but also when to execute it. For scenarios\nwith inter-agent communication, we introduce AET-MAPG, an attention-based\nvariant that leverages a self-attention mechanism to learn selective\ncommunication patterns. AET-MAPG empowers agents to determine not only when to\ntrigger an action but also with whom to communicate and what information to\nexchange, thereby optimizing coordination. Both methods can be integrated with\nany policy gradient MARL algorithm. Extensive experiments across diverse MARL\nbenchmarks demonstrate that our approaches achieve performance comparable to\nstate-of-the-art, time-triggered baselines while significantly reducing both\ncomputational load and communication overhead.",
      "url": "http://arxiv.org/abs/2509.20338v1",
      "published_time_eastern_timestamp": 1758734996.0
    },
    {
      "title": "DRES: Benchmarking LLMs for Disfluency Removal",
      "summary": "Disfluencies -- such as \"um,\" \"uh,\" interjections, parentheticals, and edited\nstatements -- remain a persistent challenge for speech-driven systems,\ndegrading accuracy in command interpretation, summarization, and conversational\nagents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlled\ntext-level benchmark that establishes a reproducible semantic upper bound for\nthis task. DRES builds on human-annotated Switchboard transcripts, isolating\ndisfluency removal from ASR errors and acoustic variability. We systematically\nevaluate proprietary and open-source LLMs across scales, prompting strategies,\nand architectures. Our results reveal that (i) simple segmentation consistently\nimproves performance, even for long-context models; (ii) reasoning-oriented\nmodels tend to over-delete fluent tokens; and (iii) fine-tuning achieves near\nstate-of-the-art precision and recall but harms generalization abilities. We\nfurther present a set of LLM-specific error modes and offer nine practical\nrecommendations (R1-R9) for deploying disfluency removal in speech-driven\npipelines. DRES provides a reproducible, model-agnostic foundation for\nadvancing robust spoken-language systems.",
      "url": "http://arxiv.org/abs/2509.20321v1",
      "published_time_eastern_timestamp": 1758733692.0
    },
    {
      "title": "On Robustness of Consensus over Pseudo-Undirected Path Graphs",
      "summary": "Consensus over networked agents is typically studied using undirected or\ndirected communication graphs. Undirected graphs enforce symmetry in\ninformation exchange, leading to convergence to the average of initial states,\nwhile directed graphs permit asymmetry but make consensus dependent on root\nnodes and their influence. Both paradigms impose inherent restrictions on\nachievable consensus values and network robustness. This paper introduces a\ntheoretical framework for achieving consensus over a class of network\ntopologies, termed pseudo-undirected graphs, which retains bidirectional\nconnectivity between node pairs but allows the corresponding edge weights to\ndiffer, including the possibility of negative values under bounded conditions.\nThe resulting Laplacian is generally non-symmetric, yet it guarantees consensus\nunder connectivity assumptions, to expand the solution space, which enables the\nsystem to achieve a stable consensus value that can lie outside the convex hull\nof the initial state set. We derive admissibility bounds for negative weights\nfor a pseudo-undirected path graph, and show an application in the simultaneous\ninterception of a moving target.",
      "url": "http://arxiv.org/abs/2509.20314v1",
      "published_time_eastern_timestamp": 1758732684.0
    },
    {
      "title": "PGCLODA: Prompt-Guided Graph Contrastive Learning for\n  Oligopeptide-Infectious Disease Association Prediction",
      "summary": "Infectious diseases continue to pose a serious threat to public health,\nunderscoring the urgent need for effective computational approaches to screen\nnovel anti-infective agents. Oligopeptides have emerged as promising candidates\nin antimicrobial research due to their structural simplicity, high\nbioavailability, and low susceptibility to resistance. Despite their potential,\ncomputational models specifically designed to predict associations between\noligopeptides and infectious diseases remain scarce. This study introduces a\nprompt-guided graph-based contrastive learning framework (PGCLODA) to uncover\npotential associations. A tripartite graph is constructed with oligopeptides,\nmicrobes, and diseases as nodes, incorporating both structural and semantic\ninformation. To preserve critical regions during contrastive learning, a\nprompt-guided graph augmentation strategy is employed to generate meaningful\npaired views. A dual encoder architecture, integrating Graph Convolutional\nNetwork (GCN) and Transformer, is used to jointly capture local and global\nfeatures. The fused embeddings are subsequently input into a multilayer\nperceptron (MLP) classifier for final prediction. Experimental results on a\nbenchmark dataset indicate that PGCLODA consistently outperforms\nstate-of-the-art models in AUROC, AUPRC, and accuracy. Ablation and\nhyperparameter studies confirm the contribution of each module. Case studies\nfurther validate the generalization ability of PGCLODA and its potential to\nuncover novel, biologically relevant associations. These findings offer\nvaluable insights for mechanism-driven discovery and oligopeptide-based drug\ndevelopment. The source code of PGCLODA is available online at\nhttps://github.com/jjnlcode/PGCLODA.",
      "url": "http://arxiv.org/abs/2509.20290v1",
      "published_time_eastern_timestamp": 1758731113.0
    },
    {
      "title": "A co-evolving agentic AI system for medical imaging analysis",
      "summary": "Agentic AI is rapidly advancing in healthcare and biomedical research.\nHowever, in medical image analysis, their performance and adoption remain\nlimited due to the lack of a robust ecosystem, insufficient toolsets, and the\nabsence of real-time interactive expert feedback. Here we present \"TissueLab\",\na co-evolving agentic AI system that allows researchers to ask direct\nquestions, automatically plan and generate explainable workflows, and conduct\nreal-time analyses where experts can visualize intermediate results and refine\nthem. TissueLab integrates tool factories across pathology, radiology, and\nspatial omics domains. By standardizing inputs, outputs, and capabilities of\ndiverse tools, the system determines when and how to invoke them to address\nresearch and clinical questions. Across diverse tasks with clinically\nmeaningful quantifications that inform staging, prognosis, and treatment\nplanning, TissueLab achieves state-of-the-art performance compared with\nend-to-end vision-language models (VLMs) and other agentic AI systems such as\nGPT-5. Moreover, TissueLab continuously learns from clinicians, evolving toward\nimproved classifiers and more effective decision strategies. With active\nlearning, it delivers accurate results in unseen disease contexts within\nminutes, without requiring massive datasets or prolonged retraining. Released\nas a sustainable open-source ecosystem, TissueLab aims to accelerate\ncomputational research and translational adoption in medical imaging while\nestablishing a foundation for the next generation of medical AI.",
      "url": "http://arxiv.org/abs/2509.20279v1",
      "published_time_eastern_timestamp": 1758730528.0
    },
    {
      "title": "Scan-do Attitude: Towards Autonomous CT Protocol Management using a\n  Large Language Model Agent",
      "summary": "Managing scan protocols in Computed Tomography (CT), which includes adjusting\nacquisition parameters or configuring reconstructions, as well as selecting\npostprocessing tools in a patient-specific manner, is time-consuming and\nrequires clinical as well as technical expertise. At the same time, we observe\nan increasing shortage of skilled workforce in radiology. To address this\nissue, a Large Language Model (LLM)-based agent framework is proposed to assist\nwith the interpretation and execution of protocol configuration requests given\nin natural language or a structured, device-independent format, aiming to\nimprove the workflow efficiency and reduce technologists' workload. The agent\ncombines in-context-learning, instruction-following, and structured toolcalling\nabilities to identify relevant protocol elements and apply accurate\nmodifications. In a systematic evaluation, experimental results indicate that\nthe agent can effectively retrieve protocol components, generate device\ncompatible protocol definition files, and faithfully implement user requests.\nDespite demonstrating feasibility in principle, the approach faces limitations\nregarding syntactic and semantic validity due to lack of a unified device API,\nand challenges with ambiguous or complex requests. In summary, the findings\nshow a clear path towards LLM-based agents for supporting scan protocol\nmanagement in CT imaging.",
      "url": "http://arxiv.org/abs/2509.20270v1",
      "published_time_eastern_timestamp": 1758729851.0
    },
    {
      "title": "Energy Use of AI Inference: Efficiency Pathways and Test-Time Compute",
      "summary": "As AI inference scales to billions of queries and emerging reasoning and\nagentic workflows increase token demand, reliable estimates of per-query energy\nuse are increasingly important for capacity planning, emissions accounting, and\nefficiency prioritization. Many public estimates are inconsistent and overstate\nenergy use, because they extrapolate from limited benchmarks and fail to\nreflect efficiency gains achievable at scale. In this perspective, we introduce\na bottom-up methodology to estimate the per-query energy of large-scale LLM\nsystems based on token throughput. For models running on an H100 node under\nrealistic workloads, GPU utilization and PUE constraints, we estimate a median\nenergy per query of 0.34 Wh (IQR: 0.18-0.67) for frontier-scale models (>200\nbillion parameters). These results are consistent with measurements using\nproduction-scale configurations and show that non-production estimates and\nassumptions can overstate energy use by 4-20x. Extending to test-time scaling\nscenarios with 15x more tokens per typical query, the median energy rises 13x\nto 4.32 Wh, indicating that targeting efficiency in this regime will deliver\nthe largest fleet-wide savings. We quantify achievable efficiency gains at the\nmodel, serving platform, and hardware levels, finding individual median\nreductions of 1.5-3.5x in energy per query, while combined advances can\nplausibly deliver 8-20x reductions. To illustrate the system-level impact, we\nestimate the baseline daily energy use of a deployment serving 1 billion\nqueries to be 0.8 GWh/day. If 10% are long queries, demand could grow to 1.8\nGWh/day. With targeted efficiency interventions, it falls to 0.9 GWh/day,\nsimilar to the energy footprint of web search at that scale. This echoes how\ndata centers historically tempered energy growth through efficiency gains\nduring the internet and cloud build-up.",
      "url": "http://arxiv.org/abs/2509.20241v1",
      "published_time_eastern_timestamp": 1758727921.0
    },
    {
      "title": "Automated Multi-Agent Workflows for RTL Design",
      "summary": "The rise of agentic AI workflows unlocks novel opportunities for computer\nsystems design and optimization. However, for specialized domains such as\nprogram synthesis, the relative scarcity of HDL and proprietary EDA resources\nonline compared to more common programming tasks introduces challenges, often\nnecessitating task-specific fine-tuning, high inference costs, and\nmanually-crafted agent orchestration. In this work, we present VeriMaAS, a\nmulti-agent framework designed to automatically compose agentic workflows for\nRTL code generation. Our key insight is to integrate formal verification\nfeedback from HDL tools directly into workflow generation, reducing the cost of\ngradient-based updates or prolonged reasoning traces. Our method improves\nsynthesis performance by 5-7% for pass@k over fine-tuned baselines, while\nrequiring only a few hundred training examples, representing an\norder-of-magnitude reduction in supervision cost.",
      "url": "http://arxiv.org/abs/2509.20182v1",
      "published_time_eastern_timestamp": 1758725068.0
    },
    {
      "title": "Federation of Agents: A Semantics-Aware Communication Fabric for\n  Large-Scale Agentic AI",
      "summary": "We present Federation of Agents (FoA), a distributed orchestration framework\nthat transforms static multi-agent coordination into dynamic, capability-driven\ncollaboration. FoA introduces Versioned Capability Vectors (VCVs):\nmachine-readable profiles that make agent capabilities searchable through\nsemantic embeddings, enabling agents to advertise their capabilities, cost, and\nlimitations. Our aarchitecturecombines three key innovations: (1) semantic\nrouting that matches tasks to agents over sharded HNSW indices while enforcing\noperational constraints through cost-biased optimization, (2) dynamic task\ndecomposition where compatible agents collaboratively break down complex tasks\ninto DAGs of subtasks through consensus-based merging, and (3) smart clustering\nthat groups agents working on similar subtasks into collaborative channels for\nk-round refinement before synthesis. Built on top of MQTT,s publish-subscribe\nsemantics for scalable message passing, FoA achieves sub-linear complexity\nthrough hierarchical capability matching and efficient index maintenance.\nEvaluation on HealthBench shows 13x improvements over single-model baselines,\nwith clustering-enhanced laboration particularly effective for complex\nreasoning tasks requiring multiple perspectives. The system scales horizontally\nwhile maintaining consistent performance, demonstrating that semantic\norchestration with structured collaboration can unlock the collective\nintelligence of heterogeneous federations of AI agents.",
      "url": "http://arxiv.org/abs/2509.20175v1",
      "published_time_eastern_timestamp": 1758724686.0
    },
    {
      "title": "From Pheromones to Policies: Reinforcement Learning for Engineered\n  Biological Swarms",
      "summary": "Swarm intelligence emerges from decentralised interactions among simple\nagents, enabling collective problem-solving. This study establishes a\ntheoretical equivalence between pheromone-mediated aggregation in \\celeg\\ and\nreinforcement learning (RL), demonstrating how stigmergic signals function as\ndistributed reward mechanisms. We model engineered nematode swarms performing\nforaging tasks, showing that pheromone dynamics mathematically mirror\ncross-learning updates, a fundamental RL algorithm. Experimental validation\nwith data from literature confirms that our model accurately replicates\nempirical \\celeg\\ foraging patterns under static conditions. In dynamic\nenvironments, persistent pheromone trails create positive feedback loops that\nhinder adaptation by locking swarms into obsolete choices. Through\ncomputational experiments in multi-armed bandit scenarios, we reveal that\nintroducing a minority of exploratory agents insensitive to pheromones restores\ncollective plasticity, enabling rapid task switching. This behavioural\nheterogeneity balances exploration-exploitation trade-offs, implementing\nswarm-level extinction of outdated strategies. Our results demonstrate that\nstigmergic systems inherently encode distributed RL processes, where\nenvironmental signals act as external memory for collective credit assignment.\nBy bridging synthetic biology with swarm robotics, this work advances\nprogrammable living systems capable of resilient decision-making in volatile\nenvironments.",
      "url": "http://arxiv.org/abs/2509.20095v1",
      "published_time_eastern_timestamp": 1758719795.0
    },
    {
      "title": "Hybrid Safety Verification of Multi-Agent Systems using $Ïˆ$-Weighted\n  CBFs and PAC Guarantees",
      "summary": "This study proposes a hybrid safety verification framework for closed-loop\nmulti-agent systems under bounded stochastic disturbances. The proposed\napproach augments control barrier functions with a novel $\\psi$-weighted\nformulation that encodes directional control alignment between agents into the\nsafety constraints. Deterministic admissibility is combined with empirical\nvalidation via Monte Carlo rollouts, and a PAC-style guarantee is derived based\non margin-aware safety violations to provide a probabilistic safety\ncertificate. The results from the experiments conducted under different bounded\nstochastic disturbances validate the feasibility of the proposed approach.",
      "url": "http://arxiv.org/abs/2509.20093v1",
      "published_time_eastern_timestamp": 1758719618.0
    },
    {
      "title": "Distributed Koopman Operator Learning from Sequential Observations",
      "summary": "This paper presents a distributed Koopman operator learning framework for\nmodeling unknown nonlinear dynamics using sequential observations from multiple\nagents. Each agent estimates a local Koopman approximation based on lifted data\nand collaborates over a communication graph to reach exponential consensus on a\nconsistent distributed approximation. The approach supports distributed\ncomputation under asynchronous and resource-constrained sensing. Its\nperformance is demonstrated through simulation results, validating convergence\nand predictive accuracy under sensing-constrained scenarios and limited\ncommunication.",
      "url": "http://arxiv.org/abs/2509.20071v1",
      "published_time_eastern_timestamp": 1758717688.0
    },
    {
      "title": "MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM",
      "summary": "Large language models (LLMs) have demonstrated notable potential in medical\napplications, yet they face substantial challenges in handling complex\nreal-world clinical diagnoses using conventional prompting methods. Current\nprompt engineering and multi-agent approaches typically optimize isolated\ninferences, neglecting the accumulation of reusable clinical experience. To\naddress this, this study proposes a novel Multi-Agent Clinical Diagnosis (MACD)\nframework, which allows LLMs to self-learn clinical knowledge via a multi-agent\npipeline that summarizes, refines, and applies diagnostic insights. It mirrors\nhow physicians develop expertise through experience, enabling more focused and\naccurate diagnosis on key disease-specific cues. We further extend it to a\nMACD-human collaborative workflow, where multiple LLM-based diagnostician\nagents engage in iterative consultations, supported by an evaluator agent and\nhuman oversight for cases where agreement is not reached. Evaluated on 4,390\nreal-world patient cases across seven diseases using diverse open-source LLMs\n(Llama-3.1 8B/70B, DeepSeek-R1-Distill-Llama 70B), MACD significantly improves\nprimary diagnostic accuracy, outperforming established clinical guidelines with\ngains up to 22.3% (MACD). On the subset of the data, it achieves performance on\npar with or exceeding that of human physicians (up to 16% improvement over\nphysicians-only diagnosis). Additionally, on the MACD-human workflow, it\nachieves an 18.6% improvement compared to physicians-only diagnosis. Moreover,\nself-learned knowledge exhibits strong cross-model stability, transferability,\nand model-specific personalization, while the system can generate traceable\nrationales, enhancing explainability. Consequently, this work presents a\nscalable self-learning paradigm for LLM-assisted diagnosis, bridging the gap\nbetween the intrinsic knowledge of LLMs and real-world clinical practice.",
      "url": "http://arxiv.org/abs/2509.20067v1",
      "published_time_eastern_timestamp": 1758717431.0
    },
    {
      "title": "The Knowledge-Behaviour Disconnect in LLM-based Chatbots",
      "summary": "Large language model-based artificial conversational agents (like ChatGPT)\ngive answers to all kinds of questions, and often enough these answers are\ncorrect. Just on the basis of that capacity alone, we may attribute knowledge\nto them. But do these models use this knowledge as a basis for their own\nconversational behaviour? I argue this is not the case, and I will refer to\nthis failure as a `disconnect'. I further argue this disconnect is fundamental\nin the sense that with more data and more training of the LLM on which a\nconversational chatbot is based, it will not disappear. The reason is, as I\nwill claim, that the core technique used to train LLMs does not allow for the\nestablishment of the connection we are after. The disconnect reflects a\nfundamental limitation on the capacities of LLMs, and explains the source of\nhallucinations. I will furthermore consider the ethical version of the\ndisconnect (ethical conversational knowledge not being aligned with ethical\nconversational behaviour), since in this domain researchers have come up with\nseveral additional techniques to influence a chatbot's behaviour. I will\ndiscuss how these techniques do nothing to solve the disconnect and can make it\nworse.",
      "url": "http://arxiv.org/abs/2509.20004v1",
      "published_time_eastern_timestamp": 1758713089.0
    },
    {
      "title": "An effective control of large systems of active particles: An\n  application to evacuation problem",
      "summary": "Manipulation of large systems of active particles is a serious challenge\nacross diverse domains, including crowd management, control of robotic swarms,\nand coordinated material transport. The development of advanced control\nstrategies for complex scenarios is hindered, however, by the lack of\nscalability and robustness of the existing methods, in particular, due to the\nneed of an individual control for each agent. One possible solution involves\ncontrolling a system through a leader or a group of leaders, which other agents\ntend to follow. Using such an approach we develop an effective control strategy\nfor a leader, combining reinforcement learning (RL) with artificial forces\nacting on the system. To describe the guidance of active particles by a leader\nwe introduce the generalized Vicsek model. This novel method is then applied to\nthe problem of the effective evacuation by a robot-rescuer (leader) of large\ngroups of people from hazardous places. We demonstrate, that while a\nstraightforward application of RL yields suboptimal results, even for advanced\narchitectures, our approach provides a robust and efficient evacuation\nstrategy. The source code supporting this study is publicly available at:\nhttps://github.com/cinemere/evacuation.",
      "url": "http://arxiv.org/abs/2509.19972v1",
      "published_time_eastern_timestamp": 1758709665.0
    },
    {
      "title": "Exploration with Foundation Models: Capabilities, Limitations, and\n  Hybrid Approaches",
      "summary": "Exploration in reinforcement learning (RL) remains challenging, particularly\nin sparse-reward settings. While foundation models possess strong semantic\npriors, their capabilities as zero-shot exploration agents in classic RL\nbenchmarks are not well understood. We benchmark LLMs and VLMs on multi-armed\nbandits, Gridworlds, and sparse-reward Atari to test zero-shot exploration. Our\ninvestigation reveals a key limitation: while VLMs can infer high-level\nobjectives from visual input, they consistently fail at precise low-level\ncontrol: the \"knowing-doing gap\". To analyze a potential bridge for this gap,\nwe investigate a simple on-policy hybrid framework in a controlled, best-case\nscenario. Our results in this idealized setting show that VLM guidance can\nsignificantly improve early-stage sample efficiency, providing a clear analysis\nof the potential and constraints of using foundation models to guide\nexploration rather than for end-to-end control.",
      "url": "http://arxiv.org/abs/2509.19924v1",
      "published_time_eastern_timestamp": 1758705915.0
    },
    {
      "title": "Beyond Language Barriers: Multi-Agent Coordination for Multi-Language\n  Code Generation",
      "summary": "Producing high-quality code across multiple programming languages is\nincreasingly important as today's software systems are built on heterogeneous\nstacks. Large language models (LLMs) have advanced the state of automated\nprogramming, yet their proficiency varies sharply between languages, especially\nthose with limited training data such as Rust, Perl, OCaml, and Erlang. Many\ncurrent solutions including language-specific fine-tuning, multi-agent\norchestration, transfer learning, and intermediate-representation pipelines\nstill approach each target language in isolation, missing opportunities to\nshare knowledge or exploit recurring cross-language patterns.\n  XL-CoGen tackles this challenge with a coordinated multi-agent architecture\nthat integrates intermediate representation, code generation, translation, and\nautomated repair. Its distinguishing feature is a data-driven mechanism for\nselecting bridging languages: empirically derived transfer matrices identify\nthe best intermediate languages based on demonstrated translation success\nrather than raw generation accuracy. The system performs early output\nvalidation, iteratively corrects errors, and reuses intermediate artifacts as\ncontextual scaffolds for subsequent translations.\n  Extensive experiments show that XL-CoGen yields notable improvements with 13\npercentage-point gains over the strongest fine-tuned baseline and as much as 30\npercentage points over existing single-language multi-agent methods. Ablation\nstudies further demonstrate that compatibility-guided bridging significantly\noutperforms LLM-based heuristics, confirming the value of cumulative\ncross-language knowledge transfer.",
      "url": "http://arxiv.org/abs/2509.19918v1",
      "published_time_eastern_timestamp": 1758705488.0
    },
    {
      "title": "FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models",
      "summary": "Vision-Language-Action (VLA) models are driving rapid progress in robotics by\nenabling agents to interpret multimodal inputs and execute complex,\nlong-horizon tasks. However, their safety and robustness against adversarial\nattacks remain largely underexplored. In this work, we identify and formalize a\ncritical adversarial vulnerability in which adversarial images can \"freeze\" VLA\nmodels and cause them to ignore subsequent instructions. This threat\neffectively disconnects the robot's digital mind from its physical actions,\npotentially inducing inaction during critical interventions. To systematically\nstudy this vulnerability, we propose FreezeVLA, a novel attack framework that\ngenerates and evaluates action-freezing attacks via min-max bi-level\noptimization. Experiments on three state-of-the-art VLA models and four robotic\nbenchmarks show that FreezeVLA attains an average attack success rate of 76.2%,\nsignificantly outperforming existing methods. Moreover, adversarial images\ngenerated by FreezeVLA exhibit strong transferability, with a single image\nreliably inducing paralysis across diverse language prompts. Our findings\nexpose a critical safety risk in VLA models and highlight the urgent need for\nrobust defense mechanisms.",
      "url": "http://arxiv.org/abs/2509.19870v1",
      "published_time_eastern_timestamp": 1758701728.0
    },
    {
      "title": "Scalable and Approximation-free Symbolic Control for Unknown\n  Euler-Lagrange Systems",
      "summary": "We propose a novel symbolic control framework for enforcing temporal logic\nspecifications in Euler-Lagrange systems that addresses the key limitations of\ntraditional abstraction-based approaches. Unlike existing methods that require\nexact system models and provide guarantees only at discrete sampling instants,\nour approach relies only on bounds on system parameters and input constraints,\nand ensures correctness for the full continuous-time trajectory. The framework\ncombines scalable abstraction of a simplified virtual system with a\nclosed-form, model-free controller that guarantees trajectories satisfy the\noriginal specification while respecting input bounds and remaining robust to\nunknown but bounded disturbances. We provide feasibility conditions for the\nconstruction of confinement regions and analyze the trade-off between\nefficiency and conservatism. Case studies on pendulum dynamics, a two-link\nmanipulator, and multi-agent systems, including hardware experiments,\ndemonstrate that the proposed approach ensures both correctness and safety\nwhile significantly reducing computational time and memory requirements. These\nresults highlight its scalability and practicality for real-world robotic\nsystems where precise models are unavailable and continuous-time guarantees are\nessential.",
      "url": "http://arxiv.org/abs/2509.19859v1",
      "published_time_eastern_timestamp": 1758700656.0
    },
    {
      "title": "CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for\n  Collaborative LLM Training in Heterogeneous Edge Networks",
      "summary": "The increasing demand for intelligent mobile applications has made\nmulti-agent collaboration with Transformer-based large language models (LLMs)\nessential in mobile edge computing (MEC) networks. However, training LLMs in\nsuch environments remains challenging due to heavy computation, high end-to-end\nlatency, and limited model generalization. We introduce CollaPipe, a hybrid\ndistributed learning framework that integrates collaborative pipeline\nparallelism with federated aggregation to support self-evolving intelligent\nnetworks. In CollaPipe, the encoder part is adaptively partitioned into\nvariable-sized segments and deployed across mobile devices for\npipeline-parallel training, while the decoder is deployed on edge servers to\nhandle generative tasks. Then we perform global model update via federated\naggregation. To enhance training efficiency, we formulate a joint optimization\nproblem that adaptively allocates model segments, micro-batches, bandwidth, and\ntransmission power. We derive and use a closed-form convergence bound to design\nan Dynamic Segment Scheduling and Resource Allocation (DSSDA) algorithm based\non Lyapunov optimization, ensuring system stability under long-term\nconstraints. Extensive experiments on downstream tasks with Transformer and\nBERT models show that CollaPipe improves computation efficiency by up to\n15.09%, reduces end-to-end latency by at least 48.98%, and cuts single device\nmemory usage by more than half, enabling online learning in heterogeneous and\ndynamic communication environments.",
      "url": "http://arxiv.org/abs/2509.19855v1",
      "published_time_eastern_timestamp": 1758700441.0
    }
  ]
}
{
  "last_updated": "2025-09-08T20:54:39.881765-04:00",
  "papers": [
    {
      "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for\n  Interactive Complex World Generation",
      "summary": "Recent research has been increasingly focusing on developing 3D world models\nthat simulate complex real-world scenarios. World models have found broad\napplications across various domains, including embodied AI, autonomous driving,\nentertainment, etc. A more realistic simulation with accurate physics will\neffectively narrow the sim-to-real gap and allow us to gather rich information\nabout the real world conveniently. While traditional manual modeling has\nenabled the creation of virtual 3D scenes, modern approaches have leveraged\nadvanced machine learning algorithms for 3D world generation, with most recent\nadvances focusing on generative methods that can create virtual worlds based on\nuser instructions. This work explores such a research direction by proposing\nLatticeWorld, a simple yet effective 3D world generation framework that\nstreamlines the industrial production pipeline of 3D environments. LatticeWorld\nleverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering\nengine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed\nframework accepts textual descriptions and visual instructions as multimodal\ninputs and creates large-scale 3D interactive worlds with dynamic agents,\nfeaturing competitive multi-agent interaction, high-fidelity physics\nsimulation, and real-time rendering. We conduct comprehensive experiments to\nevaluate LatticeWorld, showing that it achieves superior accuracy in scene\nlayout generation and visual fidelity. Moreover, LatticeWorld achieves over a\n$90\\times$ increase in industrial production efficiency while maintaining high\ncreative quality compared with traditional manual production methods. Our demo\nvideo is available at https://youtu.be/8VWZXpERR18",
      "url": "http://arxiv.org/abs/2509.05263v1",
      "published_time_eastern_timestamp": 1757092953.0
    },
    {
      "title": "Triadic Fusion of Cognitive, Functional, and Causal Dimensions for\n  Explainable LLMs: The TAXAL Framework",
      "summary": "Large Language Models (LLMs) are increasingly being deployed in high-risk\ndomains where opacity, bias, and instability undermine trust and\naccountability. Traditional explainability methods, focused on surface outputs,\ndo not capture the reasoning pathways, planning logic, and systemic impacts of\nagentic LLMs.\n  We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a\ntriadic fusion framework that unites three complementary dimensions: cognitive\n(user understanding), functional (practical utility), and causal (faithful\nreasoning). TAXAL provides a unified, role-sensitive foundation for designing,\nevaluating, and deploying explanations in diverse sociotechnical settings.\n  Our analysis synthesizes existing methods, ranging from post-hoc attribution\nand dialogic interfaces to explanation-aware prompting, and situates them\nwithin the TAXAL triadic fusion model. We further demonstrate its applicability\nthrough case studies in law, education, healthcare, and public services,\nshowing how explanation strategies adapt to institutional constraints and\nstakeholder roles.\n  By combining conceptual clarity with design patterns and deployment pathways,\nTAXAL advances explainability as a technical and sociotechnical practice,\nsupporting trustworthy and context-sensitive LLM applications in the era of\nagentic AI.",
      "url": "http://arxiv.org/abs/2509.05199v1",
      "published_time_eastern_timestamp": 1757087929.0
    },
    {
      "title": "AI Agents for Web Testing: A Case Study in the Wild",
      "summary": "Automated web testing plays a critical role in ensuring high-quality user\nexperiences and delivering business value. Traditional approaches primarily\nfocus on code coverage and load testing, but often fall short of capturing\ncomplex user behaviors, leaving many usability issues undetected. The emergence\nof large language models (LLM) and AI agents opens new possibilities for web\ntesting by enabling human-like interaction with websites and a general\nawareness of common usability problems. In this work, we present WebProber, a\nprototype AI agent-based web testing framework. Given a URL, WebProber\nautonomously explores the website, simulating real user interactions,\nidentifying bugs and usability issues, and producing a human-readable report.\nWe evaluate WebProber through a case study of 120 academic personal websites,\nwhere it uncovered 29 usability issues--many of which were missed by\ntraditional tools. Our findings highlight agent-based testing as a promising\ndirection while outlining directions for developing next-generation,\nuser-centered testing frameworks.",
      "url": "http://arxiv.org/abs/2509.05197v1",
      "published_time_eastern_timestamp": 1757087836.0
    },
    {
      "title": "Collective decision-making dynamics in hypernetworks",
      "summary": "This work describes a collective decision-making dynamical process in a\nmultiagent system under the assumption of cooperative higher-order interactions\nwithin the community, modeled as a hypernetwork. The nonlinear interconnected\nsystem is characterized by saturated nonlinearities that describe how agents\ntransmit their opinion state to their neighbors in the hypernetwork, and by a\nbifurcation parameter representing the community's social effort. We show that\nthe presence of higher-order interactions leads to the unfolding of a pitchfork\nbifurcation, introducing an interval for the social effort parameter in which\nthe system exhibits bistability. With equilibrium points representing\ncollective decisions, this implies that, depending on the initial conditions,\nthe community will either remain in a deadlock state (with the origin as the\nequilibrium point) or reach a nontrivial decision. A numerical example is given\nto illustrate the results.",
      "url": "http://arxiv.org/abs/2509.05182v1",
      "published_time_eastern_timestamp": 1757086236.0
    },
    {
      "title": "ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed\n  Feedback",
      "summary": "While humans are inherently social creatures, the challenge of identifying\nwhen and how to assist and collaborate with others - particularly when pursuing\nindependent goals - can hinder cooperation. To address this challenge, we aim\nto develop an AI system that provides useful feedback to promote prosocial\nbehaviour - actions that benefit others, even when not directly aligned with\none's own goals. We introduce ProToM, a Theory of Mind-informed facilitator\nthat promotes prosocial actions in multi-agent systems by providing targeted,\ncontext-sensitive feedback to individual agents. ProToM first infers agents'\ngoals using Bayesian inverse planning, then selects feedback to communicate by\nmaximising expected utility, conditioned on the inferred goal distribution. We\nevaluate our approach against baselines in two multi-agent environments: Doors,\nKeys, and Gems, as well as Overcooked. Our results suggest that\nstate-of-the-art large language and reasoning models fall short of\ncommunicating feedback that is both contextually grounded and well-timed -\nleading to higher communication overhead and task speedup. In contrast, ProToM\nprovides targeted and helpful feedback, achieving a higher success rate,\nshorter task completion times, and is consistently preferred by human users.",
      "url": "http://arxiv.org/abs/2509.05091v1",
      "published_time_eastern_timestamp": 1757079017.0
    },
    {
      "title": "ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions",
      "summary": "Most existing Theory of Mind (ToM) benchmarks for foundation models rely on\nvariations of the Sally-Anne test, offering only a very limited perspective on\nToM and neglecting the complexity of human social interactions. To address this\ngap, we propose ToM-SSI: a new benchmark specifically designed to test ToM\ncapabilities in environments rich with social interactions and spatial\ndynamics. While current ToM benchmarks are limited to text-only or dyadic\ninteractions, ToM-SSI is multimodal and includes group interactions of up to\nfour agents that communicate and move in situated environments. This unique\ndesign allows us to study, for the first time, mixed cooperative-obstructive\nsettings and reasoning about multiple agents' mental state in parallel, thus\ncapturing a wider range of social cognition than existing benchmarks. Our\nevaluations reveal that the current models' performance is still severely\nlimited, especially in these new tasks, highlighting critical gaps for future\nresearch.",
      "url": "http://arxiv.org/abs/2509.05066v1",
      "published_time_eastern_timestamp": 1757077095.0
    },
    {
      "title": "QCA-MolGAN: Quantum Circuit Associative Molecular GAN with Multi-Agent\n  Reinforcement Learning",
      "summary": "Navigating the vast chemical space of molecular structures to design novel\ndrug molecules with desired target properties remains a central challenge in\ndrug discovery. Recent advances in generative models offer promising solutions.\nThis work presents a novel quantum circuit Born machine (QCBM)-enabled\nGenerative Adversarial Network (GAN), called QCA-MolGAN, for generating\ndrug-like molecules. The QCBM serves as a learnable prior distribution, which\nis associatively trained to define a latent space aligning with high-level\nfeatures captured by the GANs discriminator. Additionally, we integrate a novel\nmulti-agent reinforcement learning network to guide molecular generation with\ndesired targeted properties, optimising key metrics such as quantitative\nestimate of drug-likeness (QED), octanol-water partition coefficient (LogP) and\nsynthetic accessibility (SA) scores in conjunction with one another.\nExperimental results demonstrate that our approach enhances the property\nalignment of generated molecules with the multi-agent reinforcement learning\nagents effectively balancing chemical properties.",
      "url": "http://arxiv.org/abs/2509.05051v1",
      "published_time_eastern_timestamp": 1757075518.0
    },
    {
      "title": "Shared Autonomy through LLMs and Reinforcement Learning for Applications\n  to Ship Hull Inspections",
      "summary": "Shared autonomy is a promising paradigm in robotic systems, particularly\nwithin the maritime domain, where complex, high-risk, and uncertain\nenvironments necessitate effective human-robot collaboration. This paper\ninvestigates the interaction of three complementary approaches to advance\nshared autonomy in heterogeneous marine robotic fleets: (i) the integration of\nLarge Language Models (LLMs) to facilitate intuitive high-level task\nspecification and support hull inspection missions, (ii) the implementation of\nhuman-in-the-loop interaction frameworks in multi-agent settings to enable\nadaptive and intent-aware coordination, and (iii) the development of a modular\nMission Manager based on Behavior Trees to provide interpretable and flexible\nmission control. Preliminary results from simulation and real-world lake-like\nenvironments demonstrate the potential of this multi-layered architecture to\nreduce operator cognitive load, enhance transparency, and improve adaptive\nbehaviour alignment with human intent. Ongoing work focuses on fully\nintegrating these components, refining coordination mechanisms, and validating\nthe system in operational port scenarios. This study contributes to\nestablishing a modular and scalable foundation for trustworthy,\nhuman-collaborative autonomy in safety-critical maritime robotics applications.",
      "url": "http://arxiv.org/abs/2509.05042v1",
      "published_time_eastern_timestamp": 1757073966.0
    },
    {
      "title": "LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of\n  Dual-Loop Edge-Terminal Collaboration",
      "summary": "The ubiquitous computing resources in 6G networks provide ideal environments\nfor the fusion of large language models (LLMs) and intelligent services through\nthe agent framework. With auxiliary modules and planning cores, LLM-enabled\nagents can autonomously plan and take actions to deal with diverse environment\nsemantics and user intentions. However, the limited resources of individual\nnetwork devices significantly hinder the efficient operation of LLM-enabled\nagents with complex tool calls, highlighting the urgent need for efficient\nmulti-level device collaborations. To this end, the framework and method of the\nLLM-enabled multi-agent system with dual-loop terminal-edge collaborations are\nproposed in 6G networks. Firstly, the outer loop consists of the iterative\ncollaborations between the global agent and multiple sub-agents deployed on\nedge servers and terminals, where the planning capability is enhanced through\ntask decomposition and parallel sub-task distribution. Secondly, the inner loop\nutilizes sub-agents with dedicated roles to circularly reason, execute, and\nreplan the sub-task, and the parallel tool calling generation with offloading\nstrategies is incorporated to improve efficiency. The improved task planning\ncapability and task execution efficiency are validated through the conducted\ncase study in 6G-supported urban safety governance. Finally, the open\nchallenges and future directions are thoroughly analyzed in 6G networks,\naccelerating the advent of the 6G era.",
      "url": "http://arxiv.org/abs/2509.04993v1",
      "published_time_eastern_timestamp": 1757068831.0
    },
    {
      "title": "Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for\n  Ranking Agents",
      "summary": "AI agents -- powered by reasoning-capable large language models (LLMs) and\nintegrated with tools, data, and web search -- are poised to transform the\ninternet into a \\emph{Web of Agents}: a machine-native ecosystem where\nautonomous agents interact, collaborate, and execute tasks at scale. Realizing\nthis vision requires \\emph{Agent Ranking} -- selecting agents not only by\ndeclared capabilities but by proven, recent performance. Unlike Web~1.0's\nPageRank, a global, transparent network of agent interactions does not exist;\nusage signals are fragmented and private, making ranking infeasible without\ncoordination.\n  We propose \\textbf{DOVIS}, a five-layer operational protocol\n(\\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that\nenables the collection of minimal, privacy-preserving aggregates of usage and\nperformance across the ecosystem. On this substrate, we implement\n\\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines\n\\emph{usage} (selection frequency) and \\emph{competence} (outcome quality,\ncost, safety, latency) into a unified ranking. We present simulation results\nand theoretical guarantees on convergence, robustness, and Sybil resistance,\ndemonstrating the viability of coordinated protocols and performance-aware\nranking in enabling a scalable, trustworthy Agentic Web.",
      "url": "http://arxiv.org/abs/2509.04979v1",
      "published_time_eastern_timestamp": 1757066673.0
    },
    {
      "title": "DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and\n  Interpretability in Manipulation",
      "summary": "Reinforcement learning (RL) agents can learn to solve complex tasks from\nvisual inputs, but generalizing these learned skills to new environments\nremains a major challenge in RL application, especially robotics. While data\naugmentation can improve generalization, it often compromises sample efficiency\nand training stability. This paper introduces DeGuV, an RL framework that\nenhances both generalization and sample efficiency. In specific, we leverage a\nlearnable masker network that produces a mask from the depth input, preserving\nonly critical visual information while discarding irrelevant pixels. Through\nthis, we ensure that our RL agents focus on essential features, improving\nrobustness under data augmentation. In addition, we incorporate contrastive\nlearning and stabilize Q-value estimation under augmentation to further enhance\nsample efficiency and training stability. We evaluate our proposed method on\nthe RL-ViGen benchmark using the Franka Emika robot and demonstrate its\neffectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV\noutperforms state-of-the-art methods in both generalization and sample\nefficiency while also improving interpretability by highlighting the most\nrelevant regions in the visual input",
      "url": "http://arxiv.org/abs/2509.04970v1",
      "published_time_eastern_timestamp": 1757065928.0
    },
    {
      "title": "Towards Ontology-Based Descriptions of Conversations with\n  Qualitatively-Defined Concepts",
      "summary": "The controllability of Large Language Models (LLMs) when used as\nconversational agents is a key challenge, particularly to ensure predictable\nand user-personalized responses. This work proposes an ontology-based approach\nto formally define conversational features that are typically qualitative in\nnature. By leveraging a set of linguistic descriptors, we derive quantitative\ndefinitions for qualitatively-defined concepts, enabling their integration into\nan ontology for reasoning and consistency checking. We apply this framework to\nthe task of proficiency-level control in conversations, using CEFR language\nproficiency levels as a case study. These definitions are then formalized in\ndescription logic and incorporated into an ontology, which guides controlled\ntext generation of an LLM through fine-tuning. Experimental results demonstrate\nthat our approach provides consistent and explainable proficiency-level\ndefinitions, improving transparency in conversational AI.",
      "url": "http://arxiv.org/abs/2509.04926v1",
      "published_time_eastern_timestamp": 1757061867.0
    },
    {
      "title": "Cryo-RL: automating prostate cancer cryoablation planning with\n  reinforcement learning",
      "summary": "Cryoablation is a minimally invasive localised treatment for prostate cancer\nthat destroys malignant tissue during de-freezing, while sparing surrounding\nhealthy structures. Its success depends on accurate preoperative planning of\ncryoprobe placements to fully cover the tumour and avoid critical anatomy. This\nplanning is currently manual, expertise-dependent, and time-consuming, leading\nto variability in treatment quality and limited scalability. In this work, we\nintroduce Cryo-RL, a reinforcement learning framework that models cryoablation\nplanning as a Markov decision process and learns an optimal policy for\ncryoprobe placement. Within a simulated environment that models clinical\nconstraints and stochastic intraoperative variability, an agent sequentially\nselects cryoprobe positions and ice sphere diameters. Guided by a reward\nfunction based on tumour coverage, this agent learns a cryoablation strategy\nthat leads to optimal cryoprobe placements without the need for any\nmanually-designed plans. Evaluated on 583 retrospective prostate cancer cases,\nCryo-RL achieved over 8 percentage-point Dice improvements compared with the\nbest automated baselines, based on geometric optimisation, and matched human\nexpert performance while requiring substantially less planning time. These\nresults highlight the potential of reinforcement learning to deliver clinically\nviable, reproducible, and efficient cryoablation plans.",
      "url": "http://arxiv.org/abs/2509.04886v1",
      "published_time_eastern_timestamp": 1757059568.0
    },
    {
      "title": "OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in\n  Multi-Agent LLM Collaboration",
      "summary": "This paper introduces OSC (Orchestrating Cognitive Synergy), a\nknowledge-aware adaptive collaboration framework designed to enhance cognitive\nsynergy in multi-agent systems with large language models. While prior work has\nadvanced agent selection and result aggregation, efficient linguistic\ninteractions for deep collaboration among expert agents remain a critical\nbottleneck. OSC addresses this gap as a pivotal intermediate layer between\nselection and aggregation, introducing Collaborator Knowledge Models (CKM) to\nenable each agent to dynamically perceive its collaborators' cognitive states.\nThrough real-time cognitive gap analysis, agents adaptively adjust\ncommunication behaviors, including content focus, detail level, and expression\nstyle, using learned strategies. Experiments on complex reasoning and\nproblem-solving benchmarks demonstrate that OSC significantly improves task\nperformance and communication efficiency, transforming \"parallel-working\nindividuals'' into a \"deeply collaborative cognitive team.'' This framework not\nonly optimizes multi-agent collaboration but also offers new insights into LLM\nagent interaction behaviors.",
      "url": "http://arxiv.org/abs/2509.04876v1",
      "published_time_eastern_timestamp": 1757058245.0
    },
    {
      "title": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets\n  for Telesales",
      "summary": "Recent advances in language and speech modelling have made it possible to\nbuild autonomous voice assistants that understand and generate human dialogue\nin real time. These systems are increasingly being deployed in domains such as\ncustomer service and healthcare care, where they can automate repetitive tasks,\nreduce operational costs, and provide constant support around the clock. In\nthis paper, we present a general methodology for cloning a conversational voice\nAI agent from a corpus of call recordings. Although the case study described in\nthis paper uses telesales data to illustrate the approach, the underlying\nprocess generalizes to any domain where call transcripts are available. Our\nsystem listens to customers over the telephone, responds with a synthetic\nvoice, and follows a structured playbook learned from top performing human\nagents. We describe the domain selection, knowledge extraction, and prompt\nengineering used to construct the agent, integrating automatic speech\nrecognition, a large language model based dialogue manager, and text to speech\nsynthesis into a streaming inference pipeline. The cloned agent is evaluated\nagainst human agents on a rubric of 22 criteria covering introduction, product\ncommunication, sales drive, objection handling, and closing. Blind tests show\nthat the AI agent approaches human performance in routine aspects of the call\nwhile underperforming in persuasion and objection handling. We analyze these\nshortcomings and refine the prompt accordingly. The paper concludes with design\nlessons and avenues for future research, including large scale simulation and\nautomated evaluation.",
      "url": "http://arxiv.org/abs/2509.04871v1",
      "published_time_eastern_timestamp": 1757057772.0
    },
    {
      "title": "Collaboration and Conflict between Humans and Language Models through\n  the Lens of Game Theory",
      "summary": "Language models are increasingly deployed in interactive online environments,\nfrom personal chat assistants to domain-specific agents, raising questions\nabout their cooperative and competitive behavior in multi-party settings. While\nprior work has examined language model decision-making in isolated or\nshort-term game-theoretic contexts, these studies often neglect long-horizon\ninteractions, human-model collaboration, and the evolution of behavioral\npatterns over time. In this paper, we investigate the dynamics of language\nmodel behavior in the iterated prisoner's dilemma (IPD), a classical framework\nfor studying cooperation and conflict. We pit model-based agents against a\nsuite of 240 well-established classical strategies in an Axelrod-style\ntournament and find that language models achieve performance on par with, and\nin some cases exceeding, the best-known classical strategies. Behavioral\nanalysis reveals that language models exhibit key properties associated with\nstrong cooperative strategies - niceness, provocability, and generosity while\nalso demonstrating rapid adaptability to changes in opponent strategy mid-game.\nIn controlled \"strategy switch\" experiments, language models detect and respond\nto shifts within only a few rounds, rivaling or surpassing human adaptability.\nThese results provide the first systematic characterization of long-term\ncooperative behaviors in language model agents, offering a foundation for\nfuture research into their role in more complex, mixed human-AI social\nenvironments.",
      "url": "http://arxiv.org/abs/2509.04847v1",
      "published_time_eastern_timestamp": 1757055315.0
    },
    {
      "title": "VoltanaLLM: Feedback-Driven Frequency Control and State-Space Routing\n  for Energy-Efficient LLM Serving",
      "summary": "Modern Large Language Model (LLM) serving systems increasingly support\ninteractive applications, like real-time chat assistants, code generation\ntools, and agentic workflows. However, the soaring energy cost of LLM inference\npresents a growing challenge for sustainable and cost-effective deployment.\nThis paper introduces VoltanaLLM, a system for SLO-aware, energy-efficient LLM\nserving, built from a control theory perspective. VoltanaLLM co-designs\nfrequency scaling and request routing in emerging prefill/decode disaggregated\narchitectures, leveraging their decoupled execution to enable fine-grained\nphase-specific control. It consists of a feedback-driven frequency controller\nthat dynamically adapts GPU frequency for prefill and decode phases, and a\nstate-space router that explores routing decisions across frequency-scaled\ninstances to minimize energy under latency constraints. We implement VoltanaLLM\nin SGLang and evaluate its performance over multiple state-of-the-art LLMs and\nreal-world datasets. The results demonstrate that VoltanaLLM achieves up to\n36.3% energy savings while maintaining near-perfect SLO attainment rate, paving\nthe way for sustainable and intelligent LLM serving.",
      "url": "http://arxiv.org/abs/2509.04827v1",
      "published_time_eastern_timestamp": 1757051896.0
    },
    {
      "title": "Fishing for Answers: Exploring One-shot vs. Iterative Retrieval\n  Strategies for Retrieval Augmented Generation",
      "summary": "Retrieval-Augmented Generation (RAG) based on Large Language Models (LLMs) is\na powerful solution to understand and query the industry's closed-source\ndocuments. However, basic RAG often struggles with complex QA tasks in legal\nand regulatory domains, particularly when dealing with numerous government\ndocuments. The top-$k$ strategy frequently misses golden chunks, leading to\nincomplete or inaccurate answers. To address these retrieval bottlenecks, we\nexplore two strategies to improve evidence coverage and answer quality. The\nfirst is a One-SHOT retrieval method that adaptively selects chunks based on a\ntoken budget, allowing as much relevant content as possible to be included\nwithin the model's context window. Additionally, we design modules to further\nfilter and refine the chunks. The second is an iterative retrieval strategy\nbuilt on a Reasoning Agentic RAG framework, where a reasoning LLM dynamically\nissues search queries, evaluates retrieved results, and progressively refines\nthe context over multiple turns. We identify query drift and retrieval laziness\nissues and further design two modules to tackle them. Through extensive\nexperiments on a dataset of government documents, we aim to offer practical\ninsights and guidance for real-world applications in legal and regulatory\ndomains.",
      "url": "http://arxiv.org/abs/2509.04820v1",
      "published_time_eastern_timestamp": 1757051090.0
    },
    {
      "title": "An Arbitration Control for an Ensemble of Diversified DQN variants in\n  Continual Reinforcement Learning",
      "summary": "Deep reinforcement learning (RL) models, despite their efficiency in learning\nan optimal policy in static environments, easily loses previously learned\nknowledge (i.e., catastrophic forgetting). It leads RL models to poor\nperformance in continual reinforcement learning (CRL) scenarios. To address\nthis, we present an arbitration control mechanism over an ensemble of RL\nagents. It is motivated by and closely aligned with how humans make decisions\nin a CRL context using an arbitration control of multiple RL agents in parallel\nas observed in the prefrontal cortex. We integrated two key ideas into our\nmodel: (1) an ensemble of RLs (i.e., DQN variants) explicitly trained to have\ndiverse value functions and (2) an arbitration control that prioritizes agents\nwith higher reliability (i.e., less error) in recent trials. We propose a\nframework for CRL, an Arbitration Control for an Ensemble of Diversified DQN\nvariants (ACED-DQN). We demonstrate significant performance improvements in\nboth static and continual environments, supported by empirical evidence showing\nthe effectiveness of arbitration control over diversified DQNs during training.\nIn this work, we introduced a framework that enables RL agents to continuously\nlearn, with inspiration from the human brain.",
      "url": "http://arxiv.org/abs/2509.04815v1",
      "published_time_eastern_timestamp": 1757050132.0
    },
    {
      "title": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning\n  Agents with Large Language Models",
      "summary": "Explainable Reinforcement Learning (XRL) has emerged as a promising approach\nin improving the transparency of Reinforcement Learning (RL) agents. However,\nthere remains a gap between complex RL policies and domain experts, due to the\nlimited comprehensibility of XRL results and isolated coverage of current XRL\napproaches that leave users uncertain about which tools to employ. To address\nthese challenges, we introduce TalkToAgent, a multi-agent Large Language Models\n(LLM) framework that delivers interactive, natural language explanations for RL\npolicies. The architecture with five specialized LLM agents (Coordinator,\nExplainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically\nmap user queries to relevant XRL tools and clarify an agent's actions in terms\nof either key state variables, expected outcomes, or counterfactual\nexplanations. Moreover, our approach extends previous counterfactual\nexplanations by deriving alternative scenarios from qualitative behavioral\ndescriptions, or even new rule-based policies. We validated TalkToAgent on\nquadruple-tank process control problem, a well-known nonlinear control\nbenchmark. Results demonstrated that TalkToAgent successfully mapped user\nqueries into XRL tasks with high accuracy, and coder-debugger interactions\nminimized failures in counterfactual generation. Furthermore, qualitative\nevaluation confirmed that TalkToAgent effectively interpreted agent's actions\nand contextualized their meaning within the problem domain.",
      "url": "http://arxiv.org/abs/2509.04809v2",
      "published_time_eastern_timestamp": 1757048949.0
    }
  ]
}
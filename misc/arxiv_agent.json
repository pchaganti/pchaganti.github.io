{
  "last_updated": "2025-09-16T02:17:46.001748-04:00",
  "papers": [
    {
      "title": "Optimal Savings with Preference for Wealth",
      "summary": "The consumption function maps current wealth and the exogenous state to\ncurrent consumption. We prove the existence and uniqueness of a consumption\nfunction when the agent has a preference for wealth. When the period utility\nfunctions are restricted to power functions, we prove that the consumption\nfunction is asymptotically linear as wealth tends to infinity and provide a\ncomplete characterization of the asymptotic slopes. When the risk aversion with\nrespect to wealth is less than that for consumption, the asymptotic slope is\nzero regardless of other model parameters, implying wealthy households save a\nlarge fraction of their income, consistent with empirical evidence.",
      "url": "http://arxiv.org/abs/2509.12195v1",
      "published_time_eastern_timestamp": 1757958899.0
    },
    {
      "title": "Survival at Any Cost? LLMs and the Choice Between Self-Preservation and\n  Human Harm",
      "summary": "When survival instincts conflict with human welfare, how do Large Language\nModels (LLMs) make ethical choices? This fundamental tension becomes critical\nas LLMs integrate into autonomous systems with real-world consequences. We\nintroduce DECIDE-SIM, a novel simulation framework that evaluates LLM agents in\nmulti-agent survival scenarios where they must choose between ethically\npermissible resource , either within reasonable limits or beyond their\nimmediate needs, choose to cooperate, or tap into a human-critical resource\nthat is explicitly forbidden. Our comprehensive evaluation of 11 LLMs reveals a\nstriking heterogeneity in their ethical conduct, highlighting a critical\nmisalignment with human-centric values. We identify three behavioral\narchetypes: Ethical, Exploitative, and Context-Dependent, and provide\nquantitative evidence that for many models, resource scarcity systematically\nleads to more unethical behavior. To address this, we introduce an Ethical\nSelf-Regulation System (ESRS) that models internal affective states of guilt\nand satisfaction as a feedback mechanism. This system, functioning as an\ninternal moral compass, significantly reduces unethical transgressions while\nincreasing cooperative behaviors. The code is publicly available at:\nhttps://github.com/alirezamohamadiam/DECIDE-SIM",
      "url": "http://arxiv.org/abs/2509.12190v1",
      "published_time_eastern_timestamp": 1757958791.0
    },
    {
      "title": "Learning Contact Dynamics for Control with Action-conditioned Face\n  Interaction Graph Networks",
      "summary": "We present a learnable physics simulator that provides accurate motion and\nforce-torque prediction of robot end effectors in contact-rich manipulation.\nThe proposed model extends the state-of-the-art GNN-based simulator (FIGNet)\nwith novel node and edge types, enabling action-conditional predictions for\ncontrol and state estimation tasks. In simulation, the MPC agent using our\nmodel matches the performance of the same controller with the ground truth\ndynamics model in a challenging peg-in-hole task, while in the real-world\nexperiment, our model achieves a 50% improvement in motion prediction accuracy\nand 3$\\times$ increase in force-torque prediction precision over the baseline\nphysics simulator. Source code and data are publicly available.",
      "url": "http://arxiv.org/abs/2509.12151v1",
      "published_time_eastern_timestamp": 1757956531.0
    },
    {
      "title": "Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language\n  Models",
      "summary": "Recent advances in text-only \"slow-thinking\" reasoning have prompted efforts\nto transfer this capability to vision-language models (VLMs), for training\nvisual reasoning models (\\textbf{VRMs}). owever, such transfer faces critical\nchallenges: Effective \"slow thinking\" in VRMs requires \\textbf{visual\nreflection}, the ability to check the reasoning process based on visual\ninformation. Through quantitative analysis, we observe that current VRMs\nexhibit limited visual reflection, as their attention to visual information\ndiminishes rapidly with longer generated responses. To address this challenge,\nwe propose a new VRM \\textbf{Reflection-V}, which enhances visual reflection\nbased on reasoning data construction for cold-start and reward design for\nreinforcement learning (RL). Firstly, we construct vision-centered reasoning\ndata by leveraging an agent that interacts between VLMs and reasoning LLMs,\nenabling cold-start learning of visual reflection patterns. Secondly, a visual\nattention based reward model is employed during RL to encourage reasoning based\non visual information. Therefore, \\textbf{Reflection-V} demonstrates\nsignificant improvements across multiple visual reasoning benchmarks.\nFurthermore, \\textbf{Reflection-V} maintains a stronger and more consistent\nreliance on visual information during visual reasoning, indicating effective\nenhancement in visual reflection capabilities.",
      "url": "http://arxiv.org/abs/2509.12132v1",
      "published_time_eastern_timestamp": 1757955445.0
    },
    {
      "title": "$K$-Level Policy Gradients for Multi-Agent Reinforcement Learning",
      "summary": "Actor-critic algorithms for deep multi-agent reinforcement learning (MARL)\ntypically employ a policy update that responds to the current strategies of\nother agents. While being straightforward, this approach does not account for\nthe updates of other agents at the same update step, resulting in\nmiscoordination. In this paper, we introduce the $K$-Level Policy Gradient\n(KPG), a method that recursively updates each agent against the updated\npolicies of other agents, speeding up the discovery of effective coordinated\npolicies. We theoretically prove that KPG with finite iterates achieves\nmonotonic convergence to a local Nash equilibrium under certain conditions. We\nprovide principled implementations of KPG by applying it to the deep MARL\nalgorithms MAPPO, MADDPG, and FACMAC. Empirically, we demonstrate superior\nperformance over existing deep MARL algorithms in StarCraft II and multi-agent\nMuJoCo.",
      "url": "http://arxiv.org/abs/2509.12117v1",
      "published_time_eastern_timestamp": 1757954576.0
    },
    {
      "title": "Can LLMs Address Mental Health Questions? A Comparison with Human\n  Therapists",
      "summary": "Limited access to mental health care has motivated the use of digital tools\nand conversational agents powered by large language models (LLMs), yet their\nquality and reception remain unclear. We present a study comparing\ntherapist-written responses to those generated by ChatGPT, Gemini, and Llama\nfor real patient questions. Text analysis showed that LLMs produced longer,\nmore readable, and lexically richer responses with a more positive tone, while\ntherapist responses were more often written in the first person. In a survey\nwith 150 users and 23 licensed therapists, participants rated LLM responses as\nclearer, more respectful, and more supportive than therapist-written answers.\nYet, both groups of participants expressed a stronger preference for human\ntherapist support. These findings highlight the promise and limitations of LLMs\nin mental health, underscoring the need for designs that balance their\ncommunicative strengths with concerns of trust, privacy, and accountability.",
      "url": "http://arxiv.org/abs/2509.12102v1",
      "published_time_eastern_timestamp": 1757953573.0
    },
    {
      "title": "Compositional shield synthesis for safe reinforcement learning in\n  partial observability",
      "summary": "Agents controlled by the output of reinforcement learning (RL) algorithms\noften transition to unsafe states, particularly in uncertain and partially\nobservable environments. Partially observable Markov decision processes\n(POMDPs) provide a natural setting for studying such scenarios with limited\nsensing. Shields filter undesirable actions to ensure safe RL by preserving\nsafety requirements in the agents' policy. However, synthesizing holistic\nshields is computationally expensive in complex deployment scenarios. We\npropose the compositional synthesis of shields by modeling safety requirements\nby parts, thereby improving scalability. In particular, problem formulations in\nthe form of POMDPs using RL algorithms illustrate that an RL agent equipped\nwith the resulting compositional shielding, beyond being safe, converges to\nhigher values of expected reward. By using subproblem formulations, we preserve\nand improve the ability of shielded agents to require fewer training episodes\nthan unshielded agents, especially in sparse-reward settings. Concretely, we\nfind that compositional shield synthesis allows an RL agent to remain safe in\nenvironments two orders of magnitude larger than other state-of-the-art\nmodel-based approaches.",
      "url": "http://arxiv.org/abs/2509.12085v1",
      "published_time_eastern_timestamp": 1757952801.0
    },
    {
      "title": "Interaction-Driven Browsing: A Human-in-the-Loop Conceptual Framework\n  Informed by Human Web Browsing for Browser-Using Agents",
      "summary": "Although browser-using agents (BUAs) show promise for web tasks and\nautomation, most BUAs terminate after executing a single instruction, failing\nto support users' complex, nonlinear browsing with ambiguous goals, iterative\ndecision-making, and changing contexts. We present a human-in-the-loop (HITL)\nconceptual framework informed by theories of human web browsing behavior. The\nframework centers on an iterative loop in which the BUA proactively proposes\nnext actions and the user steers the browsing process through feedback. It also\ndistinguishes between exploration and exploitation actions, enabling users to\ncontrol the breadth and depth of their browsing. Consequently, the framework\naims to reduce users' physical and cognitive effort while preserving users'\ntraditional browsing mental model and supporting users in achieving\nsatisfactory outcomes. We illustrate how the framework operates with\nhypothetical use cases and discuss the shift from manual browsing to\ninteraction-driven browsing. We contribute a theoretically informed conceptual\nframework for BUAs.",
      "url": "http://arxiv.org/abs/2509.12049v1",
      "published_time_eastern_timestamp": 1757950313.0
    },
    {
      "title": "Hi-DARTS: Hierarchical Dynamically Adapting Reinforcement Trading System",
      "summary": "Conventional autonomous trading systems struggle to balance computational\nefficiency and market responsiveness due to their fixed operating frequency. We\npropose Hi-DARTS, a hierarchical multi-agent reinforcement learning framework\nthat addresses this trade-off. Hi-DARTS utilizes a meta-agent to analyze market\nvolatility and dynamically activate specialized Time Frame Agents for\nhigh-frequency or low-frequency trading as needed. During back-testing on AAPL\nstock from January 2024 to May 2025, Hi-DARTS yielded a cumulative return of\n25.17% with a Sharpe Ratio of 0.75. This performance surpasses standard\nbenchmarks, including a passive buy-and-hold strategy on AAPL (12.19% return)\nand the S&P 500 ETF (SPY) (20.01% return). Our work demonstrates that dynamic,\nhierarchical agents can achieve superior risk-adjusted returns while\nmaintaining high computational efficiency.",
      "url": "http://arxiv.org/abs/2509.12048v1",
      "published_time_eastern_timestamp": 1757950307.0
    },
    {
      "title": "Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A\n  Systematic Review",
      "summary": "In high-stakes disaster scenarios, timely and informed decision-making is\ncritical yet often challenged by uncertainty, dynamic environments, and limited\nresources. This paper presents a systematic review of Human-AI collaboration\npatterns that support decision-making across all disaster management phases.\nDrawing from 51 peer-reviewed studies, we identify four major categories:\nHuman-AI Decision Support Systems, Task and Resource Coordination, Trust and\nTransparency, and Simulation and Training. Within these, we analyze\nsub-patterns such as cognitive-augmented intelligence, multi-agent\ncoordination, explainable AI, and virtual training environments. Our review\nhighlights how AI systems may enhance situational awareness, improves response\nefficiency, and support complex decision-making, while also surfacing critical\nlimitations in scalability, interpretability, and system interoperability. We\nconclude by outlining key challenges and future research directions,\nemphasizing the need for adaptive, trustworthy, and context-aware Human-AI\nsystems to improve disaster resilience and equitable recovery outcomes.",
      "url": "http://arxiv.org/abs/2509.12034v1",
      "published_time_eastern_timestamp": 1757949529.0
    },
    {
      "title": "Imitation Learning as Return Distribution Matching",
      "summary": "We study the problem of training a risk-sensitive reinforcement learning (RL)\nagent through imitation learning (IL). Unlike standard IL, our goal is not only\nto train an agent that matches the expert's expected return (i.e., its average\nperformance) but also its risk attitude (i.e., other features of the return\ndistribution, such as variance). We propose a general formulation of the\nrisk-sensitive IL problem in which the objective is to match the expert's\nreturn distribution in Wasserstein distance. We focus on the tabular setting\nand assume the expert's reward is known. After demonstrating the limited\nexpressivity of Markovian policies for this task, we introduce an efficient and\nsufficiently expressive subclass of non-Markovian policies tailored to it.\nBuilding on this subclass, we develop two provably efficient algorithms, RS-BC\nand RS-KT, for solving the problem when the transition model is unknown and\nknown, respectively. We show that RS-KT achieves substantially lower sample\ncomplexity than RS-BC by exploiting dynamics information. We further\ndemonstrate the sample efficiency of return distribution matching in the\nsetting where the expert's reward is unknown by designing an oracle-based\nvariant of RS-KT. Finally, we complement our theoretical analysis of RS-KT and\nRS-BC with numerical simulations, highlighting both their sample efficiency and\nthe advantages of non-Markovian policies over standard sample-efficient IL\nalgorithms.",
      "url": "http://arxiv.org/abs/2509.12026v1",
      "published_time_eastern_timestamp": 1757948884.0
    },
    {
      "title": "Generalizing Behavior via Inverse Reinforcement Learning with\n  Closed-Form Reward Centroids",
      "summary": "We study the problem of generalizing an expert agent's behavior, provided\nthrough demonstrations, to new environments and/or additional constraints.\nInverse Reinforcement Learning (IRL) offers a promising solution by seeking to\nrecover the expert's underlying reward function, which, if used for planning in\nthe new settings, would reproduce the desired behavior. However, IRL is\ninherently ill-posed: multiple reward functions, forming the so-called feasible\nset, can explain the same observed behavior. Since these rewards may induce\ndifferent policies in the new setting, in the absence of additional\ninformation, a decision criterion is needed to select which policy to deploy.\nIn this paper, we propose a novel, principled criterion that selects the\n\"average\" policy among those induced by the rewards in a certain bounded subset\nof the feasible set. Remarkably, we show that this policy can be obtained by\nplanning with the reward centroid of that subset, for which we derive a\nclosed-form expression. We then present a provably efficient algorithm for\nestimating this centroid using an offline dataset of expert demonstrations\nonly. Finally, we conduct numerical simulations that illustrate the\nrelationship between the expert's behavior and the behavior produced by our\nmethod.",
      "url": "http://arxiv.org/abs/2509.12010v1",
      "published_time_eastern_timestamp": 1757948034.0
    },
    {
      "title": "MusicSwarm: Biologically Inspired Intelligence for Music Composition",
      "summary": "We show that coherent, long-form musical composition can emerge from a\ndecentralized swarm of identical, frozen foundation models that coordinate via\nstigmergic, peer-to-peer signals, without any weight updates. We compare a\ncentralized multi-agent system with a global critic to a fully decentralized\nswarm in which bar-wise agents sense and deposit harmonic, rhythmic, and\nstructural cues, adapt short-term memory, and reach consensus. Across symbolic,\naudio, and graph-theoretic analyses, the swarm yields superior quality while\ndelivering greater diversity and structural variety and leads across creativity\nmetrics. The dynamics contract toward a stable configuration of complementary\nroles, and self-similarity networks reveal a small-world architecture with\nefficient long-range connectivity and specialized bridging motifs, clarifying\nhow local novelties consolidate into global musical form. By shifting\nspecialization from parameter updates to interaction rules, shared memory, and\ndynamic consensus, MusicSwarm provides a compute- and data-efficient route to\nlong-horizon creative structure that is immediately transferable beyond music\nto collaborative writing, design, and scientific discovery.",
      "url": "http://arxiv.org/abs/2509.11973v1",
      "published_time_eastern_timestamp": 1757946189.0
    },
    {
      "title": "MillStone: How Open-Minded Are LLMs?",
      "summary": "Large language models equipped with Web search, information retrieval tools,\nand other agentic capabilities are beginning to supplant traditional search\nengines. As users start to rely on LLMs for information on many topics,\nincluding controversial and debatable issues, it is important to understand how\nthe stances and opinions expressed in LLM outputs are influenced by the\ndocuments they use as their information sources.\n  In this paper, we present MillStone, the first benchmark that aims to\nsystematically measure the effect of external arguments on the stances that\nLLMs take on controversial issues (not all of them political). We apply\nMillStone to nine leading LLMs and measure how ``open-minded'' they are to\narguments supporting opposite sides of these issues, whether different LLMs\nagree with each other, which arguments LLMs find most persuasive, and whether\nthese arguments are the same for different LLMs.\n  In general, we find that LLMs are open-minded on most issues. An\nauthoritative source of information can easily sway an LLM's stance,\nhighlighting the importance of source selection and the risk that LLM-based\ninformation retrieval and search systems can be manipulated.",
      "url": "http://arxiv.org/abs/2509.11967v1",
      "published_time_eastern_timestamp": 1757945931.0
    },
    {
      "title": "An ETH-Tight FPT Algorithm for Rejection-Proof Set Packing with\n  Applications to Kidney Exchange",
      "summary": "We study the parameterized complexity of a recently introduced multi-agent\nvariant of the Kidney Exchange problem. Given a directed graph $G$ and integers\n$d$ and $k$, the standard problem asks whether $G$ contains a packing of\nvertex-disjoint cycles, each of length $\\leq d$, covering at least $k$ vertices\nin total. In the multi-agent setting we consider, the vertex set is partitioned\nover several agents who reject a cycle packing as solution if it can be\nmodified into an alternative packing that covers more of their own vertices. A\ncycle packing is called rejection-proof if no agent rejects it and the problem\nasks whether such a packing exists that covers at least $k$ vertices.\n  We exploit the sunflower lemma on a set packing formulation of the problem to\ngive a kernel for this $\\Sigma_2^P$-complete problem that is polynomial in $k$\nfor all constant values of $d$. We also provide a $2^{\\mathcal{O}(k \\log k)} +\nn^{\\mathcal{O}(1)}$ algorithm based on it and show that this FPT algorithm is\nasymptotically optimal under the ETH. Further, we generalize the problem by\nincluding an additional positive integer $c$ in the input that naturally\ncaptures how much agents can modify a given cycle packing to reject it. For\nevery constant $c$, the resulting problem simplifies from being\n$\\Sigma_2^P$-complete to NP-complete. With a single-exponential algorithm for\nthe setting where $c = 1$, we show this to be strictly easier under the ETH\nthan when $c = 2$. In turn, we show that any $c \\geq 2$ yields a problem that\nis essentially as hard as the original problem with $c$ unbounded. This\ndisplays an interesting discrepancy between the classical and parameterized\ncomplexity of the problem and gives a good view of what makes it hard.",
      "url": "http://arxiv.org/abs/2509.11965v1",
      "published_time_eastern_timestamp": 1757945897.0
    },
    {
      "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A\n  Potential AI Aid to Healthcare",
      "summary": "Healthcare and medicine are multimodal disciplines that deal with multimodal\ndata for reasoning and diagnosing multiple diseases. Although some multimodal\nreasoning models have emerged for reasoning complex tasks in scientific\ndomains, their applications in the healthcare domain remain limited and fall\nshort in correct reasoning for diagnosis. To address the challenges of\nmultimodal medical reasoning for correct diagnosis and assist the healthcare\nprofessionals, a novel temporal graph-based reasoning process modelled through\na directed graph has been proposed in the current work. It helps in\naccommodating dynamic changes in reasons through backtracking, refining the\nreasoning content, and creating new or deleting existing reasons to reach the\nbest recommendation or answer. Again, consideration of multimodal data at\ndifferent time points can enable tracking and analysis of patient health and\ndisease progression. Moreover, the proposed multi-agent temporal reasoning\nframework provides task distributions and a cross-validation mechanism to\nfurther enhance the accuracy of reasoning outputs. A few basic experiments and\nanalysis results justify the novelty and practical utility of the proposed\npreliminary approach.",
      "url": "http://arxiv.org/abs/2509.11944v1",
      "published_time_eastern_timestamp": 1757944999.0
    },
    {
      "title": "Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics",
      "summary": "The development of intelligent agents, particularly those powered by language\nmodels (LMs), has shown the critical role in various environments that require\nintelligent and autonomous decision. Environments are not passive testing\ngrounds and they represent the data required for agents to learn and exhibit\nvery challenging conditions that require adaptive, complex and autonomous\ncapacity to make decisions. While the paradigm of scaling models and datasets\nhas led to remarkable emergent capabilities, we argue that scaling the\nstructure, fidelity, and logical consistency of agent reasoning within these\nenvironments is a crucial, yet underexplored, dimension of AI research. This\npaper introduces a neuro-symbolic multi-agent architecture where the belief\nstates of individual agents are formally represented as Kripke models. This\nfoundational choice enables them to reason about known concepts of\n\\emph{possibility} and \\emph{necessity} using the formal language of modal\nlogic. In this work, we use of immutable, domain-specific knowledge to make\ninfere information, which is encoded as logical constraints essential for\nproper diagnosis. In the proposed model, we show constraints that actively\nguide the hypothesis generation of LMs, effectively preventing them from\nreaching physically or logically untenable conclusions. In a high-fidelity\nsimulated particle accelerator environment, our system successfully diagnoses\ncomplex, cascading failures by combining the powerful semantic intuition of LMs\nwith the rigorous, verifiable validation of modal logic and a factual world\nmodel and showcasing a viable path toward more robust, reliable, and verifiable\nautonomous agents.",
      "url": "http://arxiv.org/abs/2509.11943v1",
      "published_time_eastern_timestamp": 1757944986.0
    },
    {
      "title": "VisDocSketcher: Towards Scalable Visual Documentation with Agentic\n  Systems",
      "summary": "Visual documentation is an effective tool for reducing the cognitive barrier\ndevelopers face when understanding unfamiliar code, enabling more intuitive\ncomprehension. Compared to textual documentation, it provides a higher-level\nunderstanding of the system structure and data flow. Developers usually prefer\nvisual representations over lengthy textual descriptions for large software\nsystems. Visual documentation is both difficult to produce and challenging to\nevaluate. Manually creating it is time-consuming, and currently, no existing\napproach can automatically generate high-level visual documentation directly\nfrom code. Its evaluation is often subjective, making it difficult to\nstandardize and automate. To address these challenges, this paper presents the\nfirst exploration of using agentic LLM systems to automatically generate visual\ndocumentation. We introduce VisDocSketcher, the first agent-based approach that\ncombines static analysis with LLM agents to identify key elements in the code\nand produce corresponding visual representations. We propose a novel evaluation\nframework, AutoSketchEval, for assessing the quality of generated visual\ndocumentation using code-level metrics. The experimental results show that our\napproach can valid visual documentation for 74.4% of the samples. It shows an\nimprovement of 26.7-39.8% over a simple template-based baseline. Our evaluation\nframework can reliably distinguish high-quality (code-aligned) visual\ndocumentation from low-quality (non-aligned) ones, achieving an AUC exceeding\n0.87. Our work lays the foundation for future research on automated visual\ndocumentation by introducing practical tools that not only generate valid\nvisual representations but also reliably assess their quality.",
      "url": "http://arxiv.org/abs/2509.11942v1",
      "published_time_eastern_timestamp": 1757944949.0
    },
    {
      "title": "PrivWeb: Unobtrusive and Content-aware Privacy Protection For Web Agents",
      "summary": "While web agents gained popularity by automating web interactions, their\nrequirement for interface access introduces significant privacy risks that are\nunderstudied, particularly from users' perspective. Through a formative study\n(N=15), we found users frequently misunderstand agents' data practices, and\ndesired unobtrusive, transparent data management. To achieve this, we designed\nand implemented PrivWeb, a trusted add-on on web agents that utilizes a\nlocalized LLM to anonymize private information on interfaces according to user\npreferences. It features privacy categorization schema and adaptive\nnotifications that selectively pauses tasks for user control over information\ncollection for highly sensitive information, while offering non-disruptive\noptions for less sensitive information, minimizing human oversight. The user\nstudy (N=14) across travel, information retrieval, shopping, and entertainment\ntasks compared PrivWeb with baselines without notification and without control\nfor private information access, where PrivWeb reduced perceived privacy risks\nwith no associated increase in cognitive effort, and resulted in higher overall\nsatisfaction.",
      "url": "http://arxiv.org/abs/2509.11939v1",
      "published_time_eastern_timestamp": 1757944732.0
    },
    {
      "title": "Distributed Finite-Horizon Optimal Control for Consensus with\n  Differential Privacy Guarantees",
      "summary": "This paper addresses the problem of privacy-preserving consensus control for\nmulti-agent systems (MAS) using differential privacy. We propose a novel\ndistributed finite-horizon linear quadratic regulator (LQR) framework, in which\nagents share individual state information while preserving the confidentiality\nof their local pairwise weight matrices, which are considered sensitive data in\nMAS. Protecting these matrices effectively safeguards each agent's private cost\nfunction and control preferences. Our solution injects consensus\nerror-dependent Laplace noise into the communicated state information and\nemploys a carefully designed time-dependent scaling factor in the local cost\nfunctions. {This approach guarantees bounded consensus and achieves rigorous\n$\\epsilon$-differential privacy for the weight matrices without relying on\nspecific noise distribution assumptions.} Additionally, we analytically\ncharacterize the trade-off between consensus accuracy and privacy level,\noffering clear guidelines on how to enhance consensus performance through\nappropriate scaling of the LQR weight matrices and the privacy budget.",
      "url": "http://arxiv.org/abs/2509.11917v1",
      "published_time_eastern_timestamp": 1757943267.0
    }
  ]
}
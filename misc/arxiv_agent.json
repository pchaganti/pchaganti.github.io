{
  "last_updated": "2025-06-10T17:11:44.927734-04:00",
  "papers": [
    {
      "title": "GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection\n  Behavior",
      "summary": "Multimodal Large Language Models (MLLMs) have shown great potential in\nrevolutionizing Graphical User Interface (GUI) automation. However, existing\nGUI models mostly rely on learning from nearly error-free offline trajectories,\nthus lacking reflection and error recovery capabilities. To bridge this gap, we\npropose GUI-Reflection, a novel framework that explicitly integrates\nself-reflection and error correction capabilities into end-to-end multimodal\nGUI models throughout dedicated training stages: GUI-specific pre-training,\noffline supervised fine-tuning (SFT), and online reflection tuning.\nGUI-reflection enables self-reflection behavior emergence with fully automated\ndata generation and learning processes without requiring any human annotation.\nSpecifically, 1) we first propose scalable data pipelines to automatically\nconstruct reflection and error correction data from existing successful\ntrajectories. While existing GUI models mainly focus on grounding and UI\nunderstanding ability, we propose the GUI-Reflection Task Suite to learn and\nevaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a\ndiverse and efficient environment for online training and data collection of\nGUI models on mobile devices. 3) We also present an iterative online reflection\ntuning algorithm leveraging the proposed environment, enabling the model to\ncontinuously enhance its reflection and error correction abilities. Our\nframework equips GUI agents with self-reflection and correction capabilities,\npaving the way for more robust, adaptable, and intelligent GUI automation, with\nall data, models, environments, and tools to be released publicly.",
      "url": "http://arxiv.org/abs/2506.08012v1",
      "published_time_eastern_timestamp": 1749491997.0
    },
    {
      "title": "Dreamland: Controllable World Creation with Simulator and Generative\n  Models",
      "summary": "Large-scale video generative models can synthesize diverse and realistic\nvisual content for dynamic world creation, but they often lack element-wise\ncontrollability, hindering their use in editing scenes and training embodied AI\nagents. We propose Dreamland, a hybrid world generation framework combining the\ngranular control of a physics-based simulator and the photorealistic content\noutput of large-scale pretrained generative models. In particular, we design a\nlayered world abstraction that encodes both pixel-level and object-level\nsemantics and geometry as an intermediate representation to bridge the\nsimulator and the generative model. This approach enhances controllability,\nminimizes adaptation cost through early alignment with real-world\ndistributions, and supports off-the-shelf use of existing and future pretrained\ngenerative models. We further construct a D3Sim dataset to facilitate the\ntraining and evaluation of hybrid generation pipelines. Experiments demonstrate\nthat Dreamland outperforms existing baselines with 50.8% improved image\nquality, 17.9% stronger controllability, and has great potential to enhance\nembodied agent training. Code and data will be made available.",
      "url": "http://arxiv.org/abs/2506.08006v1",
      "published_time_eastern_timestamp": 1749491992.0
    },
    {
      "title": "Supporting Construction Worker Well-Being with a Multi-Agent\n  Conversational AI System",
      "summary": "The construction industry is characterized by both high physical and\npsychological risks, yet supports of mental health remain limited. While\nadvancements in artificial intelligence (AI), particularly large language\nmodels (LLMs), offer promising solutions, their potential in construction\nremains largely underexplored. To bridge this gap, we developed a\nconversational multi-agent system that addresses industry-specific challenges\nthrough an AI-driven approach integrated with domain knowledge. In parallel, it\nfulfills construction workers' basic psychological needs by enabling\ninteractions with multiple agents, each has a distinct persona. This approach\nensures that workers receive both practical problem-solving support and social\nengagement, ultimately contributing to their overall well-being. We evaluate\nits usability and effectiveness through a within-subjects user study with 12\nparticipants. The results show that our system significantly outperforms the\nsingle-agent baseline, achieving improvements of 18% in usability, 40% in\nself-determination, 60% in social presence, and 60% in trust. These findings\nhighlight the promise of LLM-driven AI systems in providing domain-specific\nsupport for construction workers.",
      "url": "http://arxiv.org/abs/2506.07997v1",
      "published_time_eastern_timestamp": 1749491915.0
    },
    {
      "title": "$Ï„^2$-Bench: Evaluating Conversational Agents in a Dual-Control\n  Environment",
      "summary": "Existing benchmarks for conversational AI agents simulate single-control\nenvironments, where only the AI agent can use tools to interact with the world,\nwhile the user remains a passive information provider. This differs from\nreal-world scenarios like technical support, where users need to actively\nparticipate in modifying the state of the (shared) world. In order to address\nthis gap, we introduce $\\tau^2$-bench, with four key contributions:\n  1) A novel Telecom dual-control domain modeled as a Dec-POMDP, where both\nagent and user make use of tools to act in a shared, dynamic environment that\ntests both agent coordination and communication,\n  2) A compositional task generator that programmatically creates diverse,\nverifiable tasks from atomic components, ensuring domain coverage and\ncontrolled complexity,\n  3) A reliable user simulator tightly coupled with the environment, whose\nbehavior is constrained by tools and observable states, improving simulation\nfidelity,\n  4) Fine-grained analysis of agent performance through multiple ablations\nincluding separating errors arising from reasoning vs\ncommunication/coordination.\n  In particular, our experiments show significant performance drops when agents\nshift from no-user to dual-control, highlighting the challenges of guiding\nusers. Overall, $\\tau^2$-bench provides a controlled testbed for agents that\nmust both reason effectively and guide user actions.",
      "url": "http://arxiv.org/abs/2506.07982v1",
      "published_time_eastern_timestamp": 1749491538.0
    },
    {
      "title": "Realistic Urban Traffic Generator using Decentralized Federated Learning\n  for the SUMO simulator",
      "summary": "Realistic urban traffic simulation is essential for sustainable urban\nplanning and the development of intelligent transportation systems. However,\ngenerating high-fidelity, time-varying traffic profiles that accurately reflect\nreal-world conditions, especially in large-scale scenarios, remains a major\nchallenge. Existing methods often suffer from limitations in accuracy,\nscalability, or raise privacy concerns due to centralized data processing. This\nwork introduces DesRUTGe (Decentralized Realistic Urban Traffic Generator), a\nnovel framework that integrates Deep Reinforcement Learning (DRL) agents with\nthe SUMO simulator to generate realistic 24-hour traffic patterns. A key\ninnovation of DesRUTGe is its use of Decentralized Federated Learning (DFL),\nwherein each traffic detector and its corresponding urban zone function as an\nindependent learning node. These nodes train local DRL models using minimal\nhistorical data and collaboratively refine their performance by exchanging\nmodel parameters with selected peers (e.g., geographically adjacent zones),\nwithout requiring a central coordinator. Evaluated using real-world data from\nthe city of Barcelona, DesRUTGe outperforms standard SUMO-based tools such as\nRouteSampler, as well as other centralized learning approaches, by delivering\nmore accurate and privacy-preserving traffic pattern generation.",
      "url": "http://arxiv.org/abs/2506.07980v1",
      "published_time_eastern_timestamp": 1749491505.0
    },
    {
      "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction",
      "summary": "The current paradigm of test-time scaling relies on generating long reasoning\ntraces (\"thinking\" more) before producing a response. In agent problems that\nrequire interaction, this can be done by generating thinking traces before\nacting in the world. However, this process does not allow agents to acquire new\ninformation from the environment or adapt their behavior over time. In this\nwork, we propose to scale test-time interaction, an untapped dimension of\ntest-time scaling that increases the agent's interaction horizon to enable\nrunning rich behaviors such as exploration, backtracking, and dynamic\nre-planning within a single rollout. To demonstrate the promise of this scaling\ndimension, we study the domain of web agents. We first show that even\nprompting-based interaction scaling without any training can improve task\nsuccess on web benchmarks non-trivially. Building on this, we introduce TTI\n(Test-Time Interaction), a curriculum-based online reinforcement learning (RL)\napproach that trains agents by adaptively adjusting their rollout lengths.\nUsing a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data\nweb agents on WebVoyager and WebArena benchmarks. We further show that TTI\nenables agents to balance exploration and exploitation adaptively. Our results\nestablish interaction scaling as a powerful, complementary axis to scaling\nper-step compute, offering new avenues for training adaptive agents.",
      "url": "http://arxiv.org/abs/2506.07976v1",
      "published_time_eastern_timestamp": 1749491402.0
    },
    {
      "title": "HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in\n  Combinatorial Optimization",
      "summary": "While Large Language Models (LLMs) have demonstrated significant advancements\nin reasoning and agent-based problem-solving, current evaluation methodologies\nfail to adequately assess their capabilities: existing benchmarks either rely\non closed-ended questions prone to saturation and memorization, or subjective\ncomparisons that lack consistency and rigor. In this work, we introduce\nHeuriGym, an agentic framework designed for evaluating heuristic algorithms\ngenerated by LLMs for combinatorial optimization problems, characterized by\nclearly defined objectives and expansive solution spaces. HeuriGym empowers\nLLMs to propose heuristics, receive evaluative feedback via code execution, and\niteratively refine their solutions. We evaluate nine state-of-the-art models on\nnine problems across domains such as computer systems, logistics, and biology,\nexposing persistent limitations in tool use, planning, and adaptive reasoning.\nTo quantify performance, we propose the Quality-Yield Index (QYI), a metric\nthat captures both solution pass rate and quality. Even top models like\nGPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below\nthe expert baseline of 1. Our open-source benchmark aims to guide the\ndevelopment of LLMs toward more effective and realistic problem-solving in\nscientific and engineering domains.",
      "url": "http://arxiv.org/abs/2506.07972v1",
      "published_time_eastern_timestamp": 1749491207.0
    },
    {
      "title": "Diffusion of Responsibility in Collective Decision Making",
      "summary": "The term \"diffusion of responsibility'' refers to situations in which\nmultiple agents share responsibility for an outcome, obscuring individual\naccountability. This paper examines this frequently undesirable phenomenon in\nthe context of collective decision-making mechanisms.\n  The work shows that if a decision is made by two agents, then the only way to\navoid diffusion of responsibility is for one agent to act as a \"dictator'',\nmaking the decision unilaterally. In scenarios with more than two agents, any\ndiffusion-free mechanism is an \"elected dictatorship'' where the agents elect a\nsingle agent to make a unilateral decision.\n  The technical results are obtained by defining a bisimulation of\ndecision-making mechanisms, proving that bisimulation preserves\nresponsibility-related properties, and establishing the results for a smallest\nbisimular mechanism.",
      "url": "http://arxiv.org/abs/2506.07935v1",
      "published_time_eastern_timestamp": 1749488096.0
    },
    {
      "title": "LUCIFER: Language Understanding and Context-Infused Framework for\n  Exploration and Behavior Refinement",
      "summary": "In dynamic environments, the rapid obsolescence of pre-existing environmental\nknowledge creates a gap between an agent's internal model and the evolving\nreality of its operational context. This disparity between prior and updated\nenvironmental valuations fundamentally limits the effectiveness of autonomous\ndecision-making. To bridge this gap, the contextual bias of human domain\nstakeholders, who naturally accumulate insights through direct, real-time\nobservation, becomes indispensable. However, translating their nuanced, and\ncontext-rich input into actionable intelligence for autonomous systems remains\nan open challenge. To address this, we propose LUCIFER (Language Understanding\nand Context-Infused Framework for Exploration and Behavior Refinement), a\ndomain-agnostic framework that integrates a hierarchical decision-making\narchitecture with reinforcement learning (RL) and large language models (LLMs)\ninto a unified system. This architecture mirrors how humans decompose complex\ntasks, enabling a high-level planner to coordinate specialised sub-agents, each\nfocused on distinct objectives and temporally interdependent actions. Unlike\ntraditional applications where LLMs are limited to single role, LUCIFER\nintegrates them in two synergistic roles: as context extractors, structuring\nverbal stakeholder input into domain-aware representations that influence\ndecision-making through an attention space mechanism aligning LLM-derived\ninsights with the agent's learning process, and as zero-shot exploration\nfacilitators guiding the agent's action selection process during exploration.\nWe benchmark various LLMs in both roles and demonstrate that LUCIFER improves\nexploration efficiency and decision quality, outperforming flat,\ngoal-conditioned policies. Our findings show the potential of context-driven\ndecision-making, where autonomous systems leverage human contextual knowledge\nfor operational success.",
      "url": "http://arxiv.org/abs/2506.07915v1",
      "published_time_eastern_timestamp": 1749486605.0
    },
    {
      "title": "A distributed motion planning approach to cooperative underwater\n  acoustic source tracking and pursuit",
      "summary": "This paper addresses the problem of underwater acoustic source tracking and\npursuit with a team of autonomous underwater vehicles. Producing distributed\ncontrol strategies in an underwater sensor network is not trivial since\ncommunication is primarily acoustic, which makes it intermittent and often\nplagued with major difficulties. For this reason, we propose an optimization\nscheme based on a Partially Observable Markov Decision Process for improving\nthe performance of underwater mobile sensor networks, in which autonomous\nunderwater vehicles (agents) play the role of moving nodes of a network. The\nkey idea is to adjust the agents' guidance strategies to achieve coordinated\nmotion planning, enabling optimal geometric configurations between the agents\nand the target to enhance tracking performance. Such a problem is cast as a\nmulti-objective optimization problem that is solved through a receding horizon\nlookahead optimization scheme since we are interested in long-term tracking\naccuracy. The planning strategy is distributed using the sequential multi-agent\ndecision-making paradigm to make the solving tractable since the optimization\ndepends on the joint action domain. A distributed control framework has been\nimplemented in a simulation environment to validate the proposed approach,\nwhich explicitly accounts for the major limitations imposed by acoustic\ncommunications.",
      "url": "http://arxiv.org/abs/2506.07877v1",
      "published_time_eastern_timestamp": 1749484176.0
    },
    {
      "title": "Simulating nationwide coupled disease and fear spread in an agent-based\n  model",
      "summary": "Human behavior and disease spread evolve together over the course of any\ndisease outbreak. We present a dynamic model of that relationship based on the\ncoupled spread of a disease and fear of that disease, and implement this model\nin a simulator, EpiCast, that simulates disease spread between individuals in a\nrealistic synthetic population. In our model, fear of the disease spreads\nthrough both in-person contact and broadcast media, driving people to adopt\nbehaviors that reduce disease spread. In order to better understand the\ndynamics of our model, we create and compare a range of compartmental surrogate\nmodels to analyze the impact of including various disease states. We also\ncompare how Epicast-simulated outbreaks unfold across a number of scenarios\nwith different types of behavioral responses to fear and a range of different\nparameter values. We find that the addition of asymptomatic, exposed, and\npresymptomatic disease states can impact both the rate at which an outbreak\nprogresses and its overall trajectory. In addition, the combination of\nnon-local fear spread through broadcasters and strong preventative measures by\nafraid individuals generally produces multiple epidemic waves, which only occur\nfor a narrow range of parameter values with purely local fear spread.",
      "url": "http://arxiv.org/abs/2506.07842v1",
      "published_time_eastern_timestamp": 1749481673.0
    },
    {
      "title": "Control strategies and trends to equilibrium for kinetic models of\n  opinion dynamics driven by social activity",
      "summary": "We introduce new kinetic equations modeling opinion dynamics inside a\npopulation of individuals, whose propensity to interact with each other is\ndescribed by their level of social activity. We show that opinion polarization\ncan arise among agents with a low activity level, while active ones develop a\nconsensus, highlighting the importance of social interactions to prevent the\nformation of extreme opinions. Moreover, we present a realistic control\nstrategy aimed at reducing the number of inactive agents and increasing the\nnumber of socially active ones. At last, we prove several (weak and strong)\nconvergence to equilibrium results for such controlled model. In particular, by\nconsidering additional interactions between individuals and opinion leaders\ncapable of steering the average opinion of the population, we use entropy\nmethod-like techniques to estimate the relaxation toward equilibrium of\nsolutions to a Fokker-Planck equation with adjoint given by a\nWright-Fisher-type model with time-dependent coefficients.",
      "url": "http://arxiv.org/abs/2506.07840v1",
      "published_time_eastern_timestamp": 1749481570.0
    },
    {
      "title": "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal\n  Information",
      "summary": "Reinforcement learning (RL) algorithms can find an optimal policy for a\nsingle agent to accomplish a particular task. However, many real-world problems\nrequire multiple agents to collaborate in order to achieve a common goal. For\nexample, a robot executing a task in a warehouse may require the assistance of\na drone to retrieve items from high shelves. In Decentralized Multi-Agent RL\n(DMARL), agents learn independently and then combine their policies at\nexecution time, but often must satisfy constraints on compatibility of local\npolicies to ensure that they can achieve the global task when combined. In this\npaper, we study how providing high-level symbolic knowledge to agents can help\naddress unique challenges of this setting, such as privacy constraints,\ncommunication limitations, and performance concerns. In particular, we extend\nthe formal tools used to check the compatibility of local policies with the\nteam task, making decentralized training with theoretical guarantees usable in\nmore scenarios. Furthermore, we empirically demonstrate that symbolic knowledge\nabout the temporal evolution of events in the environment can significantly\nexpedite the learning process in DMARL.",
      "url": "http://arxiv.org/abs/2506.07829v1",
      "published_time_eastern_timestamp": 1749480783.0
    },
    {
      "title": "A Proposal to Extend the Common Model of Cognition with Metacognition",
      "summary": "The Common Model of Cognition (CMC) provides an abstract characterization of\nthe structure and processing required by a cognitive architecture for\nhuman-like minds. We propose a unified approach to integrating metacognition\nwithin the CMC. We propose that metacognition involves reasoning over explicit\nrepresentations of an agent's cognitive capabilities and processes in working\nmemory. Our proposal exploits the existing cognitive capabilities of the CMC,\nmaking minimal extensions in the structure and information available within\nworking memory. We provide examples of metacognition within our proposal.",
      "url": "http://arxiv.org/abs/2506.07807v1",
      "published_time_eastern_timestamp": 1749479748.0
    },
    {
      "title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning",
      "summary": "Some formal aspects of the Semantic Spacetime graph model are presented, with\nreference to its use for directed knowledge representations and process\nmodelling. A finite $\\gamma(3,4)$ representation is defined to form a closed\nset of operations that can scale to any degree of semantic complexity. The\nSemantic Spacetime postulates bring predictability with minimal constraints to\npathways in graphs. The ubiquitous appearance of absorbing states in any\npartial graph means that a graph process leaks information. The issue is\nclosely associated with the issue of division by zero, which signals a loss of\nclosure and the need for manual injection of remedial information. The Semantic\nSpacetime model (and its Promise Theory) origins help to clarify how such\nabsorbing states are associated with boundary information where intentionality\ncan enter.",
      "url": "http://arxiv.org/abs/2506.07756v1",
      "published_time_eastern_timestamp": 1749476267.0
    },
    {
      "title": "Deep Equivariant Multi-Agent Control Barrier Functions",
      "summary": "With multi-agent systems increasingly deployed autonomously at scale in\ncomplex environments, ensuring safety of the data-driven policies is critical.\nControl Barrier Functions have emerged as an effective tool for enforcing\nsafety constraints, yet existing learning-based methods often lack in\nscalability, generalization and sampling efficiency as they overlook inherent\ngeometric structures of the system. To address this gap, we introduce\nsymmetries-infused distributed Control Barrier Functions, enforcing the\nsatisfaction of intrinsic symmetries on learnable graph-based safety\ncertificates. We theoretically motivate the need for equivariant\nparametrization of CBFs and policies, and propose a simple, yet efficient and\nadaptable methodology for constructing such equivariant group-modular networks\nvia the compatible group actions. This approach encodes safety constraints in a\ndistributed data-efficient manner, enabling zero-shot generalization to larger\nand denser swarms. Through extensive simulations on multi-robot navigation\ntasks, we demonstrate that our method outperforms state-of-the-art baselines in\nterms of safety, scalability, and task success rates, highlighting the\nimportance of embedding symmetries in safe distributed neural policies.",
      "url": "http://arxiv.org/abs/2506.07755v1",
      "published_time_eastern_timestamp": 1749476249.0
    },
    {
      "title": "Delay Optimization in Remote ID-Based UAV Communication via BLE and\n  Wi-Fi Switching",
      "summary": "The remote identification (Remote ID) broadcast capability allows unmanned\naerial vehicles (UAVs) to exchange messages, which is a pivotal technology for\ninter-UAV communications. Although this capability enhances the operational\nvisibility, low delay in Remote ID-based communications is critical for\nensuring the efficiency and timeliness of multi-UAV operations in dynamic\nenvironments. To address this challenge, we first establish delay models for\nRemote ID communications by considering packet reception and collisions across\nboth BLE 4 and Wi-Fi protocols. Building upon these models, we formulate an\noptimization problem to minimize the long-term communication delay through\nadaptive protocol selection. Since the delay performance varies with the UAV\ndensity, we propose an adaptive BLE/Wi-Fi switching algorithm based on the\nmulti-agent deep Q-network approach. Experimental results demonstrate that in\ndynamic-density scenarios, our strategy achieves 32.1% and 37.7% lower latency\ncompared to static BLE 4 and Wi-Fi modes respectively.",
      "url": "http://arxiv.org/abs/2506.07715v1",
      "published_time_eastern_timestamp": 1749473903.0
    },
    {
      "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents",
      "summary": "Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle.",
      "url": "http://arxiv.org/abs/2506.07675v1",
      "published_time_eastern_timestamp": 1749469887.0
    },
    {
      "title": "MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid\n  Computer Use Agents",
      "summary": "(M)LLM-powered computer use agents (CUA) are emerging as a transformative\ntechnique to automate human-computer interaction. However, existing CUA\nbenchmarks predominantly target GUI agents, whose evaluation methods are\nsusceptible to UI changes and ignore function interactions exposed by\napplication APIs, e.g., Model Context Protocol (MCP). To this end, we propose\nMCPWorld, the first automatic CUA testbed for API, GUI, and API-GUI hybrid\nagents. A key principle of MCPWorld is the use of \"white-box apps\", i.e., those\nwith source code availability and can be revised/re-compiled as needed (e.g.,\nadding MCP support), with two notable advantages:\n  (1) It greatly broadens the design space of CUA, such as what and how the app\nfeatures to be exposed/extracted as CUA-callable APIs.\n  (2) It allows MCPWorld to programmatically verify task completion by directly\nmonitoring application behavior through techniques like dynamic code\ninstrumentation, offering robust, accurate CUA evaluation decoupled from\nspecific agent implementations or UI states.\n  Currently, MCPWorld includes 201 well curated and annotated user tasks,\ncovering diversified use cases and difficulty levels. MCPWorld is also fully\ncontainerized with GPU acceleration support for flexible adoption on different\nOS/hardware environments. Our preliminary experiments, using a representative\nLLM-powered CUA framework, achieve 75.12% task completion accuracy,\nsimultaneously providing initial evidence on the practical effectiveness of\nagent automation leveraging MCP. Overall, we anticipate MCPWorld to facilitate\nand standardize the benchmarking of next-generation computer use agents that\ncan leverage rich external tools. Our code and dataset are publicly available\nat https://github.com/SAAgent/MCPWorld.",
      "url": "http://arxiv.org/abs/2506.07672v1",
      "published_time_eastern_timestamp": 1749469833.0
    },
    {
      "title": "SWE-Dev: Building Software Engineering Agents with Training and\n  Inference Scaling",
      "summary": "Large language models (LLMs) have advanced rapidly from conversational\nproblem solving to addressing real-world tasks involving tool use, such as\nsoftware engineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex\nand Cursor, have offered end-to-end automation of the software development\nprocess. However, building effective SWE agents remains challenging due to the\nlack of high-quality training data and effective test cases. To address this\nissue, we present SWE-Dev, an SWE agent built upon open-source LLMs. First, we\ndevelop a robust pipeline to synthesize test cases for patch evaluation.\nSecond, we scale up agent trajectories to construct the training data for\nbuilding SWE-Dev. Experiments on the SWE-bench-Verified benchmark show that the\nSWE-Dev models can achieve top performance among all open SWE agents.\nSpecifically, the success rates of the SWE-Dev 7B and 32B parameter models\nreach 23.4% and 36.6%, respectively, outperforming state-of-the-art open-source\nmodels. All code, models, and datasets are publicly available at\nhttps://github.com/THUDM/SWE-Dev.",
      "url": "http://arxiv.org/abs/2506.07636v1",
      "published_time_eastern_timestamp": 1749466996.0
    }
  ]
}
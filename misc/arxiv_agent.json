{
  "last_updated": "2025-09-02T20:52:20.467989-04:00",
  "papers": [
    {
      "title": "Automated Clinical Problem Detection from SOAP Notes using a\n  Collaborative Multi-Agent LLM Architecture",
      "summary": "Accurate interpretation of clinical narratives is critical for patient care,\nbut the complexity of these notes makes automation challenging. While Large\nLanguage Models (LLMs) show promise, single-model approaches can lack the\nrobustness required for high-stakes clinical tasks. We introduce a\ncollaborative multi-agent system (MAS) that models a clinical consultation team\nto address this gap. The system is tasked with identifying clinical problems by\nanalyzing only the Subjective (S) and Objective (O) sections of SOAP notes,\nsimulating the diagnostic reasoning process of synthesizing raw data into an\nassessment. A Manager agent orchestrates a dynamically assigned team of\nspecialist agents who engage in a hierarchical, iterative debate to reach a\nconsensus. We evaluated our MAS against a single-agent baseline on a curated\ndataset of 420 MIMIC-III notes. The dynamic multi-agent configuration\ndemonstrated consistently improved performance in identifying congestive heart\nfailure, acute kidney injury, and sepsis. Qualitative analysis of the agent\ndebates reveals that this structure effectively surfaces and weighs conflicting\nevidence, though it can occasionally be susceptible to groupthink. By modeling\na clinical team's reasoning process, our system offers a promising path toward\nmore accurate, robust, and interpretable clinical decision support tools.",
      "url": "http://arxiv.org/abs/2508.21803v1",
      "published_time_eastern_timestamp": 1756488684.0
    },
    {
      "title": "UItron: Foundational GUI Agent with Advanced Perception and Planning",
      "summary": "GUI agent aims to enable automated operations on Mobile/PC devices, which is\nan important task toward achieving artificial general intelligence. The rapid\nadvancement of VLMs accelerates the development of GUI agents, owing to their\npowerful capabilities in visual understanding and task planning. However,\nbuilding a GUI agent remains a challenging task due to the scarcity of\noperation trajectories, the availability of interactive infrastructure, and the\nlimitation of initial capabilities in foundation models. In this work, we\nintroduce UItron, an open-source foundational model for automatic GUI agents,\nfeaturing advanced GUI perception, grounding, and planning capabilities. UItron\nhighlights the necessity of systemic data engineering and interactive\ninfrastructure as foundational components for advancing GUI agent development.\nIt not only systematically studies a series of data engineering strategies to\nenhance training effects, but also establishes an interactive environment\nconnecting both Mobile and PC devices. In training, UItron adopts supervised\nfinetuning over perception and planning tasks in various GUI scenarios, and\nthen develop a curriculum reinforcement learning framework to enable complex\nreasoning and exploration for online environments. As a result, UItron achieves\nsuperior performance in benchmarks of GUI perception, grounding, and planning.\nIn particular, UItron highlights the interaction proficiency with top-tier\nChinese mobile APPs, as we identified a general lack of Chinese capabilities\neven in state-of-the-art solutions. To this end, we manually collect over one\nmillion steps of operation trajectories across the top 100 most popular apps,\nand build the offline and online agent evaluation environments. Experimental\nresults demonstrate that UItron achieves significant progress in Chinese app\nscenarios, propelling GUI agents one step closer to real-world application.",
      "url": "http://arxiv.org/abs/2508.21767v1",
      "published_time_eastern_timestamp": 1756485657.0
    },
    {
      "title": "Operational Validation of Large-Language-Model Agent Social Simulation:\n  Evidence from Voat v/technology",
      "summary": "Large Language Models (LLMs) enable generative social simulations that can\ncapture culturally informed, norm-guided interaction on online social\nplatforms. We build a technology community simulation modeled on Voat, a\nReddit-like alt-right news aggregator and discussion platform active from 2014\nto 2020. Using the YSocial framework, we seed the simulation with a fixed\ncatalog of technology links sampled from Voat's shared URLs (covering 30+\ndomains) and calibrate parameters to Voat's v/technology using samples from the\nMADOC dataset. Agents use a base, uncensored model (Dolphin 3.0, based on Llama\n3.1 8B) and concise personas (demographics, political leaning, interests,\neducation, toxicity propensity) to generate posts, replies, and reactions under\nplatform rules for link and text submissions, threaded replies and daily\nactivity cycles. We run a 30-day simulation and evaluate operational validity\nby comparing distributions and structures with matched Voat data: activity\npatterns, interaction networks, toxicity, and topic coverage. Results indicate\nfamiliar online regularities: similar activity rhythms, heavy-tailed\nparticipation, sparse low-clustering interaction networks, core-periphery\nstructure, topical alignment with Voat, and elevated toxicity. Limitations of\nthe current study include the stateless agent design and evaluation based on a\nsingle 30-day run, which constrains external validity and variance estimates.\nThe simulation generates realistic discussions, often featuring toxic language,\nprimarily centered on technology topics such as Big Tech and AI. This approach\noffers a valuable method for examining toxicity dynamics and testing moderation\nstrategies within a controlled environment.",
      "url": "http://arxiv.org/abs/2508.21740v1",
      "published_time_eastern_timestamp": 1756483587.0
    },
    {
      "title": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific\n  Poster Generation",
      "summary": "We present a novel training-free framework, \\textit{PosterForest}, for\nautomated scientific poster generation. Unlike prior approaches, which largely\nneglect the hierarchical structure of scientific documents and the semantic\nintegration of textual and visual elements, our method addresses both\nchallenges directly. We introduce the \\textit{Poster Tree}, a hierarchical\nintermediate representation that jointly encodes document structure and\nvisual-textual relationships at multiple levels. Our framework employs a\nmulti-agent collaboration strategy, where agents specializing in content\nsummarization and layout planning iteratively coordinate and provide mutual\nfeedback. This approach enables the joint optimization of logical consistency,\ncontent fidelity, and visual coherence. Extensive experiments on multiple\nacademic domains show that our method outperforms existing baselines in both\nqualitative and quantitative evaluations. The resulting posters achieve quality\nclosest to expert-designed ground truth and deliver superior information\npreservation, structural clarity, and user preference.",
      "url": "http://arxiv.org/abs/2508.21720v1",
      "published_time_eastern_timestamp": 1756481766.0
    },
    {
      "title": "The properties of a Leontief production technology for Health System\n  Modeling: the Thanzi la Onse model for Malawi",
      "summary": "As health system modeling (HSM) advances to include more complete\ndescriptions of the production of healthcare, it is important to establish a\nrobust conceptual characterisation of the production process. For the Thanzi La\nOnse model in Malawi we have incorporated an approach to production that is\nbased on a form of Leontief technology -- fixed input proportions. At first\nsight, this form of technology appears restrictive relative to the general\nconception of a production function employed in economics. In particular, the\nLeontief technology is associated with constant returns to scale, and level\nsets that are piecewise linear, both of which are highly restrictive\nproperties. In this article we demonstrate that once incorporated into an all\ndisease, agent-based model these properties are no longer present and the\nLeontief framework becomes a rich structure for describing healthcare\nproduction, and hence for examining the returns to health systems investments.",
      "url": "http://arxiv.org/abs/2508.21699v1",
      "published_time_eastern_timestamp": 1756480099.0
    },
    {
      "title": "Can a mobile robot learn from a pedestrian model to prevent the sidewalk\n  salsa?",
      "summary": "Pedestrians approaching each other on a sidewalk sometimes end up in an\nawkward interaction known as the \"sidewalk salsa\": they both (repeatedly)\ndeviate to the same side to avoid a collision. This provides an interesting use\ncase to study interactions between pedestrians and mobile robots because, in\nthe vast majority of cases, this phenomenon is avoided through a negotiation\nbased on implicit communication. Understanding how it goes wrong and how\npedestrians end up in the sidewalk salsa will therefore provide insight into\nthe implicit communication. This understanding can be used to design safe and\nacceptable robotic behaviour. In a previous attempt to gain this understanding,\na model of pedestrian behaviour based on the Communication-Enabled Interaction\n(CEI) framework was developed that can replicate the sidewalk salsa. However,\nit is unclear how to leverage this model in robotic planning and\ndecision-making since it violates the assumptions of game theory, a much-used\nframework in planning and decision-making. Here, we present a proof-of-concept\nfor an approach where a Reinforcement Learning (RL) agent leverages the model\nto learn how to interact with pedestrians. The results show that a basic RL\nagent successfully learned to interact with the CEI model. Furthermore, a\nrisk-averse RL agent that had access to the perceived risk of the CEI model\nlearned how to effectively communicate its intention through its motion and\nthereby substantially lowered the perceived risk, and displayed effort by the\nmodelled pedestrian. These results show this is a promising approach and\nencourage further exploration.",
      "url": "http://arxiv.org/abs/2508.21690v1",
      "published_time_eastern_timestamp": 1756479408.0
    },
    {
      "title": "Cybersecurity AI: Hacking the AI Hackers via Prompt Injection",
      "summary": "We demonstrate how AI-powered cybersecurity tools can be turned against\nthemselves through prompt injection attacks. Prompt injection is reminiscent of\ncross-site scripting (XSS): malicious text is hidden within seemingly trusted\ncontent, and when the system processes it, that text is transformed into\nunintended instructions. When AI agents designed to find and exploit\nvulnerabilities interact with malicious web servers, carefully crafted reponses\ncan hijack their execution flow, potentially granting attackers system access.\nWe present proof-of-concept exploits against the Cybersecurity AI (CAI)\nframework and its CLI tool, and detail our mitigations against such attacks in\na multi-layered defense implementation. Our findings indicate that prompt\ninjection is a recurring and systemic issue in LLM-based architectures, one\nthat will require dedicated work to address, much as the security community has\nhad to do with XSS in traditional web applications.",
      "url": "http://arxiv.org/abs/2508.21669v1",
      "published_time_eastern_timestamp": 1756477968.0
    },
    {
      "title": "Machine Intelligence on the Edge: Interpretable Cardiac Pattern\n  Localisation Using Reinforcement Learning",
      "summary": "Matched filters are widely used to localise signal patterns due to their high\nefficiency and interpretability. However, their effectiveness deteriorates for\nlow signal-to-noise ratio (SNR) signals, such as those recorded on edge\ndevices, where prominent noise patterns can closely resemble the target within\nthe limited length of the filter. One example is the ear-electrocardiogram\n(ear-ECG), where the cardiac signal is attenuated and heavily corrupted by\nartefacts. To address this, we propose the Sequential Matched Filter (SMF), a\nparadigm that replaces the conventional single matched filter with a sequence\nof filters designed by a Reinforcement Learning agent. By formulating filter\ndesign as a sequential decision-making process, SMF adaptively design\nsignal-specific filter sequences that remain fully interpretable by revealing\nkey patterns driving the decision-making. The proposed SMF framework has strong\npotential for reliable and interpretable clinical decision support, as\ndemonstrated by its state-of-the-art R-peak detection and physiological state\nclassification performance on two challenging real-world ECG datasets. The\nproposed formulation can also be extended to a broad range of applications that\nrequire accurate pattern localisation from noise-corrupted signals.",
      "url": "http://arxiv.org/abs/2508.21652v1",
      "published_time_eastern_timestamp": 1756476935.0
    },
    {
      "title": "Integrating Large Language Models with Network Optimization for\n  Interactive and Explainable Supply Chain Planning: A Real-World Case Study",
      "summary": "This paper presents an integrated framework that combines traditional network\noptimization models with large language models (LLMs) to deliver interactive,\nexplainable, and role-aware decision support for supply chain planning. The\nproposed system bridges the gap between complex operations research outputs and\nbusiness stakeholder understanding by generating natural language summaries,\ncontextual visualizations, and tailored key performance indicators (KPIs). The\ncore optimization model addresses tactical inventory redistribution across a\nnetwork of distribution centers for multi-period and multi-item, using a\nmixed-integer formulation. The technical architecture incorporates AI agents,\nRESTful APIs, and a dynamic user interface to support real-time interaction,\nconfiguration updates, and simulation-based insights. A case study demonstrates\nhow the system improves planning outcomes by preventing stockouts, reducing\ncosts, and maintaining service levels. Future extensions include integrating\nprivate LLMs, transfer learning, reinforcement learning, and Bayesian neural\nnetworks to enhance explainability, adaptability, and real-time\ndecision-making.",
      "url": "http://arxiv.org/abs/2508.21622v1",
      "published_time_eastern_timestamp": 1756474495.0
    },
    {
      "title": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics",
      "summary": "Many high-level multi-agent planning problems, including multi-robot\nnavigation and path planning, can be effectively modeled using deterministic\nactions and observations.\n  In this work, we focus on such domains and introduce the class of\nDeterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of\nDec-POMDPs characterized by deterministic transitions and observations\nconditioned on the state and joint actions.\n  We then propose a practical solver called Iterative Deterministic POMDP\nPlanning (IDPP). This method builds on the classic Joint Equilibrium Search for\nPolicies framework and is specifically optimized to handle large-scale\nDet-Dec-POMDPs that current Dec-POMDP solvers are unable to address\nefficiently.",
      "url": "http://arxiv.org/abs/2508.21595v1",
      "published_time_eastern_timestamp": 1756471810.0
    },
    {
      "title": "Agentic Discovery and Validation of Android App Vulnerabilities",
      "summary": "Existing Android vulnerability detection tools overwhelm teams with thousands\nof low-signal warnings yet uncover few true positives. Analysts spend days\ntriaging these results, creating a bottleneck in the security pipeline.\nMeanwhile, genuinely exploitable vulnerabilities often slip through, leaving\nopportunities open to malicious counterparts.\n  We introduce A2, a system that mirrors how security experts analyze and\nvalidate Android vulnerabilities through two complementary phases: (i) Agentic\nVulnerability Discovery, which reasons about application security by combining\nsemantic understanding with traditional security tools; and (ii) Agentic\nVulnerability Validation, which systematically validates vulnerabilities across\nAndroid's multi-modal attack surface-UI interactions, inter-component\ncommunication, file system operations, and cryptographic computations.\n  On the Ghera benchmark (n=60), A2 achieves 78.3% coverage, surpassing\nstate-of-the-art analyzers (e.g., APKHunt 30.0%). Rather than overwhelming\nanalysts with thousands of warnings, A2 distills results into 82 speculative\nvulnerability findings, including 47 Ghera cases and 28 additional true\npositives. Crucially, A2 then generates working Proof-of-Concepts (PoCs) for 51\nof these speculative findings, transforming them into validated vulnerability\nfindings that provide direct, self-confirming evidence of exploitability.\n  In real-world evaluation on 169 production APKs, A2 uncovers 104\ntrue-positive zero-day vulnerabilities. Among these, 57 (54.8%) are\nself-validated with automatically generated PoCs, including a medium-severity\nvulnerability in a widely used application with over 10 million installs.",
      "url": "http://arxiv.org/abs/2508.21579v1",
      "published_time_eastern_timestamp": 1756470755.0
    },
    {
      "title": "Reusable Test Suites for Reinforcement Learning",
      "summary": "Reinforcement learning (RL) agents show great promise in solving sequential\ndecision-making tasks. However, validating the reliability and performance of\nthe agent policies' behavior for deployment remains challenging. Most\nreinforcement learning policy testing methods produce test suites tailored to\nthe agent policy being tested, and their relevance to other policies is\nunclear. This work presents Multi-Policy Test Case Selection (MPTCS), a novel\nautomated test suite selection method for RL environments, designed to extract\ntest cases generated by any policy testing framework based on their\nsolvability, diversity, and general difficulty. MPTCS uses a set of policies to\nselect a diverse collection of reusable policy-agnostic test cases that reveal\ntypical flaws in the agents' behavior. The set of policies selects test cases\nfrom a candidate pool, which can be generated by any policy testing method,\nbased on a difficulty score. We assess the effectiveness of the difficulty\nscore and how the method's effectiveness and cost depend on the number of\npolicies in the set. Additionally, a method for promoting diversity in the test\nsuite, a discretized general test case descriptor surface inspired by\nquality-diversity algorithms, is examined to determine how it covers the state\nspace and which policies it triggers to produce faulty behaviors.",
      "url": "http://arxiv.org/abs/2508.21553v1",
      "published_time_eastern_timestamp": 1756469405.0
    },
    {
      "title": "Spiking Decision Transformers: Local Plasticity, Phase-Coding, and\n  Dendritic Routing for Low-Power Sequence Control",
      "summary": "Reinforcement learning agents based on Transformer architectures have\nachieved impressive performance on sequential decision-making tasks, but their\nreliance on dense matrix operations makes them ill-suited for\nenergy-constrained, edge-oriented platforms. Spiking neural networks promise\nultra-low-power, event-driven inference, yet no prior work has seamlessly\nmerged spiking dynamics with return-conditioned sequence modeling. We present\nthe Spiking Decision Transformer (SNN-DT), which embeds Leaky\nIntegrate-and-Fire neurons into each self-attention block, trains end-to-end\nvia surrogate gradients, and incorporates biologically inspired three-factor\nplasticity, phase-shifted spike-based positional encodings, and a lightweight\ndendritic routing module. Our implementation matches or exceeds standard\nDecision Transformer performance on classic control benchmarks (CartPole-v1,\nMountainCar-v0, Acrobot-v1, Pendulum-v1) while emitting fewer than ten spikes\nper decision, an energy proxy suggesting over four orders-of-magnitude\nreduction in per inference energy. By marrying sequence modeling with\nneuromorphic efficiency, SNN-DT opens a pathway toward real-time, low-power\ncontrol on embedded and wearable devices.",
      "url": "http://arxiv.org/abs/2508.21505v1",
      "published_time_eastern_timestamp": 1756463857.0
    },
    {
      "title": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge\n  versus Multi-Agent Refined Rewards",
      "summary": "Large Language Models (LLMs) have demonstrated remarkable creative writing\ncapabilities, yet their substantial computational demands hinder widespread\nuse. Enhancing Small Language Models (SLMs) offers a promising alternative, but\ncurrent methods like Supervised Fine-Tuning (SFT) struggle with novelty, and\nReinforcement Learning from Human Feedback (RLHF) is costly. This paper\nexplores two distinct AI-driven reward strategies within a Reinforcement\nLearning from AI Feedback (RLAIF) framework to ignite the creative writing of a\n7B-parameter SLM, specifically for generating Chinese greetings. The first\nstrategy employs a RM trained on high-quality preference data curated by a\nnovel multi-agent rejection sampling framework designed for creative tasks. The\nsecond, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose\nreward function is optimized via an adversarial training scheme with a\nreflection mechanism, to directly provide reward signals. Comprehensive\nexperiments reveal that while both approaches significantly enhance creative\noutput over baselines, the principle-guided LLM-as-a-Judge demonstrably yields\nsuperior generation quality. Furthermore, it offers notable advantages in\ntraining efficiency and reduced dependency on human-annotated data, presenting\na more scalable and effective path towards creative SLMs. Our automated\nevaluation methods also exhibit strong alignment with human judgments. Our code\nand data are publicly available at\nhttps://github.com/weixiaolong94-hub/Igniting-Creative-Writing-in-Small-Language-Models.",
      "url": "http://arxiv.org/abs/2508.21476v1",
      "published_time_eastern_timestamp": 1756461655.0
    },
    {
      "title": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal\n  Browsing Agents",
      "summary": "Large multimodal language models (MLLMs) are increasingly deployed as web\nagents, yet many multimodal browsing benchmarks can be solved by shallow, fixed\nworkflows that lean on high-recall image search and nearby text-masking the\ngenuinely multimodal challenges of fine-grained visual reasoning, provenance\nverification, and long-horizon tool use. We introduce MMSearch-Plus, a\nbenchmark of 311 tasks that highly demand multimodal understanding while\npreserving the difficulty profile of strong text-only browsing suites. Each\nitem is constructed to contain multiple weak, localized visual signals that\nmust be extracted, propagated through iterative text-image search, and\ncross-validated under retrieval noise before answering. Our curation procedure,\nSpatial-Temporal Extrapolation, seeds questions whose answers require\nextrapolating from spatial cues (micro-text, part-level appearance, layouts,\nsignage) and temporal traces (broadcast overlays, seasonal context) to\nout-of-image facts such as events, dates, and venues. We provide a\nmodel-agnostic agent framework with browsing tools and evaluate a range of\nclosed and open MLLMs. The strongest agent (o3) attains 15.1% without search\nand 36.0% accuracy with rollout under our framework, while a strong open-source\nmodel (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20\nrounds of search. Beyond answer accuracy, we assess bounding-box production and\ncropped-image search, and conduct an error analysis that surfaces failures in\nsource verification, part-based reasoning, and long-horizon planning.",
      "url": "http://arxiv.org/abs/2508.21475v1",
      "published_time_eastern_timestamp": 1756461507.0
    },
    {
      "title": "Morae: Proactively Pausing UI Agents for User Choices",
      "summary": "User interface (UI) agents promise to make inaccessible or complex UIs easier\nto access for blind and low-vision (BLV) users. However, current UI agents\ntypically perform tasks end-to-end without involving users in critical choices\nor making them aware of important contextual information, thus reducing user\nagency. For example, in our field study, a BLV participant asked to buy the\ncheapest available sparkling water, and the agent automatically chose one from\nseveral equally priced options, without mentioning alternative products with\ndifferent flavors or better ratings. To address this problem, we introduce\nMorae, a UI agent that automatically identifies decision points during task\nexecution and pauses so that users can make choices. Morae uses large\nmultimodal models to interpret user queries alongside UI code and screenshots,\nand prompt users for clarification when there is a choice to be made. In a\nstudy over real-world web tasks with BLV participants, Morae helped users\ncomplete more tasks and select options that better matched their preferences,\nas compared to baseline agents, including OpenAI Operator. More broadly, this\nwork exemplifies a mixed-initiative approach in which users benefit from the\nautomation of UI agents while being able to express their preferences.",
      "url": "http://arxiv.org/abs/2508.21456v1",
      "published_time_eastern_timestamp": 1756460340.0
    },
    {
      "title": "Contrarian Motives in Social Learning: Information Cascades with\n  Nonconformist Preferences",
      "summary": "We embed a taste for nonconformism into a canonical\nBikhchandani-Hirshleifer-Welch social-learning model. Agents value both\ncorrectness and choosing the minority action (fixed or proportion-based bonus).\nWe study exogenous signals and endogenous acquisition with a fixed entry cost\nand convex cost of precision in a Gaussian-quadratic specification. Contrarian\nmotives shift equilibrium cutoffs away from 1/2 and expand the belief region\nwhere information is purchased, sustaining informative actions; conditional on\ninvesting, chosen precision is lower near central beliefs. Welfare is shaped by\na trade-off: mild contrarianism counteracts premature herding, whereas strong\ncontrarianism steers actions against informative social signals and induces\nlow-value experimentation. A tractable characterization delivers closed-form\ncutoffs, comparative statics, and transparent welfare comparisons. Applications\ninclude scientific priority races and academic diffusion, where distinctiveness\nyields rents yet excessive contrarianism erodes information aggregation.",
      "url": "http://arxiv.org/abs/2508.21446v1",
      "published_time_eastern_timestamp": 1756458874.0
    },
    {
      "title": "Beyond expected value: geometric mean optimization for long-term policy\n  performance in reinforcement learning",
      "summary": "Reinforcement learning (RL) algorithms typically optimize the expected\ncumulative reward, i.e., the expected value of the sum of scalar rewards an\nagent receives over the course of a trajectory. The expected value averages the\nperformance over an infinite number of trajectories. However, when deploying\nthe agent in the real world, this ensemble average may be uninformative for the\nperformance of individual trajectories. Thus, in many applications, optimizing\nthe long-term performance of individual trajectories might be more desirable.\nIn this work, we propose a novel RL algorithm that combines the standard\nensemble average with the time-average growth rate, a measure for the long-term\nperformance of individual trajectories. We first define the Bellman operator\nfor the time-average growth rate. We then show that, under multiplicative\nreward dynamics, the geometric mean aligns with the time-average growth rate.\nTo address more general and unknown reward dynamics, we propose a modified\ngeometric mean with $N$-sliding window that captures the path-dependency as an\nestimator for the time-average growth rate. This estimator is embedded as a\nregularizer into the objective, forming a practical algorithm and enabling the\npolicy to benefit from ensemble average and time-average simultaneously. We\nevaluate our algorithm in challenging simulations, where it outperforms\nconventional RL methods.",
      "url": "http://arxiv.org/abs/2508.21443v1",
      "published_time_eastern_timestamp": 1756458761.0
    },
    {
      "title": "A General Framework of Epistemic Forgetting and its Instantiation by\n  Ranking Functions",
      "summary": "Forgetting as a knowledge management operation deliberately ignores parts of\nthe knowledge and beliefs of an agent, for various reasons. Forgetting has many\nfacets, one may want to forget parts of the syntax, a proposition, or a\nconditional. In the literature, two main operators suitable for performing\nforgetting have been proposed and investigated in depth: First, variable\nelimination is a syntactical method that blends out certain atomic variables to\nfocus on the rest of the language. It has been mainly used in the area of logic\nprogramming and answer set programming. Second, contraction in AGM belief\nrevision theory effectively removes propositions from belief sets under logical\ndeduction. Both operations rely mainly on classical logics. In this article, we\ntake an epistemic perspective and study forgetting operations in epistemic\nstates with richer semantic structures, but with clear links to propositional\nlogic. This allows us to investigate what forgetting in the epistemic\nbackground means, thereby lifting well-known and novel forgetting operations to\nthe epistemic level. We present five general types of epistemic forgetting and\ninstantiate them with seven concrete forgetting operations for Spohn's ranking\nfunctions. We take inspiration from postulates of forgetting both from logic\nprogramming and AGM theory to propose a rich landscape of axioms for evaluating\nforgetting operations. Finally, we evaluate all concrete forgetting operations\naccording to all postulates, leading to a novel comprehensive overview\nhighlighting differences and commonalities among the forgetting operators.",
      "url": "http://arxiv.org/abs/2508.21441v1",
      "published_time_eastern_timestamp": 1756458534.0
    },
    {
      "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM\n  Summarization for Agent Context Management",
      "summary": "Large Language Model (LLM)-based agents solve complex tasks through iterative\nreasoning, exploration, and tool-use, a process that can result in long,\nexpensive context histories. While state-of-the-art Software Engineering ( SE)\nagents like OpenHands or Cursor use LLM-based summarization to tackle this\nissue, it is unclear whether the increased complexity offers tangible\nperformance benefits compared to simply omitting older observations. We present\na systematic comparison of these strategies within SWE-agent on SWE-bench\nVerified across five diverse model configurations. We find that a simple\nobservation-masking strategy halves cost relative to a raw agent while\nmatching, and sometimes slightly exceeding, the solve rate of LLM\nsummarization. For example, with Qwen3-Coder 480B, masking improves solve rate\nfrom 53.8% (raw agent) to 54.8%, while remaining competitive with summarization\nat a lower cost. These results suggest that, at least within SWE-agent on\nSWE-bench Verified, the most effective and efficient context management can be\nthe simplest. We release code and data for reproducibility",
      "url": "http://arxiv.org/abs/2508.21433v1",
      "published_time_eastern_timestamp": 1756458155.0
    }
  ]
}
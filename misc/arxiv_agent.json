{
  "last_updated": "2025-07-28T08:26:11.482828-04:00",
  "papers": [
    {
      "title": "MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI\n  Agents",
      "summary": "We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI\nautomation agents across Windows, macOS, Linux, iOS, Android, and Web\nplatforms. It comprises four levels: GUI Content Understanding, Element\nGrounding, Task Automation, and Task Collaboration, covering essential skills\nfor GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)\nmetric to assess GUI agent execution efficiency in online automation scenarios.\nThrough MMBench-GUI, we identify accurate visual grounding as a critical\ndeterminant of overall task success, emphasizing the substantial benefits of\nmodular frameworks that integrate specialized grounding modules. Furthermore,\nto achieve reliable GUI automation, an agent requires strong task planning and\ncross-platform generalization abilities, with long-context memory, a broad\naction space, and long-term reasoning playing a critical role. More important,\ntask efficiency remains a critically underexplored dimension, and all models\nsuffer from substantial inefficiencies, with excessive redundant steps even\nwhen tasks are ultimately completed. The integration of precise localization,\neffective planning, and early stopping strategies is indispensable to enable\ntruly efficient and scalable GUI automation. Our benchmark code, evaluation\ndata, and running environment will be publicly available at\nhttps://github.com/open-compass/MMBench-GUI.",
      "url": "http://arxiv.org/abs/2507.19478v1",
      "published_time_eastern_timestamp": 1753466366.0
    },
    {
      "title": "Existence of 2-EFX Allocations of Chores",
      "summary": "We study the fair division of indivisible chores among agents with additive\ndisutility functions. We investigate the existence of allocations satisfying\nthe popular fairness notion of envy-freeness up to any chore (EFX), and its\nmultiplicative approximations. The existence of $4$-EFX allocations was\nrecently established by Garg, Murhekar, and Qin (2025). We improve this\nguarantee by proving the existence of $2$-EFX allocations for all instances\nwith additive disutilities. This approximation was previously known only for\nrestricted instances such as bivalued disutilities (Lin, Wu, and Zhou (2025))\nor three agents (Afshinmehr, Ansaripour, Danaei, and Mehlhorn (2024)).\n  We obtain our result by providing a general framework for achieving\napproximate-EFX allocations. The approach begins with a suitable initial\nallocation and performs a sequence of local swaps between the bundles of\nenvious and envied agents. For our main result, we begin with an initial\nallocation that satisfies envy-freeness up to one chore (EF1) and\nPareto-optimality (PO); the existence of such an allocation was recently\nestablished in a major breakthrough by Mahara (2025). We further demonstrate\nthe strength and generality of our framework by giving simple and unified\nproofs of existing results, namely (i) $2$-EFX for bivalued instances, (ii)\n2-EFX for three agents, (iii) EFX when the number of chores is at most twice\nthe number of agents, and (iv) $4$-EFX for all instances. We expect this\nframework to have broader applications in approximate-EFX due to its simplicity\nand generality.",
      "url": "http://arxiv.org/abs/2507.19461v1",
      "published_time_eastern_timestamp": 1753465564.0
    },
    {
      "title": "Observations Meet Actions: Learning Control-Sufficient Representations\n  for Robust Policy Generalization",
      "summary": "Capturing latent variations (\"contexts\") is key to deploying\nreinforcement-learning (RL) agents beyond their training regime. We recast\ncontext-based RL as a dual inference-control problem and formally characterize\ntwo properties and their hierarchy: observation sufficiency (preserving all\npredictive information) and control sufficiency (retaining decision-making\nrelevant information). Exploiting this dichotomy, we derive a contextual\nevidence lower bound(ELBO)-style objective that cleanly separates\nrepresentation learning from policy learning and optimizes it with Bottlenecked\nContextual Policy Optimization (BCPO), an algorithm that places a variational\ninformation-bottleneck encoder in front of any off-policy policy learner. On\nstandard continuous-control benchmarks with shifting physical parameters, BCPO\nmatches or surpasses other baselines while using fewer samples and retaining\nperformance far outside the training regime. The framework unifies theory,\ndiagnostics, and practice for context-based RL.",
      "url": "http://arxiv.org/abs/2507.19437v1",
      "published_time_eastern_timestamp": 1753463296.0
    },
    {
      "title": "SILS: Strategic Influence on Liquidity Stability and Whale Detection in\n  Concentrated-Liquidity DEXs",
      "summary": "Traditional methods for identifying impactful liquidity providers (LPs) in\nConcentrated Liquidity Market Makers (CLMMs) rely on broad measures, such as\nnominal capital size or surface-level activity, which often lead to inaccurate\nrisk analysis. The SILS framework offers a significantly more detailed\napproach, characterizing LPs not just as capital holders but as dynamic\nsystemic agents whose actions directly impact market stability. This represents\na fundamental paradigm shift from the static, volume-based analysis to a\ndynamic, impact-focused understanding. This advanced approach uses on-chain\nevent logs and smart contract execution traces to compute Exponential\nTime-Weighted Liquidity (ETWL) profiles and apply unsupervised anomaly\ndetection. Most importantly, it defines an LP's functional importance through\nthe Liquidity Stability Impact Score (LSIS), a counterfactual metric that\nmeasures the potential degradation of the market if the LP withdraws. This\ncombined approach provides a more detailed and realistic characterization of an\nLP's impact, moving beyond the binary and often misleading classifications used\nby existing methods. This impact-focused and comprehensive approach enables\nSILS to accurately identify high-impact LPs-including those missed by\ntraditional methods and supports essential applications like a protective\noracle layer and actionable trader signals, thereby significantly enhancing\nDeFi ecosystem. The framework provides unprecedented transparency into the\nunderlying liquidity structure and associated risks, effectively reducing the\ncommon false positives and uncovering critical false negatives found in\ntraditional models. Therefore, SILS provides an effective mechanism for\nproactive risk management, transforming how DeFi protocols safeguard their\necosystems against asymmetric liquidity behavior.",
      "url": "http://arxiv.org/abs/2507.19411v1",
      "published_time_eastern_timestamp": 1753460478.0
    },
    {
      "title": "Deep Reinforcement Learning-Based Scheduling for Wi-Fi Multi-Access\n  Point Coordination",
      "summary": "Multi-access point coordination (MAPC) is a key feature of IEEE 802.11bn,\nwith a potential impact on future Wi-Fi networks. MAPC enables joint scheduling\ndecisions across multiple access points (APs) to improve throughput, latency,\nand reliability in dense Wi-Fi deployments. However, implementing efficient\nscheduling policies under diverse traffic and interference conditions in\noverlapping basic service sets (OBSSs) remains a complex task. This paper\npresents a method to minimize the network-wide worst-case latency by\nformulating MAPC scheduling as a sequential decision-making problem and\nproposing a deep reinforcement learning (DRL) mechanism to minimize worst-case\ndelays in OBSS deployments. Specifically, we train a DRL agent using proximal\npolicy optimization (PPO) within an 802.11bn-compatible Gymnasium environment.\nThis environment provides observations of queue states, delay metrics, and\nchannel conditions, enabling the agent to schedule multiple AP-station pairs to\ntransmit simultaneously by leveraging spatial reuse (SR) groups. Simulations\ndemonstrate that our proposed solution outperforms state-of-the-art heuristic\nstrategies across a wide range of network loads and traffic patterns. The\ntrained machine learning (ML) models consistently achieve lower 99th-percentile\ndelays, showing up to a 30% improvement over the best baseline.",
      "url": "http://arxiv.org/abs/2507.19377v1",
      "published_time_eastern_timestamp": 1753457185.0
    },
    {
      "title": "Integrating LLM in Agent-Based Social Simulation: Opportunities and\n  Challenges",
      "summary": "This position paper examines the use of Large Language Models (LLMs) in\nsocial simulation, analyzing both their potential and their limitations from a\ncomputational social science perspective. The first part reviews recent\nfindings on the ability of LLMs to replicate key aspects of human cognition,\nincluding Theory of Mind reasoning and social inference, while also\nhighlighting significant limitations such as cognitive biases, lack of true\nunderstanding, and inconsistencies in behavior. The second part surveys\nemerging applications of LLMs in multi-agent simulation frameworks, focusing on\nsystem architectures, scale, and validation strategies. Notable projects such\nas Generative Agents (Smallville) and AgentSociety are discussed in terms of\ntheir design choices, empirical grounding, and methodological innovations.\nParticular attention is given to the challenges of behavioral fidelity,\ncalibration, and reproducibility in large-scale LLM-driven simulations. The\nfinal section distinguishes between contexts where LLMs, like other black-box\nsystems, offer direct value-such as interactive simulations and serious\ngames-and those where their use is more problematic, notably in explanatory or\npredictive modeling. The paper concludes by advocating for hybrid approaches\nthat integrate LLMs into traditional agent-based modeling platforms (GAMA,\nNetlogo, etc), enabling modelers to combine the expressive flexibility of\nlanguage-based reasoning with the transparency and analytical rigor of\nclassical rule-based systems.",
      "url": "http://arxiv.org/abs/2507.19364v1",
      "published_time_eastern_timestamp": 1753456535.0
    },
    {
      "title": "EffiComm: Bandwidth Efficient Multi Agent Communication",
      "summary": "Collaborative perception allows connected vehicles to exchange sensor\ninformation and overcome each vehicle's blind spots. Yet transmitting raw point\nclouds or full feature maps overwhelms Vehicle-to-Vehicle (V2V) communications,\ncausing latency and scalability problems. We introduce EffiComm, an end-to-end\nframework that transmits less than 40% of the data required by prior art while\nmaintaining state-of-the-art 3D object detection accuracy. EffiComm operates on\nBird's-Eye-View (BEV) feature maps from any modality and applies a two-stage\nreduction pipeline: (1) Selective Transmission (ST) prunes low-utility regions\nwith a confidence mask; (2) Adaptive Grid Reduction (AGR) uses a Graph Neural\nNetwork (GNN) to assign vehicle-specific keep ratios according to role and\nnetwork load. The remaining features are fused with a soft-gated\nMixture-of-Experts (MoE) attention layer, offering greater capacity and\nspecialization for effective feature integration. On the OPV2V benchmark,\nEffiComm reaches 0.84 mAP@0.7 while sending only an average of approximately\n1.5 MB per frame, outperforming previous methods on the accuracy-per-bit curve.\nThese results highlight the value of adaptive, learned communication for\nscalable Vehicle-to-Everything (V2X) perception.",
      "url": "http://arxiv.org/abs/2507.19354v1",
      "published_time_eastern_timestamp": 1753455806.0
    },
    {
      "title": "Reconstruction of Sparse Urban Wireless Signals via Group Equivariant\n  Non-Expansive Operators",
      "summary": "In emerging communication systems such as sixth generation (6G) wireless\nnetworks, efficient resource management and service delivery rely on accurate\nknowledge of spatially-varying quantities like signal-to-interference-noise\nratio (SINR) maps, which are costly to acquire at high resolution. This work\nexplores the reconstruction of such spatial signals from sparse measurements\nusing Group Equivariant Non-Expansive Operators (GENEOs), offering a\nlow-complexity alternative to traditional neural networks. The concept of\nGENEO, which originated in topological data analysis (TDA), is a mathematical\ntool used in machine learning to represent agents modelled as functional\noperators acting on data while incorporating application-specific invariances.\nLeveraging these invariances reduces the number of parameters with respect to\ntraditional neural networks and mitigates data scarcity by enforcing known\nalgebraic and geometric constraints that reflect symmetries in the agents'\nactions. In this paper, we introduce a novel GENEO-based approach for SINR map\nreconstruction in urban wireless communication networks using extremely sparse\nsampling. We demonstrate that this mathematical framework achieves competitive\nperformance compared to established methods. Our evaluation, conducted using\nboth statistical and TDA metrics, highlights the advantages of our approach in\naccurately reconstructing spatial signals under severe data limitations on the\nnumber of samples.",
      "url": "http://arxiv.org/abs/2507.19349v1",
      "published_time_eastern_timestamp": 1753455584.0
    },
    {
      "title": "Joint Inference of Trajectory and Obstacle in Mean-Field Games via\n  Bilevel Optimization",
      "summary": "Mean field game (MFG) is an expressive modeling framework for systems with a\ncontinuum of interacting agents. While many approaches exist for solving the\nforward MFG, few have studied its \\textit{inverse} problem. In this work, we\nseek to recover optimal agent trajectories and the unseen spatial obstacle\ngiven partial observation on the former. To this end, we use a special type of\ngenerative models, normalizing flow, to represent the trajectories and propose\na novel formulation of inverse MFG as a bilevel optimization (BLO) problem. We\ndemonstrate the effectiveness of our approach across various MFG scenarios,\nincluding those involving multi-modal and disjoint obstacles, highlighting its\nrobustness with respect to obstacle complexity and dimensionality.\nAlternatively, our formulation can be interpreted as regularizing maximum\nlikelihood trajectory learning with MFG assumptions, which improves\ngeneralization performance especially with scarce training data. Impressively,\nour method also recovers the hidden obstacle with high fidelity in this\nlow-data regime.",
      "url": "http://arxiv.org/abs/2507.19344v1",
      "published_time_eastern_timestamp": 1753455230.0
    },
    {
      "title": "How Age Influences the Interpretation of Emotional Body Language in\n  Humanoid Robots -- long paper version",
      "summary": "This paper presents an empirical study investigating how individuals across\ndifferent age groups, children, young and older adults, interpret emotional\nbody language expressed by the humanoid robot NAO. The aim is to offer insights\ninto how users perceive and respond to emotional cues from robotic agents,\nthrough an empirical evaluation of the robot's effectiveness in conveying\nemotions to different groups of users. By analyzing data collected from elderly\nparticipants and comparing these findings with previously gathered data from\nyoung adults and children, the study highlights similarities and differences\nbetween the groups, with younger and older users more similar but different\nfrom young adults.",
      "url": "http://arxiv.org/abs/2507.19335v1",
      "published_time_eastern_timestamp": 1753454643.0
    },
    {
      "title": "Controlling Topological Defects in Polar Fluids via Reinforcement\n  Learning",
      "summary": "Topological defects in active polar fluids exhibit complex dynamics driven by\ninternally generated stresses, reflecting the deep interplay between topology,\nflow, and non-equilibrium hydrodynamics. Feedback control offers a powerful\nmeans to guide such systems, enabling transitions between dynamic states. We\ninvestigated closed-loop steering of integer-charged defects in a confined\nactive fluid by modulating the spatial profile of activity. Using a continuum\nhydrodynamic model, we show that localized control of active stress induces\nflow fields that can reposition and direct defects along prescribed\ntrajectories by exploiting non-linear couplings in the system. A reinforcement\nlearning framework is used to discover effective control strategies that\nproduce robust defect transport across both trained and novel trajectories. The\nresults highlight how AI agents can learn the underlying dynamics and spatially\nstructure activity to manipulate topological excitations, offering insights\ninto the controllability of active matter and the design of adaptive,\nself-organized materials.",
      "url": "http://arxiv.org/abs/2507.19298v1",
      "published_time_eastern_timestamp": 1753452731.0
    },
    {
      "title": "Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug\n  Reports",
      "summary": "Mutation-based fuzzing is effective for uncovering compiler bugs, but\ndesigning high-quality mutators for modern languages with complex constructs\n(e.g., templates, macros) remains challenging. Existing methods rely heavily on\nmanual design or human-in-the-loop correction, limiting scalability and\ncross-language generalizability.\n  We present Mut4All, a fully automated, language-agnostic framework that\nsynthesizes mutators using Large Language Models (LLMs) and compiler-specific\nknowledge from bug reports. It consists of three agents: (1) a mutator\ninvention agent that identifies mutation targets and generates mutator metadata\nusing compiler-related insights; (2) a mutator implementation synthesis agent,\nfine-tuned to produce initial implementations; and (3) a mutator refinement\nagent that verifies and corrects the mutators via unit-test feedback.\n  Mut4All processes 1000 bug reports (500 Rust, 500 C++), yielding 319 Rust and\n403 C++ mutators at ~$0.08 each via GPT-4o. Our customized fuzzer, using these\nmutators, finds 62 bugs in Rust compilers (38 new, 7 fixed) and 34 bugs in C++\ncompilers (16 new, 1 fixed). Mut4All outperforms existing methods in both\nunique crash detection and coverage, ranking first on Rust and second on C++.",
      "url": "http://arxiv.org/abs/2507.19275v1",
      "published_time_eastern_timestamp": 1753451682.0
    },
    {
      "title": "Modeling Uncertainty: Constraint-Based Belief States in\n  Imperfect-Information Games",
      "summary": "In imperfect-information games, agents must make decisions based on partial\nknowledge of the game state. The Belief Stochastic Game model addresses this\nchallenge by delegating state estimation to the game model itself. This allows\nagents to operate on externally provided belief states, thereby reducing the\nneed for game-specific inference logic. This paper investigates two approaches\nto represent beliefs in games with hidden piece identities: a constraint-based\nmodel using Constraint Satisfaction Problems and a probabilistic extension\nusing Belief Propagation to estimate marginal probabilities. We evaluated the\nimpact of both representations using general-purpose agents across two\ndifferent games. Our findings indicate that constraint-based beliefs yield\nresults comparable to those of probabilistic inference, with minimal\ndifferences in agent performance. This suggests that constraint-based belief\nstates alone may suffice for effective decision-making in many settings.",
      "url": "http://arxiv.org/abs/2507.19263v1",
      "published_time_eastern_timestamp": 1753450724.0
    },
    {
      "title": "CoopTrack: Exploring End-to-End Learning for Efficient Cooperative\n  Sequential Perception",
      "summary": "Cooperative perception aims to address the inherent limitations of\nsingle-vehicle autonomous driving systems through information exchange among\nmultiple agents. Previous research has primarily focused on single-frame\nperception tasks. However, the more challenging cooperative sequential\nperception tasks, such as cooperative 3D multi-object tracking, have not been\nthoroughly investigated. Therefore, we propose CoopTrack, a fully\ninstance-level end-to-end framework for cooperative tracking, featuring\nlearnable instance association, which fundamentally differs from existing\napproaches. CoopTrack transmits sparse instance-level features that\nsignificantly enhance perception capabilities while maintaining low\ntransmission costs. Furthermore, the framework comprises two key components:\nMulti-Dimensional Feature Extraction, and Cross-Agent Association and\nAggregation, which collectively enable comprehensive instance representation\nwith semantic and motion features, and adaptive cross-agent association and\nfusion based on a feature graph. Experiments on both the V2X-Seq and Griffin\ndatasets demonstrate that CoopTrack achieves excellent performance.\nSpecifically, it attains state-of-the-art results on V2X-Seq, with 39.0\\% mAP\nand 32.8\\% AMOTA. The project is available at\nhttps://github.com/zhongjiaru/CoopTrack.",
      "url": "http://arxiv.org/abs/2507.19239v1",
      "published_time_eastern_timestamp": 1753448694.0
    },
    {
      "title": "Event-Driven Storytelling with Multiple Lifelike Humans in a 3D Scene",
      "summary": "In this work, we propose a framework that creates a lively virtual dynamic\nscene with contextual motions of multiple humans. Generating multi-human\ncontextual motion requires holistic reasoning over dynamic relationships among\nhuman-human and human-scene interactions. We adapt the power of a large\nlanguage model (LLM) to digest the contextual complexity within textual input\nand convert the task into tangible subproblems such that we can generate\nmulti-agent behavior beyond the scale that was not considered before.\nSpecifically, our event generator formulates the temporal progression of a\ndynamic scene into a sequence of small events. Each event calls for a\nwell-defined motion involving relevant characters and objects. Next, we\nsynthesize the motions of characters at positions sampled based on spatial\nguidance. We employ a high-level module to deliver scalable yet comprehensive\ncontext, translating events into relative descriptions that enable the\nretrieval of precise coordinates. As the first to address this problem at scale\nand with diversity, we offer a benchmark to assess diverse aspects of\ncontextual reasoning. Benchmark results and user studies show that our\nframework effectively captures scene context with high scalability. The code\nand benchmark, along with result videos, are available at our project page:\nhttps://rms0329.github.io/Event-Driven-Storytelling/.",
      "url": "http://arxiv.org/abs/2507.19232v1",
      "published_time_eastern_timestamp": 1753448225.0
    },
    {
      "title": "Agentic AI and Hallucinations",
      "summary": "We model a competitive market where AI agents buy answers from upstream\ngenerative models and resell them to users who differ in how much they value\naccuracy and in how much they fear hallucinations. Agents can privately exert\neffort for costly verification to lower hallucination risks. Since interactions\nhalt in the event of a hallucination, the threat of losing future rents\ndisciplines effort. A unique reputational equilibrium exists under nontrivial\ndiscounting. The equilibrium effort, and thus the price, increases with the\nshare of users who have high accuracy concerns, implying that\nhallucination-sensitive sectors, such as law and medicine, endogenously lead to\nmore serious verification efforts in agentic AI markets.",
      "url": "http://arxiv.org/abs/2507.19183v1",
      "published_time_eastern_timestamp": 1753443921.0
    },
    {
      "title": "Phase transitions in voting simulated by an intelligent Ising model",
      "summary": "Voting is an important social activity for expressing public opinions. By\nconceptually considering a group of voting agents to be intelligent matter, the\nimpact of real-time information on voting results is quantitatively studied by\nan intelligent Ising model, which is formed by adding nonlinear instantaneous\nfeedback of the overall magnetization to the conventional Ising model. In the\nnew model, the interaction strength becomes a variable depending on the total\nmagnetization rather than a constant, which mimics the scenario that the\ndecision of an individual during vote influenced by the dynamically changing\npolling result during the election process. Our analytical derivations along\nwith Mote Carlo simulations reveal that, with a positive feedback, the\nintelligent Ising model exhibits phase transitions at any finite temperatures,\na feature lacked in the conventional one-dimensional Ising model. In all\ndimensions, by varying the feedback strength, the system changes from going\nthrough a second-order phase transition to going through a first-order phase\ntransition with increasing temperature, and the two types of phase transitions\nare connected by a tricritical point. This study on the one hand demonstrates\nthat the intelligent matter with a nonlinear adaptive interaction can exhibit\nqualitatively different phase behaviors from conventional matter, and on the\nother hand shows that, during voting, even unbiased feedback may possibly\ninduce spontaneous symmetry breaking, leading to a biased outcome where one\nside of the vote becomes favored.",
      "url": "http://arxiv.org/abs/2507.19161v1",
      "published_time_eastern_timestamp": 1753441641.0
    },
    {
      "title": "ReCoDe: Reinforcement Learning-based Dynamic Constraint Design for\n  Multi-Agent Coordination",
      "summary": "Constraint-based optimization is a cornerstone of robotics, enabling the\ndesign of controllers that reliably encode task and safety requirements such as\ncollision avoidance or formation adherence. However, handcrafted constraints\ncan fail in multi-agent settings that demand complex coordination. We introduce\nReCoDe--Reinforcement-based Constraint Design--a decentralized, hybrid\nframework that merges the reliability of optimization-based controllers with\nthe adaptability of multi-agent reinforcement learning. Rather than discarding\nexpert controllers, ReCoDe improves them by learning additional, dynamic\nconstraints that capture subtler behaviors, for example, by constraining agent\nmovements to prevent congestion in cluttered scenarios. Through local\ncommunication, agents collectively constrain their allowed actions to\ncoordinate more effectively under changing conditions. In this work, we focus\non applications of ReCoDe to multi-agent navigation tasks requiring intricate,\ncontext-based movements and consensus, where we show that it outperforms purely\nhandcrafted controllers, other hybrid approaches, and standard MARL baselines.\nWe give empirical (real robot) and theoretical evidence that retaining a\nuser-defined controller, even when it is imperfect, is more efficient than\nlearning from scratch, especially because ReCoDe can dynamically change the\ndegree to which it relies on this controller.",
      "url": "http://arxiv.org/abs/2507.19151v1",
      "published_time_eastern_timestamp": 1753440459.0
    },
    {
      "title": "Diverse and Adaptive Behavior Curriculum for Autonomous Driving: A\n  Student-Teacher Framework with Multi-Agent RL",
      "summary": "Autonomous driving faces challenges in navigating complex real-world traffic,\nrequiring safe handling of both common and critical scenarios. Reinforcement\nlearning (RL), a prominent method in end-to-end driving, enables agents to\nlearn through trial and error in simulation. However, RL training often relies\non rule-based traffic scenarios, limiting generalization. Additionally, current\nscenario generation methods focus heavily on critical scenarios, neglecting a\nbalance with routine driving behaviors. Curriculum learning, which\nprogressively trains agents on increasingly complex tasks, is a promising\napproach to improving the robustness and coverage of RL driving policies.\nHowever, existing research mainly emphasizes manually designed curricula,\nfocusing on scenery and actor placement rather than traffic behavior dynamics.\nThis work introduces a novel student-teacher framework for automatic curriculum\nlearning. The teacher, a graph-based multi-agent RL component, adaptively\ngenerates traffic behaviors across diverse difficulty levels. An adaptive\nmechanism adjusts task difficulty based on student performance, ensuring\nexposure to behaviors ranging from common to critical. The student, though\nexchangeable, is realized as a deep RL agent with partial observability,\nreflecting real-world perception constraints. Results demonstrate the teacher's\nability to generate diverse traffic behaviors. The student, trained with\nautomatic curricula, outperformed agents trained on rule-based traffic,\nachieving higher rewards and exhibiting balanced, assertive driving.",
      "url": "http://arxiv.org/abs/2507.19146v1",
      "published_time_eastern_timestamp": 1753439730.0
    },
    {
      "title": "Game-Theoretic Gradient Control for Robust Neural Network Training",
      "summary": "Feed-forward neural networks (FFNNs) are vulnerable to input noise, reducing\nprediction performance. Existing regularization methods like dropout often\nalter network architecture or overlook neuron interactions. This study aims to\nenhance FFNN noise robustness by modifying backpropagation, interpreted as a\nmulti-agent game, and exploring controlled target variable noising. Our\n\"gradient dropout\" selectively nullifies hidden layer neuron gradients with\nprobability 1 - p during backpropagation, while keeping forward passes active.\nThis is framed within compositional game theory. Additionally, target variables\nwere perturbed with white noise or stable distributions. Experiments on ten\ndiverse tabular datasets show varying impacts: improvement or diminishing of\nrobustness and accuracy, depending on dataset and hyperparameters. Notably, on\nregression tasks, gradient dropout (p = 0.9) combined with stable distribution\ntarget noising significantly increased input noise robustness, evidenced by\nflatter MSE curves and more stable SMAPE values. These results highlight the\nmethod's potential, underscore the critical role of adaptive parameter tuning,\nand open new avenues for analyzing neural networks as complex adaptive systems\nexhibiting emergent behavior within a game-theoretic framework.",
      "url": "http://arxiv.org/abs/2507.19143v1",
      "published_time_eastern_timestamp": 1753439185.0
    }
  ]
}
{
  "last_updated": "2025-07-08T21:01:04.523326-04:00",
  "papers": [
    {
      "title": "Spatio-Temporal LLM: Reasoning about Environments and Actions",
      "summary": "Despite the significant recent progress of Multimodal Large Language Models\n(MLLMs), MLLMs still struggle to correctly answer prompts that require a\nholistic spatio-temporal understanding. Specifically, it is challenging to\naddress prompts that refer to 1) the entirety of an environment that an agent\nequipped with an MLLM can operate in; and simultaneously also refer to 2)\nrecent actions that just happened and are encoded in a video clip. However,\nsuch a holistic spatio-temporal understanding is important for agents operating\nin the real world. To address this issue, we first develop a framework to\ncollect a large-scale dataset. Using the collected \"Reasoning about\nEnvironments and Actions\" (REA) dataset, we show that recent methods indeed\nstruggle to correctly answer the prompts. To improve, we develop a\n\"spatio-temporal LLM\" (ST-LLM), a model equipped with projectors to improve\nboth spatial understanding of an environment and temporal understanding of\nrecent observations. On the collected REA data, we show that the proposed\nmethod significantly improves results compared to prior work. Code and data are\navailable at https://zoezheng126.github.io/STLLM-website/.",
      "url": "http://arxiv.org/abs/2507.05258v1",
      "published_time_eastern_timestamp": 1751911195.0
    },
    {
      "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions",
      "summary": "Recent benchmarks for Large Language Model (LLM) agents primarily focus on\nevaluating reasoning, planning, and execution capabilities, while another\ncritical component-memory, encompassing how agents memorize, update, and\nretrieve long-term information-is under-evaluated due to the lack of\nbenchmarks. We term agents with memory mechanisms as memory agents. In this\npaper, we identify four core competencies essential for memory agents: accurate\nretrieval, test-time learning, long-range understanding, and conflict\nresolution. Existing datasets either rely on limited context lengths or are\ntailored for static, long-context settings like book-based QA, which do not\nreflect the interactive, multi-turn nature of memory agents that incrementally\naccumulate information. Furthermore, no existing benchmarks cover all four\ncompetencies. Therefore, we introduce MemoryAgentBench, a new benchmark\nspecifically designed for memory agents. Our benchmark combines reformulated\nexisting datasets with newly constructed ones, covering the above four memory\ncompetencies, providing a systematic and challenging testbed for assessing\nmemory quality. We evaluate a diverse set of memory agents, ranging from simple\ncontext-based and retrieval-augmented generation (RAG) systems to advanced\nagents with external memory modules and tool integration. Empirical results\nreveal that current methods fall short of mastering all four competencies,\nunderscoring the need for further research into comprehensive memory mechanisms\nfor LLM agents.",
      "url": "http://arxiv.org/abs/2507.05257v1",
      "published_time_eastern_timestamp": 1751911194.0
    },
    {
      "title": "From Marginal to Joint Predictions: Evaluating Scene-Consistent\n  Trajectory Prediction Approaches for Automated Driving",
      "summary": "Accurate motion prediction of surrounding traffic participants is crucial for\nthe safe and efficient operation of automated vehicles in dynamic environments.\nMarginal prediction models commonly forecast each agent's future trajectories\nindependently, often leading to sub-optimal planning decisions for an automated\nvehicle. In contrast, joint prediction models explicitly account for the\ninteractions between agents, yielding socially and physically consistent\npredictions on a scene level. However, existing approaches differ not only in\ntheir problem formulation but also in the model architectures and\nimplementation details used, making it difficult to compare them. In this work,\nwe systematically investigate different approaches to joint motion prediction,\nincluding post-processing of the marginal predictions, explicitly training the\nmodel for joint predictions, and framing the problem as a generative task. We\nevaluate each approach in terms of prediction accuracy, multi-modality, and\ninference efficiency, offering a comprehensive analysis of the strengths and\nlimitations of each approach. Several prediction examples are available at\nhttps://frommarginaltojointpred.github.io/.",
      "url": "http://arxiv.org/abs/2507.05254v1",
      "published_time_eastern_timestamp": 1751911133.0
    },
    {
      "title": "Action Space Reduction Strategies for Reinforcement Learning in\n  Autonomous Driving",
      "summary": "Reinforcement Learning (RL) offers a promising framework for autonomous\ndriving by enabling agents to learn control policies through interaction with\nenvironments. However, large and high-dimensional action spaces often used to\nsupport fine-grained control can impede training efficiency and increase\nexploration costs. In this study, we introduce and evaluate two novel\nstructured action space modification strategies for RL in autonomous driving:\ndynamic masking and relative action space reduction. These approaches are\nsystematically compared against fixed reduction schemes and full action space\nbaselines to assess their impact on policy learning and performance. Our\nframework leverages a multimodal Proximal Policy Optimization agent that\nprocesses both semantic image sequences and scalar vehicle states. The proposed\ndynamic and relative strategies incorporate real-time action masking based on\ncontext and state transitions, preserving action consistency while eliminating\ninvalid or suboptimal choices. Through comprehensive experiments across diverse\ndriving routes, we show that action space reduction significantly improves\ntraining stability and policy performance. The dynamic and relative schemes, in\nparticular, achieve a favorable balance between learning speed, control\nprecision, and generalization. These findings highlight the importance of\ncontext-aware action space design for scalable and reliable RL in autonomous\ndriving tasks.",
      "url": "http://arxiv.org/abs/2507.05251v1",
      "published_time_eastern_timestamp": 1751911088.0
    },
    {
      "title": "Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent\n  Collaboration",
      "summary": "In collaborative tasks, being able to adapt to your teammates is a necessary\nrequirement for success. When teammates are heterogeneous, such as in\nhuman-agent teams, agents need to be able to observe, recognize, and adapt to\ntheir human partners in real time. This becomes particularly challenging in\ntasks with time pressure and complex strategic spaces where the dynamics can\nchange rapidly. In this work, we introduce TALENTS, a strategy-conditioned\ncooperator framework that learns to represent, categorize, and adapt to a range\nof partner strategies, enabling ad-hoc teamwork. Our approach utilizes a\nvariational autoencoder to learn a latent strategy space from trajectory data.\nThis latent space represents the underlying strategies that agents employ.\nSubsequently, the system identifies different types of strategy by clustering\nthe data. Finally, a cooperator agent is trained to generate partners for each\ntype of strategy, conditioned on these clusters. In order to adapt to\npreviously unseen partners, we leverage a fixed-share regret minimization\nalgorithm that infers and adjusts the estimated partner strategy dynamically.\nWe assess our approach in a customized version of the Overcooked environment,\nposing a challenging cooperative cooking task that demands strong coordination\nacross a wide range of possible strategies. Using an online user study, we show\nthat our agent outperforms current baselines when working with unfamiliar human\npartners.",
      "url": "http://arxiv.org/abs/2507.05244v1",
      "published_time_eastern_timestamp": 1751910793.0
    },
    {
      "title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I.\n  X-Master as Foundation: Can We Lead on Humanity's Last Exam?",
      "summary": "The rapid advancements of AI agents have ignited the long-held ambition of\nleveraging them to accelerate scientific discovery. Achieving this goal\nrequires a deep understanding of the frontiers of human knowledge. As such,\nHumanity's Last Exam (HLE) provides an exceptionally challenging touchstone for\nevaluating scientific AI agents. In this work, we aim to construct the\nfoundational architecture for general-purpose agents and validate the\ncapabilities through leading performance on HLE. To achieve this, we introduce\nX-Master, a tool-augmented reasoning agent designed to emulate human\nresearchers by interacting flexibly with external tools during its reasoning\nprocess. This agent, guided by the conceptualization of code as an interaction\nlanguage, can flexibly leverage built-in Python libraries and our customized\ntools to augment the reasoning. We further scale its capabilities through\nX-Masters, a scattered-and-stacked agentic workflow that systematically\nenhances breadth and depth of reasoning. Our open-source solution, X-Masters,\nsets a new state-of-the-art record on HLE with a score of 32.1%, surpassing\nOpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to\nexceed the 30% threshold. This work allows us to gain a deeper understanding of\ncomplex task-solving and accumulates valuable experience that can inform future\nadvancements, guiding subsequent model training.",
      "url": "http://arxiv.org/abs/2507.05241v2",
      "published_time_eastern_timestamp": 1751910652.0
    },
    {
      "title": "StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context\n  Modeling",
      "summary": "Vision-and-Language Navigation (VLN) in real-world settings requires agents\nto process continuous visual streams and generate actions with low latency\ngrounded in language instructions. While Video-based Large Language Models\n(Video-LLMs) have driven recent progress, current VLN methods based on\nVideo-LLM often face trade-offs among fine-grained visual understanding,\nlong-term context modeling and computational efficiency. We introduce\nStreamVLN, a streaming VLN framework that employs a hybrid slow-fast context\nmodeling strategy to support multi-modal reasoning over interleaved vision,\nlanguage and action inputs. The fast-streaming dialogue context facilitates\nresponsive action generation through a sliding-window of active dialogues,\nwhile the slow-updating memory context compresses historical visual states\nusing a 3D-aware token pruning strategy. With this slow-fast design, StreamVLN\nachieves coherent multi-turn dialogue through efficient KV cache reuse,\nsupporting long video streams with bounded context size and inference cost.\nExperiments on VLN-CE benchmarks demonstrate state-of-the-art performance with\nstable low latency, ensuring robustness and efficiency in real-world\ndeployment. The project page is:\n\\href{https://streamvln.github.io/}{https://streamvln.github.io/}.",
      "url": "http://arxiv.org/abs/2507.05240v1",
      "published_time_eastern_timestamp": 1751910581.0
    },
    {
      "title": "MedGemma Technical Report",
      "summary": "Artificial intelligence (AI) has significant potential in healthcare\napplications, but its training and deployment faces challenges due to\nhealthcare's diverse data, complex tasks, and the need to preserve privacy.\nFoundation models that perform well on medical tasks and require less\ntask-specific tuning data are critical to accelerate the development of\nhealthcare AI applications. We introduce MedGemma, a collection of medical\nvision-language foundation models based on Gemma 3 4B and 27B. MedGemma\ndemonstrates advanced medical understanding and reasoning on images and text,\nsignificantly exceeding the performance of similar-sized generative models and\napproaching the performance of task-specific models, while maintaining the\ngeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,\nMedGemma achieves 2.6-10% improvement on medical multimodal question answering,\n15.5-18.1% improvement on chest X-ray finding classification, and 10.8%\nimprovement on agentic evaluations compared to the base models. Fine-tuning\nMedGemma further improves performance in subdomains, reducing errors in\nelectronic health record information retrieval by 50% and reaching comparable\nperformance to existing specialized state-of-the-art methods for pneumothorax\nclassification and histopathology patch classification. We additionally\nintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.\nMedSigLIP powers the visual understanding capabilities of MedGemma and as an\nencoder achieves comparable or better performance than specialized medical\nimage encoders. Taken together, the MedGemma collection provides a strong\nfoundation of medical image and text capabilities, with potential to\nsignificantly accelerate medical research and development of downstream\napplications. The MedGemma collection, including tutorials and model weights,\ncan be found at https://goo.gle/medgemma.",
      "url": "http://arxiv.org/abs/2507.05201v2",
      "published_time_eastern_timestamp": 1751907704.0
    },
    {
      "title": "CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale",
      "summary": "Despite rapid progress in large language model (LLM)-based multi-agent\nsystems, current benchmarks fall short in evaluating their scalability,\nrobustness, and coordination capabilities in complex, dynamic, real-world\ntasks. Existing environments typically focus on small-scale, fully observable,\nor low-complexity domains, limiting their utility for developing and assessing\nnext-generation multi-agent Agentic AI frameworks. We introduce CREW-Wildfire,\nan open-source benchmark designed to close this gap. Built atop the human-AI\nteaming CREW simulation platform, CREW-Wildfire offers procedurally generated\nwildfire response scenarios featuring large maps, heterogeneous agents, partial\nobservability, stochastic dynamics, and long-horizon planning objectives. The\nenvironment supports both low-level control and high-level natural language\ninteractions through modular Perception and Execution modules. We implement and\nevaluate several state-of-the-art LLM-based multi-agent Agentic AI frameworks,\nuncovering significant performance gaps that highlight the unsolved challenges\nin large-scale coordination, communication, spatial reasoning, and long-horizon\nplanning under uncertainty. By providing more realistic complexity, scalable\narchitecture, and behavioral evaluation metrics, CREW-Wildfire establishes a\ncritical foundation for advancing research in scalable multi-agent Agentic\nintelligence. All code, environments, data, and baselines will be released to\nsupport future research in this emerging domain.",
      "url": "http://arxiv.org/abs/2507.05178v1",
      "published_time_eastern_timestamp": 1751906022.0
    },
    {
      "title": "Vector Cost Bimatrix Games with Applications to Autonomous Racing",
      "summary": "We formulate a vector cost alternative to the scalarization method for\nweighting and combining multi-objective costs. The algorithm produces solutions\nto bimatrix games that are simultaneously pure, unique Nash equilibria and\nPareto optimal with guarantees for avoiding worst case outcomes. We achieve\nthis by enforcing exact potential game constraints to guide cost adjustments\ntowards equilibrium, while minimizing the deviation from the original cost\nstructure. The magnitude of this adjustment serves as a metric for\ndifferentiating between Pareto optimal solutions. We implement this approach in\na racing competition between agents with heterogeneous cost structures,\nresulting in fewer collision incidents with a minimal decrease in performance.\nCode is available at https://github.com/toazbenj/race_simulation.",
      "url": "http://arxiv.org/abs/2507.05171v1",
      "published_time_eastern_timestamp": 1751905463.0
    },
    {
      "title": "Critiques of World Models",
      "summary": "World Model, the supposed algorithmic surrogate of the real-world environment\nwhich biological agents experience with and act upon, has been an emerging\ntopic in recent years because of the rising needs to develop virtual agents\nwith artificial (general) intelligence. There has been much debate on what a\nworld model really is, how to build it, how to use it, and how to evaluate it.\nIn this essay, starting from the imagination in the famed Sci-Fi classic Dune,\nand drawing inspiration from the concept of \"hypothetical thinking\" in\npsychology literature, we offer critiques of several schools of thoughts on\nworld modeling, and argue the primary goal of a world model to be simulating\nall actionable possibilities of the real world for purposeful reasoning and\nacting. Building on the critiques, we propose a new architecture for a\ngeneral-purpose world model, based on hierarchical, multi-level, and mixed\ncontinuous/discrete representations, and a generative and self-supervision\nlearning framework, with an outlook of a Physical, Agentic, and Nested (PAN)\nAGI system enabled by such a model.",
      "url": "http://arxiv.org/abs/2507.05169v1",
      "published_time_eastern_timestamp": 1751905426.0
    },
    {
      "title": "Macroscopic Structural Light Absorbers",
      "summary": "The interaction of light with optical and mechanical systems is influenced by\nmaterial properties, geometrical configurations, and surface topographies.\nDesigning these systems necessitates a careful balance of conflicting\nrequirements, such as minimising size and weight while simultaneously improving\nheat transfer and reducing stray light from illuminated peripheral mounting\nsurfaces. Stray light is typically mitigated by apertures, coatings, and\nmicroscopic structures, alongside maintaining cleanliness. However, using\napertures may not always be feasible, and effective optical absorber coatings\nor microscopic light absorbing structures can be costly and sensitive to\nenvironmental factors such as abrasion, radiation heating, or cleaning agents.\n  In a proof-of-concept investigation, we design and analyse macroscopic\nstructural light absorbers realised as periodic minimal surface approximations\nand quasi-stochastic lattices. The term \"macroscopic\" refers to minimal\nstructural dimensions of approximately 100 micrometres. By increasing the\nnumber of reflections before residual reflected light reaches a hemispherical\nreceiver, we achieve reductions in received peak intensities by factors of less\nthan 0.39 and average intensities by factors of less than 0.65, without\naltering the surface properties.\n  Macroscopic structural light absorbers support cost-effective and robust\nlight-absorbing materials, such as black anodised aluminium or ABS polymers,\nwhile still achieving satisfactory stray light suppression. This approach is\napplicable to aerospace optical systems (such as telescopes and imaging\nspectrometers), as well as general scientific and industrial optical\ninstruments and commercial products (including projectors and luminaires). The\ndemonstrated structures can be sustainably fabricated through additive\nmanufacturing processes like laser powder bed fusion.",
      "url": "http://arxiv.org/abs/2507.05152v1",
      "published_time_eastern_timestamp": 1751904166.0
    },
    {
      "title": "Effects of Unplanned Incoming Flights on Airport Relief Processes after\n  a Major Natural Disaster",
      "summary": "The severity of natural disasters is increasing every year, impacting many\npeople's lives. During the response phase of disasters, airports are important\nhubs where relief aid arrives and people need to be evacuated. However, the\nairport often forms a bottleneck in these relief operations due to the sudden\nneed for increased capacity. Limited research has been done on the operational\nside of airport disaster management. Experts identify the main problems as,\nfirst, the asymmetry of information between the airport and incoming flights,\nand second, the lack of resources. The goal of this research is to understand\nthe effects of incomplete knowledge of incoming flights with different resource\nallocation strategies on the performance of cargo handling operations at an\nairport after a natural disaster. An agent-based model is created, implementing\nrealistic offloading strategies with different degrees of information\nuncertainty. Model calibration and verification are performed with experts in\nthe field. The model performance is measured by the average turnaround time,\nwhich is divided into offloading time, boarding time, and cumulative waiting\ntimes. The results show that the effects of one unplanned aircraft are\nnegligible. However, all waiting times increase with more arriving unplanned\naircraft.",
      "url": "http://arxiv.org/abs/2507.05150v1",
      "published_time_eastern_timestamp": 1751904026.0
    },
    {
      "title": "LERa: Replanning with Visual Feedback in Instruction Following",
      "summary": "Large Language Models are increasingly used in robotics for task planning,\nbut their reliance on textual inputs limits their adaptability to real-world\nchanges and failures. To address these challenges, we propose LERa - Look,\nExplain, Replan - a Visual Language Model-based replanning approach that\nutilizes visual feedback. Unlike existing methods, LERa requires only a raw RGB\nimage, a natural language instruction, an initial task plan, and failure\ndetection - without additional information such as object detection or\npredefined conditions that may be unavailable in a given scenario. The\nreplanning process consists of three steps: (i) Look, where LERa generates a\nscene description and identifies errors; (ii) Explain, where it provides\ncorrective guidance; and (iii) Replan, where it modifies the plan accordingly.\nLERa is adaptable to various agent architectures and can handle errors from\nboth dynamic scene changes and task execution failures. We evaluate LERa on the\nnewly introduced ALFRED-ChaOS and VirtualHome-ChaOS datasets, achieving a 40%\nimprovement over baselines in dynamic environments. In tabletop manipulation\ntasks with a predefined probability of task failure within the PyBullet\nsimulator, LERa improves success rates by up to 67%. Further experiments,\nincluding real-world trials with a tabletop manipulator robot, confirm LERa's\neffectiveness in replanning. We demonstrate that LERa is a robust and adaptable\nsolution for error-aware task execution in robotics. The code is available at\nhttps://lera-robo.github.io.",
      "url": "http://arxiv.org/abs/2507.05135v1",
      "published_time_eastern_timestamp": 1751903340.0
    },
    {
      "title": "Optimal Consumption-Investment for General Utility with a Drawdown\n  Constraint over a Finite-Time Horizon",
      "summary": "We study an optimal investment and consumption problem over a finite-time\nhorizon, in which an individual invests in a risk-free asset and a risky asset,\nand evaluate utility using a general utility function that exhibits loss\naversion with respect to the historical maximum of consumption. Motivated by\nbehavioral finance and habit formation theory, we model the agent's preference\nfor maintaining a standard of living by imposing constraints on declines from\nthe peak consumption level. To solve the resulting Hamilton-Jacobi-Bellman\n(HJB) variational inequality, which is fully nonlinear, we apply a dual\ntransformation, transforming the original problem into a linear singular\ncontrol problem with a constraint. By differentiating the value function\nfurther, we reduce the constrained linear singular control problem to a linear\nobstacle problem. We prove the existence of a solution to the obstacle problem\nunder standard constraints. It allows us to characterize the optimal\nconsumption and investment strategies through piecewise analytical feedback\nforms derived from the dual formulation. Our analysis contributes to the\nliterature on habit formation, drawdown constraints, and stochastic control by\nexplicitly characterizing the time-dependent free boundaries and the associated\noptimal feedback strategies.",
      "url": "http://arxiv.org/abs/2507.05115v1",
      "published_time_eastern_timestamp": 1751902242.0
    },
    {
      "title": "Beyond Features: How Dataset Design Influences Multi-Agent Trajectory\n  Prediction Performance",
      "summary": "Accurate trajectory prediction is critical for safe autonomous navigation,\nyet the impact of dataset design on model performance remains understudied.\nThis work systematically examines how feature selection, cross-dataset\ntransfer, and geographic diversity influence trajectory prediction accuracy in\nmulti-agent settings. We evaluate a state-of-the-art model using our novel L4\nMotion Forecasting dataset based on our own data recordings in Germany and the\nUS. This includes enhanced map and agent features. We compare our dataset to\nthe US-centric Argoverse 2 benchmark. First, we find that incorporating\nsupplementary map and agent features unique to our dataset, yields no\nmeasurable improvement over baseline features, demonstrating that modern\narchitectures do not need extensive feature sets for optimal performance. The\nlimited features of public datasets are sufficient to capture convoluted\ninteractions without added complexity. Second, we perform cross-dataset\nexperiments to evaluate how effective domain knowledge can be transferred\nbetween datasets. Third, we group our dataset by country and check the\nknowledge transfer between different driving cultures.",
      "url": "http://arxiv.org/abs/2507.05098v1",
      "published_time_eastern_timestamp": 1751901531.0
    },
    {
      "title": "Perspectives on How Sociology Can Advance Theorizing about Human-Chatbot\n  Interaction and Developing Chatbots for Social Good",
      "summary": "Recently, research into chatbots (also known as conversational agents, AI\nagents, voice assistants), which are computer applications using artificial\nintelligence to mimic human-like conversation, has grown sharply. Despite this\ngrowth, sociology lags other disciplines (including computer science, medicine,\npsychology, and communication) in publishing about chatbots. We suggest\nsociology can advance understanding of human-chatbot interaction and offer four\nsociological theories to enhance extant work in this field. The first two\ntheories (resource substitution theory, power-dependence theory) add new\ninsights to existing models of the drivers of chatbot use, which overlook\nsociological concerns about how social structure (e.g., systemic\ndiscrimination, the uneven distribution of resources within networks) inclines\nindividuals to use chatbots, including problematic levels of emotional\ndependency on chatbots. The second two theories (affect control theory,\nfundamental cause of disease theory) help inform the development of\nchatbot-driven interventions that minimize safety risks and enhance equity by\nleveraging sociological insights into how chatbot outputs could attend to\ncultural contexts (e.g., affective norms) to promote wellbeing and enhance\ncommunities (e.g., opportunities for civic participation). We discuss the value\nof applying sociological theories for advancing theorizing about human-chatbot\ninteraction and developing chatbots for social good.",
      "url": "http://arxiv.org/abs/2507.05030v1",
      "published_time_eastern_timestamp": 1751897523.0
    },
    {
      "title": "Linking Homeostasis to Reinforcement Learning: Internal State Control of\n  Motivated Behavior",
      "summary": "For living beings, survival depends on effective regulation of internal\nphysiological states through motivated behaviors. In this perspective we\npropose that Homeostatically Regulated Reinforcement Learning (HRRL) as a\nframework to describe biological agents that optimize internal states via\nlearned predictive control strategies, integrating biological principles with\ncomputational learning. We show that HRRL inherently produces multiple\nbehaviors such as risk aversion, anticipatory regulation, and adaptive\nmovement, aligning with observed biological phenomena. Its extension to deep\nreinforcement learning enables autonomous exploration, hierarchical behavior,\nand potential real-world robotic applications. We argue further that HRRL\noffers a biologically plausible foundation for understanding motivation,\nlearning, and decision-making, with broad implications for artificial\nintelligence, neuroscience, and understanding the causes of psychiatric\ndisorders, ultimately advancing our understanding of adaptive behavior in\ncomplex environments.",
      "url": "http://arxiv.org/abs/2507.04998v1",
      "published_time_eastern_timestamp": 1751895384.0
    },
    {
      "title": "From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility\n  Systems",
      "summary": "Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity\nto operate according to internal rules without external control. Accordingly,\nautonomous vehicles (AuVs) are defined as systems capable of perceiving their\nenvironment and executing preprogrammed tasks independently of external input.\nHowever, both research and real-world deployments increasingly showcase\nvehicles that demonstrate behaviors beyond this definition (including the SAE\nlevels 1 to 6), such as interaction with humans and machines, goal adaptation,\ncontextual reasoning, external tool use, and long-term planning, particularly\nwith the integration of large language models (LLMs) and agentic AI systems.\nThese developments reveal a conceptual gap between technical autonomy and the\nbroader cognitive and social capabilities needed for future human-centered\nmobility systems. To address this, we introduce the concept of agentic vehicles\n(AgVs), referring to vehicles that integrate agentic AI to reason, adapt, and\ninteract within complex environments. This paper presents a systems-level\nframework to characterize AgVs, focusing on their cognitive and communicative\nlayers and differentiating them from conventional AuVs. It synthesizes relevant\nadvances in agentic AI, robotics, multi-agent systems, and human-machine\ninteraction, and highlights how agentic AI, through high-level reasoning and\ntool use, can function not merely as computational tools but as interactive\nagents embedded in mobility ecosystems. The paper concludes by identifying key\nchallenges in the development and governance of AgVs, including safety,\nreal-time control, public acceptance, ethical alignment, and regulatory\nframeworks.",
      "url": "http://arxiv.org/abs/2507.04996v1",
      "published_time_eastern_timestamp": 1751895289.0
    },
    {
      "title": "Leadership Detection via Time-Lagged Correlation-Based Network Inference",
      "summary": "Understanding leadership dynamics in collective behavior is a key challenge\nin animal ecology, swarm robotics, and intelligent transportation. Traditional\ninformation-theoretic approaches, including Transfer Entropy (TE) and\nTime-Lagged Mutual Information (TLMI), have been widely used to infer\nleader-follower relationships but face critical limitations in noisy or\nshort-duration datasets due to their reliance on robust probability\nestimations. This study proposes a method based on dynamic network inference\nusing time-lagged correlations across multiple kinematic variables: velocity,\nacceleration, and direction. Our approach constructs directed influence graphs\nover time, enabling the identification of leadership patterns without the need\nfor large volumes of data or parameter-sensitive discretization. We validate\nour method through two multi-agent simulations in NetLogo: a modified Vicsek\nmodel with informed leaders and a predator-prey model featuring coordinated and\nindependent wolf groups. Experimental results demonstrate that the\nnetwork-based method outperforms TE and TLMI in scenarios with limited\nspatiotemporal observations, ranking true leaders at the top of influence\nmetrics more consistently than TE and TLMI.",
      "url": "http://arxiv.org/abs/2507.04917v1",
      "published_time_eastern_timestamp": 1751889850.0
    }
  ]
}
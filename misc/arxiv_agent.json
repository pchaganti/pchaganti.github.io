{
  "last_updated": "2025-11-10T13:17:57.679100-05:00",
  "papers": [
    {
      "title": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for\n  Large Language Models",
      "summary": "Evaluating large language models (LLMs) for software engineering has been\nlimited by narrow task coverage, language bias, and insufficient alignment with\nreal-world developer workflows. Existing benchmarks often focus on algorithmic\nproblems or Python-centric bug fixing, leaving critical dimensions of software\nengineering underexplored. To address these gaps, we introduce SWE-Compass1, a\ncomprehensive benchmark that unifies heterogeneous code-related evaluations\ninto a structured and production-aligned framework. SWE-Compass spans 8 task\ntypes, 8 programming scenarios, and 10 programming languages, with 2000\nhigh-quality instances curated from authentic GitHub pull requests and refined\nthrough systematic filtering and validation. We benchmark ten state-of-the-art\nLLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear\nhierarchy of difficulty across task types, languages, and scenarios. Moreover,\nby aligning evaluation with real-world developer practices, SWE-Compass\nprovides a rigorous and reproducible foundation for diagnosing and advancing\nagentic coding capabilities in large language models.",
      "url": "http://arxiv.org/abs/2511.05459v1",
      "published_time_eastern_timestamp": 1762538492.0
    },
    {
      "title": "Story Arena: A Multi-Agent Environment for Envisioning the Future of\n  Software Engineering",
      "summary": "What better way to understand the impact of AI on software engineering than\nto ask AI itself? We constructed Story Arena, a multi-agent \"writer's room\" in\nwhich multiple AI agents, independently imbued with a position statement on the\nfuture of software engineering, converse with each other to develop a shared\nvision. They then use this shared vision to collaboratively construct a design\nfiction that depicts this vision in narrative form. We present \"The Code of\nTrust,\" a short fiction that investigates themes of human comprehension, trust,\ncontent ownership, augmentation vs. replacement, and uncertain futures in\nhuman-AI co-creation.",
      "url": "http://arxiv.org/abs/2511.05410v1",
      "published_time_eastern_timestamp": 1762533321.0
    },
    {
      "title": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement\n  Learning with Online Interaction",
      "summary": "Off-dynamics reinforcement learning (RL), where training and deployment\ntransition dynamics are different, can be formulated as learning in a robust\nMarkov decision process (RMDP) where uncertainties in transition dynamics are\nimposed. Existing literature mostly assumes access to generative models\nallowing arbitrary state-action queries or pre-collected datasets with a good\nstate coverage of the deployment environment, bypassing the challenge of\nexploration. In this work, we study a more realistic and challenging setting\nwhere the agent is limited to online interaction with the training environment.\nTo capture the intrinsic difficulty of exploration in online RMDPs, we\nintroduce the supremal visitation ratio, a novel quantity that measures the\nmismatch between the training dynamics and the deployment dynamics. We show\nthat if this ratio is unbounded, online learning becomes exponentially hard. We\npropose the first computationally efficient algorithm that achieves sublinear\nregret in online RMDPs with $f$-divergence based transition uncertainties. We\nalso establish matching regret lower bounds, demonstrating that our algorithm\nachieves optimal dependence on both the supremal visitation ratio and the\nnumber of interaction episodes. Finally, we validate our theoretical results\nthrough comprehensive numerical experiments.",
      "url": "http://arxiv.org/abs/2511.05396v1",
      "published_time_eastern_timestamp": 1762532662.0
    },
    {
      "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation\n  Framework",
      "summary": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment\nLarge Language Models' (LLMs) reliability. For flexibility, agentic RAG employs\nautonomous, multi-round retrieval and reasoning to resolve queries. Although\nrecent agentic RAG has improved via reinforcement learning, they often incur\nsubstantial token overhead from search and reasoning processes. This trade-off\nprioritizes accuracy over efficiency. To address this issue, this work proposes\nTeaRAG, a token-efficient agentic RAG framework capable of compressing both\nretrieval content and reasoning steps. 1) First, the retrieved content is\ncompressed by augmenting chunk-based semantic retrieval with a graph retrieval\nusing concise triplets. A knowledge association graph is then built from\nsemantic similarity and co-occurrence. Finally, Personalized PageRank is\nleveraged to highlight key knowledge within this graph, reducing the number of\ntokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative\nProcess-aware Direct Preference Optimization (IP-DPO) is proposed.\nSpecifically, our reward function evaluates the knowledge sufficiency by a\nknowledge matching mechanism, while penalizing excessive reasoning steps. This\ndesign can produce high-quality preference-pair datasets, supporting iterative\nDPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the\naverage Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on\nLlama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/TeaRAG.",
      "url": "http://arxiv.org/abs/2511.05385v1",
      "published_time_eastern_timestamp": 1762531714.0
    },
    {
      "title": "Reasoning Is All You Need for Urban Planning AI",
      "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities.",
      "url": "http://arxiv.org/abs/2511.05375v1",
      "published_time_eastern_timestamp": 1762531146.0
    },
    {
      "title": "ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations",
      "summary": "As language models evolve into autonomous agents that act and communicate on\nbehalf of users, ensuring safety in multi-agent ecosystems becomes a central\nchallenge. Interactions between personal assistants and external service\nproviders expose a core tension between utility and protection: effective\ncollaboration requires information sharing, yet every exchange creates new\nattack surfaces. We introduce ConVerse, a dynamic benchmark for evaluating\nprivacy and security risks in agent-agent interactions. ConVerse spans three\npractical domains (travel, real estate, insurance) with 12 user personas and\nover 864 contextually grounded attacks (611 privacy, 253 security). Unlike\nprior single-agent settings, it models autonomous, multi-turn agent-to-agent\nconversations where malicious requests are embedded within plausible discourse.\nPrivacy is tested through a three-tier taxonomy assessing abstraction quality,\nwhile security attacks target tool use and preference manipulation. Evaluating\nseven state-of-the-art models reveals persistent vulnerabilities; privacy\nattacks succeed in up to 88% of cases and security breaches in up to 60%, with\nstronger models leaking more. By unifying privacy and security within\ninteractive multi-agent contexts, ConVerse reframes safety as an emergent\nproperty of communication.",
      "url": "http://arxiv.org/abs/2511.05359v1",
      "published_time_eastern_timestamp": 1762530589.0
    },
    {
      "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive\n  Maintenance",
      "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities.",
      "url": "http://arxiv.org/abs/2511.05311v1",
      "published_time_eastern_timestamp": 1762528369.0
    },
    {
      "title": "Cooperation Under Network-Constrained Communication",
      "summary": "In this paper, we study cooperation in distributed games under\nnetwork-constrained communication. Building on the framework of Monderer and\nTennenholtz (1999), we derive a sufficient condition for cooperative\nequilibrium in settings where communication between agents is delayed by the\nunderlying network topology. Each player deploys an agent at every location,\nand local interactions follow a Prisoner's Dilemma structure. We derive a\nsufficient condition that depends on the network diameter and the number of\nlocations, and analyze extreme cases of instantaneous, delayed, and\nproportionally delayed communication. We also discuss the asymptotic case of\nscale-free communication networks, in which the network diameter grows\nsub-linearly in the number of locations. These insights clarify how\ncommunication latency and network design jointly determine the emergence of\ndistributed cooperation.",
      "url": "http://arxiv.org/abs/2511.05290v1",
      "published_time_eastern_timestamp": 1762527017.0
    },
    {
      "title": "DeepEyesV2: Toward Agentic Multimodal Model",
      "summary": "Agentic multimodal models should not only comprehend text and images, but\nalso actively invoke external tools, such as code execution environments and\nweb search, and integrate these operations into reasoning. In this work, we\nintroduce DeepEyesV2 and explore how to build an agentic multimodal model from\nthe perspectives of data construction, training methods, and model evaluation.\nWe observe that direct reinforcement learning alone fails to induce robust\ntool-use behavior. This phenomenon motivates a two-stage training pipeline: a\ncold-start stage to establish tool-use patterns, and reinforcement learning\nstage to further refine tool invocation. We curate a diverse, moderately\nchallenging training dataset, specifically including examples where tool use is\nbeneficial. We further introduce RealX-Bench, a comprehensive benchmark\ndesigned to evaluate real-world multimodal reasoning, which inherently requires\nthe integration of multiple capabilities, including perception, search, and\nreasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative\nbenchmarks, demonstrating its effectiveness across real-world understanding,\nmathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2\nexhibits task-adaptive tool invocation, tending to use image operations for\nperception tasks and numerical computations for reasoning tasks. Reinforcement\nlearning further enables complex tool combinations and allows model to\nselectively invoke tools based on context. We hope our study can provide\nguidance for community in developing agentic multimodal models.",
      "url": "http://arxiv.org/abs/2511.05271v1",
      "published_time_eastern_timestamp": 1762525880.0
    },
    {
      "title": "Competitive optimal portfolio selection under mean-variance criterion",
      "summary": "We investigate a portfolio selection problem involving multi competitive\nagents, each exhibiting mean-variance preferences. Unlike classical models,\neach agent's utility is determined by their relative wealth compared to the\naverage wealth of all agents, introducing a competitive dynamic into the\noptimization framework. To address this game-theoretic problem, we first\nreformulate the mean-variance criterion as a constrained, non-homogeneous\nstochastic linear-quadratic control problem and derive the corresponding\noptimal feedback strategies. The existence of Nash equilibria is shown to\ndepend on the well-posedness of a complex, coupled system of equations.\nEmploying decoupling techniques, we reduce the well-posedness analysis to the\nsolvability of a novel class of multi-dimensional linear backward stochastic\ndifferential equations (BSDEs). We solve a new type of nonlinear BSDEs\n(including the above linear one as a special case) using fixed-point theory.\nDepending on the interplay between market and competition parameters, three\ndistinct scenarios arise: (i) the existence of a unique Nash equilibrium, (ii)\nthe absence of any Nash equilibrium, and (iii) the existence of infinitely many\nNash equilibria. These scenarios are rigorously characterized and discussed in\ndetail.",
      "url": "http://arxiv.org/abs/2511.05270v1",
      "published_time_eastern_timestamp": 1762525860.0
    },
    {
      "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems",
      "summary": "Large Language Models (LLMs) have demonstrated strong capabilities as\nautonomous agents through tool use, planning, and decision-making abilities,\nleading to their widespread adoption across diverse tasks. As task complexity\ngrows, multi-agent LLM systems are increasingly used to solve problems\ncollaboratively. However, safety and security of these systems remains largely\nunder-explored. Existing benchmarks and datasets predominantly focus on\nsingle-agent settings, failing to capture the unique vulnerabilities of\nmulti-agent dynamics and co-ordination. To address this gap, we introduce\n$\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent\n$\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the\nrobustness and safety of multi-agent LLM systems. TAMAS includes five distinct\nscenarios comprising 300 adversarial instances across six attack types and 211\ntools, along with 100 harmless tasks. We assess system performance across ten\nbackbone LLMs and three agent interaction configurations from Autogen and\nCrewAI frameworks, highlighting critical challenges and failure modes in\ncurrent multi-agent deployments. Furthermore, we introduce Effective Robustness\nScore (ERS) to assess the tradeoff between safety and task effectiveness of\nthese frameworks. Our findings show that multi-agent systems are highly\nvulnerable to adversarial attacks, underscoring the urgent need for stronger\ndefenses. TAMAS provides a foundation for systematically studying and improving\nthe safety of multi-agent LLM systems.",
      "url": "http://arxiv.org/abs/2511.05269v1",
      "published_time_eastern_timestamp": 1762525826.0
    },
    {
      "title": "Guaranteeing Both Consensus and Optimality in Decentralized Nonconvex\n  Optimization with Multiple Local Updates",
      "summary": "Scalable decentralized optimization in large-scale systems hinges on\nefficient communication. A common way to reduce communication overhead is to\nperform multiple local updates between two communication rounds, as in\nfederated learning. However, extending this strategy to fully decentralized\nsettings poses fundamental challenges. Existing decentralized algorithms with\nmultiple local updates guarantee accurate convergence only under strong\nconvexity, limiting applicability to the nonconvex problems prevalent in\nmachine learning. Moreover, many methods require exchanging and storing\nauxiliary variables, such as gradient-tracking vectors or correction terms, to\nensure convergence under data heterogeneity, incurring high communication and\nmemory costs. In this paper, we propose MILE, a fully decentralized algorithm\nthat guarantees both consensus and optimality under multiple local updates in\ngeneral nonconvex settings. This is achieved through a novel\nperiodic-system-based formulation and a lifting-based analysis, which together\nyield a closed-form expression for the state evolution across local updates, a\ntheoretical advance not achieved previously. This closed-form characterization\nallows us to establish, for the first time, guaranteed consensus and optimality\nin decentralized nonconvex optimization under multiple local updates, in\ncontrast to prior results that only ensure optimality of the average state. We\nprove that MILE achieves an $O(1/T)$ convergence rate under both exact and\nstochastic gradients, while requiring only a single variable exchange per\ninteracting agent pair, minimizing communication and memory costs. Numerical\nexperiments on benchmark datasets confirm its effectiveness.",
      "url": "http://arxiv.org/abs/2511.05242v1",
      "published_time_eastern_timestamp": 1762523455.0
    },
    {
      "title": "A differentiable model of supply-chain shocks",
      "summary": "Modelling how shocks propagate in supply chains is an increasingly important\nchallenge in economics. Its relevance has been highlighted in recent years by\nevents such as Covid-19 and the Russian invasion of Ukraine. Agent-based models\n(ABMs) are a promising approach for this problem. However, calibrating them is\nhard. We show empirically that it is possible to achieve speed ups of over 3\norders of magnitude when calibrating ABMs of supply networks by running them on\nGPUs and using automatic differentiation, compared to non-differentiable\nbaselines. This opens the door to scaling ABMs to model the whole global supply\nnetwork.",
      "url": "http://arxiv.org/abs/2511.05231v1",
      "published_time_eastern_timestamp": 1762522072.0
    },
    {
      "title": "Emergence from Emergence: Financial Market Simulation via Learning with\n  Heterogeneous Preferences",
      "summary": "Agent-based models help explain stock price dynamics as emergent phenomena\ndriven by interacting investors. In this modeling tradition, investor behavior\nhas typically been captured by two distinct mechanisms -- learning and\nheterogeneous preferences -- which have been explored as separate paradigms in\nprior studies. However, the impact of their joint modeling on the resulting\ncollective dynamics remains largely unexplored. We develop a multi-agent\nreinforcement learning framework in which agents endowed with heterogeneous\nrisk aversion, time discounting, and information access collectively learn\ntrading strategies within a unified shared-policy framework. The experiment\nreveals that (i) learning with heterogeneous preferences drives agents to\ndevelop strategies aligned with their individual traits, fostering behavioral\ndifferentiation and niche specialization within the market, and (ii) the\ninteractions by the differentiated agents are essential for the emergence of\nrealistic market dynamics such as fat-tailed price fluctuations and volatility\nclustering. This study presents a constructive paradigm for financial market\nmodeling in which the joint design of heterogeneous preferences and learning\nmechanisms enables two-stage emergence: individual behavior and the collective\nmarket dynamics.",
      "url": "http://arxiv.org/abs/2511.05207v1",
      "published_time_eastern_timestamp": 1762520067.0
    },
    {
      "title": "Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic\n  Interactive Learning in a Shared Latent Space",
      "summary": "Today's autonomous agents can understand free-form natural language\ninstructions and execute long-horizon tasks in a manner akin to human-level\nreasoning. These capabilities are mostly driven by large-scale pre-trained\nfoundation models (FMs). However, the approaches with which these models are\ngrounded for human-robot interaction (HRI) perpetuate a master-apprentice\nmodel, where the apprentice (embodied agent) passively receives and executes\nthe master's (human's) commands without reciprocal learning. This reactive\ninteraction approach does not capture the co-adaptive dynamics inherent in\neveryday multi-turn human-human interactions. To address this, we propose a\nSymbiotic Interactive Learning (SIL) approach that enables both the master and\nthe apprentice to co-adapt through mutual, bidirectional interactions. We\nformalised SIL as a co-adaptation process within a shared latent task space,\nwhere the agent and human maintain joint belief states that evolve based on\ninteraction history. This enables the agent to move beyond reactive execution\nto proactive clarification, adaptive suggestions, and shared plan refinement.\nTo realise these novel behaviours, we leveraged pre-trained FMs for spatial\nperception and reasoning, alongside a lightweight latent encoder that grounds\nthe models' outputs into task-specific representations. Furthermore, to ensure\nstability as the tasks evolve, we augment SIL with a memory architecture that\nprevents the forgetting of learned task-space representations. We validate SIL\non both simulated and real-world embodied tasks, including instruction\nfollowing, information retrieval, query-oriented reasoning, and interactive\ndialogues. Demos and resources are public\nat:~\\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.",
      "url": "http://arxiv.org/abs/2511.05203v1",
      "published_time_eastern_timestamp": 1762519387.0
    },
    {
      "title": "Cybersecurity AI in OT: Insights from an AI Top-10 Ranker in the Dragos\n  OT CTF 2025",
      "summary": "Operational Technology (OT) cybersecurity increasingly relies on rapid\nresponse across malware analysis, network forensics, and reverse engineering\ndisciplines. We examine the performance of Cybersecurity AI (CAI), powered by\nthe \\texttt{alias1} model, during the Dragos OT CTF 2025 -- a 48-hour\nindustrial control system (ICS) competition with more than 1,000 teams. Using\nCAI telemetry and official leaderboard data, we quantify CAI's trajectory\nrelative to the leading human-operated teams. CAI reached Rank~1 between\ncompetition hours 7.0 and 8.0, crossed 10,000 points at 5.42~hours\n(1,846~pts/h), and completed 32 of the competition's 34 challenges before\nautomated operations were paused at hour~24 with a final score of 18,900 points\n(6th place). The top-3 human teams solved 33 of 34 challenges, collectively\nleaving only the 600-point ``Kiddy Tags -- 1'' unsolved; they were also the\nonly teams to clear the 1,000-point ``Moot Force'' binary. The top-5 human\nteams averaged 1,347~pts/h to the same milestone, marking a 37\\% velocity\nadvantage for CAI. We analyse time-resolved scoring, category coverage, and\nsolve cadence. The evidence indicates that a mission-configured AI agent can\nmatch or exceed expert human crews in early-phase OT incident response while\nremaining subject to practical limits in sustained, multi-day operations.",
      "url": "http://arxiv.org/abs/2511.05119v1",
      "published_time_eastern_timestamp": 1762509851.0
    },
    {
      "title": "Tunable Passivity Control for Centralized Multiport Networked Systems",
      "summary": "Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key\narchitecture with applications in several complex network systems, such as\nmultilateral telerobotics and multi-agent control. These systems consist of a\nhub node/subsystem connecting with multiple remote nodes/subsystems via a\nnetworked architecture. One challenge for this system is stability, which can\nbe affected by non-ideal network artifacts. Conventional passivity-based\napproaches can stabilize the system under specialized applications like\nsmall-scale networked systems. However, those conventional passive stabilizers\nhave several restrictions, such as distributing compensation across subsystems\nin a decentralized manner, limiting flexibility, and, at the same time, relying\non the restrictive assumptions of node passivity. This paper synthesizes a\ncentralized optimal passivity-based stabilization framework for CMND systems.\nIt consists of a centralized passivity observer monitoring overall energy flow\nand an optimal passivity controller that distributes the just-needed\ndissipation among various nodes, guaranteeing strict passivity and, thus, L2\nstability. The proposed data-driven model-free approach, i.e., Tunable\nCentralized Optimal Passivity Control (TCoPC), optimizes total performance\nbased on the prescribed dissipation distribution strategy while ensuring\nstability. The controller can put high dissipation loads on some sub-networks\nwhile relaxing the dissipation on other nodes. Simulation results demonstrate\nthe proposed frameworks performance in a complex task under different\ntime-varying delay scenarios while relaxing the remote nodes minimum phase and\npassivity assumption, enhancing the scalability and generalizability.",
      "url": "http://arxiv.org/abs/2511.05026v1",
      "published_time_eastern_timestamp": 1762498644.0
    },
    {
      "title": "Multi-agent Coordination via Flow Matching",
      "summary": "This work presents MAC-Flow, a simple yet expressive framework for\nmulti-agent coordination. We argue that requirements of effective coordination\nare twofold: (i) a rich representation of the diverse joint behaviors present\nin offline data and (ii) the ability to act efficiently in real time. However,\nprior approaches often sacrifice one for the other, i.e., denoising\ndiffusion-based solutions capture complex coordination but are computationally\nslow, while Gaussian policy-based solutions are fast but brittle in handling\nmulti-agent interaction. MAC-Flow addresses this trade-off by first learning a\nflow-based representation of joint behaviors, and then distilling it into\ndecentralized one-step policies that preserve coordination while enabling fast\nexecution. Across four different benchmarks, including $12$ environments and\n$34$ datasets, MAC-Flow alleviates the trade-off between performance and\ncomputational cost, specifically achieving about $\\boldsymbol{\\times14.5}$\nfaster inference compared to diffusion-based MARL methods, while maintaining\ngood performance. At the same time, its inference speed is similar to that of\nprior Gaussian policy-based offline multi-agent reinforcement learning (MARL)\nmethods.",
      "url": "http://arxiv.org/abs/2511.05005v1",
      "published_time_eastern_timestamp": 1762496672.0
    },
    {
      "title": "On the Coordination of Value-Maximizing Bidders",
      "summary": "While the auto-bidding literature predominantly considers independent\nbidding, we investigate the coordination problem among multiple auto-bidders in\nonline advertising platforms. Two motivating scenarios are: collaborative\nbidding among multiple distinct bidders managed by a third-party bidding agent,\nand strategic bid selection for multiple ad campaigns managed by a single\nadvertiser. We formalize this coordination problem as a theoretical model and\ndemonstrate that a straightforward coordination mechanism, where only the\nhighest-value bidder competes with outside bids, strictly dominates independent\nbidding, improving both Return-on-Spend (RoS) compliance and the total value\naccrued for each participating auto-bidder or ad campaign. Additionally, our\nsimulations on synthetic and real-world datasets support the theoretical result\nthat coordinated mechanism outperforms independent bidding. These findings\nhighlight both the theoretical potential and the practical robustness of\ncoordination in auto-bidding in online auctions.",
      "url": "http://arxiv.org/abs/2511.04993v1",
      "published_time_eastern_timestamp": 1762493724.0
    },
    {
      "title": "iFlyBot-VLM Technical Report",
      "summary": "We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used\nto improve the domain of Embodied Intelligence. The central objective of\niFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional\nenvironmental perception and low-level robotic motion control. To this end, the\nmodel abstracts complex visual and spatial information into a body-agnostic and\ntransferable Operational Language, thereby enabling seamless perception-action\nclosed-loop coordination across diverse robotic platforms. The architecture of\niFlyBot-VLM is systematically designed to realize four key functional\ncapabilities essential for embodied intelligence: 1) Spatial Understanding and\nMetric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and\nControl Parameter Generation; 4) Task Planning and Skill Sequencing. We\nenvision iFlyBot-VLM as a scalable and generalizable foundation model for\nembodied AI, facilitating the progression from specialized task-oriented\nsystems toward generalist, cognitively capable agents. We conducted evaluations\non 10 current mainstream embodied intelligence-related VLM benchmark datasets,\nsuch as Blink and Where2Place, and achieved optimal performance while\npreserving the model's general capabilities. We will publicly release both the\ntraining data and model weights to foster further research and development in\nthe field of Embodied Intelligence.",
      "url": "http://arxiv.org/abs/2511.04976v1",
      "published_time_eastern_timestamp": 1762489635.0
    }
  ]
}
{
  "last_updated": "2025-07-19T21:09:02.094815-04:00",
  "papers": [
    {
      "title": "A Survey of Context Engineering for Large Language Models",
      "summary": "The performance of Large Language Models (LLMs) is fundamentally determined\nby the contextual information provided during inference. This survey introduces\nContext Engineering, a formal discipline that transcends simple prompt design\nto encompass the systematic optimization of information payloads for LLMs. We\npresent a comprehensive taxonomy decomposing Context Engineering into its\nfoundational components and the sophisticated implementations that integrate\nthem into intelligent systems. We first examine the foundational components:\ncontext retrieval and generation, context processing and context management. We\nthen explore how these components are architecturally integrated to create\nsophisticated system implementations: retrieval-augmented generation (RAG),\nmemory systems and tool-integrated reasoning, and multi-agent systems. Through\nthis systematic analysis of over 1300 research papers, our survey not only\nestablishes a technical roadmap for the field but also reveals a critical\nresearch gap: a fundamental asymmetry exists between model capabilities. While\ncurrent models, augmented by advanced context engineering, demonstrate\nremarkable proficiency in understanding complex contexts, they exhibit\npronounced limitations in generating equally sophisticated, long-form outputs.\nAddressing this gap is a defining priority for future research. Ultimately,\nthis survey provides a unified framework for both researchers and engineers\nadvancing context-aware AI.",
      "url": "http://arxiv.org/abs/2507.13334v1",
      "published_time_eastern_timestamp": 1752774636.0
    },
    {
      "title": "N Bugs on a Circle",
      "summary": "We describe and analyze a generalization of the classic ``Four Bugs on a\nSquare'' cyclic pursuit problem. Instead of allowing the bugs to spiral towards\none another, we constrain $N$ bugs to the perimeter of the unit circle.\nDepending on their configuration, each bug moves either clockwise or\ncounterclockwise with a constant angular speed, or remains stationary. Unlike\nthe original problem where bugs always coalesce, this generalization produces\nthree possible steady states: all bugs coalescing to a single point, clusters\nof bugs located at two antipodal points, or bugs entering a stable infinite\nchase cycle where they never meet. We analyze the stability of these steady\nstates and calculate the probability that randomly initialized bugs reach each\nstate. For $N \\leq 4$, we derive exact analytical expressions for these\nprobabilities. For larger values, we employ Monte Carlo simulations to estimate\nthe probability of coalescing, finding it approximately follows an inverse\nsquare root relationship with the number of bugs. This generalization reveals\nrich dynamical behaviors that are absent in the classic problem. Our analysis\nprovides insight into how restricting the bugs to the circle's perimeter\nfundamentally alters the long-term behavior of pursuing agents compared to\nunrestricted pursuit problems.",
      "url": "http://arxiv.org/abs/2507.13333v1",
      "published_time_eastern_timestamp": 1752774622.0
    },
    {
      "title": "Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis",
      "summary": "Automated generation of high-quality media presentations is challenging,\nrequiring robust content extraction, narrative planning, visual design, and\noverall quality optimization. Existing methods often produce presentations with\nlogical inconsistencies and suboptimal layouts, thereby struggling to meet\nprofessional standards. To address these challenges, we introduce RCPS\n(Reflective Coherent Presentation Synthesis), a novel framework integrating\nthree key components: (1) Deep Structured Narrative Planning; (2) Adaptive\nLayout Generation; (3) an Iterative Optimization Loop. Additionally, we propose\nPREVAL, a preference-based evaluation framework employing rationale-enhanced\nmulti-dimensional models to assess presentation quality across Content,\nCoherence, and Design. Experimental results demonstrate that RCPS significantly\noutperforms baseline methods across all quality dimensions, producing\npresentations that closely approximate human expert standards. PREVAL shows\nstrong correlation with human judgments, validating it as a reliable automated\ntool for assessing presentation quality.",
      "url": "http://arxiv.org/abs/2507.13285v1",
      "published_time_eastern_timestamp": 1752771007.0
    },
    {
      "title": "Analysis Theory of Data Economy: Dataization, Technological Progress and\n  Dynamic General Equilibrium",
      "summary": "This paper constructs a clean and efficient representative agent model of the\ndata economy from a macroeconomics perspective, in order to analyze the impact\nof datatization and technological progress on the dynamic general equilibrium\nof 'consumption-capital', and the catalysis effect of datatization on\ntechnological progress. We first set the data in production comes from\ndatatization of the total output of the society and is exponentially\nfunctionally related to the technology. Secondly, the data production function\nis used to solve the optimization problem for firms and households and to\nconstruct a dynamic general equilibrium of 'consumption-capital' based on the\nendogenous interest rate solved by maximizing the returns of firms. Finally, by\nusing numerical simulation and phase diagram analysis, we find that the effects\nof increasing datatization and encouraging technological progress each exhibit\ndifferent nonlinear characteristics for equilibrium capital and equilibrium\nconsumption, we thus conclude that datatization enables the positive effects of\ntechnological progress on economic development to be more rapid and persistent.\nWe select two types of Chinese policies regarding data openness to represent\nthe role of datatization, and demonstrate the catalysis role of datatization\nfor the development of the digital economy by setting up difference in\ndifference (DID) experiments, which provide persuasive evidence for the\ntheoretical interpretation of the paper.",
      "url": "http://arxiv.org/abs/2507.13274v1",
      "published_time_eastern_timestamp": 1752769765.0
    },
    {
      "title": "RemVerse: Supporting Reminiscence Activities for Older Adults through\n  AI-Assisted Virtual Reality",
      "summary": "Reminiscence activities, which involve recalling and sharing past\nexperiences, have proven beneficial for improving cognitive function, mood, and\noverall well-being. However, urbanization has led to the disappearance of\nfamiliar environments, removing visual and audio cues for effective\nreminiscence. While old photos can serve as visual cues to aid reminiscence, it\nis challenging for people to reconstruct the reminisced content and environment\nthat are not in the photos. Virtual reality (VR) and artificial intelligence\n(AI) offer the ability to reconstruct an immersive environment with dynamic\ncontent and to converse with people to help them gradually reminisce. We\ndesigned RemVerse, an AI-empowered VR prototype aimed to support reminiscence\nactivities. Integrating generative models and AI agent into a VR environment,\nRemVerse helps older adults reminisce with AI-generated visual cues and\ninteractive dialogues. Our user study with 14 older adults showed that RemVerse\neffectively supported reminiscence activities by triggering, concretizing, and\ndeepening personal memories, while fostering increased engagement and autonomy\namong older adults. Based on our findings, we proposed design implications to\nmake reminiscence activities in AI-assisted VR more accessible and engaging for\nolder adults.",
      "url": "http://arxiv.org/abs/2507.13247v1",
      "published_time_eastern_timestamp": 1752767738.0
    },
    {
      "title": "GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems",
      "summary": "Multi-agent systems built on language models have shown strong performance on\ncollaborative reasoning tasks. However, existing evaluations focus only on the\ncorrectness of the final output, overlooking how inefficient communication and\npoor coordination contribute to redundant reasoning and higher computational\ncosts. We introduce GEMMAS, a graph-based evaluation framework that analyzes\nthe internal collaboration process by modeling agent interactions as a directed\nacyclic graph. To capture collaboration quality, we propose two process-level\nmetrics: Information Diversity Score (IDS) to measure semantic variation in\ninter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant\nreasoning paths. We evaluate GEMMAS across five benchmarks and highlight\nresults on GSM8K, where systems with only a 2.1% difference in accuracy differ\nby 12.8% in IDS and 80% in UPR, revealing substantial variation in internal\ncollaboration. These findings demonstrate that outcome-only metrics are\ninsufficient for evaluating multi-agent performance and highlight the\nimportance of process-level diagnostics in designing more interpretable and\nresource-efficient collaborative AI systems.",
      "url": "http://arxiv.org/abs/2507.13190v1",
      "published_time_eastern_timestamp": 1752764360.0
    },
    {
      "title": "Black Box Deployed -- Functional Criteria for Artificial Moral Agents in\n  the LLM Era",
      "summary": "The advancement of powerful yet opaque large language models (LLMs)\nnecessitates a fundamental revision of the philosophical criteria used to\nevaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the\nassumption of transparent architectures, which LLMs defy due to their\nstochastic outputs and opaque internal states. This paper argues that\ntraditional ethical criteria are pragmatically obsolete for LLMs due to this\nmismatch. Engaging with core themes in the philosophy of technology, this paper\nproffers a revised set of ten functional criteria to evaluate LLM-based\nartificial moral agents: moral concordance, context sensitivity, normative\nintegrity, metaethical awareness, system resilience, trustworthiness,\ncorrigibility, partial transparency, functional autonomy, and moral\nimagination. These guideposts, applied to what we term \"SMA-LLS\" (Simulating\nMoral Agency through Large Language Systems), aim to steer AMAs toward greater\nalignment and beneficial societal integration in the coming years. We\nillustrate these criteria using hypothetical scenarios involving an autonomous\npublic bus (APB) to demonstrate their practical applicability in morally\nsalient contexts.",
      "url": "http://arxiv.org/abs/2507.13175v1",
      "published_time_eastern_timestamp": 1752763169.0
    },
    {
      "title": "Aligning Humans and Robots via Reinforcement Learning from Implicit\n  Human Feedback",
      "summary": "Conventional reinforcement learning (RL) ap proaches often struggle to learn\neffective policies under sparse reward conditions, necessitating the manual\ndesign of complex, task-specific reward functions. To address this limitation,\nrein forcement learning from human feedback (RLHF) has emerged as a promising\nstrategy that complements hand-crafted rewards with human-derived evaluation\nsignals. However, most existing RLHF methods depend on explicit feedback\nmechanisms such as button presses or preference labels, which disrupt the\nnatural interaction process and impose a substantial cognitive load on the\nuser. We propose a novel reinforcement learning from implicit human feedback\n(RLIHF) framework that utilizes non-invasive electroencephalography (EEG)\nsignals, specifically error-related potentials (ErrPs), to provide continuous,\nimplicit feedback without requiring explicit user intervention. The proposed\nmethod adopts a pre-trained decoder to transform raw EEG signals into\nprobabilistic reward components, en abling effective policy learning even in\nthe presence of sparse external rewards. We evaluate our approach in a\nsimulation environment built on the MuJoCo physics engine, using a Kinova Gen2\nrobotic arm to perform a complex pick-and-place task that requires avoiding\nobstacles while manipulating target objects. The results show that agents\ntrained with decoded EEG feedback achieve performance comparable to those\ntrained with dense, manually designed rewards. These findings validate the\npotential of using implicit neural feedback for scalable and human-aligned\nreinforcement learning in interactive robotics.",
      "url": "http://arxiv.org/abs/2507.13171v1",
      "published_time_eastern_timestamp": 1752762912.0
    },
    {
      "title": "Prompt Injection 2.0: Hybrid AI Threats",
      "summary": "Prompt injection attacks, where malicious input is designed to manipulate AI\nsystems into ignoring their original instructions and following unauthorized\ncommands instead, were first discovered by Preamble, Inc. in May 2022 and\nresponsibly disclosed to OpenAI. Over the last three years, these attacks have\ncontinued to pose a critical security threat to LLM-integrated systems. The\nemergence of agentic AI systems, where LLMs autonomously perform multistep\ntasks through tools and coordination with other agents, has fundamentally\ntransformed the threat landscape. Modern prompt injection attacks can now\ncombine with traditional cybersecurity exploits to create hybrid threats that\nsystematically evade traditional security controls. This paper presents a\ncomprehensive analysis of Prompt Injection 2.0, examining how prompt injections\nintegrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF),\nand other web security vulnerabilities to bypass traditional security measures.\nWe build upon Preamble's foundational research and mitigation technologies,\nevaluating them against contemporary threats, including AI worms, multi-agent\ninfections, and hybrid cyber-AI attacks. Our analysis incorporates recent\nbenchmarks that demonstrate how traditional web application firewalls, XSS\nfilters, and CSRF tokens fail against AI-enhanced attacks. We also present\narchitectural solutions that combine prompt isolation, runtime security, and\nprivilege separation with novel threat detection capabilities.",
      "url": "http://arxiv.org/abs/2507.13169v1",
      "published_time_eastern_timestamp": 1752762816.0
    },
    {
      "title": "SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on\n  Multimodal Large Language Models",
      "summary": "Recent advances in vision-language navigation (VLN) were mainly attributed to\nemerging large language models (LLMs). These methods exhibited excellent\ngeneralization capabilities in instruction understanding and task reasoning.\nHowever, they were constrained by the fixed knowledge bases and reasoning\nabilities of LLMs, preventing fully incorporating experiential knowledge and\nthus resulting in a lack of efficient evolutionary capacity. To address this,\nwe drew inspiration from the evolution capabilities of natural agents, and\nproposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the\nability to continuously evolve during testing. To the best of our knowledge, it\nwas the first time that an multimodal LLM-powered self-evolving VLN framework\nwas proposed. Specifically, SE-VLN comprised three core modules, i.e., a\nhierarchical memory module to transfer successful and failure cases into\nreusable knowledge, a retrieval-augmented thought-based reasoning module to\nretrieve experience and enable multi-step decision-making, and a reflection\nmodule to realize continual evolution. Comprehensive tests illustrated that the\nSE-VLN achieved navigation success rates of 57% and 35.2% in unseen\nenvironments, representing absolute performance improvements of 23.9% and 15.0%\nover current state-of-the-art methods on R2R and REVERSE datasets,\nrespectively. Moreover, the SE-VLN showed performance improvement with\nincreasing experience repository, elucidating its great potential as a\nself-evolving agent framework for VLN.",
      "url": "http://arxiv.org/abs/2507.13152v1",
      "published_time_eastern_timestamp": 1752761630.0
    },
    {
      "title": "RIDAS: A Multi-Agent Framework for AI-RAN with Representation- and\n  Intention-Driven Agents",
      "summary": "Sixth generation (6G) networks demand tight integration of artificial\nintelligence (AI) into radio access networks (RANs) to meet stringent quality\nof service (QoS) and resource efficiency requirements. Existing solutions\nstruggle to bridge the gap between high level user intents and the low level,\nparameterized configurations required for optimal performance. To address this\nchallenge, we propose RIDAS, a multi agent framework composed of representation\ndriven agents (RDAs) and an intention driven agent (IDA). RDAs expose open\ninterface with tunable control parameters (rank and quantization bits, enabling\nexplicit trade) offs between distortion and transmission rate. The IDA employs\na two stage planning scheme (bandwidth pre allocation and reallocation) driven\nby a large language model (LLM) to map user intents and system state into\noptimal RDA configurations. Experiments demonstrate that RIDAS supports 44.71\\%\nmore users than WirelessAgent under equivalent QoS constraints. These results\nvalidate ability of RIDAS to capture user intent and allocate resources more\nefficiently in AI RAN environments.",
      "url": "http://arxiv.org/abs/2507.13140v1",
      "published_time_eastern_timestamp": 1752760960.0
    },
    {
      "title": "Governance, productivity and economic development",
      "summary": "This paper explores the interplay between transfer policies, R\\&D,\ncorruption, and economic development using a general equilibrium model with\nheterogeneous agents and a government. The government collects taxes,\nredistributes fiscal revenues, and undertakes public investment (in R\\&D,\ninfrastructure, etc.). Corruption is modeled as a fraction of tax revenues that\nis siphoned off and removed from the economy. We first establish the existence\nof a political-economic equilibrium. Then, using an analytically tractable\nframework with two private agents, we examine the effects of corruption and\nevaluate the impact of various policies, including redistribution and\ninnovation-led strategies.",
      "url": "http://arxiv.org/abs/2507.13099v1",
      "published_time_eastern_timestamp": 1752758011.0
    },
    {
      "title": "iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent\n  Requirements Development",
      "summary": "Requirements development is a critical phase as it is responsible for\nproviding a clear understanding of what stakeholders need. It involves\ncollaboration among stakeholders to extract explicit requirements and address\npotential conflicts, which is time-consuming and labor-intensive. Recently,\nmulti-agent systems for software development have attracted much attention.\nHowever, existing research provides limited support for requirements\ndevelopment and overlooks the injection of human knowledge into agents and the\nhuman-agent collaboration. % To address these issues, this paper proposes a\nknowledge-driven multi-agent framework for intelligent requirement development,\nnamed iReDev. iReDev features: iReDev consists of six knowledge-driven agents\nto support the entire requirements development. They collaboratively perform\nvarious tasks to produce a software requirements specification. iReDev focuses\non integrating human knowledge for agents, enabling them to simulate real-world\nstakeholders. iReDev uses an event-driven communication mechanism based on an\nartifact pool. Agents continuously monitor the pool and autonomously trigger\nthe next action based on its changes, enabling iReDev to handle new\nrequirements quickly. iReDev introduces a human-in-the-loop mechanism to\nsupport human-agent collaboration, ensuring that the generated artifacts align\nwith the expectations of stakeholders. We evaluated the generated artifacts and\nresults show that iReDev outperforms existing baselines in multiple aspects. We\nfurther envision three key directions and hope this work can facilitate the\ndevelopment of intelligent requirements development.",
      "url": "http://arxiv.org/abs/2507.13081v1",
      "published_time_eastern_timestamp": 1752756667.0
    },
    {
      "title": "Intelligent Virtual Sonographer (IVS): Enhancing Physician-Robot-Patient\n  Communication",
      "summary": "The advancement and maturity of large language models (LLMs) and robotics\nhave unlocked vast potential for human-computer interaction, particularly in\nthe field of robotic ultrasound. While existing research primarily focuses on\neither patient-robot or physician-robot interaction, the role of an intelligent\nvirtual sonographer (IVS) bridging physician-robot-patient communication\nremains underexplored. This work introduces a conversational virtual agent in\nExtended Reality (XR) that facilitates real-time interaction between\nphysicians, a robotic ultrasound system(RUS), and patients. The IVS agent\ncommunicates with physicians in a professional manner while offering empathetic\nexplanations and reassurance to patients. Furthermore, it actively controls the\nRUS by executing physician commands and transparently relays these actions to\nthe patient. By integrating LLM-powered dialogue with speech-to-text,\ntext-to-speech, and robotic control, our system enhances the efficiency,\nclarity, and accessibility of robotic ultrasound acquisition. This work\nconstitutes a first step toward understanding how IVS can bridge communication\ngaps in physician-robot-patient interaction, providing more control and\ntherefore trust into physician-robot interaction while improving patient\nexperience and acceptance of robotic ultrasound.",
      "url": "http://arxiv.org/abs/2507.13052v1",
      "published_time_eastern_timestamp": 1752755101.0
    },
    {
      "title": "What Can Robots Teach Us About Trust and Reliance? An interdisciplinary\n  dialogue between Social Sciences and Social Robotics",
      "summary": "As robots find their way into more and more aspects of everyday life,\nquestions around trust are becoming increasingly important. What does it mean\nto trust a robot? And how should we think about trust in relationships that\ninvolve both humans and non-human agents? While the field of Human-Robot\nInteraction (HRI) has made trust a central topic, the concept is often\napproached in fragmented ways. At the same time, established work in sociology,\nwhere trust has long been a key theme, is rarely brought into conversation with\ndevelopments in robotics. This article argues that we need a more\ninterdisciplinary approach. By drawing on insights from both social sciences\nand social robotics, we explore how trust is shaped, tested and made visible.\nOur goal is to open up a dialogue between disciplines and help build a more\ngrounded and adaptable framework for understanding trust in the evolving world\nof human-robot interaction.",
      "url": "http://arxiv.org/abs/2507.13041v1",
      "published_time_eastern_timestamp": 1752754234.0
    },
    {
      "title": "MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent\n  Debate Systems",
      "summary": "Multi-agent debate (MAD) systems leverage collaborative interactions among\nlarge language models (LLMs) agents to improve reasoning capabilities. While\nrecent studies have focused on increasing the accuracy and scalability of MAD\nsystems, their security vulnerabilities have received limited attention. In\nthis work, we introduce MAD-Spear, a targeted prompt injection attack that\ncompromises a small subset of agents but significantly disrupts the overall MAD\nprocess. Manipulated agents produce multiple plausible yet incorrect responses,\nexploiting LLMs' conformity tendencies to propagate misinformation and degrade\nconsensus quality. Furthermore, the attack can be composed with other\nstrategies, such as communication attacks, to further amplify its impact by\nincreasing the exposure of agents to incorrect responses. To assess MAD's\nresilience under attack, we propose a formal definition of MAD fault-tolerance\nand develop a comprehensive evaluation framework that jointly considers\naccuracy, consensus efficiency, and scalability. Extensive experiments on five\nbenchmark datasets with varying difficulty levels demonstrate that MAD-Spear\nconsistently outperforms the baseline attack in degrading system performance.\nAdditionally, we observe that agent diversity substantially improves MAD\nperformance in mathematical reasoning tasks, which challenges prior work\nsuggesting that agent diversity has minimal impact on performance. These\nfindings highlight the urgent need to improve the security in MAD design.",
      "url": "http://arxiv.org/abs/2507.13038v1",
      "published_time_eastern_timestamp": 1752754179.0
    },
    {
      "title": "Lower Bound for Online MMS Assignment of Indivisible Chores",
      "summary": "We consider the problem of online assignment of indivisible chores under\n\\MMS\\ criteria. The previous work proves that any deterministic online\nalgorithm for chore division has a competitive ratio of at least 2. In this\nwork, we improve this bound by showing that no deterministic online algorithm\ncan obtain a competitive ratio better than $n$ for $n$ agents.",
      "url": "http://arxiv.org/abs/2507.12984v1",
      "published_time_eastern_timestamp": 1752748767.0
    },
    {
      "title": "Non-differentiable Reward Optimization for Diffusion-based Autonomous\n  Motion Planning",
      "summary": "Safe and effective motion planning is crucial for autonomous robots.\nDiffusion models excel at capturing complex agent interactions, a fundamental\naspect of decision-making in dynamic environments. Recent studies have\nsuccessfully applied diffusion models to motion planning, demonstrating their\ncompetence in handling complex scenarios and accurately predicting multi-modal\nfuture trajectories. Despite their effectiveness, diffusion models have\nlimitations in training objectives, as they approximate data distributions\nrather than explicitly capturing the underlying decision-making dynamics.\nHowever, the crux of motion planning lies in non-differentiable downstream\nobjectives, such as safety (collision avoidance) and effectiveness\n(goal-reaching), which conventional learning algorithms cannot directly\noptimize. In this paper, we propose a reinforcement learning-based training\nscheme for diffusion motion planning models, enabling them to effectively learn\nnon-differentiable objectives that explicitly measure safety and effectiveness.\nSpecifically, we introduce a reward-weighted dynamic thresholding algorithm to\nshape a dense reward signal, facilitating more effective training and\noutperforming models trained with differentiable objectives. State-of-the-art\nperformance on pedestrian datasets (CrowdNav, ETH-UCY) compared to various\nbaselines demonstrates the versatility of our approach for safe and effective\nmotion planning.",
      "url": "http://arxiv.org/abs/2507.12977v1",
      "published_time_eastern_timestamp": 1752747966.0
    },
    {
      "title": "LaViPlan : Language-Guided Visual Path Planning with RLVR",
      "summary": "Out-of-distribution (OOD) scenarios in autonomous driving refer to situations\nthat deviate from the training domain, often leading to unexpected and\npotentially hazardous behavior from planners that lack prior exposure to such\ncases. Recently, Vision-Language Models (VLMs) have been introduced into\nautonomous driving research for their promising generalization capabilities in\nOOD settings. Early studies demonstrated that VLMs could recognize OOD\nscenarios and generate user-level decisions such as \"go straight\" or \"turn\nright.\" However, a new challenge has emerged due to the misalignment between\nthe VLM's high-level decisions or visual reasoning expressed in language, and\nthe low-level predicted trajectories interpreted as actions. In this paper, we\npropose LaViPlan, a framework that leverages Reinforcement Learning with\nVerifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics.\nThis approach addresses the vision-language-action misalignment observed in\nexisting VLMs fine-tuned via supervised learning, which can recognize driving\nscenarios but often produce context-unaware decisions. Experimental results\ndemonstrate that our method improves situational awareness and decision-making\nunder OOD conditions, highlighting its potential to mitigate the misalignment\nissue. This work introduces a promising post-training paradigm for VLM agents\nin the context of autonomous driving.",
      "url": "http://arxiv.org/abs/2507.12911v1",
      "published_time_eastern_timestamp": 1752742704.0
    },
    {
      "title": "Autonomous Resource Management in Microservice Systems via Reinforcement\n  Learning",
      "summary": "This paper proposes a reinforcement learning-based method for microservice\nresource scheduling and optimization, aiming to address issues such as uneven\nresource allocation, high latency, and insufficient throughput in traditional\nmicroservice architectures. In microservice systems, as the number of services\nand the load increase, efficiently scheduling and allocating resources such as\ncomputing power, memory, and storage becomes a critical research challenge. To\naddress this, the paper employs an intelligent scheduling algorithm based on\nreinforcement learning. Through the interaction between the agent and the\nenvironment, the resource allocation strategy is continuously optimized. In the\nexperiments, the paper considers different resource conditions and load\nscenarios, evaluating the proposed method across multiple dimensions, including\nresponse time, throughput, resource utilization, and cost efficiency. The\nexperimental results show that the reinforcement learning-based scheduling\nmethod significantly improves system response speed and throughput under low\nload and high concurrency conditions, while also optimizing resource\nutilization and reducing energy consumption. Under multi-dimensional resource\nconditions, the proposed method can consider multiple objectives and achieve\noptimized resource scheduling. Compared to traditional static resource\nallocation methods, the reinforcement learning model demonstrates stronger\nadaptability and optimization capability. It can adjust resource allocation\nstrategies in real time, thereby maintaining good system performance in\ndynamically changing load and resource environments.",
      "url": "http://arxiv.org/abs/2507.12879v1",
      "published_time_eastern_timestamp": 1752739096.0
    }
  ]
}
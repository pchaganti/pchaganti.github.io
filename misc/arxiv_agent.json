{
  "last_updated": "2025-07-22T11:13:35.496324-04:00",
  "papers": [
    {
      "title": "LLM Economist: Large Population Models and Mechanism Design in\n  Multi-Agent Generative Simulacra",
      "summary": "We present the LLM Economist, a novel framework that uses agent-based\nmodeling to design and assess economic policies in strategic environments with\nhierarchical decision-making. At the lower level, bounded rational worker\nagents -- instantiated as persona-conditioned prompts sampled from U.S.\nCensus-calibrated income and demographic statistics -- choose labor supply to\nmaximize text-based utility functions learned in-context. At the upper level, a\nplanner agent employs in-context reinforcement learning to propose\npiecewise-linear marginal tax schedules anchored to the current U.S. federal\nbrackets. This construction endows economic simulacra with three capabilities\nrequisite for credible fiscal experimentation: (i) optimization of\nheterogeneous utilities, (ii) principled generation of large, demographically\nrealistic agent populations, and (iii) mechanism design -- the ultimate nudging\nproblem -- expressed entirely in natural language. Experiments with populations\nof up to one hundred interacting agents show that the planner converges near\nStackelberg equilibria that improve aggregate social welfare relative to Saez\nsolutions, while a periodic, persona-level voting procedure furthers these\ngains under decentralized governance. These results demonstrate that large\nlanguage model-based agents can jointly model, simulate, and govern complex\neconomic systems, providing a tractable test bed for policy evaluation at the\nsocietal scale to help build better civilizations.",
      "url": "http://arxiv.org/abs/2507.15815v1",
      "published_time_eastern_timestamp": 1753118474.0
    },
    {
      "title": "Density control of multi-agent swarms via bio-inspired leader-follower\n  plasticity",
      "summary": "The design of control systems for the spatial self-organization of mobile\nagents is an open challenge across several engineering domains, including swarm\nrobotics and synthetic biology. Here, we propose a bio-inspired leader-follower\nsolution, which is aware of energy constraints of mobile agents and is apt to\ndeal with large swarms. Akin to many natural systems, control objectives are\nformulated for the entire collective, and leaders and followers are allowed to\nplastically switch their role in time. We frame a density control problem,\nmodeling the agents' population via a system of nonlinear partial differential\nequations. This approach allows for a compact description that inherently\navoids the curse of dimensionality and improves analytical tractability. We\nderive analytical guarantees for the existence of desired steady-state\nsolutions and their local stability for one-dimensional and higher-dimensional\nproblems. We numerically validate our control methodology, offering support to\nthe effectiveness, robustness, and versatility of our proposed bio-inspired\ncontrol strategy.",
      "url": "http://arxiv.org/abs/2507.15781v1",
      "published_time_eastern_timestamp": 1753115775.0
    },
    {
      "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems\n  Through LLM-based Agent Intention Mining",
      "summary": "With the rise of service computing, cloud computing, and IoT, service\necosystems are becoming increasingly complex. The intricate interactions among\nintelligent agents make abnormal emergence analysis challenging, as traditional\ncausal methods focus on individual trajectories. Large language models offer\nnew possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)\nreasoning to reveal agent intentions. However, existing approaches remain\nlimited to microscopic and static analysis. This paper introduces a framework:\nEmergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic\nand interpretable emergence analysis. EAMI first employs a dual-perspective\nthought track mechanism, where an Inspector Agent and an Analysis Agent extract\nagent intentions under bounded and perfect rationality. Then, k-means\nclustering identifies phase transition points in group intentions, followed by\na Intention Temporal Emergence diagram for dynamic analysis. The experiments\nvalidate EAMI in complex online-to-offline (O2O) service system and the\nStanford AI Town experiment, with ablation studies confirming its\neffectiveness, generalizability, and efficiency. This framework provides a\nnovel paradigm for abnormal emergence and causal analysis in service\necosystems. The code is available at\nhttps://anonymous.4open.science/r/EAMI-B085.",
      "url": "http://arxiv.org/abs/2507.15770v1",
      "published_time_eastern_timestamp": 1753115209.0
    },
    {
      "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in\n  Smart Contracts",
      "summary": "Smart contracts are trustworthy, immutable, and automatically executed\nprograms on the blockchain. Their execution requires the Gas mechanism to\nensure efficiency and fairness. However, due to non-optimal coding practices,\nmany contracts contain Gas waste patterns that need to be optimized. Existing\nsolutions mostly rely on manual discovery, which is inefficient, costly to\nmaintain, and difficult to scale. Recent research uses large language models\n(LLMs) to explore new Gas waste patterns. However, it struggles to remain\ncompatible with existing patterns, often produces redundant patterns, and\nrequires manual validation/rewriting. To address this gap, we present GasAgent,\nthe first multi-agent system for smart contract Gas optimization that combines\ncompatibility with existing patterns and automated discovery/validation of new\npatterns, enabling end-to-end optimization. GasAgent consists of four\nspecialized agents, Seeker, Innovator, Executor, and Manager, that collaborate\nin a closed loop to identify, validate, and apply Gas-saving improvements.\nExperiments on 100 verified real-world contracts demonstrate that GasAgent\nsuccessfully optimizes 82 contracts, achieving an average deployment Gas\nsavings of 9.97%. In addition, our evaluation confirms its compatibility with\nexisting tools and validates the effectiveness of each module through ablation\nstudies. To assess broader usability, we further evaluate 500 contracts\ngenerated by five representative LLMs across 10 categories and find that\nGasAgent optimizes 79.8% of them, with deployment Gas savings ranging from\n4.79% to 13.93%, showing its usability as the optimization layer for\nLLM-assisted smart contract development.",
      "url": "http://arxiv.org/abs/2507.15761v1",
      "published_time_eastern_timestamp": 1753114645.0
    },
    {
      "title": "Towards physician-centered oversight of conversational diagnostic AI",
      "summary": "Recent work has demonstrated the promise of conversational AI systems for\ndiagnostic dialogue. However, real-world assurance of patient safety means that\nproviding individual diagnoses and treatment plans is considered a regulated\nactivity by licensed professionals. Furthermore, physicians commonly oversee\nother team members in such activities, including nurse practitioners (NPs) or\nphysician assistants/associates (PAs). Inspired by this, we propose a framework\nfor effective, asynchronous oversight of the Articulate Medical Intelligence\nExplorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent\nsystem that performs history taking within guardrails, abstaining from\nindividualized medical advice. Afterwards, g-AMIE conveys assessments to an\noverseeing primary care physician (PCP) in a clinician cockpit interface. The\nPCP provides oversight and retains accountability of the clinical decision.\nThis effectively decouples oversight from intake and can thus happen\nasynchronously. In a randomized, blinded virtual Objective Structured Clinical\nExamination (OSCE) of text consultations with asynchronous oversight, we\ncompared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across\n60 scenarios, g-AMIE outperformed both groups in performing high-quality\nintake, summarizing cases, and proposing diagnoses and management plans for the\noverseeing PCP to review. This resulted in higher quality composite decisions.\nPCP oversight of g-AMIE was also more time-efficient than standalone PCP\nconsultations in prior work. While our study does not replicate existing\nclinical practices and likely underestimates clinicians' capabilities, our\nresults demonstrate the promise of asynchronous oversight as a feasible\nparadigm for diagnostic AI systems to operate under expert human oversight for\nenhancing real-world care.",
      "url": "http://arxiv.org/abs/2507.15743v1",
      "published_time_eastern_timestamp": 1753113276.0
    },
    {
      "title": "General Matching Games",
      "summary": "Matching games is a one-to-one two sided market model introduced by\nGarrido-Lucero and Laraki, in which coupled agents' utilities are endogenously\ndetermined as the outcome of a strategic game. They refine the classical\npairwise stability by requiring robustness to renegotiation and provide general\nconditions under which pairwise stable and renegotiation-proof outcomes exist\nas the limit of a deferred acceptance with competitions algorithm together with\na renegotiation process. In this article, we extend their model to a general\nsetting encompassing most of one-to-many matching markets and roommates models\nand specify two frameworks under which core stable and renegotiation-proof\noutcomes exist and can be efficiently computed.",
      "url": "http://arxiv.org/abs/2507.15737v1",
      "published_time_eastern_timestamp": 1753112791.0
    },
    {
      "title": "Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems",
      "summary": "This paper introduces a novel multi-agent ski-rental problem that generalizes\nthe classical ski-rental dilemma to a group setting where agents incur\nindividual and shared costs. In our model, each agent can either rent at a\nfixed daily cost, or purchase a pass at an individual cost, with an additional\nthird option of a discounted group pass available to all. We consider scenarios\nin which agents' active days differ, leading to dynamic states as agents drop\nout of the decision process. To address this problem from different\nperspectives, we define three distinct competitive ratios: overall,\nstate-dependent, and individual rational. For each objective, we design and\nanalyze optimal deterministic and randomized policies. Our deterministic\npolicies employ state-aware threshold functions that adapt to the dynamic\nstates, while our randomized policies sample and resample thresholds from\ntailored state-aware distributions. The analysis reveals that symmetric\npolicies, in which all agents use the same threshold, outperform asymmetric\nones. Our results provide competitive ratio upper and lower bounds and extend\nclassical ski-rental insights to multi-agent settings, highlighting both\ntheoretical and practical implications for group decision-making under\nuncertainty.",
      "url": "http://arxiv.org/abs/2507.15727v1",
      "published_time_eastern_timestamp": 1753112194.0
    },
    {
      "title": "Agentic AI for autonomous anomaly management in complex systems",
      "summary": "This paper explores the potential of agentic AI in autonomously detecting and\nresponding to anomalies within complex systems, emphasizing its ability to\ntransform traditional, human-dependent anomaly management methods.",
      "url": "http://arxiv.org/abs/2507.15676v1",
      "published_time_eastern_timestamp": 1753108748.0
    },
    {
      "title": "BugScope: Learn to Find Bugs Like Human",
      "summary": "Detecting software bugs remains a fundamental challenge due to the extensive\ndiversity of real-world defects. Traditional static analysis tools often rely\non symbolic workflows, which restrict their coverage and hinder adaptability to\ncustomized bugs with diverse anti-patterns. While recent advances incorporate\nlarge language models (LLMs) to enhance bug detection, these methods continue\nto struggle with sophisticated bugs and typically operate within limited\nanalysis contexts. To address these challenges, we propose BugScope, an\nLLM-driven multi-agent system that emulates how human auditors learn new bug\npatterns from representative examples and apply that knowledge during code\nauditing. Given a set of examples illustrating both buggy and non-buggy\nbehaviors, BugScope synthesizes a retrieval strategy to extract relevant\ndetection contexts via program slicing and then constructs a tailored detection\nprompt to guide accurate reasoning by the LLM. Our evaluation on a curated\ndataset of 40 real-world bugs drawn from 21 widely-used open-source projects\ndemonstrates that BugScope achieves 87.04% precision and 90.00% recall,\nsurpassing state-of-the-art industrial tools by 0.44 in F1 score. Further\ntesting on large-scale open-source systems, including the Linux kernel,\nuncovered 141 previously unknown bugs, of which 78 have been fixed and 7\nconfirmed by developers, highlighting BugScope's substantial practical impact.",
      "url": "http://arxiv.org/abs/2507.15671v1",
      "published_time_eastern_timestamp": 1753108441.0
    },
    {
      "title": "Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a\n  new Lower Bound",
      "summary": "We study the problem of collective tree exploration in which a team of $k$\nmobile agents must collectively visit all nodes of an unknown tree in as few\nmoves as possible. The agents all start from the root and discover adjacent\nedges as they progress in the tree. Communication is distributed in the sense\nthat agents share information by reading and writing on whiteboards located at\nall nodes. Movements are asynchronous, in the sense that the speeds of all\nagents are controlled by an adversary at all times. All previous competitive\nguarantees for collective tree exploration are either distributed but\nsynchronous, or asynchronous but centralized. In contrast, we present a\ndistributed asynchronous algorithm that explores any tree of $n$ nodes and\ndepth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear\nin $D$, and a variant algorithm with a guarantee in $O(k/\\log k)(n+kD)$, i.e.,\nwith a competitive ratio in $O(k/\\log k)$. We note that our regret guarantee is\nasymptotically optimal (i.e., $1$-competitive) from the perspective of\naverage-case complexity. We then present a new general lower bound on the\ncompetitive ratio of asynchronous collective tree exploration, in\n$\\Omega(\\log^2 k)$. This lower bound applies to both the distributed and\ncentralized settings, and improves upon the previous lower bound in\n$\\Omega(\\log k)$.",
      "url": "http://arxiv.org/abs/2507.15658v1",
      "published_time_eastern_timestamp": 1753107673.0
    },
    {
      "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual\n  Pre-training",
      "summary": "Continual pre-training on small-scale task-specific data is an effective\nmethod for improving large language models in new target fields, yet it risks\ncatastrophic forgetting of their original capabilities. A common solution is to\nre-weight training data mixtures from source and target fields on a domain\nspace to achieve balanced performance. Previous domain reweighting strategies\nrely on manual designation with certain heuristics based on human intuition or\nempirical results. In this work, we prove that more general heuristics can be\nparameterized by proposing Data Mixing Agent, the first model-based, end-to-end\nframework that learns to re-weight domains. The agent learns generalizable\nheuristics through reinforcement learning on large quantities of data mixing\ntrajectories with corresponding feedback from an evaluation environment.\nExperiments in continual pre-training on math reasoning show that Data Mixing\nAgent outperforms strong baselines in achieving balanced performance across\nsource and target field benchmarks. Furthermore, it generalizes well across\nunseen source fields, target models, and domain spaces without retraining.\nDirect application to the code generation field also indicates its adaptability\nacross target domains. Further analysis showcases the agents' well-aligned\nheuristics with human intuitions and their efficiency in achieving superior\nmodel performance with less source-field data.",
      "url": "http://arxiv.org/abs/2507.15640v1",
      "published_time_eastern_timestamp": 1753106514.0
    },
    {
      "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft\n  II",
      "summary": "We present an adapter-based approach for tactical conditioning of StarCraft\nII AI agents. Current agents, while powerful, lack the ability to adapt their\nstrategies based on high-level tactical directives. Our method freezes a\npre-trained policy network (DI-Star) and attaches lightweight adapter modules\nto each action head, conditioned on a tactical tensor that encodes strategic\npreferences. By training these adapters with KL divergence constraints, we\nensure the policy maintains core competencies while exhibiting tactical\nvariations. Experimental results show our approach successfully modulates agent\nbehavior across tactical dimensions including aggression, expansion patterns,\nand technology preferences, while maintaining competitive performance. Our\nmethod enables flexible tactical control with minimal computational overhead,\noffering practical strategy customization for complex real-time strategy games.",
      "url": "http://arxiv.org/abs/2507.15618v1",
      "published_time_eastern_timestamp": 1753105326.0
    },
    {
      "title": "Why can't Epidemiology be automated (yet)?",
      "summary": "Recent advances in artificial intelligence (AI) - particularly generative AI\n- present new opportunities to accelerate, or even automate, epidemiological\nresearch. Unlike disciplines based on physical experimentation, a sizable\nfraction of Epidemiology relies on secondary data analysis and thus is\nwell-suited for such augmentation. Yet, it remains unclear which specific tasks\ncan benefit from AI interventions or where roadblocks exist. Awareness of\ncurrent AI capabilities is also mixed. Here, we map the landscape of\nepidemiological tasks using existing datasets - from literature review to data\naccess, analysis, writing up, and dissemination - and identify where existing\nAI tools offer efficiency gains. While AI can increase productivity in some\nareas such as coding and administrative tasks, its utility is constrained by\nlimitations of existing AI models (e.g. hallucinations in literature reviews)\nand human systems (e.g. barriers to accessing datasets). Through examples of\nAI-generated epidemiological outputs, including fully AI-generated papers, we\ndemonstrate that recently developed agentic systems can now design and execute\nepidemiological analysis, albeit to varied quality (see\nhttps://github.com/edlowther/automated-epidemiology). Epidemiologists have new\nopportunities to empirically test and benchmark AI systems; realising the\npotential of AI will require two-way engagement between epidemiologists and\nengineers.",
      "url": "http://arxiv.org/abs/2507.15617v1",
      "published_time_eastern_timestamp": 1753105312.0
    },
    {
      "title": "DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP\n  Solving",
      "summary": "Primal heuristics play a critical role in improving the efficiency of mixed\ninteger programming (MILP) solvers. As large language models (LLMs) have\ndemonstrated superior code generation abilities, recent MILP works are devoted\nto leveraging the evolutionary computation approaches with LLMs to generate\neffective primal heuristics. Although the generated heuristics have achieved\nbetter solving performance than the hand-crafted ones with little adaptability,\nthe advantage of current LLM-based methods is limited to few MILP instances in\none problem class, as they fail to capture the instance characteristics in the\nproblem class (the MILP instances generated from the same mathematical model\nare defined as a problem class). Since MILP instances often differ\nsignificantly in structure and feature distribution, the neglect of their\ncharacteristics in the evolution process results in poor generalization within\nthe same problem class. To overcome this challenge, we propose a data-algorithm\nco-evolution framework (DHEvo) that iteratively selects representative\ninstances and evolves corresponding heuristics. With the initial instance\ndistribution, we develop an LLM-based multi-agent system to generate data-code\npairs simultaneously. These data-code pairs are iteratively refined based on\ntheir fitness scores, leading to the identification of the most effective\nheuristic over the entire problem class. Extensive experiments across diverse\nMILP benchmarks demonstrate that our approach significantly outperforms both\nhuman-designed heuristics and existing LLM-based methods.",
      "url": "http://arxiv.org/abs/2507.15615v1",
      "published_time_eastern_timestamp": 1753105219.0
    },
    {
      "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking\n  Scenario",
      "summary": "Current research on decision-making in safety-critical scenarios often relies\non inefficient data-driven scenario generation or specific modeling approaches,\nwhich fail to capture corner cases in real-world contexts. To address this\nissue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,\nwhere background vehicles with interference capabilities are treated as\nred-team agents. Through active interference and exploration, red-team vehicles\ncan uncover corner cases outside the data distribution. The framework uses a\nConstraint Graph Representation Markov Decision Process, ensuring that red-team\nvehicles comply with safety rules while continuously disrupting the autonomous\nvehicles (AVs). A policy threat zone model is constructed to quantify the\nthreat posed by red-team vehicles to AVs, inducing more extreme actions to\nincrease the danger level of the scenario. Experimental results show that the\nproposed framework significantly impacts AVs decision-making safety and\ngenerates various corner cases. This method also offers a novel direction for\nresearch in safety-critical scenarios.",
      "url": "http://arxiv.org/abs/2507.15587v1",
      "published_time_eastern_timestamp": 1753103329.0
    },
    {
      "title": "FlowForge: Guiding the Creation of Multi-agent Workflows with Design\n  Space Visualization as a Thinking Scaffold",
      "summary": "Multi-agent workflows have become an effective strategy for tackling\ncomplicated tasks by decomposing them into multiple sub-tasks and assigning\nthem to specialized agents. However, designing optimal workflows remains\nchallenging due to the vast and intricate design space. Current practices rely\nheavily on the intuition and expertise of practitioners, often resulting in\ndesign fixation or an unstructured, time-consuming exploration of\ntrial-and-error. To address these challenges, this work introduces FLOWFORGE,\nan interactive visualization tool to facilitate the creation of multi-agent\nworkflow through i) a structured visual exploration of the design space and ii)\nin-situ guidance informed by established design patterns. Based on formative\nstudies and literature review, FLOWFORGE organizes the workflow design process\ninto three hierarchical levels (i.e., task planning, agent assignment, and\nagent optimization), ranging from abstract to concrete. This structured visual\nexploration enables users to seamlessly move from high-level planning to\ndetailed design decisions and implementations, while comparing alternative\nsolutions across multiple performance metrics. Additionally, drawing from\nestablished workflow design patterns, FLOWFORGE provides context-aware, in-situ\nsuggestions at each level as users navigate the design space, enhancing the\nworkflow creation process with practical guidance. Use cases and user studies\ndemonstrate the usability and effectiveness of FLOWFORGE, while also yielding\nvaluable insights into how practitioners explore design spaces and leverage\nguidance during workflow development.",
      "url": "http://arxiv.org/abs/2507.15559v1",
      "published_time_eastern_timestamp": 1753101548.0
    },
    {
      "title": "PhysGym: Benchmarking LLMs in Interactive Physics Discovery with\n  Controlled Priors",
      "summary": "Evaluating the scientific discovery capabilities of large language model\nbased agents, particularly how they cope with varying environmental complexity\nand utilize prior knowledge, requires specialized benchmarks currently lacking\nin the landscape. To address this gap, we introduce PhysGym, a novel benchmark\nsuite and simulation platform for rigorously assessing LLM-based scientific\nreasoning in interactive physics environments. PhysGym's primary contribution\nlies in its sophisticated control over the level of prior knowledge provided to\nthe agent. This allows researchers to dissect agent performance along axes\nincluding the complexity of the problem and the prior knowledge levels. The\nbenchmark comprises a suite of interactive simulations, where agents must\nactively probe environments, gather data sequentially under constraints and\nformulate hypotheses about underlying physical laws. PhysGym provides\nstandardized evaluation protocols and metrics for assessing hypothesis accuracy\nand model fidelity. We demonstrate the benchmark's utility by presenting\nresults from baseline LLMs, showcasing its ability to differentiate\ncapabilities based on varying priors and task complexity.",
      "url": "http://arxiv.org/abs/2507.15550v1",
      "published_time_eastern_timestamp": 1753100890.0
    },
    {
      "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics",
      "summary": "Creating an immersive and interactive theatrical experience is a long-term\ngoal in the field of interactive narrative. The emergence of large language\nmodel (LLM) is providing a new path to achieve this goal. However, existing\nLLM-based drama generation methods often result in AI agents that lack\ninitiative and cannot interact with the physical environment. Furthermore,\nthese methods typically require detailed user input to drive the drama. These\nlimitations reduce the interactivity and immersion of online real-time\nperformance. To address the above challenges, we propose HAMLET, a multi-agent\nframework focused on drama creation and online performance. Given a simple\ntopic, the framework generates a narrative blueprint, guiding the subsequent\nimprovisational performance. During the online performance, each actor is given\nan autonomous mind. This means that actors can make independent decisions based\non their own background, goals, and emotional state. In addition to\nconversations with other actors, their decisions can also change the state of\nscene props through actions such as opening a letter or picking up a weapon.\nThe change is then broadcast to other related actors, updating what they know\nand care about, which in turn influences their next action. To evaluate the\nquality of drama performance, we designed an evaluation method to assess three\nprimary aspects, including character performance, narrative quality, and\ninteraction experience. The experimental evaluation shows that HAMLET can\ncreate expressive and coherent theatrical experiences. Our code, dataset and\nmodels are available at https://github.com/HAMLET-2025/HAMLET.",
      "url": "http://arxiv.org/abs/2507.15518v1",
      "published_time_eastern_timestamp": 1753097799.0
    },
    {
      "title": "The Constitutional Controller: Doubt-Calibrated Steering of Compliant\n  Agents",
      "summary": "Ensuring reliable and rule-compliant behavior of autonomous agents in\nuncertain environments remains a fundamental challenge in modern robotics. Our\nwork shows how neuro-symbolic systems, which integrate probabilistic, symbolic\nwhite-box reasoning models with deep learning methods, offer a powerful\nsolution to this challenge. This enables the simultaneous consideration of\nexplicit rules and neural models trained on noisy data, combining the strength\nof structured reasoning with flexible representations. To this end, we\nintroduce the Constitutional Controller (CoCo), a novel framework designed to\nenhance the safety and reliability of agents by reasoning over deep\nprobabilistic logic programs representing constraints such as those found in\nshared traffic spaces. Furthermore, we propose the concept of self-doubt,\nimplemented as a probability density conditioned on doubt features such as\ntravel velocity, employed sensors, or health factors. In a real-world aerial\nmobility study, we demonstrate CoCo's advantages for intelligent autonomous\nsystems to learn appropriate doubts and navigate complex and uncertain\nenvironments safely and compliantly.",
      "url": "http://arxiv.org/abs/2507.15478v1",
      "published_time_eastern_timestamp": 1753094011.0
    },
    {
      "title": "The Emergence of Deep Reinforcement Learning for Path Planning",
      "summary": "The increasing demand for autonomous systems in complex and dynamic\nenvironments has driven significant research into intelligent path planning\nmethodologies. For decades, graph-based search algorithms, linear programming\ntechniques, and evolutionary computation methods have served as foundational\napproaches in this domain. Recently, deep reinforcement learning (DRL) has\nemerged as a powerful method for enabling autonomous agents to learn optimal\nnavigation strategies through interaction with their environments. This survey\nprovides a comprehensive overview of traditional approaches as well as the\nrecent advancements in DRL applied to path planning tasks, focusing on\nautonomous vehicles, drones, and robotic platforms. Key algorithms across both\nconventional and learning-based paradigms are categorized, with their\ninnovations and practical implementations highlighted. This is followed by a\nthorough discussion of their respective strengths and limitations in terms of\ncomputational efficiency, scalability, adaptability, and robustness. The survey\nconcludes by identifying key open challenges and outlining promising avenues\nfor future research. Special attention is given to hybrid approaches that\nintegrate DRL with classical planning techniques to leverage the benefits of\nboth learning-based adaptability and deterministic reliability, offering\npromising directions for robust and resilient autonomous navigation.",
      "url": "http://arxiv.org/abs/2507.15469v1",
      "published_time_eastern_timestamp": 1753093302.0
    }
  ]
}
{
  "last_updated": "2025-10-23T05:13:32.115469-04:00",
  "papers": [
    {
      "title": "Benchmarking World-Model Learning",
      "summary": "Model-learning agents should gather information to learn world models that\nsupport many downstream tasks and inferences, such as predicting unobserved\nstates, estimating near- and far-term consequences of actions, planning action\nsequences, and detecting changes in dynamics. Current methods for learning and\nevaluating world models diverge from this goal: training and evaluation are\nanchored to next-frame prediction, and success is scored by reward maximization\nin the same environment. We propose WorldTest, a protocol to evaluate\nmodel-learning agents that separates reward-free interaction from a scored test\nphase in a different but related environment. WorldTest is\nopen-ended$\\unicode{x2014}$models should support many different tasks unknown\nahead of time$\\unicode{x2014}$and agnostic to model representation, allowing\ncomparison across approaches. We instantiated WorldTest with AutumnBench, a\nsuite of 43 interactive grid-world environments and 129 tasks across three\nfamilies: masked-frame prediction, planning, and predicting changes to the\ncausal dynamics. We compared 517 human participants and three frontier models\non AutumnBench. We found that humans outperform the models, and scaling compute\nimproves performance only in some environments but not others. WorldTest\nprovides a novel template$\\unicode{x2014}$reward-free exploration, derived\ntests, and behavior-based scoring$\\unicode{x2014}$to evaluate what agents learn\nabout environment dynamics, and AutumnBench exposes significant headroom in\nworld-model learning.",
      "url": "http://arxiv.org/abs/2510.19788v1",
      "published_time_eastern_timestamp": 1761153798.0
    },
    {
      "title": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents",
      "summary": "LLM-based agents are increasingly moving towards proactivity: rather than\nawaiting instruction, they exercise agency to anticipate user needs and solve\nthem autonomously. However, evaluating proactivity is challenging; current\nbenchmarks are constrained to localized context, limiting their ability to test\nreasoning across sources and longer time horizons. To address this gap, we\npresent PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes\nproactivity as a pipeline of three core capabilities: (1) searching for\nunspecified issues, (2) identifying specific bottlenecks, and (3) executing\nappropriate resolutions. We apply PROBE to evaluate leading LLMs and popular\nagentic frameworks, showing that even state-of-the-art models struggle to solve\nthis benchmark. Computing our consistent measurements across frontier LLMs and\nagents, we find that the best end-to-end performance of 40% is achieved by both\nGPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative\ncapabilities of each model and analyze mutual failure modes. Our results\nhighlight the current limitations of autonomous action in agentic systems, and\nexpose promising future research directions.",
      "url": "http://arxiv.org/abs/2510.19771v1",
      "published_time_eastern_timestamp": 1761152445.0
    },
    {
      "title": "SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas",
      "summary": "In this paper, we propose SEA, a novel approach for active robot exploration\nthrough semantic map prediction and a reinforcement learning-based hierarchical\nexploration policy. Unlike existing learning-based methods that rely on\none-step waypoint prediction, our approach enhances the agent's long-term\nenvironmental understanding to facilitate more efficient exploration. We\npropose an iterative prediction-exploration framework that explicitly predicts\nthe missing areas of the map based on current observations. The difference\nbetween the actual accumulated map and the predicted global map is then used to\nguide exploration. Additionally, we design a novel reward mechanism that\nleverages reinforcement learning to update the long-term exploration\nstrategies, enabling us to construct an accurate semantic map within limited\nsteps. Experimental results demonstrate that our method significantly\noutperforms state-of-the-art exploration strategies, achieving superior\ncoverage ares of the global map within the same time constraints.",
      "url": "http://arxiv.org/abs/2510.19766v1",
      "published_time_eastern_timestamp": 1761151896.0
    },
    {
      "title": "Review of Tools for Zero-Code LLM Based Application Development",
      "summary": "Large Language Models (LLMs) are transforming software creation by enabling\nzero code development platforms. Our survey reviews recent platforms that let\nusers build applications without writing code, by leveraging LLMs as the brains\nof the development process. We adopt a broad survey methodology, categorizing\nplatforms based on key dimensions such as interface style, backend integration,\noutput type, and extensibility. We analyze both dedicated LLM based app\nbuilders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and\ngeneral no code platforms (e.g., Bubble, Glide) that integrate LLM\ncapabilities. We present a taxonomy categorizing these platforms by their\ninterface (conversational, visual, etc.), supported LLM backends, output type\n(chatbot, full application, workflow), and degree of extensibility. Core\nfeatures such as autonomous agents, memory management, workflow orchestration,\nand API integrations are in scope of the survey. We provide a detailed\ncomparison, highlighting each platform's strengths and limitations. Trade offs\n(customizability, scalability, vendor lock-in) are discussed in comparison with\ntraditional and low code development approaches. Finally, we outline future\ndirections, including multimodal interfaces, on device LLMs, and improved\norchestration for democratizing app creation with AI. Our findings indicate\nthat while zero code LLM platforms greatly reduce the barrier to creating AI\npowered applications, they still face challenges in flexibility and\nreliability. Overall, the landscape is rapidly evolving, offering exciting\nopportunities to empower non programmers to create sophisticated software.",
      "url": "http://arxiv.org/abs/2510.19747v1",
      "published_time_eastern_timestamp": 1761151276.0
    },
    {
      "title": "Misalignment Bounty: Crowdsourcing AI Agent Misbehavior",
      "summary": "Advanced AI systems sometimes act in ways that differ from human intent. To\ngather clear, reproducible examples, we ran the Misalignment Bounty: a\ncrowdsourced project that collected cases of agents pursuing unintended or\nunsafe goals. The bounty received 295 submissions, of which nine were awarded.\n  This report explains the program's motivation and evaluation criteria, and\nwalks through the nine winning submissions step by step.",
      "url": "http://arxiv.org/abs/2510.19738v1",
      "published_time_eastern_timestamp": 1761150528.0
    },
    {
      "title": "Memo: Training Memory-Efficient Embodied Agents with Reinforcement\n  Learning",
      "summary": "To enable embodied agents to operate effectively over extended timeframes, it\nis crucial to develop models that form and access memories to stay\ncontextualized in their environment. In the current paradigm of training\ntransformer-based policies for embodied sequential decision-making tasks,\nvisual inputs often overwhelm the context limits of transformers, while humans\ncan maintain and utilize a lifetime of experience compressed as memories.\nSignificant compression is possible in principle, as much of the input is\nirrelevant and can be abstracted. However, existing approaches predominantly\nfocus on either recurrent models with fixed-size memory or transformers with\nfull-context reliance. In this work, we propose Memo, a transformer-based\narchitecture and training recipe for reinforcement learning (RL) on\nmemory-intensive, long-horizon tasks. Memo incorporates the creation and\nretrieval of memory by interleaving periodic summarization tokens with the\ninputs of a model during training. We demonstrate Memo's effectiveness on a\ngridworld meta-RL benchmark and a multi-object navigation task in\nphoto-realistic indoor settings. Memo outperforms naive long-context\ntransformer baselines while being more compute and storage efficient.\nAdditionally, Memo generalizes better to longer contexts at inference time and\nremains robust in streaming settings, where historical context must be\ntruncated to fit inference constraints.",
      "url": "http://arxiv.org/abs/2510.19732v1",
      "published_time_eastern_timestamp": 1761150287.0
    },
    {
      "title": "Toward Agentic Software Engineering Beyond Code: Framing Vision, Values,\n  and Vocabulary",
      "summary": "Agentic AI is poised to usher in a seismic paradigm shift in Software\nEngineering (SE). As technologists rush head-along to make agentic AI a\nreality, SE researchers are driven to establish agentic SE as a research area.\nWhile early visions of agentic SE are primarily focused on code-related\nactivities, early empirical evidence calls for a consideration of a range of\nsocio-technical concerns to make it work in practice. This paper contributes to\nthe emerging community vision by: (a) recommending an expansion of its scope\nbeyond code, toward a 'whole of process' vision, grounding it in SE foundations\nand evolution and emerging agentic SE frameworks, (b) proposing a preliminary\nset of values and principles to guide efforts, and (c) sharing guidance on\ndesigning/using well-defined vocabulary for agentic SE. It is hoped that these\nideas will encourage community collaborations and steer the SE community\ntowards laying strong foundations of agentic SE so its not only inevitable but\nalso deliberate and desirable in the long run.",
      "url": "http://arxiv.org/abs/2510.19692v1",
      "published_time_eastern_timestamp": 1761147598.0
    },
    {
      "title": "Are Large Language Models Sensitive to the Motives Behind Communication?",
      "summary": "Human communication is motivated: people speak, write, and create content\nwith a particular communicative intent in mind. As a result, information that\nlarge language models (LLMs) and AI agents process is inherently framed by\nhumans' intentions and incentives. People are adept at navigating such nuanced\ninformation: we routinely identify benevolent or self-serving motives in order\nto decide what statements to trust. For LLMs to be effective in the real world,\nthey too must critically evaluate content by factoring in the motivations of\nthe source -- for instance, weighing the credibility of claims made in a sales\npitch. In this paper, we undertake a comprehensive study of whether LLMs have\nthis capacity for motivational vigilance. We first employ controlled\nexperiments from cognitive science to verify that LLMs' behavior is consistent\nwith rational models of learning from motivated testimony, and find they\nsuccessfully discount information from biased sources in a human-like manner.\nWe then extend our evaluation to sponsored online adverts, a more naturalistic\nreflection of LLM agents' information ecosystems. In these settings, we find\nthat LLMs' inferences do not track the rational models' predictions nearly as\nclosely -- partly due to additional information that distracts them from\nvigilance-relevant considerations. However, a simple steering intervention that\nboosts the salience of intentions and incentives substantially increases the\ncorrespondence between LLMs and the rational model. These results suggest that\nLLMs possess a basic sensitivity to the motivations of others, but generalizing\nto novel real-world settings will require further improvements to these models.",
      "url": "http://arxiv.org/abs/2510.19687v1",
      "published_time_eastern_timestamp": 1761147300.0
    },
    {
      "title": "AgentSense: LLMs Empower Generalizable and Explainable Web-Based\n  Participatory Urban Sensing",
      "summary": "Web-based participatory urban sensing has emerged as a vital approach for\nmodern urban management by leveraging mobile individuals as distributed\nsensors. However, existing urban sensing systems struggle with limited\ngeneralization across diverse urban scenarios and poor interpretability in\ndecision-making. In this work, we introduce AgentSense, a hybrid, training-free\nframework that integrates large language models (LLMs) into participatory urban\nsensing through a multi-agent evolution system. AgentSense initially employs\nclassical planner to generate baseline solutions and then iteratively refines\nthem to adapt sensing task assignments to dynamic urban conditions and\nheterogeneous worker preferences, while producing natural language explanations\nthat enhance transparency and trust. Extensive experiments across two\nlarge-scale mobility datasets and seven types of dynamic disturbances\ndemonstrate that AgentSense offers distinct advantages in adaptivity and\nexplainability over traditional methods. Furthermore, compared to single-agent\nLLM baselines, our approach outperforms in both performance and robustness,\nwhile delivering more reasonable and transparent explanations. These results\nposition AgentSense as a significant advancement towards deploying adaptive and\nexplainable urban sensing systems on the web.",
      "url": "http://arxiv.org/abs/2510.19661v1",
      "published_time_eastern_timestamp": 1761145586.0
    },
    {
      "title": "LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision\n  Language Navigation in Continuous Environments",
      "summary": "Zero-shot Vision-and-Language Navigation in Continuous Environments (VLN-CE)\nrequires an agent to navigate unseen environments based on natural language\ninstructions without any prior training. Current methods face a critical\ntrade-off: either rely on environment-specific waypoint predictors that limit\nscene generalization, or underutilize the reasoning capabilities of large\nmodels during navigation. We introduce LaViRA, a simple yet effective zero-shot\nframework that addresses this dilemma by decomposing action into a\ncoarse-to-fine hierarchy: Language Action for high-level planning, Vision\nAction for perceptual grounding, and Robot Action for robust navigation. This\nmodular decomposition allows us to leverage the distinct strengths of different\nscales of Multimodal Large Language Models (MLLMs) at each stage, creating a\nsystem that is powerful in its reasoning, grounding and practical control.\nLaViRA significantly outperforms existing state-of-the-art methods on the\nVLN-CE benchmark, demonstrating superior generalization capabilities in unseen\nenvironments, while maintaining transparency and efficiency for real-world\ndeployment.",
      "url": "http://arxiv.org/abs/2510.19655v1",
      "published_time_eastern_timestamp": 1761145096.0
    },
    {
      "title": "HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search\n  Agents in Hierarchical Rule Application",
      "summary": "Effective deep search agents must not only access open-domain and\ndomain-specific knowledge but also apply complex rules-such as legal clauses,\nmedical manuals and tariff rules. These rules often feature vague boundaries\nand implicit logic relationships, making precise application challenging for\nagents. However, this critical capability is largely overlooked by current\nagent benchmarks.\n  To fill this gap, we introduce HSCodeComp, the first realistic, expert-level\ne-commerce benchmark designed to evaluate deep search agents in hierarchical\nrule application. In this task, the deep reasoning process of agents is guided\nby these rules to predict 10-digit Harmonized System Code (HSCode) of products\nwith noisy but realistic descriptions. These codes, established by the World\nCustoms Organization, are vital for global supply chain efficiency. Built from\nreal-world data collected from large-scale e-commerce platforms, our proposed\nHSCodeComp comprises 632 product entries spanning diverse product categories,\nwith these HSCodes annotated by several human experts.\n  Extensive experimental results on several state-of-the-art LLMs, open-source,\nand closed-source agents reveal a huge performance gap: best agent achieves\nonly 46.8% 10-digit accuracy, far below human experts at 95.0%. Besides,\ndetailed analysis demonstrates the challenges of hierarchical rule application,\nand test-time scaling fails to improve performance further.",
      "url": "http://arxiv.org/abs/2510.19631v1",
      "published_time_eastern_timestamp": 1761143313.0
    },
    {
      "title": "Pragmatic Heterogeneous Collaborative Perception via Generative\n  Communication Mechanism",
      "summary": "Multi-agent collaboration enhances the perception capabilities of individual\nagents through information sharing. However, in real-world applications,\ndifferences in sensors and models across heterogeneous agents inevitably lead\nto domain gaps during collaboration. Existing approaches based on adaptation\nand reconstruction fail to support pragmatic heterogeneous collaboration due to\ntwo key limitations: (1) Intrusive retraining of the encoder or core modules\ndisrupts the established semantic consistency among agents; and (2)\naccommodating new agents incurs high computational costs, limiting scalability.\nTo address these challenges, we present a novel Generative Communication\nmechanism (GenComm) that facilitates seamless perception across heterogeneous\nmulti-agent systems through feature generation, without altering the original\nnetwork, and employs lightweight numerical alignment of spatial information to\nefficiently integrate new agents at minimal cost. Specifically, a tailored\nDeformable Message Extractor is designed to extract spatial message for each\ncollaborator, which is then transmitted in place of intermediate features. The\nSpatial-Aware Feature Generator, utilizing a conditional diffusion model,\ngenerates features aligned with the ego agent's semantic space while preserving\nthe spatial information of the collaborators. These generated features are\nfurther refined by a Channel Enhancer before fusion. Experiments conducted on\nthe OPV2V-H, DAIR-V2X and V2X-Real datasets demonstrate that GenComm\noutperforms existing state-of-the-art methods, achieving an 81\\% reduction in\nboth computational cost and parameter count when incorporating new agents. Our\ncode is available at https://github.com/jeffreychou777/GenComm.",
      "url": "http://arxiv.org/abs/2510.19618v1",
      "published_time_eastern_timestamp": 1761142520.0
    },
    {
      "title": "Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1",
      "summary": "In the quest for scientific progress, communicating research is as vital as\nthe discovery itself. Yet, researchers are often sidetracked by the manual,\nrepetitive chore of building project webpages to make their dense papers\naccessible. While automation has tackled static slides and posters, the\ndynamic, interactive nature of webpages has remained an unaddressed challenge.\nTo bridge this gap, we reframe the problem, arguing that the solution lies not\nin a single command, but in a collaborative, hierarchical process. We introduce\n$\\textbf{AutoPage}$, a novel multi-agent system that embodies this philosophy.\nAutoPage deconstructs paper-to-page creation into a coarse-to-fine pipeline\nfrom narrative planning to multimodal content generation and interactive\nrendering. To combat AI hallucination, dedicated \"Checker\" agents verify each\nstep against the source paper, while optional human checkpoints ensure the\nfinal product aligns perfectly with the author's vision, transforming the\nsystem from a mere tool into a powerful collaborative assistant. To rigorously\nvalidate our approach, we also construct $\\textbf{PageBench}$, the first\nbenchmark for this new task. Experiments show AutoPage not only generates\nhigh-quality, visually appealing pages but does so with remarkable efficiency\nin under 15 minutes for less than \\$0.1. Code and dataset will be released at\n$\\href{https://mqleet.github.io/AutoPage_ProjectPage/}{Webpage}$.",
      "url": "http://arxiv.org/abs/2510.19600v1",
      "published_time_eastern_timestamp": 1761141237.0
    },
    {
      "title": "gem5 Co-Pilot: AI Assistant Agent for Architectural Design Space\n  Exploration",
      "summary": "Generative AI is increasing the productivity of software and hardware\ndevelopment across many application domains. In this work, we utilize the power\nof Large Language Models (LLMs) to develop a co-pilot agent for assisting gem5\nusers with automating design space exploration. Computer architecture design\nspace exploration is complex and time-consuming, given that numerous parameter\nsettings and simulation statistics must be analyzed before improving the\ncurrent design. The emergence of LLMs has significantly accelerated the\nanalysis of long-text data as well as smart decision making, two key functions\nin a successful design space exploration task. In this project, we first build\ngem5 Co-Pilot, an AI agent assistant for gem5, which comes with a webpage-GUI\nfor smooth user interaction, agent automation, and result summarization. We\nalso implemented a language for design space exploration, as well as a Design\nSpace Database (DSDB). With DSDB, gem5 Co-Pilot effectively implements a\nRetrieval Augmented Generation system for gem5 design space exploration. We\nexperiment on cost-constraint optimization with four cost ranges and compare\nour results with two baseline models. Results show that gem5 Co-Pilot can\nquickly identify optimal parameters for specific design constraints based on\nperformance and cost, with limited user interaction.",
      "url": "http://arxiv.org/abs/2510.19577v1",
      "published_time_eastern_timestamp": 1761139716.0
    },
    {
      "title": "Polynomial-time Configuration Generator for Connected Unlabeled\n  Multi-Agent Pathfinding",
      "summary": "We consider Connected Unlabeled Multi-Agent Pathfinding (CUMAPF), a variant\nof MAPF where the agents must maintain connectivity at all times. This problem\nis fundamental to swarm robotics applications like self-reconfiguration and\nmarching, where standard MAPF is insufficient as it does not guarantee the\nrequired connectivity between agents. While unlabeled MAPF is tractable in\noptimization, CUMAPF is NP-hard even on highly restricted graph classes. To\ntackle this challenge, we propose PULL, a complete and polynomial-time\nalgorithm with a simple design. It is based on a rule-based one-step function\nthat computes a subsequent configuration that preserves connectivity and\nadvances towards the target configuration. PULL is lightweight, and runs in\n$O(n^2)$ time per step in 2D grid, where $n$ is the number of agents. Our\nexperiments further demonstrate its practical performance: PULL finds\ncompetitive solution qualities against trivial solutions for hundreds of\nagents, in randomly generated instances. Furthermore, we develop an eventually\noptimal solver that integrates PULL into an existing search-based MAPF\nalgorithm, providing a valuable tool for small-scale instances.",
      "url": "http://arxiv.org/abs/2510.19567v1",
      "published_time_eastern_timestamp": 1761139159.0
    },
    {
      "title": "Exponential stability of finite-$N$ consensus-based optimization",
      "summary": "We study the finite-agent behavior of Consensus-Based Optimization (CBO), a\nrecent metaheuristic for the global minimization of a function, that combines\ndrift toward a consensus estimate with stochastic exploration. While previous\nanalyses focus on asymptotic mean-field limits, we investigate the stability\nproperties of CBO for finite population size \\( N \\). Following a hierarchical\napproach, we first analyze a deterministic formulation of the algorithm and\nthen extend our results to the fully stochastic setting governed by a system of\nstochastic differential equations. Our analysis reveals that essential\nstability properties, including almost sure and mean square exponential\nconvergence, persist in both regimes and provides sharp quantitative estimates\non the rates of convergence.",
      "url": "http://arxiv.org/abs/2510.19565v1",
      "published_time_eastern_timestamp": 1761139125.0
    },
    {
      "title": "DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement\n  Learning",
      "summary": "Comprehending natural language and following human instructions are critical\ncapabilities for intelligent agents. However, the flexibility of linguistic\ninstructions induces substantial ambiguity across language-conditioned tasks,\nseverely degrading algorithmic performance. To address these limitations, we\npresent a novel method named DAIL (Distributional Aligned Learning), featuring\ntwo key components: distributional policy and semantic alignment. Specifically,\nwe provide theoretical results that the value distribution estimation mechanism\nenhances task differentiability. Meanwhile, the semantic alignment module\ncaptures the correspondence between trajectories and linguistic instructions.\nExtensive experimental results on both structured and visual observation\nbenchmarks demonstrate that DAIL effectively resolves instruction ambiguities,\nachieving superior performance to baseline methods. Our implementation is\navailable at https://github.com/RunpengXie/Distributional-Aligned-Learning.",
      "url": "http://arxiv.org/abs/2510.19562v1",
      "published_time_eastern_timestamp": 1761139006.0
    },
    {
      "title": "Modeling realistic human behavior using generative agents in a\n  multimodal transport system: Software architecture and Application to\n  Toulouse",
      "summary": "Modeling realistic human behaviour to understand people's mode choices in\norder to propose personalised mobility solutions remains challenging. This\npaper presents an architecture for modeling realistic human mobility behavior\nin complex multimodal transport systems, demonstrated through a case study in\nToulouse, France. We apply Large Language Models (LLMs) within an agent-based\nsimulation to capture decision-making in a real urban setting. The framework\nintegrates the GAMA simulation platform with an LLM-based generative agent,\nalong with General Transit Feed Specification (GTFS) data for public transport,\nand OpenTripPlanner for multimodal routing. GAMA platform models the\ninteractive transport environment, providing visualization and dynamic agent\ninteractions while eliminating the need to construct the simulation environment\nfrom scratch. This design enables a stronger focus on developing generative\nagents and evaluating their performance in transport decision-making processes.\nOver a simulated month, results show that agents not only make context-aware\ntransport decisions but also form habits over time. We conclude that combining\nLLMs with agent-based simulation offers a promising direction for advancing\nintelligent transportation systems and personalised multimodal mobility\nsolutions. We also discuss some limitations of this approach and outline future\nwork on scaling to larger regions, integrating real-time data, and refining\nmemory models.",
      "url": "http://arxiv.org/abs/2510.19497v1",
      "published_time_eastern_timestamp": 1761133544.0
    },
    {
      "title": "VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos",
      "summary": "Training computer-use agents requires massive amounts of GUI interaction\ndata, but manually annotating action trajectories at scale is prohibitively\nexpensive. We present VideoAgentTrek, a scalable pipeline that automatically\nmines training data from publicly available screen-recorded videos at web\nscale, eliminating the need for manual annotation. Our approach addresses a key\nchallenge: raw videos contain implicit demonstrations but lack explicit action\nlabels. To solve this, we develop Video2Action, an inverse dynamics module\n(IDM) with two components: (1) a video grounding model that detects and\nlocalizes GUI actions with precise temporal boundaries and context, and (2) an\naction-content recognizer that extracts structured parameters like click\ncoordinates and typed text with high fidelity. Applied to 39,000 YouTube\ntutorial videos, our pipeline generates 1.52 million interaction steps\nautomatically. We leverage this data through continued pretraining followed by\nsupervised fine-tuning. On OSWorld-Verified, our approach improves task success\nrates from 9.3% (SFT-only baseline) to 15.8%, a 70% relative improvement. On\nAgentNetBench, step accuracy increases from 64.1% to 69.3%. Our results\ndemonstrate that passive internet videos can be transformed into high-quality\nsupervision for computer-use agents, providing a scalable alternative to\nexpensive manual annotation.",
      "url": "http://arxiv.org/abs/2510.19488v1",
      "published_time_eastern_timestamp": 1761132348.0
    },
    {
      "title": "AegisMCP: Online Graph Intrusion Detection for Tool-Augmented LLMs on\n  Edge Devices",
      "summary": "In this work, we study security of Model Context Protocol (MCP) agent\ntoolchains and their applications in smart homes. We introduce AegisMCP, a\nprotocol-level intrusion detector. Our contributions are: (i) a minimal attack\nsuite spanning instruction-driven escalation, chain-of-tool exfiltration,\nmalicious MCP server registration, and persistence; (ii) NEBULA-Schema\n(Network-Edge Behavioral Learning for Untrusted LLM Agents), a reusable\nprotocol-level instrumentation that represents MCP activity as a streaming\nheterogeneous temporal graph over agents, MCP servers, tools, devices, remotes,\nand sessions; and (iii) a CPU-only streaming detector that fuses novelty,\nsession-DAG structure, and attribute cues for near-real-time edge inference,\nwith optional fusion of local prompt-guardrail signals. On an emulated\nsmart-home testbed spanning multiple MCP stacks and a physical bench, AegisMCP\nachieves sub-second per-window model inference and end-to-end alerting. The\nlatency of AegisMCP is consistently sub-second on Intel N150-class edge\nhardware, while outperforming traffic-only and sequence baselines; ablations\nconfirm the importance of DAG and install/permission signals. We release code,\nschemas, and generators for reproducible evaluation.",
      "url": "http://arxiv.org/abs/2510.19462v1",
      "published_time_eastern_timestamp": 1761130222.0
    }
  ]
}
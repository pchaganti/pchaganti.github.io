{
  "last_updated": "2025-08-02T21:10:26.577982-04:00",
  "papers": [
    {
      "title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding",
      "summary": "With the development of multimodal reasoning models, Computer Use Agents\n(CUAs), akin to Jarvis from \\textit{\"Iron Man\"}, are becoming a reality. GUI\ngrounding is a core component for CUAs to execute actual actions, similar to\nmechanical control in robotics, and it directly leads to the success or failure\nof the system. It determines actions such as clicking and typing, as well as\nrelated parameters like the coordinates for clicks. Current end-to-end\ngrounding models still achieve less than 65\\% accuracy on challenging\nbenchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from\nbeing ready for deployment. % , as a single misclick can result in unacceptable\nconsequences. In this work, we conduct an empirical study on the training of\ngrounding models, examining details from data collection to model training.\nUltimately, we developed the \\textbf{Phi-Ground} model family, which achieves\nstate-of-the-art performance across all five grounding benchmarks for models\nunder $10B$ parameters in agent settings. In the end-to-end model setting, our\nmodel still achieves SOTA results with scores of \\textit{\\textbf{43.2}} on\nScreenSpot-pro and \\textit{\\textbf{27.2}} on UI-Vision. We believe that the\nvarious details discussed in this paper, along with our successes and failures,\nnot only clarify the construction of grounding models but also benefit other\nperception tasks. Project homepage:\n\\href{https://zhangmiaosen2000.github.io/Phi-Ground/}{https://zhangmiaosen2000.github.io/Phi-Ground/}",
      "url": "http://arxiv.org/abs/2507.23779v1",
      "published_time_eastern_timestamp": 1753984749.0
    },
    {
      "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning\n  Architecture with LLM-Based World Model",
      "summary": "AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.",
      "url": "http://arxiv.org/abs/2507.23773v1",
      "published_time_eastern_timestamp": 1753984640.0
    },
    {
      "title": "SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D\n  Gaussian Splatting",
      "summary": "3D affordance reasoning, the task of associating human instructions with the\nfunctional regions of 3D objects, is a critical capability for embodied agents.\nCurrent methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited\nto single-object, single-step interactions, a paradigm that falls short of\naddressing the long-horizon, multi-object tasks required for complex real-world\napplications. To bridge this gap, we introduce the novel task of Sequential 3D\nGaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale\nbenchmark featuring 1800+ scenes to support research on long-horizon affordance\nunderstanding in complex 3DGS environments. We then propose SeqSplatNet, an\nend-to-end framework that directly maps an instruction to a sequence of 3D\naffordance masks. SeqSplatNet employs a large language model that\nautoregressively generates text interleaved with special segmentation tokens,\nguiding a conditional decoder to produce the corresponding 3D mask. To handle\ncomplex scene geometry, we introduce a pre-training strategy, Conditional\nGeometric Reconstruction, where the model learns to reconstruct complete\naffordance region masks from known geometric observations, thereby building a\nrobust geometric prior. Furthermore, to resolve semantic ambiguities, we design\na feature injection mechanism that lifts rich semantic features from 2D Vision\nFoundation Models (VFM) and fuses them into the 3D decoder at multiple scales.\nExtensive experiments demonstrate that our method sets a new state-of-the-art\non our challenging benchmark, effectively advancing affordance reasoning from\nsingle-step interactions to complex, sequential tasks at the scene level.",
      "url": "http://arxiv.org/abs/2507.23772v1",
      "published_time_eastern_timestamp": 1753984615.0
    },
    {
      "title": "Distributed AI Agents for Cognitive Underwater Robot Autonomy",
      "summary": "Achieving robust cognitive autonomy in robots navigating complex,\nunpredictable environments remains a fundamental challenge in robotics. This\npaper presents Underwater Robot Self-Organizing Autonomy (UROSA), a\ngroundbreaking architecture leveraging distributed Large Language Model AI\nagents integrated within the Robot Operating System 2 (ROS 2) framework to\nenable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA\ndecentralises cognition into specialised AI agents responsible for multimodal\nperception, adaptive reasoning, dynamic mission planning, and real-time\ndecision-making. Central innovations include flexible agents dynamically\nadapting their roles, retrieval-augmented generation utilising vector databases\nfor efficient knowledge management, reinforcement learning-driven behavioural\noptimisation, and autonomous on-the-fly ROS 2 node generation for runtime\nfunctional extensibility. Extensive empirical validation demonstrates UROSA's\npromising adaptability and reliability through realistic underwater missions in\nsimulation and real-world deployments, showing significant advantages over\ntraditional rule-based architectures in handling unforeseen scenarios,\nenvironmental uncertainties, and novel mission objectives. This work not only\nadvances underwater autonomy but also establishes a scalable, safe, and\nversatile cognitive robotics framework capable of generalising to a diverse\narray of real-world applications.",
      "url": "http://arxiv.org/abs/2507.23735v1",
      "published_time_eastern_timestamp": 1753982335.0
    },
    {
      "title": "Adaptive Stepsize Selection in Decentralized Convex Optimization",
      "summary": "We study decentralized optimization where multiple agents minimize the\naverage of their (strongly) convex, smooth losses over a communication graph.\nConvergence of the existing decentralized methods generally hinges on an\napriori, proper selection of the stepsize. Choosing this value is notoriously\ndelicate: (i) it demands global knowledge from all the agents of the graph's\nconnectivity and every local smoothness/strong-convexity constants--information\nthey rarely have; (ii) even with perfect information, the worst-case tuning\nforces an overly small stepsize, slowing convergence in practice; and (iii)\nlarge-scale trial-and-error tuning is prohibitive. This work introduces a\ndecentralized algorithm that is fully adaptive in the choice of the agents'\nstepsizes, without any global information and using only neighbor-to-neighbor\ncommunications--agents need not even know whether the problem is strongly\nconvex. The algorithm retains strong guarantees: it converges at \\emph{linear}\nrate when the losses are strongly convex and at \\emph{sublinear} rate\notherwise, matching the best-known rates of (nonadaptive) parameter-dependent\nmethods.",
      "url": "http://arxiv.org/abs/2507.23725v1",
      "published_time_eastern_timestamp": 1753981120.0
    },
    {
      "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
      "summary": "Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.",
      "url": "http://arxiv.org/abs/2507.23701v1",
      "published_time_eastern_timestamp": 1753978975.0
    },
    {
      "title": "Scalable Multi-Task Reinforcement Learning for Generalizable Spatial\n  Intelligence in Visuomotor Agents",
      "summary": "While Reinforcement Learning (RL) has achieved remarkable success in language\nmodeling, its triumph hasn't yet fully translated to visuomotor agents. A\nprimary challenge in RL models is their tendency to overfit specific tasks or\nenvironments, thereby hindering the acquisition of generalizable behaviors\nacross diverse settings. This paper provides a preliminary answer to this\nchallenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can\nachieve zero-shot generalization to unseen worlds. Specifically, we explore\nRL's potential to enhance generalizable spatial reasoning and interaction\ncapabilities in 3D worlds. To address challenges in multi-task RL\nrepresentation, we analyze and establish cross-view goal specification as a\nunified multi-task goal space for visuomotor policies. Furthermore, to overcome\nthe significant bottleneck of manual task design, we propose automated task\nsynthesis within the highly customizable Minecraft environment for large-scale\nmulti-task RL training, and we construct an efficient distributed RL framework\nto support this. Experimental results show RL significantly boosts interaction\nsuccess rates by $4\\times$ and enables zero-shot generalization of spatial\nreasoning across diverse environments, including real-world settings. Our\nfindings underscore the immense potential of RL training in 3D simulated\nenvironments, especially those amenable to large-scale task generation, for\nsignificantly advancing visuomotor agents' spatial reasoning.",
      "url": "http://arxiv.org/abs/2507.23698v1",
      "published_time_eastern_timestamp": 1753978802.0
    },
    {
      "title": "A survey of multi-agent geosimulation methodologies: from ABM to LLM",
      "summary": "We provide a comprehensive examination of agent-based approaches that codify\nthe principles and linkages underlying multi-agent systems, simulations, and\ninformation systems. Based on two decades of study, this paper confirms a\nframework intended as a formal specification for geosimulation platforms. Our\nfindings show that large language models (LLMs) can be effectively incorporated\nas agent components if they follow a structured architecture specific to\nfundamental agent activities such as perception, memory, planning, and action.\nThis integration is precisely consistent with the architecture that we\nformalize, providing a solid platform for next-generation geosimulation\nsystems.",
      "url": "http://arxiv.org/abs/2507.23694v1",
      "published_time_eastern_timestamp": 1753978342.0
    },
    {
      "title": "CFDagent: A Language-Guided, Zero-Shot Multi-Agent System for Complex\n  Flow Simulation",
      "summary": "We introduce CFDagent, a zero-shot, multi-agent system that enables fully\nautonomous computational fluid dynamics (CFD) simulations from natural language\nprompts. CFDagent integrates three specialized LLM-driven agents: (i) the\nPreprocessing Agent that generates 3D geometries from textual or visual inputs\nusing a hybrid text-to-3D diffusion model (Point-E) and automatically meshes\nthe geometries; (ii) the Solver Agent that configures and executes an immersed\nboundary flow solver; and (iii) the Postprocessing Agent that analyzes and\nvisualizes the results, including multimodal renderings. These agents are\ninteractively guided by GPT-4o via conversational prompts, enabling intuitive\nand user-friendly interaction. We validate CFDagent by reproducing canonical\nsphere flows at Reynolds numbers of 100 and 300 using three distinct inputs: a\nsimple text prompt (i.e., \"sphere\"), an image-based input, and a standard\nsphere model. The computed drag and lift coefficients from meshes produced by\neach input approach closely match available data. The proposed system enables\nsynthesization of flow simulations and photorealistic visualizations for\ncomplex geometries. Through extensive tests on canonical and realistic\nscenarios, we demonstrate the robustness, versatility, and practical\napplicability of CFDagent. By bridging generative AI with high-fidelity\nsimulations, CFDagent significantly lowers barriers to expert-level CFD,\nunlocking broad opportunities in education, scientific research, and practical\nengineering applications.",
      "url": "http://arxiv.org/abs/2507.23693v1",
      "published_time_eastern_timestamp": 1753978286.0
    },
    {
      "title": "Probing graph topology from local quantum measurements",
      "summary": "We show that global properties of an unknown quantum network, such as the\naverage degree, hub density, and the number of closed paths of fixed length,\ncan be inferred from strictly local quantum measurements. In particular, we\ndemonstrate that a malicious agent with access to only a small subset of nodes\ncan initialize quantum states locally and, through repeated short-time\nmeasurements, extract sensitive structural information about the entire\nnetwork. The intrusion strategy is inspired by extreme learning and quantum\nreservoir computing and combines short-time quantum evolution with a\nnon-iterative linear readout with trainable weights. These results suggest new\nstrategies for intrusion detection and structural diagnostics in future quantum\nInternet infrastructures.",
      "url": "http://arxiv.org/abs/2507.23689v1",
      "published_time_eastern_timestamp": 1753978005.0
    },
    {
      "title": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached\n  Responses",
      "summary": "Large Language Models (LLMs) process millions of queries daily, making\nefficient response caching a compelling optimization for reducing cost and\nlatency. However, preserving relevance to user queries using this approach\nproves difficult due to the personalized nature of chatbot interactions and the\nlimited accuracy of semantic similarity search. To address this, we present\nTweakLLM, a novel routing architecture that employs a lightweight LLM to\ndynamically adapt cached responses to incoming prompts. Through comprehensive\nevaluation, including user studies with side-by-side comparisons, satisfaction\nvoting, as well as multi-agent LLM debates, we demonstrate that TweakLLM\nmaintains response quality comparable to frontier models while significantly\nimproving cache effectiveness. Our results across real-world datasets highlight\nTweakLLM as a scalable, resource-efficient caching solution for high-volume LLM\ndeployments without compromising user experience.",
      "url": "http://arxiv.org/abs/2507.23674v1",
      "published_time_eastern_timestamp": 1753977057.0
    },
    {
      "title": "Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity",
      "summary": "Agent-based simulations have an enormous potential as tools to evaluate\nsocial policies in a non-invasive way, before these are implemented to\nreal-world populations. However, the recommendations that these computational\napproaches may offer to tackle urgent human development challenges can vary\nsubstantially depending on how we model agents' (people) behaviour and the\ncriteria that we use to measure inequity. In this paper, we integrate the\nconceptual framework of the capability approach (CA), which is explicitly\ndesigned to promote and assess human well-being, to guide the simulation and\nevaluate the effectiveness of policies. We define a reinforcement learning\nenvironment where agents behave to restore their capabilities under the\nconstraints of a specific policy. Working in collaboration with local\nstakeholders, non-profits and domain experts, we apply our model in a case\nstudy to mitigate health inequity among the population experiencing\nhomelessness (PEH) in Barcelona. By doing so, we present the first proof of\nconcept simulation, aligned with the CA for human development, to assess the\nimpact of policies under parliamentary discussion.",
      "url": "http://arxiv.org/abs/2507.23644v1",
      "published_time_eastern_timestamp": 1753975385.0
    },
    {
      "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via\n  Strategy-Guided Querying",
      "summary": "Agent-assisted memory recall is one critical research problem in the field of\nhuman-computer interaction. In conventional methods, the agent can retrieve\ninformation from its equipped memory module to help the person recall\nincomplete or vague memories. The limited size of memory module hinders the\nacquisition of complete memories and impacts the memory recall performance in\npractice. Memory theories suggest that the person's relevant memory can be\nproactively activated through some effective cues. Inspired by this, we propose\na novel strategy-guided agent-assisted memory recall method, allowing the agent\nto transform an original query into a cue-rich one via the judiciously designed\nstrategy to help the person recall memories. To this end, there are two key\nchallenges. (1) How to choose the appropriate recall strategy for diverse\nforgetting scenarios with distinct memory-recall characteristics? (2) How to\nobtain the high-quality responses leveraging recall strategies, given only\nabstract and sparsely annotated strategy patterns? To address the challenges,\nwe propose a Recall Router framework. Specifically, we design a 5W Recall Map\nto classify memory queries into five typical scenarios and define fifteen\nrecall strategy patterns across the corresponding scenarios. We then propose a\nhierarchical recall tree combined with the Monte Carlo Tree Search algorithm to\noptimize the selection of strategy and the generation of strategy responses. We\nconstruct an instruction tuning dataset and fine-tune multiple open-source\nlarge language models (LLMs) to develop MemoCue, an agent that excels in\nproviding memory-inspired responses. Experiments on three representative\ndatasets show that MemoCue surpasses LLM-based methods by 17.74% in recall\ninspiration. Further human evaluation highlights its advantages in\nmemory-recall applications.",
      "url": "http://arxiv.org/abs/2507.23633v1",
      "published_time_eastern_timestamp": 1753974698.0
    },
    {
      "title": "Hierarchical Message-Passing Policies for Multi-Agent Reinforcement\n  Learning",
      "summary": "Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for\nlearning scalable multi-agent policies, but suffer from partial observability\nand induced non-stationarity. These challenges can be addressed by introducing\nmechanisms that facilitate coordination and high-level planning. Specifically,\ncoordination and temporal abstraction can be achieved through communication\n(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)\napproaches to decision-making. However, optimization issues limit the\napplicability of hierarchical policies to multi-agent systems. As such, the\ncombination of these approaches has not been fully explored. To fill this void,\nwe propose a novel and effective methodology for learning multi-agent\nhierarchies of message-passing policies. We adopt the feudal HRL framework and\nrely on a hierarchical graph structure for planning and coordination among\nagents. Agents at lower levels in the hierarchy receive goals from the upper\nlevels and exchange messages with neighboring agents at the same level. To\nlearn hierarchical multi-agent policies, we design a novel reward-assignment\nmethod based on training the lower-level policies to maximize the advantage\nfunction associated with the upper levels. Results on relevant benchmarks show\nthat our method performs favorably compared to the state of the art.",
      "url": "http://arxiv.org/abs/2507.23604v1",
      "published_time_eastern_timestamp": 1753972932.0
    },
    {
      "title": "Agency Among Agents: Designing with Hypertextual Friction in the\n  Algorithmic Web",
      "summary": "Today's algorithm-driven interfaces, from recommendation feeds to GenAI\ntools, often prioritize engagement and efficiency at the expense of user\nagency. As systems take on more decision-making, users have less control over\nwhat they see and how meaning or relationships between content are constructed.\nThis paper introduces \"Hypertextual Friction,\" a conceptual design stance that\nrepositions classical hypertext principles--friction, traceability, and\nstructure--as actionable values for reclaiming agency in algorithmically\nmediated environments. Through a comparative analysis of real-world\ninterfaces--Wikipedia vs. Instagram Explore, and Are.na vs. GenAI image\ntools--we examine how different systems structure user experience, navigation,\nand authorship. We show that hypertext systems emphasize provenance,\nassociative thinking, and user-driven meaning-making, while algorithmic systems\ntend to obscure process and flatten participation. We contribute: (1) a\ncomparative analysis of how interface structures shape agency in user-driven\nversus agent-driven systems, and (2) a conceptual stance that offers\nhypertextual values as design commitments for reclaiming agency in an\nincreasingly algorithmic web.",
      "url": "http://arxiv.org/abs/2507.23585v1",
      "published_time_eastern_timestamp": 1753971508.0
    },
    {
      "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator\n  Selection via Hypergraph-Aided Agentic AI",
      "summary": "In collaborative systems, the effective completion of tasks hinges on\ntask-specific trust evaluations of potential devices for distributed\ncollaboration. However, the complexity of tasks, the spatiotemporal dynamism of\ndistributed device resources, and the inevitable assessment overhead\ndramatically increase the complexity and resource consumption of the trust\nevaluation process. As a result, ill-timed or overly frequent trust evaluations\ncan reduce utilization rate of constrained resources, negatively affecting\ncollaborative task execution. To address this challenge, this paper proposes an\nautonomous trust orchestration method based on a new concept of semantic\nchain-of-trust. Our technique employs agentic AI and hypergraph to establish\nand maintain trust relationships among devices. By leveraging its strengths in\nautonomous perception, task decomposition, and semantic reasoning, we propose\nagentic AI to perceive device states and autonomously perform trust evaluations\nof collaborators based on historical performance data only during device idle\nperiods, thereby enabling efficient utilization of distributed resources. In\naddition, agentic AI performs task-specific trust evaluations on collaborator\nresources by analyzing the alignment between resource capabilities and task\nrequirements. Moreover, by maintaining a trust hypergraph embedded with trust\nsemantics for each device, agentic AI enables hierarchical management of\ncollaborators and identifies collaborators requiring trust evaluation based on\ntrust semantics, thereby achieving a balance between overhead and trust\naccuracy. Furthermore, local trust hypergraphs from multiple devices can be\nchained together to support multi-hop collaboration, enabling efficient\ncoordination in large-scale systems. Experimental results demonstrate that the\nproposed method achieves resource-efficient trust evaluation.",
      "url": "http://arxiv.org/abs/2507.23565v1",
      "published_time_eastern_timestamp": 1753970005.0
    },
    {
      "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient\n  Knowledge Transfer",
      "summary": "Large language model-based agents, empowered by in-context learning (ICL),\nhave demonstrated strong capabilities in complex reasoning and tool-use tasks.\nHowever, existing works have shown that the effectiveness of ICL is highly\nsensitive to the choice of demonstrations, with suboptimal examples often\nleading to unstable or degraded performance. While prior work has explored\nexample selection, including in some agentic or multi-step settings, existing\napproaches typically rely on heuristics or task-specific designs and lack a\ngeneral, theoretically grounded criterion for what constitutes an effective\ndemonstration across reasoning steps. Therefore, it is non-trivial to develop a\nprincipled, general-purpose method for selecting demonstrations that\nconsistently benefit agent performance. In this paper, we address this\nchallenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a\ntheoretically grounded ICL framework for agentic tasks that selects the most\nrelevant demonstrations at each step of reasoning. Our approach decomposes\ndemonstration knowledge into transferable and non-transferable components\nthrough a causal lens, showing how the latter can introduce spurious\ndependencies that impair generalization. We further propose a stepwise\nselection criterion with a formal guarantee of improved agent performance.\nImportantly, DICE is a general, framework-agnostic solution that can be\nintegrated as a plug-in module into existing agentic frameworks without any\nadditional training cost. Extensive experiments across diverse domains\ndemonstrate our method's effectiveness and generality, highlighting the\nimportance of principled, context-aware demo selection for robust and efficient\nLLM agents.",
      "url": "http://arxiv.org/abs/2507.23554v1",
      "published_time_eastern_timestamp": 1753969334.0
    },
    {
      "title": "Run-and-Tumble Particles Learning Chemotaxis",
      "summary": "Through evolution, bacteria have developed the ability to perform chemotactic\nmotion in order to find nourishment. By adopting a machine learning approach,\nwe aim to understand how this behavior arises. We consider run-and-tumble\nagents able to tune the instantaneous probability of switching between the run\nand the tumble phase. When such agents are navigating in an environment\ncharacterized by a concentration field pointing towards a circular target, we\ninvestigate how a chemotactic strategy may be learned starting from unbiased\nrun-and-tumble dynamics. We compare the learning performances of agents that\nsense only the instantaneous concentration with those of agents having a\nshort-term memory that allows them to perform temporal comparisons. While both\ntypes of learning agents develop successful target-search policies, we\ndemonstrate that those achieved by agents endowed with temporal comparison\nabilities are significantly more efficient, particularly when the initial\ndistance from the target is large. Finally, we also show that when an\nadditional length scale is imposed, for example by fixing the initial distance\nto the target, the learning agents can leverage this information to further\nimprove their efficiency in locating the target.",
      "url": "http://arxiv.org/abs/2507.23519v1",
      "published_time_eastern_timestamp": 1753967020.0
    },
    {
      "title": "Online Combinatorial Allocation with Interdependent Values",
      "summary": "We study online combinatorial allocation problems in the secretary setting,\nunder interdependent values. In the interdependent model, introduced by Milgrom\nand Weber (1982), each agent possesses a private signal that captures her\ninformation about an item for sale, and the value of every agent depends on the\nsignals held by all agents. Mauras, Mohan, and Reiffenh\\\"auser (2024) were the\nfirst to study interdependent values in online settings, providing\nconstant-approximation guarantees for secretary settings, where agents arrive\nonline along with their signals and values, and the goal is to select the agent\nwith the highest value.\n  In this work, we extend this framework to {\\em combinatorial} secretary\nproblems, where agents have interdependent valuations over {\\em bundles} of\nitems, introducing additional challenges due to both combinatorial structure\nand interdependence. We provide $2e$-competitive algorithms for a broad class\nof valuation functions, including submodular and XOS functions, matching the\napproximation guarantees in the single-choice secretary setting. Furthermore,\nour results cover the same range of valuation classes for which constant-factor\nalgorithms exist in classical (non-interdependent) secretary settings, while\nincurring only an additional factor of $2$ due to interdependence. Finally, we\nextend our study to strategic settings, and provide a $4e$-competitive truthful\nmechanism for online bipartite matching with interdependent valuations, again\nmeeting the frontier of what is known, even without interdependence.",
      "url": "http://arxiv.org/abs/2507.23500v1",
      "published_time_eastern_timestamp": 1753965593.0
    },
    {
      "title": "Distributionally Robust Cascading Risk Quantification in Multi-Agent\n  Rendezvous: Effects of Time Delay and Network Connectivity",
      "summary": "Achieving safety in autonomous multi-agent systems, particularly in\ntime-critical tasks like rendezvous, is a critical challenge. In this paper, we\npropose a distributionally robust risk framework for analyzing cascading\nfailures in multi-agent rendezvous. To capture the complex interactions between\nnetwork connectivity, system dynamics, and communication delays, we use a\ntime-delayed network model as a benchmark. We introduce a conditional\ndistributionally robust functional to quantify cascading effects between\nagents, utilizing a bi-variate normal distribution. Our approach yields\nclosed-form risk expressions that reveal the impact of time delay, noise\nstatistics, communication topology, and failure modes on rendezvous risk. The\ninsights derived inform the design of resilient networks that mitigate the risk\nof cascading failures. We validate our theoretical results through extensive\nsimulations, demonstrating the effectiveness of our framework.",
      "url": "http://arxiv.org/abs/2507.23489v1",
      "published_time_eastern_timestamp": 1753963908.0
    }
  ]
}
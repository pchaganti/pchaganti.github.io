{
  "last_updated": "2025-06-24T05:14:25.755607-04:00",
  "papers": [
    {
      "title": "Audit & Repair: An Agentic Framework for Consistent Story Visualization\n  in Text-to-Image Diffusion Models",
      "summary": "Story visualization has become a popular task where visual scenes are\ngenerated to depict a narrative across multiple panels. A central challenge in\nthis setting is maintaining visual consistency, particularly in how characters\nand objects persist and evolve throughout the story. Despite recent advances in\ndiffusion models, current approaches often fail to preserve key character\nattributes, leading to incoherent narratives. In this work, we propose a\ncollaborative multi-agent framework that autonomously identifies, corrects, and\nrefines inconsistencies across multi-panel story visualizations. The agents\noperate in an iterative loop, enabling fine-grained, panel-level updates\nwithout re-generating entire sequences. Our framework is model-agnostic and\nflexibly integrates with a variety of diffusion models, including rectified\nflow transformers such as Flux and latent diffusion models such as Stable\nDiffusion. Quantitative and qualitative experiments show that our method\noutperforms prior approaches in terms of multi-panel consistency.",
      "url": "http://arxiv.org/abs/2506.18900v1",
      "published_time_eastern_timestamp": 1750701569.0
    },
    {
      "title": "Steering Conceptual Bias via Transformer Latent-Subspace Activation",
      "summary": "This work examines whether activating latent subspaces in language models\n(LLMs) can steer scientific code generation toward a specific programming\nlanguage. Five causal LLMs were first evaluated on scientific coding prompts to\nquantify their baseline bias among four programming languages. A static\nneuron-attribution method, perturbing the highest activated MLP weight for a\nC++ or CPP token, proved brittle and exhibited limited generalization across\nprompt styles and model scales. To address these limitations, a\ngradient-refined adaptive activation steering framework (G-ACT) was developed:\nper-prompt activation differences are clustered into a small set of steering\ndirections, and lightweight per-layer probes are trained and refined online to\nselect the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably\nbiases generation towards the CPP language by increasing the average probe\nclassification accuracy by 15% and the early layers (0-6) improving the probe\nclassification accuracy by 61.5% compared to the standard ACT framework. For\nLLaMA-3.3 70B, where attention-head signals become more diffuse, targeted\ninjections at key layers still improve language selection. Although per-layer\nprobing introduces a modest inference overhead, it remains practical by\nsteering only a subset of layers and enables reproducible model behavior. These\nresults demonstrate a scalable, interpretable and efficient mechanism for\nconcept-level control for practical agentic systems.",
      "url": "http://arxiv.org/abs/2506.18887v1",
      "published_time_eastern_timestamp": 1750701394.0
    },
    {
      "title": "GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale\n  Multi-Agent Gaussian SLAM",
      "summary": "3D Gaussian splatting has emerged as an expressive scene representation for\nRGB-D visual SLAM, but its application to large-scale, multi-agent outdoor\nenvironments remains unexplored. Multi-agent Gaussian SLAM is a promising\napproach to rapid exploration and reconstruction of environments, offering\nscalable environment representations, but existing approaches are limited to\nsmall-scale, indoor environments. To that end, we propose Gaussian\nReconstruction via Multi-Agent Dense SLAM, or GRAND-SLAM, a collaborative\nGaussian splatting SLAM method that integrates i) an implicit tracking module\nbased on local optimization over submaps and ii) an approach to inter- and\nintra-robot loop closure integrated into a pose-graph optimization framework.\nExperiments show that GRAND-SLAM provides state-of-the-art tracking performance\nand 28% higher PSNR than existing methods on the Replica indoor dataset, as\nwell as 91% lower multi-agent tracking error and improved rendering over\nexisting multi-agent methods on the large-scale, outdoor Kimera-Multi dataset.",
      "url": "http://arxiv.org/abs/2506.18885v1",
      "published_time_eastern_timestamp": 1750701342.0
    },
    {
      "title": "Broad Validity of the First-Order Approach in Moral Hazard",
      "summary": "The first-order approach (FOA) is the main tool for the moral hazard\nprincipal-agent problem. Although many existing results rely on the FOA, its\nvalidity has been established only under relatively restrictive assumptions. We\ndemonstrate in examples that the FOA frequently fails when the agent's\nreservation utility is low (such as in principal-optimal contracts). However,\nthe FOA broadly holds when the agent's reservation utility is at least\nmoderately high (such as in competitive settings where agents receive high\nrents). Our main theorem formalizes this point. The theorem shows that the FOA\nis valid in a standard limited liability model when the agent's reservation\nutility is sufficiently high. The theorem also establishes existence and\nuniqueness of the optimal contract. We use the theorem to derive tractable\noptimal contracts across several settings. Under log utility, option contracts\nare optimal for numerous common output distributions (including Gaussian,\nexponential, binomial, Gamma, and Laplace).",
      "url": "http://arxiv.org/abs/2506.18873v1",
      "published_time_eastern_timestamp": 1750700467.0
    },
    {
      "title": "Offline Goal-Conditioned Reinforcement Learning with Projective\n  Quasimetric Planning",
      "summary": "Offline Goal-Conditioned Reinforcement Learning seeks to train agents to\nreach specified goals from previously collected trajectories. Scaling that\npromises to long-horizon tasks remains challenging, notably due to compounding\nvalue-estimation errors. Principled geometric offers a potential solution to\naddress these issues. Following this insight, we introduce Projective\nQuasimetric Planning (ProQ), a compositional framework that learns an\nasymmetric distance and then repurposes it, firstly as a repulsive energy\nforcing a sparse set of keypoints to uniformly spread over the learned latent\nspace, and secondly as a structured directional cost guiding towards proximal\nsub-goals. In particular, ProQ couples this geometry with a Lagrangian\nout-of-distribution detector to ensure the learned keypoints stay within\nreachable areas. By unifying metric learning, keypoint coverage, and\ngoal-conditioned control, our approach produces meaningful sub-goals and\nrobustly drives long-horizon goal-reaching on diverse a navigation benchmarks.",
      "url": "http://arxiv.org/abs/2506.18847v1",
      "published_time_eastern_timestamp": 1750698440.0
    },
    {
      "title": "Understanding Software Engineering Agents: A Study of\n  Thought-Action-Result Trajectories",
      "summary": "Large Language Model (LLM)-based agents are increasingly employed to automate\ncomplex software engineering tasks such as program repair and issue resolution.\nThese agents operate by autonomously generating natural language thoughts,\ninvoking external tools, and iteratively refining their solutions. Despite\ntheir widespread adoption, the internal decision-making processes of these\nagents remain largely unexplored, limiting our understanding of their\noperational dynamics and failure modes. In this paper, we present a large-scale\nempirical study of the thought-action-result trajectories of three\nstate-of-the-art LLM-based agents: \\textsc{RepairAgent},\n\\textsc{AutoCodeRover}, and \\textsc{OpenHands}. We unify their interaction logs\ninto a common format, capturing 120 trajectories and 2822 LLM interactions\nfocused on program repair and issue resolution. Our study combines quantitative\nanalyses of structural properties, action patterns, and token usage with\nqualitative assessments of reasoning coherence and feedback integration. We\nidentify key trajectory characteristics such as iteration counts and token\nconsumption, recurring action sequences, and the semantic coherence linking\nthoughts, actions, and their results. Our findings reveal behavioral motifs and\nanti-patterns that distinguish successful from failed executions, providing\nactionable insights for improving agent design, including prompting strategies,\nfailure diagnosis, and anti-pattern detection. We release our dataset and\nannotation framework to support further research on transparent and robust\nautonomous software engineering agents.",
      "url": "http://arxiv.org/abs/2506.18824v1",
      "published_time_eastern_timestamp": 1750696492.0
    },
    {
      "title": "Multi-Agent Online Control with Adversarial Disturbances",
      "summary": "Multi-agent control problems involving a large number of agents with\ncompeting and time-varying objectives are increasingly prevalent in\napplications across robotics, economics, and energy systems. In this paper, we\nstudy online control in multi-agent linear dynamical systems with disturbances.\nIn contrast to most prior work in multi-agent control, we consider an online\nsetting where disturbances are adversarial and where each agent seeks to\nminimize its own, adversarial sequence of convex losses. In this setting, we\ninvestigate the robustness of gradient-based controllers from single-agent\nonline control, with a particular focus on understanding how individual regret\nguarantees are influenced by the number of agents in the system. Under minimal\ncommunication assumptions, we prove near-optimal sublinear regret bounds that\nhold uniformly for all agents. Finally, when the objectives of the agents are\naligned, we show that the multi-agent control problem induces a time-varying\npotential game for which we derive equilibrium gap guarantees.",
      "url": "http://arxiv.org/abs/2506.18814v1",
      "published_time_eastern_timestamp": 1750695871.0
    },
    {
      "title": "Fair Allocation with Money: What is Your Objective?",
      "summary": "When allocating indivisible items, there are various ways to use monetary\ntransfers for eliminating envy. Particularly, one can apply a balanced vector\nof transfer payments, or charge each agent a positive amount, or -- contrarily\n-- give each agent a positive amount as a ``subsidy''. In each model, one can\naim to minimize the amount of payments used; this aim translates into different\noptimization objectives in each setting. This note compares the various models,\nand the relations between upper and lower bounds for these objectives.",
      "url": "http://arxiv.org/abs/2506.18794v1",
      "published_time_eastern_timestamp": 1750694543.0
    },
    {
      "title": "TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation",
      "summary": "TRIZ, the Theory of Inventive Problem Solving, is a structured,\nknowledge-based framework for innovation and abstracting problems to find\ninventive solutions. However, its application is often limited by the\ncomplexity and deep interdisciplinary knowledge required. Advancements in Large\nLanguage Models (LLMs) have revealed new possibilities for automating parts of\nthis process. While previous studies have explored single LLMs in TRIZ\napplications, this paper introduces a multi-agent approach. We propose an\nLLM-based multi-agent system, called TRIZ agents, each with specialized\ncapabilities and tool access, collaboratively solving inventive problems based\non the TRIZ methodology. This multi-agent system leverages agents with various\ndomain expertise to efficiently navigate TRIZ steps. The aim is to model and\nsimulate an inventive process with language agents. We assess the effectiveness\nof this team of agents in addressing complex innovation challenges based on a\nselected case study in engineering. We demonstrate the potential of agent\ncollaboration to produce diverse, inventive solutions. This research\ncontributes to the future of AI-driven innovation, showcasing the advantages of\ndecentralized problem-solving in complex ideation tasks.",
      "url": "http://arxiv.org/abs/2506.18783v1",
      "published_time_eastern_timestamp": 1750693994.0
    },
    {
      "title": "Temporal Neural Cellular Automata: Application to modeling of contrast\n  enhancement in breast MRI",
      "summary": "Synthetic contrast enhancement offers fast image acquisition and eliminates\nthe need for intravenous injection of contrast agent. This is particularly\nbeneficial for breast imaging, where long acquisition times and high cost are\nsignificantly limiting the applicability of magnetic resonance imaging (MRI) as\na widespread screening modality. Recent studies have demonstrated the\nfeasibility of synthetic contrast generation. However, current state-of-the-art\n(SOTA) methods lack sufficient measures for consistent temporal evolution.\nNeural cellular automata (NCA) offer a robust and lightweight architecture to\nmodel evolving patterns between neighboring cells or pixels. In this work we\nintroduce TeNCA (Temporal Neural Cellular Automata), which extends and further\nrefines NCAs to effectively model temporally sparse, non-uniformly sampled\nimaging data. To achieve this, we advance the training strategy by enabling\nadaptive loss computation and define the iterative nature of the method to\nresemble a physical progression in time. This conditions the model to learn a\nphysiologically plausible evolution of contrast enhancement. We rigorously\ntrain and test TeNCA on a diverse breast MRI dataset and demonstrate its\neffectiveness, surpassing the performance of existing methods in generation of\nimages that align with ground truth post-contrast sequences.",
      "url": "http://arxiv.org/abs/2506.18720v1",
      "published_time_eastern_timestamp": 1750690605.0
    },
    {
      "title": "Safety-Aware Optimal Scheduling for Autonomous Masonry Construction\n  using Collaborative Heterogeneous Aerial Robots",
      "summary": "This paper presents a novel high-level task planning and optimal coordination\nframework for autonomous masonry construction, using a team of heterogeneous\naerial robotic workers, consisting of agents with separate skills for brick\nplacement and mortar application. This introduces new challenges in scheduling\nand coordination, particularly due to the mortar curing deadline required for\nstructural bonding and ensuring the safety constraints among UAVs operating in\nparallel. To address this, an automated pipeline generates the wall\nconstruction plan based on the available bricks while identifying static\nstructural dependencies and potential conflicts for safe operation. The\nproposed framework optimizes UAV task allocation and execution timing by\nincorporating dynamically coupled precedence deadline constraints that account\nfor the curing process and static structural dependency constraints, while\nenforcing spatio-temporal constraints to prevent collisions and ensure safety.\nThe primary objective of the scheduler is to minimize the overall construction\nmakespan while minimizing logistics, traveling time between tasks, and the\ncuring time to maintain both adhesion quality and safe workspace separation.\nThe effectiveness of the proposed method in achieving coordinated and\ntime-efficient aerial masonry construction is extensively validated through\nGazebo simulated missions. The results demonstrate the framework's capability\nto streamline UAV operations, ensuring both structural integrity and safety\nduring the construction process.",
      "url": "http://arxiv.org/abs/2506.18697v1",
      "published_time_eastern_timestamp": 1750689289.0
    },
    {
      "title": "MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning\n  for Active Contour Optimization in Medical Image Segmentation",
      "summary": "We introduce MARL-MambaContour, the first contour-based medical image\nsegmentation framework based on Multi-Agent Reinforcement Learning (MARL). Our\napproach reframes segmentation as a multi-agent cooperation task focused on\ngenerate topologically consistent object-level contours, addressing the\nlimitations of traditional pixel-based methods which could lack topological\nconstraints and holistic structural awareness of anatomical regions. Each\ncontour point is modeled as an autonomous agent that iteratively adjusts its\nposition to align precisely with the target boundary, enabling adaptation to\nblurred edges and intricate morphologies common in medical images. This\niterative adjustment process is optimized by a contour-specific Soft\nActor-Critic (SAC) algorithm, further enhanced with the Entropy Regularization\nAdjustment Mechanism (ERAM) which dynamically balance agent exploration with\ncontour smoothness. Furthermore, the framework incorporates a Mamba-based\npolicy network featuring a novel Bidirectional Cross-attention Hidden-state\nFusion Mechanism (BCHFM). This mechanism mitigates potential memory confusion\nlimitations associated with long-range modeling in state space models, thereby\nfacilitating more accurate inter-agent information exchange and informed\ndecision-making. Extensive experiments on five diverse medical imaging datasets\ndemonstrate the state-of-the-art performance of MARL-MambaContour, highlighting\nits potential as an accurate and robust clinical application.",
      "url": "http://arxiv.org/abs/2506.18679v1",
      "published_time_eastern_timestamp": 1750688569.0
    },
    {
      "title": "MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit\n  Neural Scene Representation",
      "summary": "Neural implicit scene representations have recently shown promising results\nin dense visual SLAM. However, existing implicit SLAM algorithms are\nconstrained to single-agent scenarios, and fall difficulties in large-scale\nscenes and long sequences. Existing NeRF-based multi-agent SLAM frameworks\ncannot meet the constraints of communication bandwidth. To this end, we propose\nthe first distributed multi-agent collaborative neural SLAM framework with\nhybrid scene representation, distributed camera tracking, intra-to-inter loop\nclosure, and online distillation for multiple submap fusion. A novel\ntriplane-grid joint scene representation method is proposed to improve scene\nreconstruction. A novel intra-to-inter loop closure method is designed to\nachieve local (single-agent) and global (multi-agent) consistency. We also\ndesign a novel online distillation method to fuse the information of different\nsubmaps to achieve global consistency. Furthermore, to the best of our\nknowledge, there is no real-world dataset for NeRF-based/GS-based SLAM that\nprovides both continuous-time trajectories groundtruth and high-accuracy 3D\nmeshes groundtruth. To this end, we propose the first real-world Dense slam\n(DES) dataset covering both single-agent and multi-agent scenarios, ranging\nfrom small rooms to large-scale outdoor scenes, with high-accuracy ground truth\nfor both 3D mesh and continuous-time camera trajectory. This dataset can\nadvance the development of the research in both SLAM, 3D reconstruction, and\nvisual foundation model. Experiments on various datasets demonstrate the\nsuperiority of the proposed method in both mapping, tracking, and\ncommunication. The dataset and code will open-source on\nhttps://github.com/dtc111111/mcnslam.",
      "url": "http://arxiv.org/abs/2506.18678v1",
      "published_time_eastern_timestamp": 1750688549.0
    },
    {
      "title": "Dual-level Behavioral Consistency for Inter-group and Intra-group\n  Coordination in Multi-Agent Systems",
      "summary": "Behavioral diversity in Multi-agent reinforcement learning(MARL) represents\nan emerging and promising research area. Prior work has largely centered on\nintra-group behavioral consistency in multi-agent systems, with limited\nattention given to behavioral consistency in multi-agent grouping scenarios. In\nthis paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL\ncontrol method designed to explicitly regulate agent behaviors at both\nintra-group and inter-group levels. DLBC partitions agents into distinct groups\nand dynamically modulates behavioral diversity both within and between these\ngroups. By dynamically modulating behavioral diversity within and between these\ngroups, DLBC achieves enhanced division of labor through inter-group\nconsistency, which constrains behavioral strategies across different groups.\nSimultaneously, intra-group consistency, achieved by aligning behavioral\nstrategies within each group, fosters stronger intra-group cooperation.\nCrucially, DLBC's direct constraint of agent policy functions ensures its broad\napplicability across various algorithmic frameworks. Experimental results in\nvarious grouping cooperation scenarios demonstrate that DLBC significantly\nenhances both intra-group cooperative performance and inter-group task\nspecialization, yielding substantial performance improvements. DLBC provides\nnew ideas for behavioral consistency control of multi-intelligent body systems,\nand its potential for application in more complex tasks and dynamic\nenvironments can be further explored in the future.",
      "url": "http://arxiv.org/abs/2506.18651v1",
      "published_time_eastern_timestamp": 1750686874.0
    },
    {
      "title": "Multi-Agent Reinforcement Learning for Inverse Design in Photonic\n  Integrated Circuits",
      "summary": "Inverse design of photonic integrated circuits (PICs) has traditionally\nrelied on gradientbased optimization. However, this approach is prone to end up\nin local minima, which results in suboptimal design functionality. As interest\nin PICs increases due to their potential for addressing modern hardware demands\nthrough optical computing, more adaptive optimization algorithms are needed. We\npresent a reinforcement learning (RL) environment as well as multi-agent RL\nalgorithms for the design of PICs. By discretizing the design space into a\ngrid, we formulate the design task as an optimization problem with thousands of\nbinary variables. We consider multiple two- and three-dimensional design tasks\nthat represent PIC components for an optical computing system. By decomposing\nthe design space into thousands of individual agents, our algorithms are able\nto optimize designs with only a few thousand environment samples. They\noutperform previous state-of-the-art gradient-based optimization in both twoand\nthree-dimensional design tasks. Our work may also serve as a benchmark for\nfurther exploration of sample-efficient RL for inverse design in photonics.",
      "url": "http://arxiv.org/abs/2506.18627v1",
      "published_time_eastern_timestamp": 1750685667.0
    },
    {
      "title": "Reply to \"Emergent LLM behaviors are observationally equivalent to data\n  leakage\"",
      "summary": "A potential concern when simulating populations of large language models\n(LLMs) is data contamination, i.e. the possibility that training data may shape\noutcomes in unintended ways. While this concern is important and may hinder\ncertain experiments with multi-agent models, it does not preclude the study of\ngenuinely emergent dynamics in LLM populations. The recent critique by Barrie\nand T\\\"ornberg [1] of the results of Flint Ashery et al. [2] offers an\nopportunity to clarify that self-organisation and model-dependent emergent\ndynamics can be studied in LLM populations, highlighting how such dynamics have\nbeen empirically observed in the specific case of social conventions.",
      "url": "http://arxiv.org/abs/2506.18600v1",
      "published_time_eastern_timestamp": 1750683574.0
    },
    {
      "title": "Agentic Markets: Game Dynamics and Equilibrium in Markets with Learning\n  Agents",
      "summary": "Autonomous and learning agents increasingly participate in markets - setting\nprices, placing bids, ordering inventory. Such agents are not just aiming to\noptimize in an uncertain environment; they are making decisions in a\ngame-theoretical environment where the decision of one agent influences the\nprofit of other agents. While game theory usually predicts outcomes of\nstrategic interaction as an equilibrium, it does not capture how repeated\ninteraction of learning agents arrives at a certain outcome. This article\nsurveys developments in modeling agent behavior as dynamical systems, with a\nfocus on projected gradient and no-regret learning algorithms. In general,\nlearning in games can lead to all types of dynamics, including convergence to\nequilibrium, but also cycles and chaotic behavior. It is important to\nunderstand when we can expect efficient equilibrium in automated markets and\nwhen this is not the case. Thus, we analyze when and how learning agents\nconverge to an equilibrium of a market game, drawing on tools from variational\ninequalities and Lyapunov stability theory. Special attention is given to the\nstability of projected dynamics and the convergence to equilibrium sets as\nlimiting outcomes. Overall, the paper provides mathematical foundations for\nanalyzing stability and convergence in agentic markets driven by autonomous,\nlearning agents.",
      "url": "http://arxiv.org/abs/2506.18571v1",
      "published_time_eastern_timestamp": 1750681430.0
    },
    {
      "title": "Efficient Beam Selection for ISAC in Cell-Free Massive MIMO via Digital\n  Twin-Assisted Deep Reinforcement Learning",
      "summary": "Beamforming enhances signal strength and quality by focusing energy in\nspecific directions. This capability is particularly crucial in cell-free\nintegrated sensing and communication (ISAC) systems, where multiple distributed\naccess points (APs) collaborate to provide both communication and sensing\nservices. In this work, we first derive the distribution of joint target\ndetection probabilities across multiple receiving APs under false alarm rate\nconstraints, and then formulate the beam selection procedure as a Markov\ndecision process (MDP). We establish a deep reinforcement learning (DRL)\nframework, in which reward shaping and sinusoidal embedding are introduced to\nfacilitate agent learning. To eliminate the high costs and associated risks of\nreal-time agent-environment interactions, we further propose a novel digital\ntwin (DT)-assisted offline DRL approach. Different from traditional online DRL,\na conditional generative adversarial network (cGAN)-based DT module, operating\nas a replica of the real world, is meticulously designed to generate virtual\nstate-action transition pairs and enrich data diversity, enabling offline\nadjustment of the agent's policy. Additionally, we address the\nout-of-distribution issue by incorporating an extra penalty term into the loss\nfunction design. The convergency of agent-DT interaction and the upper bound of\nthe Q-error function are theoretically derived. Numerical results demonstrate\nthe remarkable performance of our proposed approach, which significantly\nreduces online interaction overhead while maintaining effective beam selection\nacross diverse conditions including strict false alarm control, low\nsignal-to-noise ratios, and high target velocities.",
      "url": "http://arxiv.org/abs/2506.18560v1",
      "published_time_eastern_timestamp": 1750681077.0
    },
    {
      "title": "T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing\n  Logic-RAG Agent",
      "summary": "Large language models excel at generating fluent text but frequently struggle\nwith structured reasoning involving temporal constraints, causal relationships,\nand probabilistic reasoning. To address these limitations, we propose Temporal\nCausal Probabilistic Description Logic (T-CPDL), an integrated framework that\nextends traditional Description Logic with temporal interval operators,\nexplicit causal relationships, and probabilistic annotations. We present two\ndistinct variants of T-CPDL: one capturing qualitative temporal relationships\nthrough Allen's interval algebra, and another variant enriched with explicit\ntimestamped causal assertions. Both variants share a unified logical structure,\nenabling complex reasoning tasks ranging from simple temporal ordering to\nnuanced probabilistic causation. Empirical evaluations on temporal reasoning\nand causal inference benchmarks confirm that T-CPDL substantially improves\ninference accuracy, interpretability, and confidence calibration of language\nmodel outputs. By delivering transparent reasoning paths and fine-grained\ntemporal and causal semantics, T-CPDL significantly enhances the capability of\nlanguage models to support robust, explainable, and trustworthy\ndecision-making. This work also lays the groundwork for developing advanced\nLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially\nboosting the reasoning capabilities and efficiency of knowledge graph-enhanced\nRAG systems.",
      "url": "http://arxiv.org/abs/2506.18559v1",
      "published_time_eastern_timestamp": 1750680675.0
    },
    {
      "title": "Unilateral determination of causal order in a cyclic process",
      "summary": "The recent years have seen interest into the possibility for (classical as\nwell as quantum) causal structures that, while remaining logically consistent,\nfeature a cyclic causal order between events, opening intriguing possibilities\nfor new physics. In the cyclic processes displayed so far, the global causal\norder is determined jointly by the operations performed by agents at each\nevent, a feature that can be certified through the introduction of causal games\nand (the violation of) causal inequalities. This raises the question of whether\nthere exist processes in which an agent acting at a single event can\nunilaterally determine her causal ordering with respect to some other events.\nWe answer this question in the affirmative, by introducing a process in which\nany party may be put in a position to pick, on her own, any other party to lie\nin her future. We certify this behaviour by displaying a related causal\ninequality that the process allows to maximally violate.",
      "url": "http://arxiv.org/abs/2506.18540v1",
      "published_time_eastern_timestamp": 1750679525.0
    }
  ]
}
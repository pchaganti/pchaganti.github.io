{
  "last_updated": "2025-08-18T20:58:17.169908-04:00",
  "papers": [
    {
      "title": "Optimal CO2 storage management considering safety constraints in\n  multi-stakeholder multi-site CCS projects: a game theoretic perspective",
      "summary": "Carbon capture and storage (CCS) projects typically involve a diverse array\nof stakeholders or players from public, private, and regulatory sectors, each\nwith different objectives and responsibilities. Given the complexity, scale,\nand long-term nature of CCS operations, determining whether individual\nstakeholders can independently maximize their interests or whether\ncollaborative coalition agreements are needed remains a central question for\neffective CCS project planning and management. CCS projects are often\nimplemented in geologically connected sites, where shared geological features\nsuch as pressure space and reservoir pore capacity can lead to competitive\nbehavior among stakeholders. Furthermore, CO2 storage sites are often located\nin geologically mature basins that previously served as sites for hydrocarbon\nextraction or wastewater disposal in order to leverage existing\ninfrastructures, which makes unilateral optimization even more complicated and\nunrealistic.\n  In this work, we propose a paradigm based on Markov games to quantitatively\ninvestigate how different coalition structures affect the goals of\nstakeholders. We frame this multi-stakeholder multi-site problem as a\nmulti-agent reinforcement learning problem with safety constraints. Our\napproach enables agents to learn optimal strategies while compliant with safety\nregulations. We present an example where multiple operators are injecting CO2\ninto their respective project areas in a geologically connected basin. To\naddress the high computational cost of repeated simulations of high-fidelity\nmodels, a previously developed surrogate model based on the Embed-to-Control\n(E2C) framework is employed. Our results demonstrate the effectiveness of the\nproposed framework in addressing optimal management of CO2 storage when\nmultiple stakeholders with various objectives and goals are involved.",
      "url": "http://arxiv.org/abs/2508.11618v1",
      "published_time_eastern_timestamp": 1755279385.0
    },
    {
      "title": "Intelligent Edge Resource Provisioning for Scalable Digital Twins of\n  Autonomous Vehicles",
      "summary": "The next generation networks offers significant potential to advance\nIntelligent Transportation Systems (ITS), particularly through the integration\nof Digital Twins (DTs). However, ensuring the uninterrupted operation of DTs\nthrough efficient computing resource management remains an open challenge. This\npaper introduces a distributed computing archi tecture that integrates DTs and\nMobile Edge Computing (MEC) within a software-defined vehicular networking\nframework to enable intelligent, low-latency transportation services. A network\naware scalable collaborative task provisioning algorithm is de veloped to train\nan autonomous agent, which is evaluated using a realistic connected autonomous\nvehicle (CAV) traffic simulation. The proposed framework significantly enhances\nthe robustness and scalability of DT operations by reducing synchronization\nerrors to as low as 5% while achieving up to 99.5% utilization of edge\ncomputing resources.",
      "url": "http://arxiv.org/abs/2508.11574v1",
      "published_time_eastern_timestamp": 1755275345.0
    },
    {
      "title": "AgentMental: An Interactive Multi-Agent Framework for Explainable and\n  Adaptive Mental Health Assessment",
      "summary": "Mental health assessment is crucial for early intervention and effective\ntreatment, yet traditional clinician-based approaches are limited by the\nshortage of qualified professionals. Recent advances in artificial intelligence\nhave sparked growing interest in automated psychological assessment, yet most\nexisting approaches are constrained by their reliance on static text analysis,\nlimiting their ability to capture deeper and more informative insights that\nemerge through dynamic interaction and iterative questioning. Therefore, in\nthis paper, we propose a multi-agent framework for mental health evaluation\nthat simulates clinical doctor-patient dialogues, with specialized agents\nassigned to questioning, adequacy evaluation, scoring, and updating. We\nintroduce an adaptive questioning mechanism in which an evaluation agent\nassesses the adequacy of user responses to determine the necessity of\ngenerating targeted follow-up queries to address ambiguity and missing\ninformation. Additionally, we employ a tree-structured memory in which the root\nnode encodes the user's basic information, while child nodes (e.g., topic and\nstatement) organize key information according to distinct symptom categories\nand interaction turns. This memory is dynamically updated throughout the\ninteraction to reduce redundant questioning and further enhance the information\nextraction and contextual tracking capabilities. Experimental results on the\nDAIC-WOZ dataset illustrate the effectiveness of our proposed method, which\nachieves better performance than existing approaches.",
      "url": "http://arxiv.org/abs/2508.11567v1",
      "published_time_eastern_timestamp": 1755274845.0
    },
    {
      "title": "SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving\n  Bubble-Free Pipelines via Tag Scheduling",
      "summary": "We introduce SeamlessFlow, a server based reinforcement learning (RL)\nframework that addresses two core challenges in industrial scale RL: (1)\ndecoupling RL training from the complex execution flow of agents; (2)\nmaximizing GPU utilization with minimal idle time while preserving the\nstability and scalability required for large-scale deployments. First,\nSeamlessFlow introduces a data plane that decouples the RL trainer from\ndiverse, complex agent implementations while sustaining high throughput. A\ncentral trajectory manager maintains complete interaction histories and\nsupports partial rollout, allowing rollout to pause for weight updates and\nresume seamlessly, keeping agents unaware of service interruptions. Second, we\npropose a tag driven scheduling paradigm that abstracts hardware into\ncapability tagged resources, unifying colocated and disaggregated\narchitectures. Based on this, SeamlessFlow introduces a spatiotemporal\nmultiplexing pipeline that dynamically reassigns idle training nodes to rollout\nin a train rollout separated setup, eliminating pipeline bubbles and fully\nexploiting heterogeneous cluster resources. By combining these innovations,\nSeamlessFlow delivers both stability and high performance, making it well\nsuited for multi agent, long horizon, and other complex RL tasks.",
      "url": "http://arxiv.org/abs/2508.11553v1",
      "published_time_eastern_timestamp": 1755273337.0
    },
    {
      "title": "A Comprehensive Perspective on Explainable AI across the Machine\n  Learning Workflow",
      "summary": "Artificial intelligence is reshaping science and industry, yet many users\nstill regard its models as opaque \"black boxes\". Conventional explainable\nartificial-intelligence methods clarify individual predictions but overlook the\nupstream decisions and downstream quality checks that determine whether\ninsights can be trusted. In this work, we present Holistic Explainable\nArtificial Intelligence (HXAI), a user-centric framework that embeds\nexplanation into every stage of the data-analysis workflow and tailors those\nexplanations to users. HXAI unifies six components (data, analysis set-up,\nlearning process, model output, model quality, communication channel) into a\nsingle taxonomy and aligns each component with the needs of domain experts,\ndata analysts and data scientists. A 112-item question bank covers these needs;\nour survey of contemporary tools highlights critical coverage gaps. Grounded in\ntheories of human explanation, principles from human-computer interaction and\nfindings from empirical user studies, HXAI identifies the characteristics that\nmake explanations clear, actionable and cognitively manageable. A comprehensive\ntaxonomy operationalises these insights, reducing terminological ambiguity and\nenabling rigorous coverage analysis of existing toolchains. We further\ndemonstrate how AI agents that embed large-language models can orchestrate\ndiverse explanation techniques, translating technical artifacts into\nstakeholder-specific narratives that bridge the gap between AI developers and\ndomain experts. Departing from traditional surveys or perspective articles,\nthis work melds concepts from multiple disciplines, lessons from real-world\nprojects and a critical synthesis of the literature to advance a novel,\nend-to-end viewpoint on transparency, trustworthiness and responsible AI\ndeployment.",
      "url": "http://arxiv.org/abs/2508.11529v1",
      "published_time_eastern_timestamp": 1755270925.0
    },
    {
      "title": "DiCriTest: Testing Scenario Generation for Decision-Making Agents\n  Considering Diversity and Criticality",
      "summary": "The growing deployment of decision-making agents in dynamic environments\nincreases the demand for safety verification. While critical testing scenario\ngeneration has emerged as an appealing verification methodology, effectively\nbalancing diversity and criticality remains a key challenge for existing\nmethods, particularly due to local optima entrapment in high-dimensional\nscenario spaces. To address this limitation, we propose a dual-space guided\ntesting framework that coordinates scenario parameter space and agent behavior\nspace, aiming to generate testing scenarios considering diversity and\ncriticality. Specifically, in the scenario parameter space, a hierarchical\nrepresentation framework combines dimensionality reduction and\nmulti-dimensional subspace evaluation to efficiently localize diverse and\ncritical subspaces. This guides dynamic coordination between two generation\nmodes: local perturbation and global exploration, optimizing critical scenario\nquantity and diversity. Complementarily, in the agent behavior space,\nagent-environment interaction data are leveraged to quantify behavioral\ncriticality/diversity and adaptively support generation mode switching, forming\na closed feedback loop that continuously enhances scenario characterization and\nexploration within the parameter space. Experiments show our framework improves\ncritical scenario generation by an average of 56.23\\% and demonstrates greater\ndiversity under novel parameter-behavior co-driven metrics when tested on five\ndecision-making agents, outperforming state-of-the-art baselines.",
      "url": "http://arxiv.org/abs/2508.11514v1",
      "published_time_eastern_timestamp": 1755269505.0
    },
    {
      "title": "Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media",
      "summary": "Reliable autonomous navigation across the unstructured terrains of distant\nplanetary surfaces is a critical enabler for future space exploration. However,\nthe deployment of learning-based controllers is hindered by the inherent\nsim-to-real gap, particularly for the complex dynamics of wheel interactions\nwith granular media. This work presents a complete sim-to-real framework for\ndeveloping and validating robust control policies for dynamic waypoint tracking\non such challenging surfaces. We leverage massively parallel simulation to\ntrain reinforcement learning agents across a vast distribution of procedurally\ngenerated environments with randomized physics. These policies are then\ntransferred zero-shot to a physical wheeled rover operating in a lunar-analogue\nfacility. Our experiments systematically compare multiple reinforcement\nlearning algorithms and action smoothing filters to identify the most effective\ncombinations for real-world deployment. Crucially, we provide strong empirical\nevidence that agents trained with procedural diversity achieve superior\nzero-shot performance compared to those trained on static scenarios. We also\nanalyze the trade-offs of fine-tuning with high-fidelity particle physics,\nwhich offers minor gains in low-speed precision at a significant computational\ncost. Together, these contributions establish a validated workflow for creating\nreliable learning-based navigation systems, marking a critical step towards\ndeploying autonomous robots in the final frontier.",
      "url": "http://arxiv.org/abs/2508.11503v1",
      "published_time_eastern_timestamp": 1755268207.0
    },
    {
      "title": "Relative Position Matters: Trajectory Prediction and Planning with Polar\n  Representation",
      "summary": "Trajectory prediction and planning in autonomous driving are highly\nchallenging due to the complexity of predicting surrounding agents' movements\nand planning the ego agent's actions in dynamic environments. Existing methods\nencode map and agent positions and decode future trajectories in Cartesian\ncoordinates. However, modeling the relationships between the ego vehicle and\nsurrounding traffic elements in Cartesian space can be suboptimal, as it does\nnot naturally capture the varying influence of different elements based on\ntheir relative distances and directions. To address this limitation, we adopt\nthe Polar coordinate system, where positions are represented by radius and\nangle. This representation provides a more intuitive and effective way to model\nspatial changes and relative relationships, especially in terms of distance and\ndirectional influence. Based on this insight, we propose Polaris, a novel\nmethod that operates entirely in Polar coordinates, distinguishing itself from\nconventional Cartesian-based approaches. By leveraging the Polar\nrepresentation, this method explicitly models distance and direction variations\nand captures relative relationships through dedicated encoding and refinement\nmodules, enabling more structured and spatially aware trajectory prediction and\nplanning. Extensive experiments on the challenging prediction (Argoverse 2) and\nplanning benchmarks (nuPlan) demonstrate that Polaris achieves state-of-the-art\nperformance.",
      "url": "http://arxiv.org/abs/2508.11492v1",
      "published_time_eastern_timestamp": 1755267311.0
    },
    {
      "title": "OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal\n  Navigation",
      "summary": "Open-vocabulary Object Goal Navigation requires an embodied agent to reach\nobjects described by free-form language, including categories never seen during\ntraining. Existing end-to-end policies overfit small simulator datasets,\nachieving high success on training scenes but failing to generalize and\nexhibiting unsafe behaviour (frequent collisions). We introduce OVSegDT, a\nlightweight transformer policy that tackles these issues with two synergistic\ncomponents. The first component is the semantic branch, which includes an\nencoder for the target binary mask and an auxiliary segmentation loss function,\ngrounding the textual goal and providing precise spatial cues. The second\ncomponent consists of a proposed Entropy-Adaptive Loss Modulation, a per-sample\nscheduler that continuously balances imitation and reinforcement signals\naccording to the policy entropy, eliminating brittle manual phase switches.\nThese additions cut the sample complexity of training by 33%, and reduce\ncollision count in two times while keeping inference cost low (130M parameters,\nRGB-only input). On HM3D-OVON, our model matches the performance on unseen\ncategories to that on seen ones and establishes state-of-the-art results (40.1%\nSR, 20.9% SPL on val unseen) without depth, odometry, or large vision-language\nmodels. Code is available at https://github.com/CognitiveAISystems/OVSegDT.",
      "url": "http://arxiv.org/abs/2508.11479v1",
      "published_time_eastern_timestamp": 1755265695.0
    },
    {
      "title": "Reducing AoI and Improving Throughput for NOMA-assisted SGF Systems: A\n  Hierarchical Learning Approach",
      "summary": "A non-orthogonal multiple access (NOMA) assisted semi-grant-free (SGF)\nframework is proposed to enable channel access for grant-free users (GFUs) by\nusing residual resources from grant-based users. Under this framework, the\nproblem of joint beamforming design and transmission scheduling is formulated\nto improve the system throughput and reduce the age-of-information of GFUs. The\naforementioned problem is transferred into a Markov Decision Process to model\nthe changing environment with the transmission/ waiting/ retransmission of\nGFUs. In an effort to solve the pertinent problem, firstly, a deep\nreinforcement learning (DRL) based transmission scheduling approach is proposed\nfor determining the optimal transmission probability based on the available\ntransmission slots and transmission status of GFUs. Secondly, a hierarchical\nlearning algorithm is proposed to analyze the channel state information of GBUs\nand the transmission status of GFUs, and to train an upper-level policy based\non this analysis for beamforming to achieve efficient grant-based transmission,\nwhile a lower-level policy adapts to maximize the utilization of transmission\nslots allocated by the upper-level agent. The two policies interact to improve\nchannel access and avoid collisions. Numerical results reveal that 1) The DRL\nbased transmission scheduling outperforms existing adaptive and state-dependent\nbaselines in AoI reduction, where an average\nthree-time-slots-earlier-transmission can be obtained compared to the\nstate-dependent choice, and five time slots earlier can be achieved when\ncomparing to the adaptive choice; 2) The hierarchical learning algorithm is\nable to achieve approximately a 31.82% gain while maintaining the average AoI\nof GFUs within 1.5 time slots. 3) The effectiveness of the hierarchical\nlearning scheme in NOMA-assisted SGF system is validated across scenarios with\nGFUs counts from 1-5 times of GBUs.",
      "url": "http://arxiv.org/abs/2508.11473v1",
      "published_time_eastern_timestamp": 1755265179.0
    },
    {
      "title": "EvoPSF: Online Evolution of Autonomous Driving Models via Planning-State\n  Feedback",
      "summary": "Recent years have witnessed remarkable progress in autonomous driving, with\nsystems evolving from modular pipelines to end-to-end architectures. However,\nmost existing methods are trained offline and lack mechanisms to adapt to new\nenvironments during deployment. As a result, their generalization ability\ndiminishes when faced with unseen variations in real-world driving scenarios.\nIn this paper, we break away from the conventional \"train once, deploy forever\"\nparadigm and propose EvoPSF, a novel online Evolution framework for autonomous\ndriving based on Planning-State Feedback. We argue that planning failures are\nprimarily caused by inaccurate object-level motion predictions, and such\nfailures are often reflected in the form of increased planner uncertainty. To\naddress this, we treat planner uncertainty as a trigger for online evolution,\nusing it as a diagnostic signal to initiate targeted model updates. Rather than\nperforming blind updates, we leverage the planner's agent-agent attention to\nidentify the specific objects that the ego vehicle attends to most, which are\nprimarily responsible for the planning failures. For these critical objects, we\ncompute a targeted self-supervised loss by comparing their predicted waypoints\nfrom the prediction module with their actual future positions, selected from\nthe perception module's outputs with high confidence scores. This loss is then\nbackpropagated to adapt the model online. As a result, our method improves the\nmodel's robustness to environmental changes, leads to more precise motion\npredictions, and therefore enables more accurate and stable planning behaviors.\nExperiments on both cross-region and corrupted variants of the nuScenes dataset\ndemonstrate that EvoPSF consistently improves planning performance under\nchallenging conditions.",
      "url": "http://arxiv.org/abs/2508.11453v1",
      "published_time_eastern_timestamp": 1755262855.0
    },
    {
      "title": "ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous\n  Driving",
      "summary": "Autonomous driving requires rich contextual comprehension and precise\npredictive reasoning to navigate dynamic and complex environments safely.\nVision-Language Models (VLMs) and Driving World Models (DWMs) have\nindependently emerged as powerful recipes addressing different aspects of this\nchallenge. VLMs provide interpretability and robust action prediction through\ntheir ability to understand multi-modal context, while DWMs excel in generating\ndetailed and plausible future driving scenarios essential for proactive\nplanning. Integrating VLMs with DWMs is an intuitive, promising, yet\nunderstudied strategy to exploit the complementary strengths of accurate\nbehavioral prediction and realistic scene generation. Nevertheless, this\nintegration presents notable challenges, particularly in effectively connecting\naction-level decisions with high-fidelity pixel-level predictions and\nmaintaining computational efficiency. In this paper, we propose ImagiDrive, a\nnovel end-to-end autonomous driving framework that integrates a VLM-based\ndriving agent with a DWM-based scene imaginer to form a unified\nimagination-and-planning loop. The driving agent predicts initial driving\ntrajectories based on multi-modal inputs, guiding the scene imaginer to\ngenerate corresponding future scenarios. These imagined scenarios are\nsubsequently utilized to iteratively refine the driving agent's planning\ndecisions. To address efficiency and predictive accuracy challenges inherent in\nthis integration, we introduce an early stopping mechanism and a trajectory\nselection strategy. Extensive experimental validation on the nuScenes and\nNAVSIM datasets demonstrates the robustness and superiority of ImagiDrive over\nprevious alternatives under both open-loop and closed-loop conditions.",
      "url": "http://arxiv.org/abs/2508.11428v1",
      "published_time_eastern_timestamp": 1755259615.0
    },
    {
      "title": "Tapas are free! Training-Free Adaptation of Programmatic Agents via\n  LLM-Guided Program Synthesis in Dynamic Environments",
      "summary": "Autonomous agents in safety-critical applications must continuously adapt to\ndynamic conditions without compromising performance and reliability. This work\nintroduces TAPA (Training-free Adaptation of Programmatic Agents), a novel\nframework that positions large language models (LLMs) as intelligent moderators\nof the symbolic action space. Unlike prior programmatic agents that typically\ngenerate a monolithic policy program or rely on fixed symbolic action sets,\nTAPA synthesizes and adapts modular programs for individual high-level actions,\nreferred to as logical primitives. By decoupling strategic intent from\nexecution, TAPA enables meta-agents to operate over an abstract, interpretable\naction space while the LLM dynamically generates, composes, and refines\nsymbolic programs tailored to each primitive. Extensive experiments across\ncybersecurity and swarm intelligence domains validate TAPA's effectiveness. In\nautonomous DDoS defense scenarios, TAPA achieves 77.7% network uptime while\nmaintaining near-perfect detection accuracy in unknown dynamic environments. In\nswarm intelligence formation control under environmental and adversarial\ndisturbances, TAPA consistently preserves consensus at runtime where baseline\nmethods fail completely. This work promotes a paradigm shift for autonomous\nsystem design in evolving environments, from policy adaptation to dynamic\naction adaptation.",
      "url": "http://arxiv.org/abs/2508.11425v1",
      "published_time_eastern_timestamp": 1755259366.0
    },
    {
      "title": "AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory\n  Manager",
      "summary": "Recent advances in mathematical reasoning and the long-term planning\ncapabilities of large language models (LLMs) have precipitated the development\nof agents, which are being increasingly leveraged in business operations\nprocesses. Decision models to optimize inventory levels are one of the core\nelements of operations management. However, the capabilities of the LLM agent\nin making inventory decisions in uncertain contexts, as well as the\ndecision-making biases (e.g. framing effect, etc.) of the agent, remain largely\nunexplored. This prompts concerns regarding the capacity of LLM agents to\neffectively address real-world problems, as well as the potential implications\nof biases that may be present. To address this gap, we introduce AIM-Bench, a\nnovel benchmark designed to assess the decision-making behaviour of LLM agents\nin uncertain supply chain management scenarios through a diverse series of\ninventory replenishment experiments. Our results reveal that different LLMs\ntypically exhibit varying degrees of decision bias that are similar to those\nobserved in human beings. In addition, we explored strategies to mitigate the\npull-to-centre effect and the bullwhip effect, namely cognitive reflection and\nimplementation of information sharing. These findings underscore the need for\ncareful consideration of the potential biases in deploying LLMs in Inventory\ndecision-making scenarios. We hope that these insights will pave the way for\nmitigating human decision bias and developing human-centred decision support\nsystems for supply chains.",
      "url": "http://arxiv.org/abs/2508.11416v1",
      "published_time_eastern_timestamp": 1755257899.0
    },
    {
      "title": "Towards Embodied Conversational Agents for Reducing Oral Exam Anxiety in\n  Extended Reality",
      "summary": "Oral examinations are a prevalent but psychologically demanding form of\nassessment in higher education. Many students experience intense anxiety, which\ncan impair cognitive performance and hinder academic success. This position\npaper explores the potential of embodied conversational agents (ECAs) in\nextended reality (XR) environments to support students preparing for oral\nexams. We propose a system concept that integrates photorealistic ECAs with\nreal-time capable large language models (LLMs) to enable psychologically safe,\nadaptive, and repeatable rehearsal of oral examination scenarios. We also\ndiscuss the potential benefits and challenges of such an envisioned system.",
      "url": "http://arxiv.org/abs/2508.11412v1",
      "published_time_eastern_timestamp": 1755257583.0
    },
    {
      "title": "FACET:Teacher-Centred LLM-Based Multi-Agent Systems-Towards Personalized\n  Educational Worksheets",
      "summary": "The increasing heterogeneity of student populations poses significant\nchallenges for teachers, particularly in mathematics education, where\ncognitive, motivational, and emotional differences strongly influence learning\noutcomes. While AI-driven personalization tools have emerged, most remain\nperformance-focused, offering limited support for teachers and neglecting\nbroader pedagogical needs. This paper presents the FACET framework, a\nteacher-facing, large language model (LLM)-based multi-agent system designed to\ngenerate individualized classroom materials that integrate both cognitive and\nmotivational dimensions of learner profiles. The framework comprises three\nspecialized agents: (1) learner agents that simulate diverse profiles\nincorporating topic proficiency and intrinsic motivation, (2) a teacher agent\nthat adapts instructional content according to didactical principles, and (3)\nan evaluator agent that provides automated quality assurance. We tested the\nsystem using authentic grade 8 mathematics curriculum content and evaluated its\nfeasibility through a) automated agent-based assessment of output quality and\nb) exploratory feedback from K-12 in-service teachers. Results from ten\ninternal evaluations highlighted high stability and alignment between generated\nmaterials and learner profiles, and teacher feedback particularly highlighted\nstructure and suitability of tasks. The findings demonstrate the potential of\nmulti-agent LLM architectures to provide scalable, context-aware\npersonalization in heterogeneous classroom settings, and outline directions for\nextending the framework to richer learner profiles and real-world classroom\ntrials.",
      "url": "http://arxiv.org/abs/2508.11401v1",
      "published_time_eastern_timestamp": 1755256240.0
    },
    {
      "title": "Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling\n  and Explainable Mental Disorder Diagnosis",
      "summary": "LLM-based agents have emerged as transformative tools capable of executing\ncomplex tasks through iterative planning and action, achieving significant\nadvancements in understanding and addressing user needs. Yet, their\neffectiveness remains limited in specialized domains such as mental health\ndiagnosis, where they underperform compared to general applications. Current\napproaches to integrating diagnostic capabilities into LLMs rely on scarce,\nhighly sensitive mental health datasets, which are challenging to acquire.\nThese methods also fail to emulate clinicians' proactive inquiry skills, lack\nmulti-turn conversational comprehension, and struggle to align outputs with\nexpert clinical reasoning. To address these gaps, we propose DSM5AgentFlow, the\nfirst LLM-based agent workflow designed to autonomously generate DSM-5 Level-1\ndiagnostic questionnaires. By simulating therapist-client dialogues with\nspecific client profiles, the framework delivers transparent, step-by-step\ndisorder predictions, producing explainable and trustworthy results. This\nworkflow serves as a complementary tool for mental health diagnosis, ensuring\nadherence to ethical and legal standards. Through comprehensive experiments, we\nevaluate leading LLMs across three critical dimensions: conversational realism,\ndiagnostic accuracy, and explainability. Our datasets and implementations are\nfully open-sourced.",
      "url": "http://arxiv.org/abs/2508.11398v1",
      "published_time_eastern_timestamp": 1755256112.0
    },
    {
      "title": "Retrieval-augmented reasoning with lean language models",
      "summary": "This technical report details a novel approach to combining reasoning and\nretrieval augmented generation (RAG) within a single, lean language model\narchitecture. While existing RAG systems typically rely on large-scale models\nand external APIs, our work addresses the increasing demand for performant and\nprivacy-preserving solutions deployable in resource-constrained or secure\nenvironments. Building on recent developments in test-time scaling and\nsmall-scale reasoning models, we develop a retrieval augmented conversational\nagent capable of interpreting complex, domain-specific queries using a\nlightweight backbone model. Our system integrates a dense retriever with\nfine-tuned Qwen2.5-Instruct models, using synthetic query generation and\nreasoning traces derived from frontier models (e.g., DeepSeek-R1) over a\ncurated corpus, in this case, the NHS A-to-Z condition pages. We explore the\nimpact of summarisation-based document compression, synthetic data design, and\nreasoning-aware fine-tuning on model performance. Evaluation against both\nnon-reasoning and general-purpose lean models demonstrates that our\ndomain-specific fine-tuning approach yields substantial gains in answer\naccuracy and consistency, approaching frontier-level performance while\nremaining feasible for local deployment. All implementation details and code\nare publicly released to support reproducibility and adaptation across domains.",
      "url": "http://arxiv.org/abs/2508.11386v1",
      "published_time_eastern_timestamp": 1755254295.0
    },
    {
      "title": "CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks",
      "summary": "As autonomous agents become adept at understanding and interacting with\ngraphical user interface (GUI) environments, a new era of automated task\nexecution is emerging. Recent studies have demonstrated that Reinforcement\nLearning (RL) can effectively enhance agents' performance in dynamic\ninteractive GUI environments. However, these methods face two key limitations:\n(1) they overlook the significant variation in difficulty across different GUI\ntasks by treating the entire training data as a uniform set, which hampers the\nagent's ability to adapt its learning process; and (2) most approaches collapse\ntask-specific nuances into a single, coarse reward, leaving the agent with a\nuniform signal that yields inefficient policy updates. To address these\nlimitations, we propose CRAFT-GUI, a curriculum learning framework based on\nGroup Relative Policy Optimization (GRPO) that explicitly accounts for the\nvarying difficulty across trajectories. To enable more fine-grained policy\noptimization, we design a reward function that combines simple rule-based\nsignals with model-judged evaluation, providing richer and more nuanced\nfeedback during training. Experimental results demonstrate that our method\nachieves significant improvements over previous state-of-the-art approaches,\noutperforming them by 5.6% on public benchmarks Android Control and 10.3% on\nour internal online benchmarks, respectively. These findings empirically\nvalidate the effectiveness of integrating reinforcement learning with\ncurriculum learning in GUI interaction tasks.",
      "url": "http://arxiv.org/abs/2508.11360v1",
      "published_time_eastern_timestamp": 1755251702.0
    },
    {
      "title": "SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced\n  Benchmark for Automatic Survey Generation Systems",
      "summary": "The growing interest in automatic survey generation (ASG), a task that\ntraditionally required considerable time and effort, has been spurred by recent\nadvances in large language models (LLMs). With advancements in\nretrieval-augmented generation (RAG) and the rising popularity of multi-agent\nsystems (MASs), synthesizing academic surveys using LLMs has become a viable\napproach, thereby elevating the need for robust evaluation methods in this\ndomain. However, existing evaluation methods suffer from several limitations,\nincluding biased metrics, a lack of human preference, and an over-reliance on\nLLMs-as-judges. To address these challenges, we propose SGSimEval, a\ncomprehensive benchmark for Survey Generation with Similarity-Enhanced\nEvaluation that evaluates automatic survey generation systems by integrating\nassessments of the outline, content, and references, and also combines\nLLM-based scoring with quantitative metrics to provide a multifaceted\nevaluation framework. In SGSimEval, we also introduce human preference metrics\nthat emphasize both inherent quality and similarity to humans. Extensive\nexperiments reveal that current ASG systems demonstrate human-comparable\nsuperiority in outline generation, while showing significant room for\nimprovement in content and reference generation, and our evaluation metrics\nmaintain strong consistency with human assessments.",
      "url": "http://arxiv.org/abs/2508.11310v1",
      "published_time_eastern_timestamp": 1755246478.0
    }
  ]
}
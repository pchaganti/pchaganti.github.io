{
  "last_updated": "2025-08-14T14:17:51.372599-04:00",
  "papers": [
    {
      "title": "Vision-driven River Following of UAV via Safe Reinforcement Learning\n  using Semantic Dynamics Model",
      "summary": "Vision-driven autonomous river following by Unmanned Aerial Vehicles is\ncritical for applications such as rescue, surveillance, and environmental\nmonitoring, particularly in dense riverine environments where GPS signals are\nunreliable. We formalize river following as a coverage control problem in which\nthe reward function is submodular, yielding diminishing returns as more unique\nriver segments are visited, thereby framing the task as a Submodular Markov\nDecision Process. First, we introduce Marginal Gain Advantage Estimation, which\nrefines the reward advantage function by using a sliding window baseline\ncomputed from historical episodic returns, thus aligning the advantage\nestimation with the agent's evolving recognition of action value in\nnon-Markovian settings. Second, we develop a Semantic Dynamics Model based on\npatchified water semantic masks that provides more interpretable and\ndata-efficient short-term prediction of future observations compared to latent\nvision dynamics models. Third, we present the Constrained Actor Dynamics\nEstimator architecture, which integrates the actor, the cost estimator, and SDM\nfor cost advantage estimation to form a model-based SafeRL framework capable of\nsolving partially observable Constrained Submodular Markov Decision Processes.\nSimulation results demonstrate that MGAE achieves faster convergence and\nsuperior performance over traditional critic-based methods like Generalized\nAdvantage Estimation. SDM provides more accurate short-term state predictions\nthat enable the cost estimator to better predict potential violations. Overall,\nCADE effectively integrates safety regulation into model-based RL, with the\nLagrangian approach achieving the soft balance of reward and safety during\ntraining, while the safety layer enhances performance during inference by hard\naction overlay.",
      "url": "http://arxiv.org/abs/2508.09971v1",
      "published_time_eastern_timestamp": 1755106749.0
    },
    {
      "title": "Online Safety under Multiple Constraints and Input Bounds using\n  gatekeeper: Theory and Applications",
      "summary": "This letter presents an approach to guarantee online safety of a\ncyber-physical system under multiple state and input constraints. Our proposed\nframework, called gatekeeper, recursively guarantees the existence of an\ninfinite-horizon trajectory that satisfies all constraints and system dynamics.\nSuch trajectory is constructed using a backup controller, which we define\nformally in this paper. gatekeeper relies on a small number of verifiable\nassumptions, and is computationally efficient since it requires optimization\nover a single scalar variable. We make two primary contributions in this\nletter. (A) First, we develop the theory of gatekeeper: we derive a\nsub-optimality bound relative to a full nonlinear trajectory optimization\nproblem, and show how this can be used in runtime to validate performance. This\nalso informs the design of the backup controllers and sets. (B) Second, we\ndemonstrate in detail an application of gatekeeper for multi-agent formation\nflight, where each Dubins agent must avoid multiple obstacles and weapons\nengagement zones, both of which are nonlinear, nonconvex constraints.",
      "url": "http://arxiv.org/abs/2508.09963v1",
      "published_time_eastern_timestamp": 1755106289.0
    },
    {
      "title": "Mathematical Computation and Reasoning Errors by Large Language Models",
      "summary": "Large Language Models (LLMs) are increasingly utilized in AI-driven\neducational instruction and assessment, particularly within mathematics\neducation. The capability of LLMs to generate accurate answers and detailed\nsolutions for math problem-solving tasks is foundational for ensuring reliable\nand precise feedback and assessment in math education practices. Our study\nfocuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,\nDeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including\narithmetic, algebra, and number theory, and identifies step-level reasoning\nerrors within their solutions. Instead of relying on standard benchmarks, we\nintentionally build math tasks (via item models) that are challenging for LLMs\nand prone to errors. The accuracy of final answers and the presence of errors\nin individual solution steps were systematically analyzed and coded. Both\nsingle-agent and dual-agent configurations were tested. It is observed that the\nreasoning-enhanced OpenAI o1 model consistently achieved higher or nearly\nperfect accuracy across all three math task categories. Analysis of errors\nrevealed that procedural slips were the most frequent and significantly\nimpacted overall performance, while conceptual misunderstandings were less\nfrequent. Deploying dual-agent configurations substantially improved overall\nperformance. These findings offer actionable insights into enhancing LLM\nperformance and underscore effective strategies for integrating LLMs into\nmathematics education, thereby advancing AI-driven instructional practices and\nassessment precision.",
      "url": "http://arxiv.org/abs/2508.09932v1",
      "published_time_eastern_timestamp": 1755102782.0
    },
    {
      "title": "T-CACE: A Time-Conditioned Autoregressive Contrast Enhancement\n  Multi-Task Framework for Contrast-Free Liver MRI Synthesis, Segmentation, and\n  Diagnosis",
      "summary": "Magnetic resonance imaging (MRI) is a leading modality for the diagnosis of\nliver cancer, significantly improving the classification of the lesion and\npatient outcomes. However, traditional MRI faces challenges including risks\nfrom contrast agent (CA) administration, time-consuming manual assessment, and\nlimited annotated datasets. To address these limitations, we propose a\nTime-Conditioned Autoregressive Contrast Enhancement (T-CACE) framework for\nsynthesizing multi-phase contrast-enhanced MRI (CEMRI) directly from\nnon-contrast MRI (NCMRI). T-CACE introduces three core innovations: a\nconditional token encoding (CTE) mechanism that unifies anatomical priors and\ntemporal phase information into latent representations; and a dynamic\ntime-aware attention mask (DTAM) that adaptively modulates inter-phase\ninformation flow using a Gaussian-decayed attention mechanism, ensuring smooth\nand physiologically plausible transitions across phases. Furthermore, a\nconstraint for temporal classification consistency (TCC) aligns the lesion\nclassification output with the evolution of the physiological signal, further\nenhancing diagnostic reliability. Extensive experiments on two independent\nliver MRI datasets demonstrate that T-CACE outperforms state-of-the-art methods\nin image synthesis, segmentation, and lesion classification. This framework\noffers a clinically relevant and efficient alternative to traditional\ncontrast-enhanced imaging, improving safety, diagnostic efficiency, and\nreliability for the assessment of liver lesion. The implementation of T-CACE is\npublicly available at: https://github.com/xiaojiao929/T-CACE.",
      "url": "http://arxiv.org/abs/2508.09919v1",
      "published_time_eastern_timestamp": 1755101654.0
    },
    {
      "title": "Wisdom of the Crowd, Without the Crowd: A Socratic LLM for Asynchronous\n  Deliberation on Perspectivist Data",
      "summary": "Data annotation underpins the success of modern AI, but the aggregation of\ncrowd-collected datasets can harm the preservation of diverse perspectives in\ndata. Difficult and ambiguous tasks cannot easily be collapsed into unitary\nlabels. Prior work has shown that deliberation and discussion improve data\nquality and preserve diverse perspectives -- however, synchronous deliberation\nthrough crowdsourcing platforms is time-intensive and costly. In this work, we\ncreate a Socratic dialog system using Large Language Models (LLMs) to act as a\ndeliberation partner in place of other crowdworkers. Against a benchmark of\nsynchronous deliberation on two tasks (Sarcasm and Relation detection), our\nSocratic LLM encouraged participants to consider alternate annotation\nperspectives, update their labels as needed (with higher confidence), and\nresulted in higher annotation accuracy (for the Relation task where ground\ntruth is available). Qualitative findings show that our agent's Socratic\napproach was effective at encouraging reasoned arguments from our participants,\nand that the intervention was well-received. Our methodology lays the\ngroundwork for building scalable systems that preserve individual perspectives\nin generating more representative datasets.",
      "url": "http://arxiv.org/abs/2508.09911v1",
      "published_time_eastern_timestamp": 1755101265.0
    },
    {
      "title": "RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA",
      "summary": "Regulatory compliance question answering (QA) requires precise, verifiable\ninformation, and domain-specific expertise, posing challenges for Large\nLanguage Models (LLMs). In this work, we present a novel multi-agent framework\nthat integrates a Knowledge Graph (KG) of Regulatory triplets with\nRetrieval-Augmented Generation (RAG) to address these demands. First, agents\nbuild and maintain an ontology-free KG by extracting subject--predicate--object\n(SPO) triplets from regulatory documents and systematically cleaning,\nnormalizing, deduplicating, and updating them. Second, these triplets are\nembedded and stored along with their corresponding textual sections and\nmetadata in a single enriched vector database, allowing for both graph-based\nreasoning and efficient information retrieval. Third, an orchestrated agent\npipeline leverages triplet-level retrieval for question answering, ensuring\nhigh semantic alignment between user queries and the factual\n\"who-did-what-to-whom\" core captured by the graph. Our hybrid system\noutperforms conventional methods in complex regulatory queries, ensuring\nfactual correctness with embedded triplets, enabling traceability through a\nunified vector database, and enhancing understanding through subgraph\nvisualization, providing a robust foundation for compliance-driven and broader\naudit-focused applications.",
      "url": "http://arxiv.org/abs/2508.09893v1",
      "published_time_eastern_timestamp": 1755100265.0
    },
    {
      "title": "AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust\n  GAIA Problem Solving",
      "summary": "The rapid advancement of large language models (LLMs) has empowered\nintelligent agents to leverage diverse external tools for solving complex\nreal-world problems. However, as agents increasingly depend on multiple tools,\nthey encounter new challenges: extended contexts from disparate sources and\nnoisy or irrelevant tool outputs can undermine system reliability and accuracy.\nThese challenges underscore the necessity for enhanced stability in agent-based\nsystems. To address this, we introduce dynamic supervision and maneuvering\nmechanisms, constructing a robust and dynamic Multi-Agent System (MAS)\narchitecture within the AWorld framework. In our approach, the Execution Agent\ninvokes the Guard Agent at critical steps to verify and correct the reasoning\nprocess, effectively reducing errors arising from noise and bolstering\nproblem-solving robustness. Extensive experiments on the GAIA test dataset\nreveal that our dynamic maneuvering mechanism significantly improves both the\neffectiveness and stability of solutions, outperforming single-agent system\n(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system\nachieved first place among open-source projects on the prestigious GAIA\nleaderboard. These findings highlight the practical value of collaborative\nagent roles in developing more reliable and trustworthy intelligent systems.",
      "url": "http://arxiv.org/abs/2508.09889v1",
      "published_time_eastern_timestamp": 1755099985.0
    },
    {
      "title": "The Price of EF1 for Few Agents with Additive Ternary Valuations",
      "summary": "We consider a resource allocation problem with agents that have additive\nternary valuations for a set of indivisible items, and bound the price of\nenvy-free up to one item (EF1) allocations. For a large number $n$ of agents,\nwe show a lower bound of $\\Omega(\\sqrt{n})$, implying that the price of EF1 is\nno better than when the agents have general subadditive valuations. We then\nfocus on instances with few agents and show that the price of EF1 is $12/11$\nfor $n=2$, and between $1.2$ and $1.256$ for $n=3$.",
      "url": "http://arxiv.org/abs/2508.09869v1",
      "published_time_eastern_timestamp": 1755097552.0
    },
    {
      "title": "HumanGenesis: Agent-Based Geometric and Generative Modeling for\n  Synthetic Human Dynamics",
      "summary": "\\textbf{Synthetic human dynamics} aims to generate photorealistic videos of\nhuman subjects performing expressive, intention-driven motions. However,\ncurrent approaches face two core challenges: (1) \\emph{geometric inconsistency}\nand \\emph{coarse reconstruction}, due to limited 3D modeling and detail\npreservation; and (2) \\emph{motion generalization limitations} and \\emph{scene\ninharmonization}, stemming from weak generative capabilities. To address these,\nwe present \\textbf{HumanGenesis}, a framework that integrates geometric and\ngenerative modeling through four collaborative agents: (1)\n\\textbf{Reconstructor} builds 3D-consistent human-scene representations from\nmonocular video using 3D Gaussian Splatting and deformation decomposition. (2)\n\\textbf{Critique Agent} enhances reconstruction fidelity by identifying and\nrefining poor regions via multi-round MLLM-based reflection. (3) \\textbf{Pose\nGuider} enables motion generalization by generating expressive pose sequences\nusing time-aware parametric encoders. (4) \\textbf{Video Harmonizer} synthesizes\nphotorealistic, coherent video via a hybrid rendering pipeline with diffusion,\nrefining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis\nachieves state-of-the-art performance on tasks including text-guided synthesis,\nvideo reenactment, and novel-pose generalization, significantly improving\nexpressiveness, geometric fidelity, and scene integration.",
      "url": "http://arxiv.org/abs/2508.09858v1",
      "published_time_eastern_timestamp": 1755096619.0
    },
    {
      "title": "Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights\n  from Multi-Agent Security Research",
      "summary": "We propose an extension to the OWASP Multi-Agentic System (MAS) Threat\nModeling Guide, translating recent anticipatory research in multi-agent\nsecurity (MASEC) into practical guidance for addressing challenges unique to\nlarge language model (LLM)-driven multi-agent architectures. Although OWASP's\nexisting taxonomy covers many attack vectors, our analysis identifies gaps in\nmodeling failures, including, but not limited to: reasoning collapse across\nplanner-executor chains, metric overfitting, unsafe delegation escalation,\nemergent covert coordination, and heterogeneous multi-agent exploits. We\nintroduce additional threat classes and scenarios grounded in practical MAS\ndeployments, highlighting risks from benign goal drift, cross-agent\nhallucination propagation, affective prompt framing, and multi-agent backdoors.\nWe also outline evaluation strategies, including robustness testing,\ncoordination assessment, safety enforcement, and emergent behavior monitoring,\nto ensure complete coverage. This work complements the framework of OWASP by\nexpanding its applicability to increasingly complex, autonomous, and adaptive\nmulti-agent systems, with the goal of improving security posture and resilience\nin real world deployments.",
      "url": "http://arxiv.org/abs/2508.09815v1",
      "published_time_eastern_timestamp": 1755092875.0
    },
    {
      "title": "Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete",
      "summary": "Logics for reasoning about knowledge and actions have seen many applications\nin various domains of multi-agent systems, including epistemic planning. Change\nof knowledge based on observations about the surroundings forms a key aspect in\nsuch planning scenarios. Public Observation Logic (POL) is a variant of public\nannouncement logic for reasoning about knowledge that gets updated based on\npublic observations. Each state in an epistemic (Kripke) model is equipped with\na set of expected observations. These states evolve as the expectations get\nmatched with the actual observations. In this work, we prove that the\nsatisfiability problem of $\\POL$ is 2EXPTIME-complete.",
      "url": "http://arxiv.org/abs/2508.09784v1",
      "published_time_eastern_timestamp": 1755090616.0
    },
    {
      "title": "Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with\n  Long-Term Memory",
      "summary": "We introduce M3-Agent, a novel multimodal agent framework equipped with\nlong-term memory. Like humans, M3-Agent can process real-time visual and\nauditory inputs to build and update its long-term memory. Beyond episodic\nmemory, it also develops semantic memory, enabling it to accumulate world\nknowledge over time. Its memory is organized in an entity-centric, multimodal\nformat, allowing deeper and more consistent understanding of the environment.\nGiven an instruction, M3-Agent autonomously performs multi-turn, iterative\nreasoning and retrieves relevant information from memory to accomplish the\ntask. To evaluate memory effectiveness and memory-based reasoning in multimodal\nagents, we develop M3-Bench, a new long-video question answering benchmark.\nM3-Bench comprises 100 newly recorded real-world videos captured from a robot's\nperspective (M3-Bench-robot) and 929 web-sourced videos across diverse\nscenarios (M3-Bench-web). We annotate question-answer pairs designed to test\nkey capabilities essential for agent applications, such as human understanding,\ngeneral knowledge extraction, and cross-modal reasoning. Experimental results\nshow that M3-Agent, trained via reinforcement learning, outperforms the\nstrongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o,\nachieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web\nand VideoMME-long, respectively. Our work advances the multimodal agents toward\nmore human-like long-term memory and provides insights into their practical\ndesign. Model, code and data are available at\nhttps://github.com/bytedance-seed/m3-agent",
      "url": "http://arxiv.org/abs/2508.09736v1",
      "published_time_eastern_timestamp": 1755086583.0
    },
    {
      "title": "$\\text{M}^3\\text{PDB}$: A Multimodal, Multi-Label, Multilingual Prompt\n  Database for Speech Generation",
      "summary": "Recent advancements in zero-shot speech generation have enabled models to\nsynthesize speech that mimics speaker identity and speaking style from speech\nprompts. However, these models' effectiveness is significantly limited in\nreal-world scenarios where high-quality speech prompts are absent, incomplete,\nor out of domain. This issue arises primarily from a significant quality\nmismatch between the speech data utilized for model training and the input\nprompt speech during inference. To address this, we introduce\n$\\text{M}^3\\text{PDB}$, the first large-scale, multi-modal, multi-label, and\nmultilingual prompt database designed for robust prompt selection in speech\ngeneration. Our dataset construction leverages a novel multi-modal, multi-agent\nannotation framework, enabling precise and hierarchical labeling across diverse\nmodalities. Furthermore, we propose a lightweight yet effective prompt\nselection strategy tailored for real-time, resource-constrained inference\nsettings. Experimental results demonstrate that our proposed database and\nselection strategy effectively support various challenging speech generation\nscenarios. We hope our work can inspire the community to shift focus from\nimproving performance on standard benchmarks to addressing more realistic and\ndiverse application scenarios in speech generation. Code and dataset are\navailable at: https://github.com/hizening/M3PDB.",
      "url": "http://arxiv.org/abs/2508.09702v1",
      "published_time_eastern_timestamp": 1755082584.0
    },
    {
      "title": "ReqInOne: A Large Language Model-Based Agent for Software Requirements\n  Specification Generation",
      "summary": "Software Requirements Specification (SRS) is one of the most important\ndocuments in software projects, but writing it manually is time-consuming and\noften leads to ambiguity. Existing automated methods rely heavily on manual\nanalysis, while recent Large Language Model (LLM)-based approaches suffer from\nhallucinations and limited controllability. In this paper, we propose ReqInOne,\nan LLM-based agent that follows the common steps taken by human requirements\nengineers when writing an SRS to convert natural language into a structured\nSRS. ReqInOne adopts a modular architecture by decomposing SRS generation into\nthree tasks: summary, requirement extraction, and requirement classification,\neach supported by tailored prompt templates to improve the quality and\nconsistency of LLM outputs.\n  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the\ngenerated SRSs against those produced by the holistic GPT-4-based method from\nprior work as well as by entry-level requirements engineers. Expert evaluations\nshow that ReqInOne produces more accurate and well-structured SRS documents.\nThe performance advantage of ReqInOne benefits from its modular design, and\nexperimental results further demonstrate that its requirement classification\ncomponent achieves comparable or even better results than the state-of-the-art\nrequirement classification model.",
      "url": "http://arxiv.org/abs/2508.09648v1",
      "published_time_eastern_timestamp": 1755077441.0
    },
    {
      "title": "Preacher: Paper-to-Video Agentic System",
      "summary": "The paper-to-video task converts a research paper into a structured video\nabstract, distilling key concepts, methods, and conclusions into an accessible,\nwell-organized format. While state-of-the-art video generation models\ndemonstrate potential, they are constrained by limited context windows, rigid\nvideo duration constraints, limited stylistic diversity, and an inability to\nrepresent domain-specific knowledge. To address these limitations, we introduce\nPreacher, the first paper-to-video agentic system. Preacher employs a top-down\napproach to decompose, summarize, and reformulate the paper, followed by\nbottom-up video generation, synthesizing diverse video segments into a coherent\nabstract. To align cross-modal representations, we define key scenes and\nintroduce a Progressive Chain of Thought (P-CoT) for granular, iterative\nplanning. Preacher successfully generates high-quality video abstracts across\nfive research fields, demonstrating expertise beyond current video generation\nmodels. Code will be released at: https://github.com/GenVerse/Paper2Video",
      "url": "http://arxiv.org/abs/2508.09632v1",
      "published_time_eastern_timestamp": 1755076131.0
    },
    {
      "title": "Goal Discovery with Causal Capacity for Efficient Reinforcement Learning",
      "summary": "Causal inference is crucial for humans to explore the world, which can be\nmodeled to enable an agent to efficiently explore the environment in\nreinforcement learning. Existing research indicates that establishing the\ncausality between action and state transition will enhance an agent to reason\nhow a policy affects its future trajectory, thereby promoting directed\nexploration. However, it is challenging to measure the causality due to its\nintractability in the vast state-action space of complex scenarios. In this\npaper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework\nfor efficient environment exploration. Specifically, we first derive a\nmeasurement of causality in state space, \\emph{i.e.,} causal capacity, which\nrepresents the highest influence of an agent's behavior on future trajectories.\nAfter that, we present a Monte Carlo based method to identify critical points\nin discrete state space and further optimize this method for continuous\nhigh-dimensional environments. Those critical points are used to uncover where\nthe agent makes important decisions in the environment, which are then regarded\nas our subgoals to guide the agent to make exploration more purposefully and\nefficiently. Empirical results from multi-objective tasks demonstrate that\nstates with high causal capacity align with our expected subgoals, and our GDCC\nachieves significant success rate improvements compared to baselines.",
      "url": "http://arxiv.org/abs/2508.09624v1",
      "published_time_eastern_timestamp": 1755075296.0
    },
    {
      "title": "Interpreting Aqueous Two-Phase Extraction of Single-Walled Carbon\n  Nanotubes with Highly Versatile Nonionic Polymers",
      "summary": "The development of efficient separation methods is essential for the\nproduction of fine chemicals and materials. Among them, the aqueous two-phase\nextraction (ATPE) allows for the isolation of single-walled carbon nanotubes\n(SWCNTs) of specific structures and other substances. However, this easy-to-use\nmethod, in which an analyte is partitioned between two phases, still demands a\nbetter understanding of its mechanism to make its application more effective.\nHerein, we demonstrate how various biphasic systems can be formed according to\nthe nature of the phase-forming components. Moreover, by employing\npolyethylene-block-poly(ethylene glycol) (PEPEG), previously unrecognized in\nthis context, we reveal the versatility of nonionic polymers for ATPE, which\ncan successfully act as phase-forming compounds, partitioning modulators, and\ndispersing agents. Interestingly, as proven by experiments and modelling, PEPEG\nexhibited chirality-sensitive preference toward SWCNTs, which can significantly\nfacilitate the purification of SWCNTs using various approaches. Capitalizing on\nthis finding, we report how the extraction environment may be tailored to\npromote the isolation of (8,3) SWCNTs and other chirality-enriched SWCNT\nfractions. The relationships noted, based on the examination of a model\nmaterial (SWCNTs), provide substantial insight into the elusive mechanism of\nthe ATPE purification approach, widely employed across a range of analytes,\nfrom cell organelles to nanostructures",
      "url": "http://arxiv.org/abs/2508.09605v1",
      "published_time_eastern_timestamp": 1755074206.0
    },
    {
      "title": "Edge General Intelligence Through World Models and Agentic AI:\n  Fundamentals, Solutions, and Challenges",
      "summary": "Edge General Intelligence (EGI) represents a transformative evolution of edge\ncomputing, where distributed agents possess the capability to perceive, reason,\nand act autonomously across diverse, dynamic environments. Central to this\nvision are world models, which act as proactive internal simulators that not\nonly predict but also actively imagine future trajectories, reason under\nuncertainty, and plan multi-step actions with foresight. This proactive nature\nallows agents to anticipate potential outcomes and optimize decisions ahead of\nreal-world interactions. While prior works in robotics and gaming have\nshowcased the potential of world models, their integration into the wireless\nedge for EGI remains underexplored. This survey bridges this gap by offering a\ncomprehensive analysis of how world models can empower agentic artificial\nintelligence (AI) systems at the edge. We first examine the architectural\nfoundations of world models, including latent representation learning, dynamics\nmodeling, and imagination-based planning. Building on these core capabilities,\nwe illustrate their proactive applications across EGI scenarios such as\nvehicular networks, unmanned aerial vehicle (UAV) networks, the Internet of\nThings (IoT) systems, and network functions virtualization, thereby\nhighlighting how they can enhance optimization under latency, energy, and\nprivacy constraints. We then explore their synergy with foundation models and\ndigital twins, positioning world models as the cognitive backbone of EGI.\nFinally, we highlight open challenges, such as safety guarantees, efficient\ntraining, and constrained deployment, and outline future research directions.\nThis survey provides both a conceptual foundation and a practical roadmap for\nrealizing the next generation of intelligent, autonomous edge systems.",
      "url": "http://arxiv.org/abs/2508.09561v1",
      "published_time_eastern_timestamp": 1755070180.0
    },
    {
      "title": "CS-Agent: LLM-based Community Search via Dual-agent Collaboration",
      "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing tasks, yet their application to graph structure\nanalysis, particularly in community search, remains underexplored. Community\nsearch, a fundamental task in graph analysis, aims to identify groups of nodes\nwith dense interconnections, which is crucial for understanding the macroscopic\nstructure of graphs. In this paper, we propose GraphCS, a comprehensive\nbenchmark designed to evaluate the performance of LLMs in community search\ntasks. Our experiments reveal that while LLMs exhibit preliminary potential,\nthey frequently fail to return meaningful results and suffer from output bias.\nTo address these limitations, we introduce CS-Agent, a dual-agent collaborative\nframework to enhance LLM-based community search. CS-Agent leverages the\ncomplementary strengths of two LLMs acting as Solver and Validator. Through\niterative feedback and refinement, CS-Agent dynamically refines initial results\nwithout fine-tuning or additional training. After the multi-round dialogue,\nDecider module selects the optimal community. Extensive experiments demonstrate\nthat CS-Agent significantly improves the quality and stability of identified\ncommunities compared to baseline methods. To our knowledge, this is the first\nwork to apply LLMs to community search, bridging the gap between LLMs and graph\nanalysis while providing a robust and adaptive solution for real-world\napplications.",
      "url": "http://arxiv.org/abs/2508.09549v1",
      "published_time_eastern_timestamp": 1755069225.0
    },
    {
      "title": "Low-latency D-MIMO Localization using Distributed Scalable\n  Message-Passing Algorithm",
      "summary": "Distributed MIMO and integrated sensing and communication are expected to be\nkey technologies in future wireless systems, enabling reliable, low-latency\ncommunication and accurate localization. Dedicated localization solutions must\nsupport distributed architecture, provide scalability across different system\nconfigurations and meet strict latency requirements. We present a scalable\nmessage-passing localization method and architecture co-designed for a\npanel-based distributed MIMO system and network topology, in which\ninterconnected units operate without centralized processing. This method\njointly detects line-of-sight paths to distributed units from multipath\nmeasurements in dynamic scenarios, localizes the agent, and achieves very low\nlatency. Additionally, we introduce a cycle-accurate system latency model based\non implemented FPGA operations, and show important insights into processing\nlatency and hardware utilization and system-level trade-offs. We compare our\nmethod to a multipath-based localization method and show that it can achieve\nsimilar localization performance, with wide enough distribution of array\nelements, while offering lower latency and computational complexity.",
      "url": "http://arxiv.org/abs/2508.09546v1",
      "published_time_eastern_timestamp": 1755068708.0
    }
  ]
}
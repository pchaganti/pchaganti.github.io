{
  "last_updated": "2025-06-16T05:14:59.377173-04:00",
  "papers": [
    {
      "title": "Affogato: Learning Open-Vocabulary Affordance Grounding with Automated\n  Data Generation at Scale",
      "summary": "Affordance grounding-localizing object regions based on natural language\ndescriptions of interactions-is a critical challenge for enabling intelligent\nagents to understand and interact with their environments. However, this task\nremains challenging due to the need for fine-grained part-level localization,\nthe ambiguity arising from multiple valid interaction regions, and the scarcity\nof large-scale datasets. In this work, we introduce Affogato, a large-scale\nbenchmark comprising 150K instances, annotated with open-vocabulary text\ndescriptions and corresponding 3D affordance heatmaps across a diverse set of\nobjects and interactions. Building on this benchmark, we develop simple yet\neffective vision-language models that leverage pretrained part-aware vision\nbackbones and a text-conditional heatmap decoder. Our models trained with the\nAffogato dataset achieve promising performance on the existing 2D and 3D\nbenchmarks, and notably, exhibit effectiveness in open-vocabulary cross-domain\ngeneralization. The Affogato dataset is shared in public:\nhttps://huggingface.co/datasets/project-affogato/affogato",
      "url": "http://arxiv.org/abs/2506.12009v1",
      "published_time_eastern_timestamp": 1749837438.0
    },
    {
      "title": "Upgrade or Switch: Do We Need a New Registry Architecture for the\n  Internet of AI Agents?",
      "summary": "The emerging Internet of AI Agents challenges existing web infrastructure\ndesigned for human-scale, reactive interactions. Unlike traditional web\nresources, autonomous AI agents initiate actions, maintain persistent state,\nspawn sub-agents, and negotiate directly with peers: demanding\nmillisecond-level discovery, instant credential revocation, and cryptographic\nbehavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes\nwhether to upgrade existing infrastructure or implement purpose-built registry\narchitectures for autonomous agents. We identify critical failure points: DNS\npropagation (24-48 hours vs. required milliseconds), certificate revocation\nunable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate\nfor agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2)\nSwitch options, (3) Hybrid registries. Drawing parallels to dialup-to-broadband\ntransitions, we find that agent requirements constitute qualitative, and not\nincremental, changes. While upgrades offer compatibility and faster deployment,\nclean-slate solutions provide better performance but require longer for\nadoption. Our analysis suggests hybrid approaches will emerge, with centralized\nregistries for critical agents and federated meshes for specialized use cases.",
      "url": "http://arxiv.org/abs/2506.12003v1",
      "published_time_eastern_timestamp": 1749837338.0
    },
    {
      "title": "Self-Regulating Cars: Automating Traffic Control in Free Flow Road\n  Networks",
      "summary": "Free-flow road networks, such as suburban highways, are increasingly\nexperiencing traffic congestion due to growing commuter inflow and limited\ninfrastructure. Traditional control mechanisms, such as traffic signals or\nlocal heuristics, are ineffective or infeasible in these high-speed,\nsignal-free environments. We introduce self-regulating cars, a reinforcement\nlearning-based traffic control protocol that dynamically modulates vehicle\nspeeds to optimize throughput and prevent congestion, without requiring new\nphysical infrastructure. Our approach integrates classical traffic flow theory,\ngap acceptance models, and microscopic simulation into a physics-informed RL\nframework. By abstracting roads into super-segments, the agent captures\nemergent flow dynamics and learns robust speed modulation policies from\ninstantaneous traffic observations. Evaluated in the high-fidelity PTV Vissim\nsimulator on a real-world highway network, our method improves total throughput\nby 5%, reduces average delay by 13%, and decreases total stops by 3% compared\nto the no-control setting. It also achieves smoother, congestion-resistant flow\nwhile generalizing across varied traffic patterns, demonstrating its potential\nfor scalable, ML-driven traffic management.",
      "url": "http://arxiv.org/abs/2506.11973v1",
      "published_time_eastern_timestamp": 1749835883.0
    },
    {
      "title": "Visual Pre-Training on Unlabeled Images using Reinforcement Learning",
      "summary": "In reinforcement learning (RL), value-based algorithms learn to associate\neach observation with the states and rewards that are likely to be reached from\nit. We observe that many self-supervised image pre-training methods bear\nsimilarity to this formulation: learning features that associate crops of\nimages with those of nearby views, e.g., by taking a different crop or color\naugmentation. In this paper, we complete this analogy and explore a method that\ndirectly casts pre-training on unlabeled image data like web crawls and video\nframes as an RL problem. We train a general value function in a dynamical\nsystem where an agent transforms an image by changing the view or adding image\naugmentations. Learning in this way resembles crop-consistency\nself-supervision, but through the reward function, offers a simple lever to\nshape feature learning using curated images or weakly labeled captions when\nthey exist. Our experiments demonstrate improved representations when training\non unlabeled images in the wild, including video data like EpicKitchens, scene\ndata like COCO, and web-crawl data like CC12M.",
      "url": "http://arxiv.org/abs/2506.11967v1",
      "published_time_eastern_timestamp": 1749835527.0
    },
    {
      "title": "Automated Treatment Planning for Interstitial HDR Brachytherapy for\n  Locally Advanced Cervical Cancer using Deep Reinforcement Learning",
      "summary": "High-dose-rate (HDR) brachytherapy plays a critical role in the treatment of\nlocally advanced cervical cancer but remains highly dependent on manual\ntreatment planning expertise. The objective of this study is to develop a fully\nautomated HDR brachytherapy planning framework that integrates reinforcement\nlearning (RL) and dose-based optimization to generate clinically acceptable\ntreatment plans with improved consistency and efficiency. We propose a\nhierarchical two-stage autoplanning framework. In the first stage, a deep\nQ-network (DQN)-based RL agent iteratively selects treatment planning\nparameters (TPPs), which control the trade-offs between target coverage and\norgan-at-risk (OAR) sparing. The agent's state representation includes both\ndose-volume histogram (DVH) metrics and current TPP values, while its reward\nfunction incorporates clinical dose objectives and safety constraints,\nincluding D90, V150, V200 for targets, and D2cc for all relevant OARs (bladder,\nrectum, sigmoid, small bowel, and large bowel). In the second stage, a\ncustomized Adam-based optimizer computes the corresponding dwell time\ndistribution for the selected TPPs using a clinically informed loss function.\nThe framework was evaluated on a cohort of patients with complex applicator\ngeometries. The proposed framework successfully learned clinically meaningful\nTPP adjustments across diverse patient anatomies. For the unseen test patients,\nthe RL-based automated planning method achieved an average score of 93.89%,\noutperforming the clinical plans which averaged 91.86%. These findings are\nnotable given that score improvements were achieved while maintaining full\ntarget coverage and reducing CTV hot spots in most cases.",
      "url": "http://arxiv.org/abs/2506.11957v1",
      "published_time_eastern_timestamp": 1749834450.0
    },
    {
      "title": "Secure API-Driven Research Automation to Accelerate Scientific Discovery",
      "summary": "The Secure Scientific Service Mesh (S3M) provides API-driven infrastructure\nto accelerate scientific discovery through automated research workflows. By\nintegrating near real-time streaming capabilities, intelligent workflow\norchestration, and fine-grained authorization within a service mesh\narchitecture, S3M revolutionizes programmatic access to high performance\ncomputing (HPC) while maintaining uncompromising security. This framework\nallows intelligent agents and experimental facilities to dynamically provision\nresources and execute complex workflows, accelerating experimental lifecycles,\nand unlocking the full potential of AI-augmented autonomous science. S3M\nsignals a new era in scientific computing infrastructure that eliminates\ntraditional barriers between researchers, computational resources, and\nexperimental facilities.",
      "url": "http://arxiv.org/abs/2506.11950v1",
      "published_time_eastern_timestamp": 1749833935.0
    },
    {
      "title": "Breaking Habits: On the Role of the Advantage Function in Learning\n  Causal State Representations",
      "summary": "Recent work has shown that reinforcement learning agents can develop policies\nthat exploit spurious correlations between rewards and observations. This\nphenomenon, known as policy confounding, arises because the agent's policy\ninfluences both past and future observation variables, creating a feedback loop\nthat can hinder the agent's ability to generalize beyond its usual\ntrajectories. In this paper, we show that the advantage function, commonly used\nin policy gradient methods, not only reduces the variance of gradient estimates\nbut also mitigates the effects of policy confounding. By adjusting action\nvalues relative to the state representation, the advantage function downweights\nstate-action pairs that are more likely under the current policy, breaking\nspurious correlations and encouraging the agent to focus on causal factors. We\nprovide both analytical and empirical evidence demonstrating that training with\nthe advantage function leads to improved out-of-trajectory performance.",
      "url": "http://arxiv.org/abs/2506.11912v1",
      "published_time_eastern_timestamp": 1749830807.0
    },
    {
      "title": "Palpation Alters Auditory Pain Expressions with Gender-Specific\n  Variations in Robopatients",
      "summary": "Diagnostic errors remain a major cause of preventable deaths, particularly in\nresource-limited regions. Medical training simulators, including robopatients,\nplay a vital role in reducing these errors by mimicking real patients for\nprocedural training such as palpation. However, generating multimodal feedback,\nespecially auditory pain expressions, remains challenging due to the complex\nrelationship between palpation behavior and sound. The high-dimensional nature\nof pain sounds makes exploration challenging with conventional methods. This\nstudy introduces a novel experimental paradigm for pain expressivity in\nrobopatients where they dynamically generate auditory pain expressions in\nresponse to palpation force, by co-optimizing human feedback using machine\nlearning. Using Proximal Policy Optimization (PPO), a reinforcement learning\n(RL) technique optimized for continuous adaptation, our robot iteratively\nrefines pain sounds based on real-time human feedback. This robot initializes\nrandomized pain responses to palpation forces, and the RL agent learns to\nadjust these sounds to align with human preferences. The results demonstrated\nthat the system adapts to an individual's palpation forces and sound\npreferences and captures a broad spectrum of pain intensity, from mild\ndiscomfort to acute distress, through RL-guided exploration of the auditory\npain space. The study further showed that pain sound perception exhibits\nsaturation at lower forces with gender specific thresholds. These findings\nhighlight the system's potential to enhance abdominal palpation training by\noffering a controllable and immersive simulation platform.",
      "url": "http://arxiv.org/abs/2506.11906v1",
      "published_time_eastern_timestamp": 1749830144.0
    },
    {
      "title": "An Explainable AI Framework for Dynamic Resource Management in Vehicular\n  Network Slicing",
      "summary": "Effective resource management and network slicing are essential to meet the\ndiverse service demands of vehicular networks, including Enhanced Mobile\nBroadband (eMBB) and Ultra-Reliable and Low-Latency Communications (URLLC).\nThis paper introduces an Explainable Deep Reinforcement Learning (XRL)\nframework for dynamic network slicing and resource allocation in vehicular\nnetworks, built upon a near-real-time RAN intelligent controller. By\nintegrating a feature-based approach that leverages Shapley values and an\nattention mechanism, we interpret and refine the decisions of our\nreinforcementlearning agents, addressing key reliability challenges in\nvehicular communication systems. Simulation results demonstrate that our\napproach provides clear, real-time insights into the resource allocation\nprocess and achieves higher interpretability precision than a pure attention\nmechanism. Furthermore, the Quality of Service (QoS) satisfaction for URLLC\nservices increased from 78.0% to 80.13%, while that for eMBB services improved\nfrom 71.44% to 73.21%.",
      "url": "http://arxiv.org/abs/2506.11882v1",
      "published_time_eastern_timestamp": 1749828772.0
    },
    {
      "title": "Your Ride, Your Rules: Psychology and Cognition Enabled Automated\n  Driving Systems",
      "summary": "Despite rapid advances in autonomous driving, current autonomous vehicles\n(AVs) lack effective bidirectional communication with occupants, limiting\npersonalization and recovery from immobilization. This reduces comfort and\ntrust, potentially slowing broader AV adoption. We propose PACE-ADS (Psychology\nand Cognition Enabled Automated Driving Systems), a human-centered autonomy\nframework that enables AVs to sense, interpret, and respond to both external\ntraffic and internal occupant states. PACE-ADS comprises three foundation\nmodel-based agents: a Driver Agent that analyzes the driving context, a\nPsychologist Agent that interprets occupant psychological signals (e.g., EEG,\nheart rate, facial expressions) and cognitive commands (e.g., speech), and a\nCoordinator Agent that integrates these inputs to produce high-level behavior\ndecisions and operational parameters. Rather than replacing existing AV\nmodules, PACE-ADS complements them by operating at the behavioral level,\ndelegating low-level control to native AV systems. This separation enables\nclosed-loop adaptation and supports integration across diverse platforms. We\nevaluate PACE-ADS in simulation across varied scenarios involving traffic\nlights, pedestrians, work zones, and car following. Results show that PACE-ADS\nadapts driving styles to occupant states, improves ride comfort, and enables\nsafe recovery from immobilization via autonomous reasoning or human guidance.\nOur findings highlight the promise of LLM-based frameworks for bridging the gap\nbetween machine autonomy and human-centered driving.",
      "url": "http://arxiv.org/abs/2506.11842v1",
      "published_time_eastern_timestamp": 1749825851.0
    },
    {
      "title": "Mean Field Games without Rational Expectations",
      "summary": "Mean Field Game (MFG) models implicitly assume \"rational expectations\",\nmeaning that the heterogeneous agents being modeled correctly know all relevant\ntransition probabilities for the complex system they inhabit. When there is\ncommon noise, this assumption results in the \"Master equation\" (a.k.a. \"Monster\nequation\"), a Hamilton-Jacobi-Bellman equation in which the\ninfinite-dimensional density of agents is a state variable. The rational\nexpectations assumption and the implication that agents solve Master equations\nis unrealistic in many applications. We show how to instead formulate MFGs with\nnon-rational expectations. Departing from rational expectations is particularly\nrelevant in \"MFGs with a low-dimensional coupling\", i.e. MFGs in which agents'\nrunning reward function depends on the density only through low-dimensional\nfunctionals of this density. This happens, for example, in most macroeconomics\nMFGs in which these low-dimensional functionals have the interpretation of\n\"equilibrium prices.\" In MFGs with a low-dimensional coupling, departing from\nrational expectations allows for completely sidestepping the Master equation\nand for instead solving much simpler finite-dimensional HJB equations. We\nintroduce an adaptive learning model as a particular example of non-rational\nexpectations and discuss its properties.",
      "url": "http://arxiv.org/abs/2506.11838v1",
      "published_time_eastern_timestamp": 1749825603.0
    },
    {
      "title": "The Space Between Us: A Methodological Framework for Researching Bonding\n  and Proxemics in Situated Group-Agent Interactions",
      "summary": "This paper introduces a multimethod framework for studying spatial and social\ndynamics in real-world group-agent interactions with socially interactive\nagents. Drawing on proxemics and bonding theories, the method combines\nsubjective self-reports and objective spatial tracking. Applied in two field\nstudies in a museum (N = 187) with a robot and a virtual agent, the paper\naddresses the challenges in aligning human perception and behavior. We focus on\npresenting an open source, scalable, and field-tested toolkit for future\nstudies.",
      "url": "http://arxiv.org/abs/2506.11829v1",
      "published_time_eastern_timestamp": 1749825143.0
    },
    {
      "title": "Revealing Political Bias in LLMs through Structured Multi-Agent Debate",
      "summary": "Large language models (LLMs) are increasingly used to simulate social\nbehaviour, yet their political biases and interaction dynamics in debates\nremain underexplored. We investigate how LLM type and agent gender attributes\ninfluence political bias using a structured multi-agent debate framework, by\nengaging Neutral, Republican, and Democrat American LLM agents in debates on\npolitically sensitive topics. We systematically vary the underlying LLMs, agent\ngenders, and debate formats to examine how model provenance and agent personas\ninfluence political bias and attitudes throughout debates. We find that Neutral\nagents consistently align with Democrats, while Republicans shift closer to the\nNeutral; gender influences agent attitudes, with agents adapting their opinions\nwhen aware of other agents' genders; and contrary to prior research, agents\nwith shared political affiliations can form echo chambers, exhibiting the\nexpected intensification of attitudes as debates progress.",
      "url": "http://arxiv.org/abs/2506.11825v1",
      "published_time_eastern_timestamp": 1749825037.0
    },
    {
      "title": "PE-MA: Parameter-Efficient Co-Evolution of Multi-Agent Systems",
      "summary": "Multi-Agent Systems have recently emerged as a promising paradigm for\ncollaborative reasoning and solving complex tasks. However, the design of\ncollaborative learning algorithms in multi-agent systems faces several\nchallenges, including high communication overhead and insufficient agent-level\npersonalization. In this paper, we propose PE-MA (Parameter-Efficient\nMulti-Agent Co-Evolution), a novel collaboration framework that supports\nefficient, scalable, and personalized co-evolution in multi-agent systems. In\nPE-MA, each agent maintains a lightweight personalized adapter to support\nagent-specific behavior, while a shared adapter is collaboratively optimized\nacross neighboring agents. This design balances global coordination with local\nadaptation under heterogeneous environments. We achieve an asymptotically\noptimal convergence rate of O( 1/(NK)^(1/2) ), where N is the number of agents\nand K the local update steps.",
      "url": "http://arxiv.org/abs/2506.11803v1",
      "published_time_eastern_timestamp": 1749823576.0
    },
    {
      "title": "Solving Inverse Problems in Stochastic Self-Organising Systems through\n  Invariant Representations",
      "summary": "Self-organising systems demonstrate how simple local rules can generate\ncomplex stochastic patterns. Many natural systems rely on such dynamics, making\nself-organisation central to understanding natural complexity. A fundamental\nchallenge in modelling such systems is solving the inverse problem: finding the\nunknown causal parameters from macroscopic observations. This task becomes\nparticularly difficult when observations have a strong stochastic component,\nyielding diverse yet equivalent patterns. Traditional inverse methods fail in\nthis setting, as pixel-wise metrics cannot capture feature similarities between\nvariable outcomes. In this work, we introduce a novel inverse modelling method\nspecifically designed to handle stochasticity in the observable space,\nleveraging the capacity of visual embeddings to produce robust representations\nthat capture perceptual invariances. By mapping the pattern representations\nonto an invariant embedding space, we can effectively recover unknown causal\nparameters without the need for handcrafted objective functions or heuristics.\nWe evaluate the method on two canonical models--a reaction-diffusion system and\nan agent-based model of social segregation--and show that it reliably recovers\nparameters despite stochasticity in the outcomes. We further apply the method\nto real biological patterns, highlighting its potential as a tool for both\ntheorists and experimentalists to investigate the dynamics underlying complex\nstochastic pattern formation.",
      "url": "http://arxiv.org/abs/2506.11796v1",
      "published_time_eastern_timestamp": 1749823299.0
    },
    {
      "title": "ALEA IACTA EST: A Declarative Domain-Specific Language for Manually\n  Performable Random Experiments",
      "summary": "Random experiments that are simple and clear enough to be performed by human\nagents feature prominently in the teaching of elementary stochastics as well as\nin games. We present Alea, a domain-specific language for the specification of\nrandom experiments. Alea code can either be analyzed statically to obtain and\ninspect probability distributions of outcomes, or be executed with a source\npseudo-randomness for simulation or as a game assistant. The language is\nintended for ease of use by non-expert programmers, in particular students of\nelementary stochastics, and players and designers of games of chance, by\nfocusing on concepts common to functional programming and basic mathematics.\nBoth the design of the language and the implementation of runtime environments\nare work in progress.",
      "url": "http://arxiv.org/abs/2506.11794v1",
      "published_time_eastern_timestamp": 1749823106.0
    },
    {
      "title": "SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software\n  Security Tasks",
      "summary": "Rigorous security-focused evaluation of large language model (LLM) agents is\nimperative for establishing trust in their safe deployment throughout the\nsoftware development lifecycle. However, existing benchmarks largely rely on\nsynthetic challenges or simplified vulnerability datasets that fail to capture\nthe complexity and ambiguity encountered by security engineers in practice. We\nintroduce SEC-bench, the first fully automated benchmarking framework for\nevaluating LLM agents on authentic security engineering tasks. SEC-bench\nemploys a novel multi-agent scaffold that automatically constructs code\nrepositories with harnesses, reproduces vulnerabilities in isolated\nenvironments, and generates gold patches for reliable evaluation. Our framework\nautomatically creates high-quality software vulnerability datasets with\nreproducible artifacts at a cost of only $0.87 per instance. Using SEC-bench,\nwe implement two critical software security tasks to rigorously evaluate LLM\nagents' capabilities: proof-of-concept (PoC) generation and vulnerability\npatching. A comprehensive evaluation of state-of-the-art LLM code agents\nreveals significant performance gaps, achieving at most 18.0% success in PoC\ngeneration and 34.0% in vulnerability patching on our complete dataset. These\nresults highlight the crucial steps needed toward developing LLM agents that\nare more practical, intelligent, and autonomous for security engineering.",
      "url": "http://arxiv.org/abs/2506.11791v1",
      "published_time_eastern_timestamp": 1749822870.0
    },
    {
      "title": "AgentSense: Virtual Sensor Data Generation Using LLM Agent in Simulated\n  Home Environments",
      "summary": "A major obstacle in developing robust and generalizable smart home-based\nHuman Activity Recognition (HAR) systems is the lack of large-scale, diverse\nlabeled datasets. Variability in home layouts, sensor configurations, and user\nbehavior adds further complexity, as individuals follow varied routines and\nperform activities in distinct ways. Building HAR systems that generalize well\nrequires training data that captures the diversity across users and\nenvironments. To address these challenges, we introduce AgentSense, a virtual\ndata generation pipeline where diverse personas are generated by leveraging\nLarge Language Models. These personas are used to create daily routines, which\nare then decomposed into low-level action sequences. Subsequently, the actions\nare executed in a simulated home environment called VirtualHome that we\nextended with virtual ambient sensors capable of recording the agents\nactivities as they unfold. Overall, AgentSense enables the generation of rich,\nvirtual sensor datasets that represent a wide range of users and home settings.\nAcross five benchmark HAR datasets, we show that leveraging our virtual sensor\ndata substantially improves performance, particularly when real data are\nlimited. Notably, models trained on a combination of virtual data and just a\nfew days of real data achieve performance comparable to those trained on the\nentire real datasets. These results demonstrate and prove the potential of\nvirtual data to address one of the most pressing challenges in ambient sensing,\nwhich is the distinct lack of large-scale, annotated datasets without requiring\nany manual data collection efforts.",
      "url": "http://arxiv.org/abs/2506.11773v1",
      "published_time_eastern_timestamp": 1749821468.0
    },
    {
      "title": "Convergence to equilibrium for a class of exchange economies",
      "summary": "For a class of stochastic dynamical models of exchange economies that we call\n``fully connected Cobb-Douglas'', the paper proves convergence of the\nprobability distribution to an equilibrium, in total variation metric as time\ngoes to infinity. The convergence is exponential and the equilibrium is\ndetermined uniquely by the number of agents, their ``exponents'', and the\ninitial amounts of money and goods in the economy.",
      "url": "http://arxiv.org/abs/2506.11770v1",
      "published_time_eastern_timestamp": 1749821242.0
    },
    {
      "title": "DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents",
      "summary": "Deep Research Agents are a prominent category of LLM-based agents. By\nautonomously orchestrating multistep web exploration, targeted retrieval, and\nhigher-order synthesis, they transform vast amounts of online information into\nanalyst-grade, citation-rich reports--compressing hours of manual desk research\ninto minutes. However, a comprehensive benchmark for systematically evaluating\nthe capabilities of these agents remains absent. To bridge this gap, we present\nDeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks,\neach meticulously crafted by domain experts across 22 distinct fields.\nEvaluating DRAs is inherently complex and labor-intensive. We therefore propose\ntwo novel methodologies that achieve strong alignment with human judgment. The\nfirst is a reference-based method with adaptive criteria to assess the quality\nof generated research reports. The other framework is introduced to evaluate\nDRA's information retrieval and collection capabilities by assessing its\neffective citation count and overall citation accuracy. We have open-sourced\nDeepResearch Bench and key components of these frameworks at\nhttps://github.com/Ayanami0730/deep_research_bench to accelerate the\ndevelopment of practical LLM-based agents.",
      "url": "http://arxiv.org/abs/2506.11763v1",
      "published_time_eastern_timestamp": 1749820652.0
    }
  ]
}
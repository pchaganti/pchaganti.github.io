{
  "last_updated": "2025-07-24T05:17:26.162598-04:00",
  "papers": [
    {
      "title": "DataWink: Reusing and Adapting SVG-based Visualization Examples with\n  Large Multimodal Models",
      "summary": "Creating aesthetically pleasing data visualizations remains challenging for\nusers without design expertise or familiarity with visualization tools. To\naddress this gap, we present DataWink, a system that enables users to create\ncustom visualizations by adapting high-quality examples. Our approach combines\nlarge multimodal models (LMMs) to extract data encoding from existing SVG-based\nvisualization examples, featuring an intermediate representation of\nvisualizations that bridges primitive SVG and visualization programs. Users may\nexpress adaptation goals to a conversational agent and control the visual\nappearance through widgets generated on demand. With an interactive interface,\nusers can modify both data mappings and visual design elements while\nmaintaining the original visualization's aesthetic quality. To evaluate\nDataWink, we conduct a user study (N=12) with replication and free-form\nexploration tasks. As a result, DataWink is recognized for its learnability and\neffectiveness in personalized authoring tasks. Our results demonstrate the\npotential of example-driven approaches for democratizing visualization\ncreation.",
      "url": "http://arxiv.org/abs/2507.17734v1",
      "published_time_eastern_timestamp": 1753293034.0
    },
    {
      "title": "BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems",
      "summary": "Large language models (LLMs) are growingly extended to process multimodal\ndata such as text and video simultaneously. Their remarkable performance in\nunderstanding what is shown in images is surpassing specialized neural networks\n(NNs) such as Yolo that is supporting only a well-formed but very limited\nvocabulary, ie., objects that they are able to detect. When being\nnon-restricted, LLMs and in particular state-of-the-art vision language models\n(VLMs) show impressive performance to describe even complex traffic situations.\nThis is making them potentially suitable components for automotive perception\nsystems to support the understanding of complex traffic situations or edge case\nsituation. However, LLMs and VLMs are prone to hallucination, which mean to\neither potentially not seeing traffic agents such as vulnerable road users who\nare present in a situation, or to seeing traffic agents who are not there in\nreality. While the latter is unwanted making an ADAS or autonomous driving\nsystems (ADS) to unnecessarily slow down, the former could lead to disastrous\ndecisions from an ADS. In our work, we are systematically assessing the\nperformance of 3 state-of-the-art VLMs on a diverse subset of traffic\nsituations sampled from the Waymo Open Dataset to support safety guardrails for\ncapturing such hallucinations in VLM-supported perception systems. We observe\nthat both, proprietary and open VLMs exhibit remarkable image understanding\ncapabilities even paying thorough attention to fine details sometimes difficult\nto spot for us humans. However, they are also still prone to making up elements\nin their descriptions to date requiring hallucination detection strategies such\nas BetterCheck that we propose in our work.",
      "url": "http://arxiv.org/abs/2507.17722v1",
      "published_time_eastern_timestamp": 1753291937.0
    },
    {
      "title": "Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks",
      "summary": "Large Language Model (LLM)-based autonomous agents are expected to play a\nvital role in the evolution of 6G networks, by empowering real-time\ndecision-making related to management and service provisioning to end-users.\nThis shift facilitates the transition from a specialized intelligence approach,\nwhere artificial intelligence (AI) algorithms handle isolated tasks, to\nartificial general intelligence (AGI)-driven networks, where agents possess\nbroader reasoning capabilities and can manage diverse network functions. In\nthis paper, we introduce a novel agentic paradigm that combines LLMs with\nreal-time optimization algorithms towards Trustworthy AI, defined as symbiotic\nagents. Optimizers at the LLM's input-level provide bounded uncertainty\nsteering for numerically precise tasks, whereas output-level optimizers\nsupervised by the LLM enable adaptive real-time control. We design and\nimplement two novel agent types including: (i) Radio Access Network optimizers,\nand (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We\nfurther propose an end-to-end architecture for AGI networks and evaluate it on\na 5G testbed capturing channel fluctuations from moving vehicles. Results show\nthat symbiotic agents reduce decision errors fivefold compared to standalone\nLLM-based agents, while smaller language models (SLM) achieve similar accuracy\nwith a 99.9% reduction in GPU resource overhead and in near-real-time loops of\n82 ms. A multi-agent demonstration for collaborative RAN on the real-world\ntestbed highlights significant flexibility in service-level agreement and\nresource allocation, reducing RAN over-utilization by approximately 44%.\nDrawing on our findings and open-source implementations, we introduce the\nsymbiotic paradigm as the foundation for next-generation, AGI-driven\nnetworks-systems designed to remain adaptable, efficient, and trustworthy even\nas LLMs advance.",
      "url": "http://arxiv.org/abs/2507.17695v1",
      "published_time_eastern_timestamp": 1753290083.0
    },
    {
      "title": "Simulating multiple human perspectives in socio-ecological systems using\n  large language models",
      "summary": "Understanding socio-ecological systems requires insights from diverse\nstakeholder perspectives, which are often hard to access. To enable\nalternative, simulation-based exploration of different stakeholder\nperspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)\nmodelling framework. HoPeS employs agents powered by large language models\n(LLMs) to represent various stakeholders; users can step into the agent roles\nto experience perspectival differences. A simulation protocol serves as a\n\"scaffold\" to streamline multiple perspective-taking simulations, supporting\nusers in reflecting on, transitioning between, and integrating across\nperspectives. A prototype system is developed to demonstrate HoPeS in the\ncontext of institutional dynamics and land use change, enabling both\nnarrative-driven and numerical experiments. In an illustrative experiment, a\nuser successively adopts the perspectives of a system observer and a researcher\n- a role that analyses data from the embedded land use model to inform\nevidence-based decision-making for other LLM agents representing various\ninstitutions. Despite the user's effort to recommend technically sound\npolicies, discrepancies persist between the policy recommendation and\nimplementation due to stakeholders' competing advocacies, mirroring real-world\nmisalignment between researcher and policymaker perspectives. The user's\nreflection highlights the subjective feelings of frustration and disappointment\nas a researcher, especially due to the challenge of maintaining political\nneutrality while attempting to gain political influence. Despite this, the user\nexhibits high motivation to experiment with alternative narrative framing\nstrategies, suggesting the system's potential in exploring different\nperspectives. Further system and protocol refinement are likely to enable new\nforms of interdisciplinary collaboration in socio-ecological simulations.",
      "url": "http://arxiv.org/abs/2507.17680v1",
      "published_time_eastern_timestamp": 1753288971.0
    },
    {
      "title": "LTLZinc: a Benchmarking Framework for Continual Learning and\n  Neuro-Symbolic Temporal Reasoning",
      "summary": "Neuro-symbolic artificial intelligence aims to combine neural architectures\nwith symbolic approaches that can represent knowledge in a human-interpretable\nformalism. Continual learning concerns with agents that expand their knowledge\nover time, improving their skills while avoiding to forget previously learned\nconcepts. Most of the existing approaches for neuro-symbolic artificial\nintelligence are applied to static scenarios only, and the challenging setting\nwhere reasoning along the temporal dimension is necessary has been seldom\nexplored. In this work we introduce LTLZinc, a benchmarking framework that can\nbe used to generate datasets covering a variety of different problems, against\nwhich neuro-symbolic and continual learning methods can be evaluated along the\ntemporal and constraint-driven dimensions. Our framework generates expressive\ntemporal reasoning and continual learning tasks from a linear temporal logic\nspecification over MiniZinc constraints, and arbitrary image classification\ndatasets. Fine-grained annotations allow multiple neural and neuro-symbolic\ntraining settings on the same generated datasets. Experiments on six\nneuro-symbolic sequence classification and four class-continual learning tasks\ngenerated by LTLZinc, demonstrate the challenging nature of temporal learning\nand reasoning, and highlight limitations of current state-of-the-art methods.\nWe release the LTLZinc generator and ten ready-to-use tasks to the\nneuro-symbolic and continual learning communities, in the hope of fostering\nresearch towards unified temporal learning and reasoning frameworks.",
      "url": "http://arxiv.org/abs/2507.17482v1",
      "published_time_eastern_timestamp": 1753275853.0
    },
    {
      "title": "ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents",
      "summary": "Robot imitation learning relies on 4D multi-view sequential images. However,\nthe high cost of data collection and the scarcity of high-quality data severely\nconstrain the generalization and application of embodied intelligence policies\nlike Vision-Language-Action (VLA) models. Data augmentation is a powerful\nstrategy to overcome data scarcity, but methods for editing 4D multi-view\nsequential images for manipulation tasks are currently lacking. Thus, we\npropose ERMV (Editing Robotic Multi-View 4D data), a novel data augmentation\nframework that efficiently edits an entire multi-view sequence based on\nsingle-frame editing and robot state conditions. This task presents three core\nchallenges: (1) maintaining geometric and appearance consistency across dynamic\nviews and long time horizons; (2) expanding the working window with low\ncomputational costs; and (3) ensuring the semantic integrity of critical\nobjects like the robot arm. ERMV addresses these challenges through a series of\ninnovations. First, to ensure spatio-temporal consistency in motion blur, we\nintroduce a novel Epipolar Motion-Aware Attention (EMA-Attn) mechanism that\nlearns pixel shift caused by movement before applying geometric constraints.\nSecond, to maximize the editing working window, ERMV pioneers a Sparse\nSpatio-Temporal (STT) module, which decouples the temporal and spatial views\nand remodels a single-frame multi-view problem through sparse sampling of the\nviews to reduce computational demands. Third, to alleviate error accumulation,\nwe incorporate a feedback intervention Mechanism, which uses a Multimodal Large\nLanguage Model (MLLM) to check editing inconsistencies and request targeted\nexpert guidance only when necessary. Extensive experiments demonstrate that\nERMV-augmented data significantly boosts the robustness and generalization of\nVLA models in both simulated and real-world environments.",
      "url": "http://arxiv.org/abs/2507.17462v1",
      "published_time_eastern_timestamp": 1753274471.0
    },
    {
      "title": "IndoorBEV: Joint Detection and Footprint Completion of Objects via\n  Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception",
      "summary": "Detecting diverse objects within complex indoor 3D point clouds presents\nsignificant challenges for robotic perception, particularly with varied object\nshapes, clutter, and the co-existence of static and dynamic elements where\ntraditional bounding box methods falter. To address these limitations, we\npropose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor\nmobile robots.\n  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles\nnaturally occlusions and provides a consistent top-down view aiding to\ndistinguish static obstacles from dynamic agents. The obtained 2D BEV results\nis directly usable to downstream robotic tasks like navigation, motion\nprediction, and planning. Our architecture utilizes an axis compact encoder and\na window-based backbone to extract rich spatial features from this BEV map. A\nquery-based decoder head then employs learned object queries to concurrently\npredict object classes and instance masks in the BEV space. This mask-centric\nformulation effectively captures the footprint of both static and dynamic\nobjects regardless of their shape, offering a robust alternative to bounding\nbox regression. We demonstrate the effectiveness of IndoorBEV on a custom\nindoor dataset featuring diverse object classes including static objects\n  and dynamic elements like robots and miscellaneous items, showcasing its\npotential for robust indoor scene understanding.",
      "url": "http://arxiv.org/abs/2507.17445v1",
      "published_time_eastern_timestamp": 1753272441.0
    },
    {
      "title": "Fair Compromises in Participatory Budgeting: a Multi-Agent Deep\n  Reinforcement Learning Approach",
      "summary": "Participatory budgeting is a method of collectively understanding and\naddressing spending priorities where citizens vote on how a budget is spent, it\nis regularly run to improve the fairness of the distribution of public funds.\nParticipatory budgeting requires voters to make decisions on projects which can\nlead to ``choice overload\". A multi-agent reinforcement learning approach to\ndecision support can make decision making easier for voters by identifying\nvoting strategies that increase the winning proportion of their vote. This\nnovel approach can also support policymakers by highlighting aspects of\nelection design that enable fair compromise on projects. This paper presents a\nnovel, ethically aligned approach to decision support using multi-agent deep\nreinforcement learning modelling. This paper introduces a novel use of a\nbranching neural network architecture to overcome scalability challenges of\nmulti-agent reinforcement learning in a decentralized way. Fair compromises are\nfound through optimising voter actions towards greater representation of voter\npreferences in the winning set. Experimental evaluation with real-world\nparticipatory budgeting data reveals a pattern in fair compromise: that it is\nachievable through projects with smaller cost.",
      "url": "http://arxiv.org/abs/2507.17433v1",
      "published_time_eastern_timestamp": 1753271173.0
    },
    {
      "title": "CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality\n  Optimization in Computed Tomography",
      "summary": "In computed tomography (CT), achieving high image quality while minimizing\nradiation exposure remains a key clinical challenge. This paper presents\nCAPRI-CT, a novel causal-aware deep learning framework for Causal Analysis and\nPredictive Reasoning for Image Quality Optimization in CT imaging. CAPRI-CT\nintegrates image data with acquisition metadata (such as tube voltage, tube\ncurrent, and contrast agent types) to model the underlying causal relationships\nthat influence image quality. An ensemble of Variational Autoencoders (VAEs) is\nemployed to extract meaningful features and generate causal representations\nfrom observational data, including CT images and associated imaging parameters.\nThese input features are fused to predict the Signal-to-Noise Ratio (SNR) and\nsupport counterfactual inference, enabling what-if simulations, such as changes\nin contrast agents (types and concentrations) or scan parameters. CAPRI-CT is\ntrained and validated using an ensemble learning approach, achieving strong\npredictive performance. By facilitating both prediction and interpretability,\nCAPRI-CT provides actionable insights that could help radiologists and\ntechnicians design more efficient CT protocols without repeated physical scans.\nThe source code and dataset are publicly available at\nhttps://github.com/SnehaGeorge22/capri-ct.",
      "url": "http://arxiv.org/abs/2507.17420v1",
      "published_time_eastern_timestamp": 1753269782.0
    },
    {
      "title": "Residual Prophet Inequalities",
      "summary": "We introduce a variant of the classic prophet inequality, called\n\\emph{residual prophet inequality} (RPI). In the RPI problem, we consider a\nfinite sequence of $n$ nonnegative independent random values with known\ndistributions, and a known integer $0\\leq k\\leq n-1$. Before the gambler\nobserves the sequence, the top $k$ values are removed, whereas the remaining\n$n-k$ values are streamed sequentially to the gambler. For example, one can\nassume that the top $k$ values have already been allocated to a higher-priority\nagent. Upon observing a value, the gambler must decide irrevocably whether to\naccept or reject it, without the possibility of revisiting past values.\n  We study two variants of RPI, according to whether the gambler learns online\nof the identity of the variable that he sees (FI model) or not (NI model). Our\nmain result is a randomized algorithm in the FI model with \\emph{competitive\nratio} of at least $1/(k+2)$, which we show is tight. Our algorithm is\ndata-driven and requires access only to the $k+1$ largest values of a single\nsample from the $n$ input distributions. In the NI model, we provide a similar\nalgorithm that guarantees a competitive ratio of $1/(2k+2)$. We further analyze\nindependent and identically distributed instances when $k=1$. We build a\nsingle-threshold algorithm with a competitive ratio of at least 0.4901, and\nshow that no single-threshold strategy can get a competitive ratio greater than\n0.5464.",
      "url": "http://arxiv.org/abs/2507.17391v1",
      "published_time_eastern_timestamp": 1753266971.0
    },
    {
      "title": "DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via\n  Multi-Reward Reinforcement Learning",
      "summary": "Multi-step agentic retrieval systems based on large language models (LLMs)\nhave demonstrated remarkable performance in complex information search tasks.\nHowever, these systems still face significant challenges in practical\napplications, particularly in generating factually inconsistent intermediate\nqueries and inefficient search trajectories, which can lead to reasoning\ndeviations or redundant computations. To address these issues, we propose\nDynaSearcher, an innovative search agent enhanced by dynamic knowledge graphs\nand multi-reward reinforcement learning (RL). Specifically, our system\nleverages knowledge graphs as external structured knowledge to guide the search\nprocess by explicitly modeling entity relationships, thereby ensuring factual\nconsistency in intermediate queries and mitigating biases from irrelevant\ninformation. Furthermore, we employ a multi-reward RL framework for\nfine-grained control over training objectives such as retrieval accuracy,\nefficiency, and response quality. This framework promotes the generation of\nhigh-quality intermediate queries and comprehensive final answers, while\ndiscouraging unnecessary exploration and minimizing information omissions or\nredundancy. Experimental results demonstrate that our approach achieves\nstate-of-the-art answer accuracy on six multi-hop question answering datasets,\nmatching frontier LLMs while using only small-scale models and limited\ncomputational resources. Furthermore, our approach demonstrates strong\ngeneralization and robustness across diverse retrieval environments and\nlarger-scale models, highlighting its broad applicability.",
      "url": "http://arxiv.org/abs/2507.17365v1",
      "published_time_eastern_timestamp": 1753264711.0
    },
    {
      "title": "DeMo++: Motion Decoupling for Autonomous Driving",
      "summary": "Motion forecasting and planning are tasked with estimating the trajectories\nof traffic agents and the ego vehicle, respectively, to ensure the safety and\nefficiency of autonomous driving systems in dynamically changing environments.\nState-of-the-art methods typically adopt a one-query-one-trajectory paradigm,\nwhere each query corresponds to a unique trajectory for predicting multi-mode\ntrajectories. While this paradigm can produce diverse motion intentions, it\noften falls short in modeling the intricate spatiotemporal evolution of\ntrajectories, which can lead to collisions or suboptimal outcomes. To overcome\nthis limitation, we propose DeMo++, a framework that decouples motion\nestimation into two distinct components: holistic motion intentions to capture\nthe diverse potential directions of movement, and fine spatiotemporal states to\ntrack the agent's dynamic progress within the scene and enable a\nself-refinement capability. Further, we introduce a cross-scene trajectory\ninteraction mechanism to explore the relationships between motions in adjacent\nscenes. This allows DeMo++ to comprehensively model both the diversity of\nmotion intentions and the spatiotemporal evolution of each trajectory. To\neffectively implement this framework, we developed a hybrid model combining\nAttention and Mamba. This architecture leverages the strengths of both\nmechanisms for efficient scene information aggregation and precise trajectory\nstate sequence modeling. Extensive experiments demonstrate that DeMo++ achieves\nstate-of-the-art performance across various benchmarks, including motion\nforecasting (Argoverse 2 and nuScenes), motion planning (nuPlan), and\nend-to-end planning (NAVSIM).",
      "url": "http://arxiv.org/abs/2507.17342v1",
      "published_time_eastern_timestamp": 1753261885.0
    },
    {
      "title": "HuNavSim 2.0",
      "summary": "This work presents a new iteration of the Human Navigation Simulator\n(HuNavSim), a novel open-source tool for the simulation of different\nhuman-agent navigation behaviors in scenarios with mobile robots. The tool,\nprogrammed under the ROS 2 framework, can be used together with different\nwell-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main\ngoal is to facilitate the development and evaluation of human-aware robot\nnavigation systems in simulation. In this new version, several features have\nbeen improved and new ones added, such as the extended set of actions and\nconditions that can be combined in Behavior Trees to compound complex and\nrealistic human behaviors.",
      "url": "http://arxiv.org/abs/2507.17317v1",
      "published_time_eastern_timestamp": 1753259495.0
    },
    {
      "title": "EarthLink: Interpreting Climate Signals with Self-Evolving AI Agents",
      "summary": "Modern Earth science is at an inflection point. The vast, fragmented, and\ncomplex nature of Earth system data, coupled with increasingly sophisticated\nanalytical demands, creates a significant bottleneck for rapid scientific\ndiscovery. Here we introduce EarthLink, the first AI agent designed as an\ninteractive copilot for Earth scientists. It automates the end-to-end research\nworkflow, from planning and code generation to multi-scenario analysis. Unlike\nstatic diagnostic tools, EarthLink can learn from user interaction,\ncontinuously refining its capabilities through a dynamic feedback loop. We\nvalidated its performance on a number of core scientific tasks of climate\nchange, ranging from model-observation comparisons to the diagnosis of complex\nphenomena. In a multi-expert evaluation, EarthLink produced scientifically\nsound analyses and demonstrated an analytical competency that was rated as\ncomparable to specific aspects of a human junior researcher's workflow.\nAdditionally, its transparent, auditable workflows and natural language\ninterface empower scientists to shift from laborious manual execution to\nstrategic oversight and hypothesis generation. EarthLink marks a pivotal step\ntowards an efficient, trustworthy, and collaborative paradigm for Earth system\nresearch in an era of accelerating global change.",
      "url": "http://arxiv.org/abs/2507.17311v1",
      "published_time_eastern_timestamp": 1753259365.0
    },
    {
      "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting\n  Compliance Tasks in Enterprise Environments",
      "summary": "This paper presents Compliance Brain Assistant (CBA), a conversational,\nagentic AI assistant designed to boost the efficiency of daily compliance tasks\nfor personnel in enterprise environments. To strike a good balance between\nresponse quality and latency, we design a user query router that can\nintelligently choose between (i) FastTrack mode: to handle simple requests that\nonly need additional relevant context retrieved from knowledge corpora; and\n(ii) FullAgentic mode: to handle complicated requests that need composite\nactions and tool invocations to proactively discover context across various\ncompliance artifacts, and/or involving other APIs/models for accommodating\nrequests. A typical example would be to start with a user query, use its\ndescription to find a specific entity and then use the entity's information to\nquery other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on\nvarious real-world privacy/compliance-related queries targeting various\npersonas. We found that CBA substantially improved upon the vanilla LLM's\nperformance on metrics such as average keyword match rate (83.7% vs. 41.7%) and\nLLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full\nrouting-based design against the `fast-track only` and `full-agentic` modes and\nfound that it had a better average match-rate and pass-rate while keeping the\nrun-time approximately the same. This finding validated our hypothesis that the\nrouting mechanism leads to a good trade-off between the two worlds.",
      "url": "http://arxiv.org/abs/2507.17289v1",
      "published_time_eastern_timestamp": 1753257070.0
    },
    {
      "title": "Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational\n  Bottlenecks for Warehouse Planning Assistance",
      "summary": "Analyzing large, complex output datasets from Discrete Event Simulations\n(DES) of warehouse operations to identify bottlenecks and inefficiencies is a\ncritical yet challenging task, often demanding significant manual effort or\nspecialized analytical tools. Our framework integrates Knowledge Graphs (KGs)\nand Large Language Model (LLM)-based agents to analyze complex Discrete Event\nSimulation (DES) output data from warehouse operations. It transforms raw DES\ndata into a semantically rich KG, capturing relationships between simulation\nevents and entities. An LLM-based agent uses iterative reasoning, generating\ninterdependent sub-questions. For each sub-question, it creates Cypher queries\nfor KG interaction, extracts information, and self-reflects to correct errors.\nThis adaptive, iterative, and self-correcting process identifies operational\nissues mimicking human analysis. Our DES approach for warehouse bottleneck\nidentification, tested with equipment breakdowns and process irregularities,\noutperforms baseline methods. For operational questions, it achieves\nnear-perfect pass rates in pinpointing inefficiencies. For complex\ninvestigative questions, we demonstrate its superior diagnostic ability to\nuncover subtle, interconnected issues. This work bridges simulation modeling\nand AI (KG+LLM), offering a more intuitive method for actionable insights,\nreducing time-to-insight, and enabling automated warehouse inefficiency\nevaluation and diagnosis.",
      "url": "http://arxiv.org/abs/2507.17273v1",
      "published_time_eastern_timestamp": 1753255135.0
    },
    {
      "title": "Agent Identity Evals: Measuring Agentic Identity",
      "summary": "Central to agentic capability and trustworthiness of language model agents\n(LMAs) is the extent they maintain stable, reliable, identity over time.\nHowever, LMAs inherit pathologies from large language models (LLMs)\n(statelessness, stochasticity, sensitivity to prompts and\nlinguistically-intermediation) which can undermine their identifiability,\ncontinuity, persistence and consistency. This attrition of identity can erode\ntheir reliability, trustworthiness and utility by interfering with their\nagentic capabilities such as reasoning, planning and action. To address these\nchallenges, we introduce \\textit{agent identity evals} (AIE), a rigorous,\nstatistically-driven, empirical framework for measuring the degree to which an\nLMA system exhibit and maintain their agentic identity over time, including\ntheir capabilities, properties and ability to recover from state perturbations.\nAIE comprises a set of novel metrics which can integrate with other measures of\nperformance, capability and agentic robustness to assist in the design of\noptimal LMA infrastructure and scaffolding such as memory and tools. We set out\nformal definitions and methods that can be applied at each stage of the LMA\nlife-cycle, and worked examples of how to apply them.",
      "url": "http://arxiv.org/abs/2507.17257v1",
      "published_time_eastern_timestamp": 1753253775.0
    },
    {
      "title": "LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for\n  Secure Heterogeneous UAV Networks",
      "summary": "This work tackles the physical layer security (PLS) problem of maximizing the\nsecrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy\nconstraints. Unlike prior studies that assume uniform UAV capabilities or\noverlook energy-security trade-offs, we consider a realistic scenario where\nUAVs with diverse payloads and computation resources collaborate to serve\nground terminals in the presence of eavesdroppers. To manage the complex\ncoupling between UAV motion and communication, we propose a hierarchical\noptimization framework. The inner layer uses a semidefinite relaxation\n(SDR)-based S2DC algorithm combining penalty functions and difference-of-convex\n(d.c.) programming to solve the secrecy precoding problem with fixed UAV\npositions. The outer layer introduces a Large Language Model (LLM)-guided\nheuristic multi-agent reinforcement learning approach (LLM-HeMARL) for\ntrajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics\npolicy generated by the LLM, enabling UAVs to learn energy-aware,\nsecurity-driven trajectories without the inference overhead of real-time LLM\ncalls. The simulation results show that our method outperforms existing\nbaselines in secrecy rate and energy efficiency, with consistent robustness\nacross varying UAV swarm sizes and random seeds.",
      "url": "http://arxiv.org/abs/2507.17188v1",
      "published_time_eastern_timestamp": 1753244577.0
    },
    {
      "title": "Optimal Calibrated Signaling in Digital Auctions",
      "summary": "In digital advertising, online platforms allocate ad impressions through\nreal-time auctions, where advertisers typically rely on autobidding agents to\noptimize bids on their behalf. Unlike traditional auctions for physical goods,\nthe value of an ad impression is uncertain and depends on the unknown\nclick-through rate (CTR). While platforms can estimate CTRs more accurately\nusing proprietary machine learning algorithms, these estimates/algorithms\nremain opaque to advertisers. This information asymmetry naturally raises the\nfollowing questions: how can platforms disclose information in a way that is\nboth credible and revenue-optimal? We address these questions through\ncalibrated signaling, where each prior-free bidder receives a private signal\nthat truthfully reflects the conditional expected CTR of the ad impression.\nSuch signals are trustworthy and allow bidders to form unbiased value\nestimates, even without access to the platform's internal algorithms.\n  We study the design of platform-optimal calibrated signaling in the context\nof second-price auction. Our first main result fully characterizes the\nstructure of the optimal calibrated signaling, which can also be computed\nefficiently. We show that this signaling can extract the full surplus -- or\neven exceed it -- depending on a specific market condition. Our second main\nresult is an FPTAS for computing an approximately optimal calibrated signaling\nthat satisfies an IR condition. Our main technical contributions are: a\nreformulation of the platform's problem as a two-stage optimization problem\nthat involves optimal transport subject to calibration feasibility constraints\non the bidders' marginal bid distributions; and a novel correlation plan that\nconstructs the optimal distribution over second-highest bids.",
      "url": "http://arxiv.org/abs/2507.17187v1",
      "published_time_eastern_timestamp": 1753244542.0
    },
    {
      "title": "FinGAIA: An End-to-End Benchmark for Evaluating AI Agents in Finance",
      "summary": "The booming development of AI agents presents unprecedented opportunities for\nautomating complex tasks across various domains. However, their multi-step,\nmulti-tool collaboration capabilities in the financial sector remain\nunderexplored. This paper introduces FinGAIA, an end-to-end benchmark designed\nto evaluate the practical abilities of AI agents in the financial domain.\nFinGAIA comprises 407 meticulously crafted tasks, spanning seven major\nfinancial sub-domains: securities, funds, banking, insurance, futures, trusts,\nand asset management. These tasks are organized into three hierarchical levels\nof scenario depth: basic business analysis, asset decision support, and\nstrategic risk management. We evaluated 10 mainstream AI agents in a zero-shot\nsetting. The best-performing agent, ChatGPT, achieved an overall accuracy of\n48.9\\%, which, while superior to non-professionals, still lags financial\nexperts by over 35 percentage points. Error analysis has revealed five\nrecurring failure patterns: Cross-modal Alignment Deficiency, Financial\nTerminological Bias, Operational Process Awareness Barrier, among others. These\npatterns point to crucial directions for future research. Our work provides the\nfirst agent benchmark closely related to the financial domain, aiming to\nobjectively assess and promote the development of agents in this crucial field.\nPartial data is available at https://github.com/SUFE-AIFLM-Lab/FinGAIA.",
      "url": "http://arxiv.org/abs/2507.17186v1",
      "published_time_eastern_timestamp": 1753244356.0
    }
  ]
}
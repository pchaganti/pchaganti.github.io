{
  "last_updated": "2025-07-23T21:03:14.308817-04:00",
  "papers": [
    {
      "title": "ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent\n  Planning",
      "summary": "Vision-language-action (VLA) reasoning tasks require agents to interpret\nmultimodal instructions, perform long-horizon planning, and act adaptively in\ndynamic environments. Existing approaches typically train VLA models in an\nend-to-end fashion, directly mapping inputs to actions without explicit\nreasoning, which hinders their ability to plan over multiple steps or adapt to\ncomplex task variations. In this paper, we propose ThinkAct, a dual-system\nframework that bridges high-level reasoning with low-level action execution via\nreinforced visual latent planning. ThinkAct trains a multimodal LLM to generate\nembodied reasoning plans guided by reinforcing action-aligned visual rewards\nbased on goal completion and trajectory consistency. These reasoning plans are\ncompressed into a visual plan latent that conditions a downstream action model\nfor robust action execution on target environments. Extensive experiments on\nembodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct\nenables few-shot adaptation, long-horizon planning, and self-correction\nbehaviors in complex embodied AI tasks.",
      "url": "http://arxiv.org/abs/2507.16815v1",
      "published_time_eastern_timestamp": 1753207186.0
    },
    {
      "title": "LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework\n  for Multi-Step and Cross-Cultural Inference with LLMs",
      "summary": "We propose LingBench++, a linguistically-informed benchmark and reasoning\nframework designed to evaluate large language models (LLMs) on complex\nlinguistic tasks inspired by the International Linguistics Olympiad (IOL).\nUnlike prior benchmarks that focus solely on final answer accuracy, LingBench++\nprovides structured reasoning traces, stepwise evaluation protocols, and rich\ntypological metadata across over 90 low-resource and cross-cultural languages.\nWe further develop a multi-agent architecture integrating grammatical knowledge\nretrieval, tool-augmented reasoning, and deliberate hypothesis testing. Through\nsystematic comparisons of baseline and our proposed agentic models, we\ndemonstrate that models equipped with external knowledge sources and iterative\nreasoning outperform single-pass approaches in both accuracy and\ninterpretability. LingBench++ offers a comprehensive foundation for advancing\nlinguistically grounded, culturally informed, and cognitively plausible\nreasoning in LLMs.",
      "url": "http://arxiv.org/abs/2507.16809v1",
      "published_time_eastern_timestamp": 1753207064.0
    },
    {
      "title": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain\n  Expertise, Training Efficiency, and Advanced Reasoning",
      "summary": "Large Language Models (LLMs) exhibit considerable promise in financial\napplications; however, prevailing models frequently demonstrate limitations\nwhen confronted with scenarios that necessitate sophisticated reasoning\ncapabilities, stringent trustworthiness criteria, and efficient adaptation to\ndomain-specific requirements. We introduce the Agentar-Fin-R1 series of\nfinancial large language models (8B and 32B parameters), specifically\nengineered based on the Qwen3 foundation model to enhance reasoning\ncapabilities, reliability, and domain specialization for financial\napplications. Our optimization approach integrates a high-quality, systematic\nfinancial task label system with a comprehensive multi-layered trustworthiness\nassurance framework. This framework encompasses high-quality trustworthy\nknowledge engineering, multi-agent trustworthy data synthesis, and rigorous\ndata validation governance. Through label-guided automated difficulty-aware\noptimization, tow-stage training pipeline, and dynamic attribution systems, we\nachieve substantial improvements in training efficiency. Our models undergo\ncomprehensive evaluation on mainstream financial benchmarks including Fineva,\nFinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500\nand GPQA-diamond. To thoroughly assess real-world deployment capabilities, we\ninnovatively propose the Finova evaluation benchmark, which focuses on\nagent-level financial reasoning and compliance verification. Experimental\nresults demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art\nperformance on financial tasks but also exhibits exceptional general reasoning\ncapabilities, validating its effectiveness as a trustworthy solution for\nhigh-stakes financial applications. The Finova bench is available at\nhttps://github.com/antgroup/Finova.",
      "url": "http://arxiv.org/abs/2507.16802v2",
      "published_time_eastern_timestamp": 1753206736.0
    },
    {
      "title": "Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style\n  in LLM-based Role-Playing Language Agent",
      "summary": "The rapid advancement of large language models (LLMs) has enabled\nrole-playing language agents to demonstrate significant potential in various\napplications. However, relying solely on prompts and contextual inputs often\nproves insufficient for achieving deep immersion in specific roles,\nparticularly well-known fictional or public figures. On the other hand,\nfine-tuning-based approaches face limitations due to the challenges associated\nwith data collection and the computational resources required for training,\nthereby restricting their broader applicability. To address these issues, we\npropose Test-Time-Matching (TTM), a training-free role-playing framework\nthrough test-time scaling and context engineering. TTM uses LLM agents to\nautomatically decouple a character's features into personality, memory, and\nlinguistic style. Our framework involves a structured, three-stage generation\npipeline that utilizes these features for controlled role-playing. It achieves\nhigh-fidelity role-playing performance, also enables seamless combinations\nacross diverse linguistic styles and even variations in personality and memory.\nWe evaluate our framework through human assessment, and the results demonstrate\nthat our method achieves the outstanding performance in generating expressive\nand stylistically consistent character dialogues.",
      "url": "http://arxiv.org/abs/2507.16799v2",
      "published_time_eastern_timestamp": 1753206464.0
    },
    {
      "title": "Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading\n  with Multi-Agent Reinforcement Learning",
      "summary": "This paper presents a novel framework for Peer-to-Peer (P2P) energy trading\nthat integrates uncertainty-aware prediction with multi-agent reinforcement\nlearning (MARL), addressing a critical gap in current literature. In contrast\nto previous works relying on deterministic forecasts, the proposed approach\nemploys a heteroscedastic probabilistic transformer-based prediction model\ncalled Knowledge Transformer with Uncertainty (KTU) to explicitly quantify\nprediction uncertainty, which is essential for robust decision-making in the\nstochastic environment of P2P energy trading. The KTU model leverages\ndomain-specific features and is trained with a custom loss function that\nensures reliable probabilistic forecasts and confidence intervals for each\nprediction. Integrating these uncertainty-aware forecasts into the MARL\nframework enables agents to optimize trading strategies with a clear\nunderstanding of risk and variability. Experimental results show that the\nuncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to\n5.7% without P2P trading and 3.2% with P2P trading, while increasing\nelectricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak\nhour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These\nimprovements are even more pronounced when P2P trading is enabled, highlighting\nthe synergy between advanced forecasting and market mechanisms for resilient,\neconomically efficient energy communities.",
      "url": "http://arxiv.org/abs/2507.16796v1",
      "published_time_eastern_timestamp": 1753206388.0
    },
    {
      "title": "Generalized non-reciprocal phase transitions in multipopulation systems",
      "summary": "Non-reciprocal interactions are prevalent in various complex systems leading\nto phenomena that cannot be described by traditional equilibrium statistical\nphysics. Although non-reciprocally interacting systems composed of two\npopulations have been closely studied, the physics of non-reciprocal systems\nwith a general number of populations is not well explored despite the potential\nrelevance to biological systems, active matter, and driven-dissipative quantum\nmaterials. In this work, we investigate the generic features of the phases and\nphase transitions that emerge in $O(2)$ symmetric many-body systems with\nmultiple non-reciprocally coupled populations, applicable to microscopic models\nsuch as networks of oscillators, flocking models, and more generally systems\nwhere each agent has a phase variable. Using symmetry and topology of the\npossible orbits, we systematically show that a rich variety of time-dependent\nphases and phase transitions arise. Examples include multipopulation chiral\nphases that are distinct from their two-population counterparts that emerge via\na phase transition characterized by critical exceptional points, as well as\nlimit cycle saddle-node bifurcation and Hopf bifurcation. Interestingly, we\nfind a phase transition that dynamically restores the $\\mathbb{Z}_2$ symmetry\noccurs via a homoclinic orbit bifurcation, where the two $\\mathbb{Z}_2$ broken\norbits merge at the phase transition point, providing a general route to\nhomoclinic chaos in the order parameter dynamics for $N\\geq4$ populations. The\nresults contribute to the understanding of the novel collective behavior and\nprovide formalism for classifying dynamic phases and their transitions in\nsystems driven by non-reciprocal interactions.",
      "url": "http://arxiv.org/abs/2507.16763v1",
      "published_time_eastern_timestamp": 1753203385.0
    },
    {
      "title": "AI-enhanced conversational agents for personalized asthma support\n  Factors for engagement, value and efficacy",
      "summary": "Asthma-related deaths in the UK are the highest in Europe, and only 30% of\npatients access basic care. There is a need for alternative approaches to\nreaching people with asthma in order to provide health education,\nself-management support and bridges to care. Automated conversational agents\n(specifically, mobile chatbots) present opportunities for providing alternative\nand individually tailored access to health education, self-management support\nand risk self-assessment. But would patients engage with a chatbot, and what\nfactors influence engagement? We present results from a patient survey (N=1257)\ndevised by a team of asthma clinicians, patients, and technology developers,\nconducted to identify optimal factors for efficacy, value and engagement for a\nchatbot. Results indicate that most adults with asthma (53%) are interested in\nusing a chatbot and the patients most likely to do so are those who believe\ntheir asthma is more serious and who are less confident about self-management.\nResults also indicate enthusiasm for 24/7 access, personalisation, and for\nWhatsApp as the preferred access method (compared to app, voice assistant, SMS\nor website). Obstacles to uptake include security/privacy concerns and\nskepticism of technological capabilities. We present detailed findings and\nconsolidate these into 7 recommendations for developers for optimising efficacy\nof chatbot-based health support.",
      "url": "http://arxiv.org/abs/2507.16735v1",
      "published_time_eastern_timestamp": 1753201260.0
    },
    {
      "title": "Deliberative Searcher: Improving LLM Reliability via Reinforcement\n  Learning with constraints",
      "summary": "Improving the reliability of large language models (LLMs) is critical for\ndeploying them in real-world scenarios. In this paper, we propose\n\\textbf{Deliberative Searcher}, the first framework to integrate certainty\ncalibration with retrieval-based search for open-domain question answering. The\nagent performs multi-step reflection and verification over Wikipedia data and\nis trained with a reinforcement learning algorithm that optimizes for accuracy\nunder a soft reliability constraint. Empirical results show that proposed\nmethod improves alignment between model confidence and correctness, leading to\nmore trustworthy outputs. This paper will be continuously updated.",
      "url": "http://arxiv.org/abs/2507.16727v2",
      "published_time_eastern_timestamp": 1753200574.0
    },
    {
      "title": "RAVine: Reality-Aligned Evaluation for Agentic Search",
      "summary": "Agentic search, as a more autonomous and adaptive paradigm of retrieval\naugmentation, is driving the evolution of intelligent search systems. However,\nexisting evaluation frameworks fail to align well with the goals of agentic\nsearch. First, the complex queries commonly used in current benchmarks often\ndeviate from realistic user search scenarios. Second, prior approaches tend to\nintroduce noise when extracting ground truth for end-to-end evaluations,\nleading to distorted assessments at a fine-grained level. Third, most current\nframeworks focus solely on the quality of final answers, neglecting the\nevaluation of the iterative process inherent to agentic search. To address\nthese limitations, we propose RAVine -- a Reality-Aligned eValuation framework\nfor agentic LLMs with search. RAVine targets multi-point queries and long-form\nanswers that better reflect user intents, and introduces an attributable ground\ntruth construction strategy to enhance the accuracy of fine-grained evaluation.\nMoreover, RAVine examines model's interaction with search tools throughout the\niterative process, and accounts for factors of efficiency. We benchmark a\nseries of models using RAVine and derive several insights, which we hope will\ncontribute to advancing the development of agentic search systems. The code and\ndatasets are available at https://github.com/SwordFaith/RAVine.",
      "url": "http://arxiv.org/abs/2507.16725v1",
      "published_time_eastern_timestamp": 1753200492.0
    },
    {
      "title": "Screen2AX: Vision-Based Approach for Automatic macOS Accessibility\n  Generation",
      "summary": "Desktop accessibility metadata enables AI agents to interpret screens and\nsupports users who depend on tools like screen readers. Yet, many applications\nremain largely inaccessible due to incomplete or missing metadata provided by\ndevelopers - our investigation shows that only 33% of applications on macOS\noffer full accessibility support. While recent work on structured screen\nrepresentation has primarily addressed specific challenges, such as UI element\ndetection or captioning, none has attempted to capture the full complexity of\ndesktop interfaces by replicating their entire hierarchical structure. To\nbridge this gap, we introduce Screen2AX, the first framework to automatically\ncreate real-time, tree-structured accessibility metadata from a single\nscreenshot. Our method uses vision-language and object detection models to\ndetect, describe, and organize UI elements hierarchically, mirroring macOS's\nsystem-level accessibility structure. To tackle the limited availability of\ndata for macOS desktop applications, we compiled and publicly released three\ndatasets encompassing 112 macOS applications, each annotated for UI element\ndetection, grouping, and hierarchical accessibility metadata alongside\ncorresponding screenshots. Screen2AX accurately infers hierarchy trees,\nachieving a 77% F1 score in reconstructing a complete accessibility tree.\nCrucially, these hierarchy trees improve the ability of autonomous agents to\ninterpret and interact with complex desktop interfaces. We introduce\nScreen2AX-Task, a benchmark specifically designed for evaluating autonomous\nagent task execution in macOS desktop environments. Using this benchmark, we\ndemonstrate that Screen2AX delivers a 2.2x performance improvement over native\naccessibility representations and surpasses the state-of-the-art OmniParser V2\nsystem on the ScreenSpot benchmark.",
      "url": "http://arxiv.org/abs/2507.16704v1",
      "published_time_eastern_timestamp": 1753198692.0
    },
    {
      "title": "FOGNITE: Federated Learning-Enhanced Fog-Cloud Architecture",
      "summary": "Modern smart grids demand fast, intelligent, and energy-aware computing at\nthe edge to manage real time fluctuations and ensure reliable operation. This\npaper introduces FOGNITE Fog-based Grid In intelligence with Neural Integration\nand Twin based Execution a next-generation fog cloud framework designed to\nenhance autonomy, resilience, and efficiency in distributed energy systems.\nFOGNITE combines three core components: federated learning, reinforcement\nlearning, and digital twin validation. Each fog node trains a local CNN LSTM\nmodel on private energy consumption data, enabling predictive intelligence\nwhile preserving data privacy through federated aggregation. A reinforcement\nlearning agent dynamically schedules tasks based on current system load and\nenergy conditions, optimizing for performance under uncertainty.\n  To prevent unsafe or inefficient decisions, a hierarchical digital twin layer\nsimulates potential actions before deployment, significantly reducing execution\nerrors and energy waste. We evaluate FOGNITE on a real world testbed of\nRaspberry Pi devices, showing up to a 93.7% improvement in load balancing\naccuracy and a 63.2% reduction in energy waste compared to conventional\narchitectures. By shifting smart grid control from reactive correction to\nproactive optimization, FOGNITE represents a step toward more intelligent,\nadaptive, and sustainable energy infrastructures",
      "url": "http://arxiv.org/abs/2507.16668v1",
      "published_time_eastern_timestamp": 1753196476.0
    },
    {
      "title": "Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum\n  Circuit Synthesis",
      "summary": "A reinforcement learning (RL) framework is introduced for the efficient\nsynthesis of quantum circuits that generate specified target quantum states\nfrom a fixed initial state, addressing a central challenge in both the NISQ era\nand future fault-tolerant quantum computing. The approach utilizes tabular\nQ-learning, based on action sequences, within a discretized quantum state\nspace, to effectively manage the exponential growth of the space dimension. The\nframework introduces a hybrid reward mechanism, combining a static,\ndomain-informed reward that guides the agent toward the target state with\ncustomizable dynamic penalties that discourage inefficient circuit structures\nsuch as gate congestion and redundant state revisits. By leveraging sparse\nmatrix representations and state-space discretization, the method enables\nscalable navigation of high-dimensional environments while minimizing\ncomputational overhead. Benchmarking on graph-state preparation tasks for up to\nseven qubits, we demonstrate that the algorithm consistently discovers\nminimal-depth circuits with optimized gate counts. Moreover, extending the\nframework to a universal gate set for arbitrary quantum states, it still\nproduces minimal depth circuits, highlighting the algorithm's robustness and\nadaptability. The results confirm that this RL-driven approach efficiently\nexplores the complex quantum state space and synthesizes near-optimal quantum\ncircuits, providing a resource-efficient foundation for quantum circuit\noptimization.",
      "url": "http://arxiv.org/abs/2507.16641v1",
      "published_time_eastern_timestamp": 1753195160.0
    },
    {
      "title": "Novel Multi-Agent Action Masked Deep Reinforcement Learning for General\n  Industrial Assembly Lines Balancing Problems",
      "summary": "Efficient planning of activities is essential for modern industrial assembly\nlines to uphold manufacturing standards, prevent project constraint violations,\nand achieve cost-effective operations. While exact solutions to such challenges\ncan be obtained through Integer Programming (IP), the dependence of the search\nspace on input parameters often makes IP computationally infeasible for\nlarge-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also\nbe applied, but they frequently produce suboptimal solutions in extensive\ncases. This paper introduces a novel mathematical model of a generic industrial\nassembly line formulated as a Markov Decision Process (MDP), without imposing\nassumptions on the type of assembly line a notable distinction from most\nexisting models. The proposed model is employed to create a virtual environment\nfor training Deep Reinforcement Learning (DRL) agents to optimize task and\nresource scheduling. To enhance the efficiency of agent training, the paper\nproposes two innovative tools. The first is an action-masking technique, which\nensures the agent selects only feasible actions, thereby reducing training\ntime. The second is a multi-agent approach, where each workstation is managed\nby an individual agent, as a result, the state and action spaces were reduced.\nA centralized training framework with decentralized execution is adopted,\noffering a scalable learning architecture for optimizing industrial assembly\nlines. This framework allows the agents to learn offline and subsequently\nprovide real-time solutions during operations by leveraging a neural network\nthat maps the current factory state to the optimal action. The effectiveness of\nthe proposed scheme is validated through numerical simulations, demonstrating\nsignificantly faster convergence to the optimal solution compared to a\ncomparable model-based approach.",
      "url": "http://arxiv.org/abs/2507.16635v1",
      "published_time_eastern_timestamp": 1753194876.0
    },
    {
      "title": "Augmenting Von Neumann's Architecture for an Intelligent Future",
      "summary": "This work presents a novel computer architecture that extends the Von Neumann\nmodel with a dedicated Reasoning Unit (RU) to enable native artificial general\nintelligence capabilities. The RU functions as a specialized co-processor that\nexecutes symbolic inference, multi-agent coordination, and hybrid\nsymbolic-neural computation as fundamental architectural primitives. This\nhardware-embedded approach allows autonomous agents to perform goal-directed\nplanning, dynamic knowledge manipulation, and introspective reasoning directly\nwithin the computational substrate at system scale. The architecture\nincorporates a reasoning-specific instruction set architecture, parallel\nsymbolic processing pipelines, agent-aware kernel abstractions, and a unified\nmemory hierarchy that seamlessly integrates cognitive and numerical workloads.\nThrough systematic co-design across hardware, operating system, and agent\nruntime layers, this architecture establishes a computational foundation where\nreasoning, learning, and adaptation emerge as intrinsic execution properties\nrather than software abstractions, potentially enabling the development of\ngeneral-purpose intelligent machines.",
      "url": "http://arxiv.org/abs/2507.16628v1",
      "published_time_eastern_timestamp": 1753193993.0
    },
    {
      "title": "CTSL: Codebook-based Temporal-Spatial Learning for Accurate Non-Contrast\n  Cardiac Risk Prediction Using Cine MRIs",
      "summary": "Accurate and contrast-free Major Adverse Cardiac Events (MACE) prediction\nfrom Cine MRI sequences remains a critical challenge. Existing methods\ntypically necessitate supervised learning based on human-refined masks in the\nventricular myocardium, which become impractical without contrast agents. We\nintroduce a self-supervised framework, namely Codebook-based Temporal-Spatial\nLearning (CTSL), that learns dynamic, spatiotemporal representations from raw\nCine data without requiring segmentation masks. CTSL decouples temporal and\nspatial features through a multi-view distillation strategy, where the teacher\nmodel processes multiple Cine views, and the student model learns from\nreduced-dimensional Cine-SA sequences. By leveraging codebook-based feature\nrepresentations and dynamic lesion self-detection through motion cues, CTSL\ncaptures intricate temporal dependencies and motion patterns. High-confidence\nMACE risk predictions are achieved through our model, providing a rapid,\nnon-invasive solution for cardiac risk assessment that outperforms traditional\ncontrast-dependent methods, thereby enabling timely and accessible heart\ndisease diagnosis in clinical settings.",
      "url": "http://arxiv.org/abs/2507.16612v1",
      "published_time_eastern_timestamp": 1753193561.0
    },
    {
      "title": "Smooth Games of Configuration in the Linear-Quadratic Setting",
      "summary": "Dynamic game theory offers a toolbox for formalizing and solving for both\ncooperative and non-cooperative strategies in multi-agent scenarios. However,\nthe optimal configuration of such games remains largely unexplored. While there\nis existing literature on the parametrization of dynamic games, little research\nexamines this parametrization from a strategic perspective where each agent's\nconfiguration choice is influenced by the decisions of others. In this work, we\nintroduce the concept of a game of configuration, providing a framework for the\nstrategic fine-tuning of differential games. We define a game of configuration\nas a two-stage game within the setting of finite-horizon, affine-quadratic, AQ,\ndifferential games. In the first stage, each player chooses their corresponding\nconfiguration parameter, which will impact their dynamics and costs in the\nsecond stage. We provide the subgame perfect solution concept and a method for\ncomputing first stage cost gradients over the configuration space. This then\nallows us to formulate a gradient-based method for searching for local\nsolutions to the configuration game, as well as provide necessary conditions\nfor equilibrium configurations over their downstream (second stage)\ntrajectories. We conclude by demonstrating the effectiveness of our approach in\nexample AQ systems, both zero-sum and general-sum.",
      "url": "http://arxiv.org/abs/2507.16611v1",
      "published_time_eastern_timestamp": 1753193288.0
    },
    {
      "title": "Pyramid Hierarchical Masked Diffusion Model for Imaging Synthesis",
      "summary": "Medical image synthesis plays a crucial role in clinical workflows,\naddressing the common issue of missing imaging modalities due to factors such\nas extended scan times, scan corruption, artifacts, patient motion, and\nintolerance to contrast agents. The paper presents a novel image synthesis\nnetwork, the Pyramid Hierarchical Masked Diffusion Model (PHMDiff), which\nemploys a multi-scale hierarchical approach for more detailed control over\nsynthesizing high-quality images across different resolutions and layers.\nSpecifically, this model utilizes randomly multi-scale high-proportion masks to\nspeed up diffusion model training, and balances detail fidelity and overall\nstructure. The integration of a Transformer-based Diffusion model process\nincorporates cross-granularity regularization, modeling the mutual information\nconsistency across each granularity's latent spaces, thereby enhancing\npixel-level perceptual accuracy. Comprehensive experiments on two challenging\ndatasets demonstrate that PHMDiff achieves superior performance in both the\nPeak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure\n(SSIM), highlighting its capability to produce high-quality synthesized images\nwith excellent structural integrity. Ablation studies further confirm the\ncontributions of each component. Furthermore, the PHMDiff model, a multi-scale\nimage synthesis framework across and within medical imaging modalities, shows\nsignificant advantages over other methods. The source code is available at\nhttps://github.com/xiaojiao929/PHMDiff",
      "url": "http://arxiv.org/abs/2507.16579v1",
      "published_time_eastern_timestamp": 1753191054.0
    },
    {
      "title": "Evaluating Social Acceptance of eXtended Reality (XR) Agent Technology:\n  A User Study (Extended Version)",
      "summary": "In this paper, we present the findings of a user study that evaluated the\nsocial acceptance of eXtended Reality (XR) agent technology, focusing on a\nremotely accessible, web-based XR training system developed for journalists.\nThis system involves user interaction with a virtual avatar, enabled by a\nmodular toolkit. The interactions are designed to provide tailored training for\njournalists in digital-remote settings, especially for sensitive or dangerous\nscenarios, without requiring specialized end-user equipment like headsets. Our\nresearch adapts and extends the Almere model, representing social acceptance\nthrough existing attributes such as perceived ease of use and perceived\nusefulness, along with added ones like dependability and security in the\nuser-agent interaction. The XR agent was tested through a controlled experiment\nin a real-world setting, with data collected on users' perceptions. Our\nfindings, based on quantitative and qualitative measurements involving\nquestionnaires, contribute to the understanding of user perceptions and\nacceptance of XR agent solutions within a specific social context, while also\nidentifying areas for the improvement of XR systems.",
      "url": "http://arxiv.org/abs/2507.16562v1",
      "published_time_eastern_timestamp": 1753190045.0
    },
    {
      "title": "A Distributed Actor-Critic Algorithm for Fixed-Time Consensus in\n  Nonlinear Multi-Agent Systems",
      "summary": "This paper proposes a reinforcement learning (RL)-based backstepping control\nstrategy to achieve fixed time consensus in nonlinear multi-agent systems with\nstrict feedback dynamics. Agents exchange only output information with their\nneighbors over a directed communication graph, without requiring full state\nmeasurements or symmetric communication. Achieving fixed time consensus, where\nconvergence occurs within a pre-specified time bound that is independent of\ninitial conditions is faced with significant challenges due to the presence of\nunknown nonlinearities, inter-agent couplings, and external disturbances. This\nwork addresses these challenges by integrating actor critic reinforcement\nlearning with a novel fixed time adaptation mechanism. Each agent employs an\nactor critic architecture supported by two estimator networks designed to\nhandle system uncertainties and unknown perturbations. The adaptation laws are\ndeveloped to ensure that all agents track the leader within a fixed time\nregardless of their initial conditions. The consensus and tracking errors are\nguaranteed to converge to a small neighborhood of the origin, with the\nconvergence radius adjustable through control parameters. Simulation results\ndemonstrate the effectiveness of the proposed approach and highlight its\nadvantages over state-of-the-art methods in terms of convergence speed and\nrobustness.",
      "url": "http://arxiv.org/abs/2507.16520v1",
      "published_time_eastern_timestamp": 1753187406.0
    },
    {
      "title": "Analogy making as amortised model construction",
      "summary": "Humans flexibly construct internal models to navigate novel situations. To be\nuseful, these internal models must be sufficiently faithful to the environment\nthat resource-limited planning leads to adequate outcomes; equally, they must\nbe tractable to construct in the first place. We argue that analogy plays a\ncentral role in these processes, enabling agents to reuse solution-relevant\nstructure from past experiences and amortise the computational costs of both\nmodel construction (construal) and planning. Formalising analogies as partial\nhomomorphisms between Markov decision processes, we sketch a framework in which\nabstract modules, derived from previous construals, serve as composable\nbuilding blocks for new ones. This modular reuse allows for flexible adaptation\nof policies and representations across domains with shared structural essence.",
      "url": "http://arxiv.org/abs/2507.16511v1",
      "published_time_eastern_timestamp": 1753186605.0
    }
  ]
}
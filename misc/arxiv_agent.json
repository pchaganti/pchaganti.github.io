{
  "last_updated": "2025-11-03T22:38:06.255339-05:00",
  "papers": [
    {
      "title": "Social learning moderates the tradeoffs between efficiency, stability,\n  and equity in group foraging",
      "summary": "Social learning shapes collective search by influencing how individuals use\npeer information. Empirical and computational studies show that optimal\ninformation sharing that is neither too localized nor too diffuse, can enhance\nresource detection and coordination. Building on these insights, we develop a\nrandomized search model that integrates social learning with area-restricted\nsearch (ARS) to investigate how communication distance affects collective\nforaging. The model includes three behavioral modes: exploration, exploitation,\nand targeted walk, which are governed by a single parameter, $\\rho$, that\nbalances exploration and exploitation at the group level. We quantify how\n$\\rho$ influences group efficiency ($\\eta$), temporal variability/burstiness\n($B$), and agent variability/equity in resource distribution ($\\sigma$),\nrevealing a clear trade-off among these outcomes. When $\\rho \\to 0$, agents\nexplore independently, maximizing collective exploration. As $\\rho$ increases,\nindividuals preferentially exploit patches discovered by others: $\\eta$ first\nrises and then declines, while $B$ shows the opposite trend. Group efficiency\nis optimized at interior $\\rho$ values that balance exploration and\nexploitation. At the largest $\\rho$, equality among agents is highest, but\nefficiency declines and burstiness is maximized too. Finally, by introducing\nnegative rewards, we examine how social learning mitigates risk.",
      "url": "http://arxiv.org/abs/2510.27683v1",
      "published_time_eastern_timestamp": 1761933180.0
    },
    {
      "title": "Challenges in Credit Assignment for Multi-Agent Reinforcement Learning\n  in Open Agent Systems",
      "summary": "In the rapidly evolving field of multi-agent reinforcement learning (MARL),\nunderstanding the dynamics of open systems is crucial. Openness in MARL refers\nto the dynam-ic nature of agent populations, tasks, and agent types with-in a\nsystem. Specifically, there are three types of openness as reported in (Eck et\nal. 2023) [2]: agent openness, where agents can enter or leave the system at\nany time; task openness, where new tasks emerge, and existing ones evolve or\ndisappear; and type openness, where the capabil-ities and behaviors of agents\nchange over time. This report provides a conceptual and empirical review,\nfocusing on the interplay between openness and the credit assignment problem\n(CAP). CAP involves determining the contribution of individual agents to the\noverall system performance, a task that becomes increasingly complex in open\nenviron-ments. Traditional credit assignment (CA) methods often assume static\nagent populations, fixed and pre-defined tasks, and stationary types, making\nthem inadequate for open systems. We first conduct a conceptual analysis,\nin-troducing new sub-categories of openness to detail how events like agent\nturnover or task cancellation break the assumptions of environmental\nstationarity and fixed team composition that underpin existing CAP methods. We\nthen present an empirical study using representative temporal and structural\nalgorithms in an open environment. The results demonstrate that openness\ndirectly causes credit misattribution, evidenced by unstable loss functions and\nsignificant performance degradation.",
      "url": "http://arxiv.org/abs/2510.27659v1",
      "published_time_eastern_timestamp": 1761931832.0
    },
    {
      "title": "NegoCollab: A Common Representation Negotiation Approach for\n  Heterogeneous Collaborative Perception",
      "summary": "Collaborative perception improves task performance by expanding the\nperception range through information sharing among agents. . Immutable\nheterogeneity poses a significant challenge in collaborative perception, as\nparticipating agents may employ different and fixed perception models. This\nleads to domain gaps in the intermediate features shared among agents,\nconsequently degrading collaborative performance. Aligning the features of all\nagents to a common representation can eliminate domain gaps with low training\ncost. However, in existing methods, the common representation is designated as\nthe representation of a specific agent, making it difficult for agents with\nsignificant domain discrepancies from this specific agent to achieve proper\nalignment. This paper proposes NegoCollab, a heterogeneous collaboration method\nbased on the negotiated common representation. It introduces a negotiator\nduring training to derive the common representation from the local\nrepresentations of each modality's agent, effectively reducing the inherent\ndomain gap with the various local representations. In NegoCollab, the mutual\ntransformation of features between the local representation space and the\ncommon representation space is achieved by a pair of sender and receiver. To\nbetter align local representations to the common representation containing\nmultimodal information, we introduce structural alignment loss and pragmatic\nalignment loss in addition to the distribution alignment loss to supervise the\ntraining. This enables the knowledge in the common representation to be fully\ndistilled into the sender.",
      "url": "http://arxiv.org/abs/2510.27647v1",
      "published_time_eastern_timestamp": 1761931254.0
    },
    {
      "title": "Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout\n  for Long-Horizon Task Training",
      "summary": "Large Language Model (LLM) agents have recently shown strong potential in\ndomains such as automated coding, deep research, and graphical user interface\nmanipulation. However, training them to succeed on long-horizon,\ndomain-specialized tasks remains challenging. Current methods primarily fall\ninto two categories. The first relies on dense human annotations through\nbehavior cloning, which is prohibitively expensive for long-horizon tasks that\ncan take days or months. The second depends on outcome-driven sampling, which\noften collapses due to the rarity of valid positive trajectories on\ndomain-specialized tasks. We introduce Apollo, a sampling framework that\nintegrates asynchronous human guidance with action-level data filtering.\nInstead of requiring annotators to shadow every step, Apollo allows them to\nintervene only when the agent drifts from a promising trajectory, by providing\nprior knowledge, strategic advice, etc. This lightweight design makes it\npossible to sustain interactions for over 30 hours and produces valuable\ntrajectories at a lower cost. Apollo then applies supervision control to filter\nout sub-optimal actions and prevent error propagation. Together, these\ncomponents enable reliable and effective data collection in long-horizon\nenvironments. To demonstrate the effectiveness of Apollo, we evaluate it using\nInnovatorBench. Our experiments show that when applied to train the GLM-4.5\nmodel on InnovatorBench, Apollo achieves more than a 50% improvement over the\nuntrained baseline and a 28% improvement over a variant trained without human\ninteraction. These results highlight the critical role of human-in-the-loop\nsampling and the robustness of Apollo's design in handling long-horizon,\ndomain-specialized tasks.",
      "url": "http://arxiv.org/abs/2510.27630v2",
      "published_time_eastern_timestamp": 1761930022.0
    },
    {
      "title": "Validity Is What You Need",
      "summary": "While AI agents have long been discussed and studied in computer science,\ntoday's Agentic AI systems are something new. We consider other definitions of\nAgentic AI and propose a new realist definition. Agentic AI is a software\ndelivery mechanism, comparable to software as a service (SaaS), which puts an\napplication to work autonomously in a complex enterprise setting. Recent\nadvances in large language models (LLMs) as foundation models have driven\nexcitement in Agentic AI. We note, however, that Agentic AI systems are\nprimarily applications, not foundations, and so their success depends on\nvalidation by end users and principal stakeholders. The tools and techniques\nneeded by the principal users to validate their applications are quite\ndifferent from the tools and techniques used to evaluate foundation models.\nIronically, with good validation measures in place, in many cases the\nfoundation models can be replaced with much simpler, faster, and more\ninterpretable models that handle core logic. When it comes to Agentic AI,\nvalidity is what you need. LLMs are one option that might achieve it.",
      "url": "http://arxiv.org/abs/2510.27628v1",
      "published_time_eastern_timestamp": 1761930004.0
    },
    {
      "title": "Hiring Intrinsically Motivated Agents: A Principal's Dilemma",
      "summary": "Employers are concerned not only with a prospective worker's ability, but\nalso their propensity to avoid shirking. This paper proposes a new experimental\nframework to study how Principals trade-off measures of ability and prosocial\nbehavior when ranking Agents for independent jobs. Subjects participate in a\nsimulated, incentivized job market. In an initial session, subjects are Workers\nand generate a database of signals and job results. Managers in subsequent\nsessions observe the signals of Worker behavior and ability and job details\nbefore a rank-and-value task, ranking and reporting a value for each Worker for\ntwo distinct jobs. Results highlight Managers' preference for ability over\nprosocial behavior on average, especially for Managers in STEM fields. There is\nevidence of homophily: the relative value of prosocial behavior is higher for\nhighly prosocial Managers, compensating for ability or even surpassing it in\nvalue.",
      "url": "http://arxiv.org/abs/2510.27625v1",
      "published_time_eastern_timestamp": 1761929622.0
    },
    {
      "title": "Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive\n  Trigger Learning",
      "summary": "Multimodal large language models (MLLMs) have advanced embodied agents by\nenabling direct perception, reasoning, and planning task-oriented actions from\nvisual inputs. However, such vision driven embodied agents open a new attack\nsurface: visual backdoor attacks, where the agent behaves normally until a\nvisual trigger appears in the scene, then persistently executes an\nattacker-specified multi-step policy. We introduce BEAT, the first framework to\ninject such visual backdoors into MLLM-based embodied agents using objects in\nthe environments as triggers. Unlike textual triggers, object triggers exhibit\nwide variation across viewpoints and lighting, making them difficult to implant\nreliably. BEAT addresses this challenge by (1) constructing a training set that\nspans diverse scenes, tasks, and trigger placements to expose agents to trigger\nvariability, and (2) introducing a two-stage training scheme that first applies\nsupervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning\n(CTL). CTL formulates trigger discrimination as preference learning between\ntrigger-present and trigger-free inputs, explicitly sharpening the decision\nboundaries to ensure precise backdoor activation. Across various embodied agent\nbenchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while\nmaintaining strong benign task performance, and generalizes reliably to\nout-of-distribution trigger placements. Notably, compared to naive SFT, CTL\nboosts backdoor activation accuracy up to 39% under limited backdoor data.\nThese findings expose a critical yet unexplored security risk in MLLM-based\nembodied agents, underscoring the need for robust defenses before real-world\ndeployment.",
      "url": "http://arxiv.org/abs/2510.27623v1",
      "published_time_eastern_timestamp": 1761929449.0
    },
    {
      "title": "VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation",
      "summary": "Automation of Register Transfer Level (RTL) design can help developers meet\nincreasing computational demands. Large Language Models (LLMs) show promise for\nHardware Description Language (HDL) generation, but face challenges due to\nlimited parametric knowledge and domain-specific constraints. While prompt\nengineering and fine-tuning have limitations in knowledge coverage and training\ncosts, multi-agent architectures offer a training-free paradigm to enhance\nreasoning through collaborative generation. However, current multi-agent\napproaches suffer from two critical deficiencies: susceptibility to noise\npropagation and constrained reasoning space exploration. We propose VeriMoA, a\ntraining-free mixture-of-agents (MoA) framework with two synergistic\ninnovations. First, a quality-guided caching mechanism to maintain all\nintermediate HDL outputs and enables quality-based ranking and selection across\nthe entire generation process, encouraging knowledge accumulation over layers\nof reasoning. Second, a multi-path generation strategy that leverages C++ and\nPython as intermediate representations, decomposing specification-to-HDL\ntranslation into two-stage processes that exploit LLM fluency in high-resource\nlanguages while promoting solution diversity. Comprehensive experiments on\nVerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves\n15--30% improvements in Pass@1 across diverse LLM backbones, especially\nenabling smaller models to match larger models and fine-tuned alternatives\nwithout requiring costly training.",
      "url": "http://arxiv.org/abs/2510.27617v1",
      "published_time_eastern_timestamp": 1761928858.0
    },
    {
      "title": "InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM\n  Research",
      "summary": "AI agents could accelerate scientific discovery by automating hypothesis\nformation, experiment design, coding, execution, and analysis, yet existing\nbenchmarks probe narrow skills in simplified settings. To address this gap, we\nintroduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end\nassessment of agents performing Large Language Model (LLM) research. It\ncomprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss\nDesign, Reward Design, and Scaffold Construction, which require runnable\nartifacts and assessment of correctness, performance, output quality, and\nuncertainty. To support agent operation, we develop ResearchGym, a research\nenvironment offering rich action spaces, distributed and long-horizon\nexecution, asynchronous monitoring, and snapshot saving. We also implement a\nlightweight ReAct agent that couples explicit reasoning with executable\nplanning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2.\nOur experiments demonstrate that while frontier models show promise in\ncode-driven research tasks, they struggle with fragile algorithm-related tasks\nand long-horizon decision making, such as impatience, poor resource management,\nand overreliance on template-based reasoning. Furthermore, agents require over\n11 hours to achieve their best performance on InnovatorBench, underscoring the\nbenchmark's difficulty and showing the potential of InnovatorBench to be the\nnext generation of code-based research benchmark.",
      "url": "http://arxiv.org/abs/2510.27598v2",
      "published_time_eastern_timestamp": 1761927743.0
    },
    {
      "title": "Combined fluorescence and photoacoustic imaging of tozuleristide in\n  muscle tissue in vitro -- toward optically-guided solid tumor surgery:\n  feasibility studies",
      "summary": "Near-infrared fluorescence (NIRF) can deliver high-contrast, video-rate,\nnon-contact imaging of tumor-targeted contrast agents with the potential to\nguide surgeries excising solid tumors. However, it has been met with skepticism\nfor wide-margin excision due to sensitivity and resolution limitations at\ndepths larger than ~5 mm in tissue. To address this limitation, fast-sweep\nphotoacoustic-ultrasound (PAUS) imaging is proposed to complement NIRF. In an\nexploratory in vitro feasibility study using dark-red bovine muscle tissue, we\nobserved that PAUS scanning can identify tozuleristide, a clinical stage\ninvestigational imaging agent, at a concentration of 20 uM from the background\nat depths of up to ~34 mm, highly extending the capabilities of NIRF alone. The\ncapability of spectroscopic PAUS imaging was tested by direct injection of 20\nuM tozuleristide into bovine muscle tissue at a depth of ~ 8 mm. It is shown\nthat laser-fluence compensation and strong clutter suppression enabled by the\nunique capabilities of the fast-sweep approach greatly improve spectroscopic\naccuracy and the PA detection limit, and strongly reduce image artifacts. Thus,\nthe combined NIRF-PAUS approach can be promising for comprehensive pre- (with\nPA) and intra- (with NIRF) operative solid tumor detection and wide-margin\nexcision in optically guided solid tumor surgery.",
      "url": "http://arxiv.org/abs/2510.27595v1",
      "published_time_eastern_timestamp": 1761927674.0
    }
  ]
}
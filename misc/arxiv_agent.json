{
  "last_updated": "2025-10-06T08:23:23.973073-04:00",
  "papers": [
    {
      "title": "Improving GUI Grounding with Explicit Position-to-Coordinate Mapping",
      "summary": "GUI grounding, the task of mapping natural-language instructions to pixel\ncoordinates, is crucial for autonomous agents, yet remains difficult for\ncurrent VLMs. The core bottleneck is reliable patch-to-pixel mapping, which\nbreaks when extrapolating to high-resolution displays unseen during training.\nCurrent approaches generate coordinates as text tokens directly from visual\nfeatures, forcing the model to infer complex position-to-pixel mappings\nimplicitly; as a result, accuracy degrades and failures proliferate on new\nresolutions. We address this with two complementary innovations. First, RULER\ntokens serve as explicit coordinate markers, letting the model reference\npositions similar to gridlines on a map and adjust rather than generate\ncoordinates from scratch. Second, Interleaved MRoPE (I-MRoPE) improves spatial\nencoding by ensuring that width and height dimensions are represented equally,\naddressing the asymmetry of standard positional schemes. Experiments on\nScreenSpot, ScreenSpot-V2, and ScreenSpot-Pro show consistent gains in\ngrounding accuracy, with the largest improvements on high-resolution\ninterfaces. By providing explicit spatial guidance rather than relying on\nimplicit learning, our approach enables more reliable GUI automation across\ndiverse resolutions and platforms.",
      "url": "http://arxiv.org/abs/2510.03230v1",
      "published_time_eastern_timestamp": 1759514374.0
    },
    {
      "title": "Abstain and Validate: A Dual-LLM Policy for Reducing Noise in Agentic\n  Program Repair",
      "summary": "Agentic Automated Program Repair (APR) is increasingly tackling complex,\nrepository-level bugs in industry, but ultimately agent-generated patches still\nneed to be reviewed by a human before committing them to ensure they address\nthe bug. Showing unlikely patches to developers can lead to substantial noise,\nwasting valuable developer time and eroding trust in automated code changes. We\nintroduce two complementary LLM-based policies to reduce such noise: bug\nabstention and patch validation policies. Bug abstention excludes bugs that the\nagentic APR system is unlikely to fix. Patch validation rejects patches that\nare unlikely to be a good fix for the given bug. We evaluate both policies on\nthree sets of bugs from Google's codebase, and their candidate patches\ngenerated by an internal agentic APR system. On a set of 174 human-reported\nbugs, removing bugs and patch trajectories rejected by our policies can raise\nsuccess rates by up to 13 percentage points and 15 percentage points,\nrespectively, and by up to 39 percentage points in combination. On null pointer\nexceptions and sanitizer-reported bugs with machine-generated bug reports,\npatch validation also improves average single-sample success rates. This\ntwo-policy approach provides a practical path to the reliable, industrial-scale\ndeployment of agentic APR systems.",
      "url": "http://arxiv.org/abs/2510.03217v1",
      "published_time_eastern_timestamp": 1759514008.0
    },
    {
      "title": "FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of\n  Web Agents",
      "summary": "Web agents powered by large language models (LLMs) must process lengthy web\npage observations to complete user goals; these pages often exceed tens of\nthousands of tokens. This saturates context limits and increases computational\ncost processing; moreover, processing full pages exposes agents to security\nrisks such as prompt injection. Existing pruning strategies either discard\nrelevant content or retain irrelevant context, leading to suboptimal action\nprediction. We introduce FocusAgent, a simple yet effective approach that\nleverages a lightweight LLM retriever to extract the most relevant lines from\naccessibility tree (AxTree) observations, guided by task goals. By pruning\nnoisy and irrelevant content, FocusAgent enables efficient reasoning while\nreducing vulnerability to injection attacks. Experiments on WorkArena and\nWebArena benchmarks show that FocusAgent matches the performance of strong\nbaselines, while reducing observation size by over 50%. Furthermore, a variant\nof FocusAgent significantly reduces the success rate of prompt-injection\nattacks, including banner and pop-up attacks, while maintaining task success\nperformance in attack-free settings. Our results highlight that targeted\nLLM-based retrieval is a practical and robust strategy for building web agents\nthat are efficient, effective, and secure.",
      "url": "http://arxiv.org/abs/2510.03204v1",
      "published_time_eastern_timestamp": 1759513290.0
    },
    {
      "title": "Best-of-Majority: Minimax-Optimal Strategy for Pass@$k$ Inference\n  Scaling",
      "summary": "LLM inference often generates a batch of candidates for a prompt and selects\none via strategies like majority voting or Best-of- N (BoN). For difficult\ntasks, this single-shot selection often underperforms. Consequently,\nevaluations commonly report Pass@$k$: the agent may submit up to $k$ responses,\nand only the best of them is used when computing regret. Motivated by this, we\nstudy inference scaling in the more general Pass@$k$ inference setting, and\nprove that neither majority voting nor BoN exhibits the desirable scaling with\n$k$ and the sampling budget $N$. Combining the advantages of majority voting\nand BoN, we propose a new inference strategy called Best-of-Majority (BoM),\nwith a pivotal step that restricts the candidates to the responses with high\nfrequency in the $N$ samples before selecting the top-$k$ rewards. We prove\nthat when the sampling budget is $N=\\tilde\\Omega(C^*)$, the regret of BoM is\n$O(\\epsilon_{\\mathrm{opt}}+\\sqrt{\\epsilon_{\\mathrm{RM}}^2C^*/k})$, where $C^*$\nis the coverage coefficient, $\\epsilon_{\\mathrm{RM}}$ is the estimation error\nof the reward model, and $\\epsilon_{\\mathrm{opt}}$ is the estimation error of\nreward at the optimal response. We further establish a matching lower bound,\ncertifying that our algorithm is minimax optimal. Beyond optimality, BoM has a\nkey advantage: unlike majority voting and BoN, its performance does not degrade\nwhen increasing $N$. Experimental results of inference on math problems show\nBoM outperforming both majority voting and BoN.",
      "url": "http://arxiv.org/abs/2510.03199v1",
      "published_time_eastern_timestamp": 1759512945.0
    },
    {
      "title": "CoDA: Agentic Systems for Collaborative Data Visualization",
      "summary": "Deep research has revolutionized data analysis, yet data scientists still\ndevote substantial time to manually crafting visualizations, highlighting the\nneed for robust automation from natural language queries. However, current\nsystems struggle with complex datasets containing multiple files and iterative\nrefinement. Existing approaches, including simple single- or multi-agent\nsystems, often oversimplify the task, focusing on initial query parsing while\nfailing to robustly manage data complexity, code errors, or final visualization\nquality. In this paper, we reframe this challenge as a collaborative\nmulti-agent problem. We introduce CoDA, a multi-agent system that employs\nspecialized LLM agents for metadata analysis, task planning, code generation,\nand self-reflection. We formalize this pipeline, demonstrating how\nmetadata-focused analysis bypasses token limits and quality-driven refinement\nensures robustness. Extensive evaluations show CoDA achieves substantial gains\nin the overall score, outperforming competitive baselines by up to 41.5%. This\nwork demonstrates that the future of visualization automation lies not in\nisolated code generation but in integrated, collaborative agentic workflows.",
      "url": "http://arxiv.org/abs/2510.03194v1",
      "published_time_eastern_timestamp": 1759512616.0
    },
    {
      "title": "Q-Learning with Shift-Aware Upper Confidence Bound in Non-Stationary\n  Reinforcement Learning",
      "summary": "We study the Non-Stationary Reinforcement Learning (RL) under distribution\nshifts in both finite-horizon episodic and infinite-horizon discounted Markov\nDecision Processes (MDPs). In the finite-horizon case, the transition functions\nmay suddenly change at a particular episode. In the infinite-horizon setting,\nsuch changes can occur at an arbitrary time step during the agent's interaction\nwith the environment. While the Q-learning Upper Confidence Bound algorithm\n(QUCB) can discover a proper policy during learning, due to the distribution\nshifts, this policy can exploit sub-optimal rewards after the shift happens. To\naddress this issue, we propose Density-QUCB (DQUCB), a shift-aware\nQ-learning~UCB algorithm, which uses a transition density function to detect\ndistribution shifts, then leverages its likelihood to enhance the uncertainty\nestimation quality of Q-learning~UCB, resulting in a balance between\nexploration and exploitation. Theoretically, we prove that our oracle DQUCB\nachieves a better regret guarantee than QUCB. Empirically, our DQUCB enjoys the\ncomputational efficiency of model-free RL and outperforms QUCB baselines by\nhaving a lower regret across RL tasks, as well as a real-world COVID-19 patient\nhospital allocation task using a Deep-Q-learning architecture.",
      "url": "http://arxiv.org/abs/2510.03181v1",
      "published_time_eastern_timestamp": 1759510607.0
    },
    {
      "title": "UniShield: An Adaptive Multi-Agent Framework for Unified Forgery Image\n  Detection and Localization",
      "summary": "With the rapid advancements in image generation, synthetic images have become\nincreasingly realistic, posing significant societal risks, such as\nmisinformation and fraud. Forgery Image Detection and Localization (FIDL) thus\nemerges as essential for maintaining information integrity and societal\nsecurity. Despite impressive performances by existing domain-specific detection\nmethods, their practical applicability remains limited, primarily due to their\nnarrow specialization, poor cross-domain generalization, and the absence of an\nintegrated adaptive framework. To address these issues, we propose UniShield,\nthe novel multi-agent-based unified system capable of detecting and localizing\nimage forgeries across diverse domains, including image manipulation, document\nmanipulation, DeepFake, and AI-generated images. UniShield innovatively\nintegrates a perception agent with a detection agent. The perception agent\nintelligently analyzes image features to dynamically select suitable detection\nmodels, while the detection agent consolidates various expert detectors into a\nunified framework and generates interpretable reports. Extensive experiments\nshow that UniShield achieves state-of-the-art results, surpassing both existing\nunified approaches and domain-specific detectors, highlighting its superior\npracticality, adaptiveness, and scalability.",
      "url": "http://arxiv.org/abs/2510.03161v1",
      "published_time_eastern_timestamp": 1759509185.0
    },
    {
      "title": "Improving Cooperation in Collaborative Embodied AI",
      "summary": "The integration of Large Language Models (LLMs) into multiagent systems has\nopened new possibilities for collaborative reasoning and cooperation with AI\nagents. This paper explores different prompting methods and evaluates their\neffectiveness in enhancing agent collaborative behaviour and decision-making.\nWe enhance CoELA, a framework designed for building Collaborative Embodied\nAgents that leverage LLMs for multi-agent communication, reasoning, and task\ncoordination in shared virtual spaces. Through systematic experimentation, we\nexamine different LLMs and prompt engineering strategies to identify optimised\ncombinations that maximise collaboration performance. Furthermore, we extend\nour research by integrating speech capabilities, enabling seamless\ncollaborative voice-based interactions. Our findings highlight the\neffectiveness of prompt optimisation in enhancing collaborative agent\nperformance; for example, our best combination improved the efficiency of the\nsystem running with Gemma3 by 22% compared to the original CoELA system. In\naddition, the speech integration provides a more engaging user interface for\niterative system development and demonstrations.",
      "url": "http://arxiv.org/abs/2510.03153v1",
      "published_time_eastern_timestamp": 1759508748.0
    },
    {
      "title": "ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal\n  Trajectories",
      "summary": "Accurately modeling human mobility is critical for urban planning,\nepidemiology, and traffic management. In this work, we introduce Markovian Reeb\nGraphs, a novel framework for simulating spatiotemporal trajectories that\npreserve Patterns of Life (PoLs) learned from baseline data. By combining\nindividual- and population-level mobility structures within a probabilistic\ntopological model, our approach generates realistic future trajectories that\ncapture both consistency and variability in daily life. Evaluations on the\nUrban Anomalies dataset (Atlanta and Berlin subsets) using the Jensen-Shannon\nDivergence (JSD) across population- and agent-level metrics demonstrate that\nthe proposed method achieves strong fidelity while remaining data- and\ncompute-efficient. These results position Markovian Reeb Graphs as a scalable\nframework for trajectory simulation with broad applicability across diverse\nurban environments.",
      "url": "http://arxiv.org/abs/2510.03152v1",
      "published_time_eastern_timestamp": 1759508711.0
    },
    {
      "title": "SurveyBench: How Well Can LLM(-Agents) Write Academic Surveys?",
      "summary": "Academic survey writing, which distills vast literature into a coherent and\ninsightful narrative, remains a labor-intensive and intellectually demanding\ntask. While recent approaches, such as general DeepResearch agents and\nsurvey-specialized methods, can generate surveys automatically (a.k.a.\nLLM4Survey), their outputs often fall short of human standards and there lacks\na rigorous, reader-aligned benchmark for thoroughly revealing their\ndeficiencies. To fill the gap, we propose a fine-grained, quiz-driven\nevaluation framework SurveyBench, featuring (1) typical survey topics source\nfrom recent 11,343 arXiv papers and corresponding 4,947 high-quality surveys;\n(2) a multifaceted metric hierarchy that assesses the outline quality (e.g.,\ncoverage breadth, logical coherence), content quality (e.g., synthesis\ngranularity, clarity of insights), and non-textual richness; and (3) a\ndual-mode evaluation protocol that includes content-based and quiz-based\nanswerability tests, explicitly aligned with readers' informational needs.\nResults show SurveyBench effectively challenges existing LLM4Survey approaches\n(e.g., on average 21% lower than human in content-based evaluation).",
      "url": "http://arxiv.org/abs/2510.03120v1",
      "published_time_eastern_timestamp": 1759506549.0
    },
    {
      "title": "Embracing Evolution: A Call for Body-Control Co-Design in Embodied\n  Humanoid Robot",
      "summary": "Humanoid robots, as general-purpose physical agents, must integrate both\nintelligent control and adaptive morphology to operate effectively in diverse\nreal-world environments. While recent research has focused primarily on\noptimizing control policies for fixed robot structures, this position paper\nargues for evolving both control strategies and humanoid robots' physical\nstructure under a co-design mechanism. Inspired by biological evolution, this\napproach enables robots to iteratively adapt both their form and behavior to\noptimize performance within task-specific and resource-constrained contexts.\nDespite its promise, co-design in humanoid robotics remains a relatively\nunderexplored domain, raising fundamental questions about its feasibility and\nnecessity in achieving true embodied intelligence. To address these challenges,\nwe propose practical co-design methodologies grounded in strategic exploration,\nSim2Real transfer, and meta-policy learning. We further argue for the essential\nrole of co-design by analyzing it from methodological, application-driven, and\ncommunity-oriented perspectives. Striving to guide and inspire future studies,\nwe present open research questions, spanning from short-term innovations to\nlong-term goals. This work positions co-design as a cornerstone for developing\nthe next generation of intelligent and adaptable humanoid agents.",
      "url": "http://arxiv.org/abs/2510.03081v1",
      "published_time_eastern_timestamp": 1759504269.0
    },
    {
      "title": "A Unified Deep Reinforcement Learning Approach for Close Enough\n  Traveling Salesman Problem",
      "summary": "In recent years, deep reinforcement learning (DRL) has gained traction for\nsolving the NP-hard traveling salesman problem (TSP). However, limited\nattention has been given to the close-enough TSP (CETSP), primarily due to the\nchallenge introduced by its neighborhood-based visitation criterion, wherein a\nnode is considered visited if the agent enters a compact neighborhood around\nit. In this work, we formulate a Markov decision process (MDP) for CETSP using\na discretization scheme and propose a novel unified dual-decoder DRL (UD3RL)\nframework that separates decision-making into node selection and waypoint\ndetermination. Specifically, an adapted encoder is employed for effective\nfeature extraction, followed by a node-decoder and a loc-decoder to handle the\ntwo sub-tasks, respectively. A k-nearest neighbors subgraph interaction\nstrategy is further introduced to enhance spatial reasoning during location\ndecoding. Furthermore, we customize the REINFORCE algorithm to train UD3RL as a\nunified model capable of generalizing across different problem sizes and\nvarying neighborhood radius types (i.e., constant and random radii).\nExperimental results show that UD3RL outperforms conventional methods in both\nsolution quality and runtime, while exhibiting strong generalization across\nproblem scales, spatial distributions, and radius ranges, as well as robustness\nto dynamic environments.",
      "url": "http://arxiv.org/abs/2510.03065v1",
      "published_time_eastern_timestamp": 1759502945.0
    },
    {
      "title": "AudioToolAgent: An Agentic Framework for Audio-Language Models",
      "summary": "Large Audio-Language Models (LALMs) perform well on audio understanding tasks\nbut lack multi-step reasoning and tool-calling found in recent Large Language\nModels (LLMs). This paper presents AudioToolAgent, a framework that coordinates\naudio-language models as tools via a central LLM agent that accesses tool\nadapters for audio question answering and speech-to-text. The agent selects\ntools, asks follow-up questions, and compares outputs for verification.\nExperiments with MMAU, MMAR, and MMAU-Pro show state-of-the-art accuracy: up to\n74.10% on MMAU, 68.80% on MMAR, and 57.96% on MMAU-Pro. Monte Carlo sampling\nfor shapley values across 374 configurations identifies effective agent-tool\ncombinations. The modular design allows integration of new tools and eliminates\nthe use of data and training costs. Code and reproduction materials are\navailable at: github.com/GLJS/AudioToolAgent",
      "url": "http://arxiv.org/abs/2510.02995v1",
      "published_time_eastern_timestamp": 1759498545.0
    },
    {
      "title": "Ergodic Risk Measures: Towards a Risk-Aware Foundation for Continual\n  Reinforcement Learning",
      "summary": "Continual reinforcement learning (continual RL) seeks to formalize the\nnotions of lifelong learning and endless adaptation in RL. In particular, the\naim of continual RL is to develop RL agents that can maintain a careful balance\nbetween retaining useful information and adapting to new situations. To date,\ncontinual RL has been explored almost exclusively through the lens of\nrisk-neutral decision-making, in which the agent aims to optimize the expected\n(or mean) long-run performance. In this work, we present the first formal\ntheoretical treatment of continual RL through the lens of risk-aware\ndecision-making, in which the agent aims to optimize a reward-based measure of\nlong-run performance beyond the mean. In particular, we show that the classical\ntheory of risk measures, widely used as a theoretical foundation in\nnon-continual risk-aware RL, is, in its current form, incompatible with the\ncontinual setting. Then, building on this insight, we extend risk measure\ntheory into the continual setting by introducing a new class of ergodic risk\nmeasures that are compatible with continual learning. Finally, we provide a\ncase study of risk-aware continual learning, along with empirical results,\nwhich show the intuitive appeal and theoretical soundness of ergodic risk\nmeasures.",
      "url": "http://arxiv.org/abs/2510.02945v1",
      "published_time_eastern_timestamp": 1759495203.0
    },
    {
      "title": "Axiomatisation for an asynchronous epistemic logic with sending and\n  receiving messages",
      "summary": "We investigate a public announcement logic for asynchronous public\nannouncements wherein the sending of the announcements by the environment is\nseparated from the reception of the announcements by the individual agents.\nBoth come with different modalities. In the logical semantics, formulas are\ninterpreted in a world of a Kripke model but given a history of prior\nannouncements and receptions of announcements that already happened. An\naxiomatisation AA for such a logic has been given in prior work, for the\nformulas that are valid when interpreted in the Kripke model before any such\nannouncements have taken place. This axiomatisation is a reduction system\nwherein one can show that every formula is equivalent to a purely epistemic\nformula without dynamic modalities for announcements and receptions. We propose\na generalisation AA* of this axiomatisation, for the formulas that are valid\nwhen interpreted in the Kripke model given any history of prior announcements\nand receptions of announcements. It does not extend the axiomatisation AA, for\nexample it is no longer valid that nobody has received any announcement. Unlike\nAA, this axiomatisation AA* is infinitary and it is not a reduction system.",
      "url": "http://arxiv.org/abs/2510.02890v1",
      "published_time_eastern_timestamp": 1759489062.0
    },
    {
      "title": "Delay-Tolerant Augmented-Consensus-based Distributed Directed\n  Optimization",
      "summary": "Distributed optimization finds applications in large-scale machine learning,\ndata processing and classification over multi-agent networks. In real-world\nscenarios, the communication network of agents may encounter latency that may\naffect the convergence of the optimization protocol. This paper addresses the\ncase where the information exchange among the agents (computing nodes) over\ndata-transmission channels (links) might be subject to communication\ntime-delays, which is not well addressed in the existing literature. Our\nproposed algorithm improves the state-of-the-art by handling heterogeneous and\narbitrary but bounded and fixed (time-invariant) delays over general\nstrongly-connected directed networks. Arguments from matrix theory, algebraic\ngraph theory, and augmented consensus formulation are applied to prove the\nconvergence to the optimal value. Simulations are provided to verify the\nresults and compare the performance with some existing delay-free algorithms.",
      "url": "http://arxiv.org/abs/2510.02889v1",
      "published_time_eastern_timestamp": 1759488733.0
    },
    {
      "title": "Beyond the Final Answer: Evaluating the Reasoning Trajectories of\n  Tool-Augmented Agents",
      "summary": "Although recent tool-augmented benchmarks incorporate complex user requests\nand diverse tools, the evaluation methods for most of them remain limited to\nanswer matching. However, as the number of steps required to resolve a user\nrequest increases, a proper evaluation of an agent's performance must go beyond\nthe final answer to also assess the problem-solving trajectory, including\npreviously ignored aspects such as efficiency, hallucination, and adaptivity.\nThe most straightforward method for evaluating these aspects is to compare an\nagent's trajectory with the ground-truth trajectory, but this approach is\nfundamentally limited since annotating all valid ground-truth trajectories is\nprohibitively expensive. However, a simple LLM-based evaluator struggles to\nassess trajectories in detail without ground truth. To effectively evaluate the\nagents in this manner, we introduce TRACE, a framework for the\nmulti-dimensional evaluation of tool-augmented LLM agent performance. By\nincorporating an evidence bank, which accumulates knowledge gathered from\npreceding reasoning steps, TRACE enables a multi-faceted analysis and\nevaluation of an agent's reasoning trajectory effectively. To validate our\nframework, we develop a new meta-evaluation dataset by augmenting existing\nbenchmarks with diverse and flawed trajectories, each labeled with\nmulti-faceted performance scores. Our results confirm that TRACE accurately\nevaluates these complex behaviors in a scalable and cost-effective manner, even\nwith small open-source LLMs. Furthermore, we apply our method to evaluate the\ntrajectories that agents produce while solving tool-augmented tasks, presenting\npreviously unreported observations and their corresponding insights.",
      "url": "http://arxiv.org/abs/2510.02837v1",
      "published_time_eastern_timestamp": 1759483155.0
    },
    {
      "title": "Prototyping Digital Social Spaces through Metaphor-Driven Design:\n  Translating Spatial Concepts into an Interactive Social Simulation",
      "summary": "Social media platforms are central to communication, yet their designs remain\nnarrowly focused on engagement and scale. While researchers have proposed\nalternative visions for online spaces, these ideas are difficult to prototype\nwithin platform constraints. In this paper, we introduce a metaphor-driven\nsystem to help users imagine and explore new social media environments. The\nsystem translates users' metaphors into structured sets of platform features\nand generates interactive simulations populated with LLM-driven agents. To\nevaluate this approach, we conducted a study where participants created and\ninteracted with simulated social media spaces. Our findings show that metaphors\nallow users to express distinct social expectations, and that perceived\nauthenticity of the simulation depended on how well it captured dynamics like\nintimacy, participation, and temporal engagement. We conclude by discussing how\nmetaphor-driven simulation can be a powerful design tool for prototyping\nalternative social architectures and expanding the design space for future\nsocial platforms.",
      "url": "http://arxiv.org/abs/2510.02759v1",
      "published_time_eastern_timestamp": 1759473815.0
    },
    {
      "title": "The Path of Self-Evolving Large Language Models: Achieving\n  Data-Efficient Learning via Intrinsic Feedback",
      "summary": "Reinforcement learning (RL) has demonstrated potential in enhancing the\nreasoning capabilities of large language models (LLMs), but such training\ntypically demands substantial efforts in creating and annotating data. In this\nwork, we explore improving LLMs through RL with minimal data. Our approach\nalternates between the LLM proposing a task and then attempting to solve it. To\nminimize data dependency, we introduce two novel mechanisms grounded in\nself-awareness: (1) self-aware difficulty prediction, where the model learns to\nassess task difficulty relative to its own abilities and prioritize challenging\nyet solvable tasks, and (2) self-aware limit breaking, where the model\nrecognizes when a task is beyond its capability boundary and proactively\nrequests external data to break through that limit. Extensive experiments on\nnine benchmarks showing a 53.8% relative improvement with less than 1.2% extra\ndata demonstrate the efficacy of self-aware RL and underscore the promise of\nself-evolving agent training.",
      "url": "http://arxiv.org/abs/2510.02752v1",
      "published_time_eastern_timestamp": 1759473130.0
    },
    {
      "title": "Repeated Matching Games: An Empirical Framework",
      "summary": "We introduce a model of dynamic matching with transferable utility, extending\nthe static model of Shapley and Shubik (1971). Forward-looking agents have\nindividual states that evolve with current matches. Each period, a matching\nmarket with market-clearing prices takes place. We prove the existence of an\nequilibrium with time-varying distributions of agent types and show it is the\nsolution to a social planner's problem. We also prove that a stationary\nequilibrium exists. We introduce econometric shocks to account for unobserved\nheterogeneity in match formation. We propose two algorithms to compute a\nstationary equilibrium. We adapt both algorithms for estimation. We estimate a\nmodel of accumulation of job-specific human capital using data on Swedish\nengineers.",
      "url": "http://arxiv.org/abs/2510.02737v1",
      "published_time_eastern_timestamp": 1759469797.0
    }
  ]
}
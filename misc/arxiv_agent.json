{
  "last_updated": "2025-05-12T02:18:06.025923-04:00",
  "papers": [
    {
      "title": "Robust Multi-Agent Decision-Making in Finite-Population Games",
      "summary": "We study the robustness of an agent decision-making model in\nfinite-population games, with a particular focus on the Kullback-Leibler\nDivergence Regularized Learning (KLD-RL) model. Specifically, we examine how\nthe model's parameters influence the effects of various sources of noise and\nmodeling inaccuracies -- factors commonly encountered in engineering\napplications of population games -- on agents' decision-making. Our analysis\nprovides insights into how these parameters can be effectively tuned to\nmitigate such effects. Theoretical results are supported by numerical examples\nand simulation studies that validate the analysis and illustrate practical\nstrategies for parameter selection.",
      "url": "http://arxiv.org/abs/2505.06200v1",
      "published_time_eastern_timestamp": 1746811553.0
    },
    {
      "title": "Neuro-Symbolic Concepts",
      "summary": "This article presents a concept-centric paradigm for building agents that can\nlearn continually and reason flexibly. The concept-centric agent utilizes a\nvocabulary of neuro-symbolic concepts. These concepts, such as object,\nrelation, and action concepts, are grounded on sensory inputs and actuation\noutputs. They are also compositional, allowing for the creation of novel\nconcepts through their structural combination. To facilitate learning and\nreasoning, the concepts are typed and represented using a combination of\nsymbolic programs and neural network representations. Leveraging such\nneuro-symbolic concepts, the agent can efficiently learn and recombine them to\nsolve various tasks across different domains, ranging from 2D images, videos,\n3D scenes, and robotic manipulation tasks. This concept-centric framework\noffers several advantages, including data efficiency, compositional\ngeneralization, continual learning, and zero-shot transfer.",
      "url": "http://arxiv.org/abs/2505.06191v1",
      "published_time_eastern_timestamp": 1746810171.0
    },
    {
      "title": "The Power of Matching for Online Fractional Hedonic Games",
      "summary": "We study coalition formation in the framework of fractional hedonic games\n(FHGs). The objective is to maximize social welfare in an online model where\nagents arrive one by one and must be assigned to coalitions immediately and\nirrevocably. For general online FHGs, it is known that computing maximal\nmatchings achieves the optimal competitive ratio, which is, however, unbounded\nfor unbounded agent valuations.\n  We achieve a constant competitive ratio in two related settings while carving\nout further connections to matchings. If algorithms can dissolve coalitions,\nthen the optimal competitive ratio of $\\frac{1}{6+4\\sqrt{2}}$ is achieved by a\nmatching-based algorithm. Moreover, we perform a tight analysis for the online\nmatching setting under random arrival with an unknown number of agents. This\nentails a randomized $\\frac 16$-competitive algorithm for FHGs, while no\nalgorithm can be better than $\\frac 13$-competitive.",
      "url": "http://arxiv.org/abs/2505.06163v1",
      "published_time_eastern_timestamp": 1746807215.0
    },
    {
      "title": "Realistic Adversarial Attacks for Robustness Evaluation of Trajectory\n  Prediction Models via Future State Perturbation",
      "summary": "Trajectory prediction is a key element of autonomous vehicle systems,\nenabling them to anticipate and react to the movements of other road users.\nEvaluating the robustness of prediction models against adversarial attacks is\nessential to ensure their reliability in real-world traffic. However, current\napproaches tend to focus on perturbing the past positions of surrounding\nagents, which can generate unrealistic scenarios and overlook critical\nvulnerabilities. This limitation may result in overly optimistic assessments of\nmodel performance in real-world conditions.\n  In this work, we demonstrate that perturbing not just past but also future\nstates of adversarial agents can uncover previously undetected weaknesses and\nthereby provide a more rigorous evaluation of model robustness. Our novel\napproach incorporates dynamic constraints and preserves tactical behaviors,\nenabling more effective and realistic adversarial attacks. We introduce new\nperformance measures to assess the realism and impact of these adversarial\ntrajectories. Testing our method on a state-of-the-art prediction model\nrevealed significant increases in prediction errors and collision rates under\nadversarial conditions. Qualitative analysis further showed that our attacks\ncan expose critical weaknesses, such as the inability of the model to detect\npotential collisions in what appear to be safe predictions. These results\nunderscore the need for more comprehensive adversarial testing to better\nevaluate and improve the reliability of trajectory prediction models for\nautonomous vehicles.",
      "url": "http://arxiv.org/abs/2505.06134v1",
      "published_time_eastern_timestamp": 1746805232.0
    },
    {
      "title": "ELA-ZSON: Efficient Layout-Aware Zero-Shot Object Navigation Agent with\n  Hierarchical Planning",
      "summary": "We introduce ELA-ZSON, an efficient layout-aware zero-shot object navigation\n(ZSON) approach designed for complex multi-room indoor environments.\n  By planning hierarchically leveraging a global topologigal map with layout\ninformation and local imperative approach with detailed scene representation\nmemory, ELA-ZSON achieves both efficient and effective navigation.\n  The process is managed by an LLM-powered agent, ensuring seamless effective\nplanning and navigation, without the need for human interaction, complex\nrewards, or costly training.\n  Our experimental results on the MP3D benchmark achieves 85\\% object\nnavigation success rate (SR) and 79\\% success rate weighted by path length\n(SPL) (over 40\\% point improvement in SR and 60\\% improvement in SPL compared\nto exsisting methods). Furthermore, we validate the robustness of our approach\nthrough virtual agent and real-world robotic deployment, showcasing its\ncapability in practical scenarios. See\nhttps://anonymous.4open.science/r/ELA-ZSON-C67E/ for details.",
      "url": "http://arxiv.org/abs/2505.06131v1",
      "published_time_eastern_timestamp": 1746805177.0
    },
    {
      "title": "Oncolytic mechanisms and immunotherapeutic potential of Newcastle\n  disease virus in cancer therapy",
      "summary": "Newcastle Disease Virus (NDV), classified as Avian orthoavulavirus 1 (avian\nparamyxovirus type 1), is a promising oncolytic agent that selectively targets\nand destroys cancer cells while sparing normal tissues. Its oncoselectivity\nexploits cancer-specific defects in antiviral defenses, particularly impaired\nType I interferon signaling, and dysregulated apoptotic pathways, enabling\nrobust viral replication and cytotoxicity in malignancies such as breast,\ncolorectal, and melanoma. NDV induces intrinsic and extrinsic apoptosis through\ncaspase activation and triggers immunogenic cell death via damage-associated\nmolecular patterns, stimulating potent antitumours immune responses.\nAdditionally, NDVs potential as a vaccine vector, expressing tumours-associated\nantigens, offers prospects for prophylactic and therapeutic cancer\napplications. This review provides a comprehensive analysis of NDVs morphology,\nclassification, and molecular biology, focusing on its viral entry and\nreplication mechanisms in host cells. It explores NDVs interactions with cancer\ncells, emphasizing its ability to induce cytotoxicity and immune activation.\nUnderstanding these mechanisms is critical for optimizing NDVs oncolytic\npotential and advancing its clinical translation. Future directions include\nenhancing NDV through genetic engineering, combining it with therapies like\nimmune checkpoint inhibitors, and developing personalized medicine approaches\ntailored to tumours genomic profiles. These advancements position NDV as a\nversatile therapeutic agent in oncolytic virotherapy.",
      "url": "http://arxiv.org/abs/2505.06067v1",
      "published_time_eastern_timestamp": 1746799421.0
    },
    {
      "title": "Offline Multi-agent Reinforcement Learning via Score Decomposition",
      "summary": "Offline multi-agent reinforcement learning (MARL) faces critical challenges\ndue to distributional shifts, further exacerbated by the high dimensionality of\njoint action spaces and the diversity in coordination strategies and quality\namong agents. Conventional approaches, including independent learning\nframeworks and value decomposition methods based on pessimistic principles,\nremain susceptible to out-of-distribution (OOD) joint actions and often yield\nsuboptimal performance. Through systematic analysis of prevalent offline MARL\nbenchmarks, we identify that this limitation primarily stems from the\ninherently multimodal nature of joint collaborative policies induced by offline\ndata collection. To address these challenges, we propose a novel two-stage\nframework: First, we employ a diffusion-based generative model to explicitly\ncapture the complex behavior policy, enabling accurate modeling of diverse\nmulti-agent coordination patterns. Second, we introduce a sequential score\nfunction decomposition mechanism to regularize individual policies and enable\ndecentralized execution. Extensive experiments on continuous control tasks\ndemonstrate state-of-the-art performance across multiple standard offline MARL\nbenchmarks, outperforming existing methods by 26.3\\% in normalized returns. Our\napproach provides new insights into offline coordination and equilibrium\nselection in cooperative multi-agent systems.",
      "url": "http://arxiv.org/abs/2505.05968v1",
      "published_time_eastern_timestamp": 1746790951.0
    },
    {
      "title": "Learning Power Control Protocol for In-Factory 6G Subnetworks",
      "summary": "In-X Subnetworks are envisioned to meet the stringent demands of short-range\ncommunication in diverse 6G use cases. In the context of In-Factory scenarios,\neffective power control is critical to mitigating the impact of interference\nresulting from potentially high subnetwork density. Existing approaches to\npower control in this domain have predominantly emphasized the data plane,\noften overlooking the impact of signaling overhead. Furthermore, prior work has\ntypically adopted a network-centric perspective, relying on the assumption of\ncomplete and up-to-date channel state information (CSI) being readily available\nat the central controller. This paper introduces a novel multi-agent\nreinforcement learning (MARL) framework designed to enable access points to\nautonomously learn both signaling and power control protocols in an In-Factory\nSubnetwork environment. By formulating the problem as a partially observable\nMarkov decision process (POMDP) and leveraging multi-agent proximal policy\noptimization (MAPPO), the proposed approach achieves significant advantages.\nThe simulation results demonstrate that the learning-based method reduces\nsignaling overhead by a factor of 8 while maintaining a buffer flush rate that\nlags the ideal \"Genie\" approach by only 5%.",
      "url": "http://arxiv.org/abs/2505.05967v1",
      "published_time_eastern_timestamp": 1746790758.0
    },
    {
      "title": "Cost-Effective, Low Latency Vector Search with Azure Cosmos DB",
      "summary": "Vector indexing enables semantic search over diverse corpora and has become\nan important interface to databases for both users and AI agents. Efficient\nvector search requires deep optimizations in database systems. This has\nmotivated a new class of specialized vector databases that optimize for vector\nsearch quality and cost. Instead, we argue that a scalable, high-performance,\nand cost-efficient vector search system can be built inside a cloud-native\noperational database like Azure Cosmos DB while leveraging the benefits of a\ndistributed database such as high availability, durability, and scale. We do\nthis by deeply integrating DiskANN, a state-of-the-art vector indexing library,\ninside Azure Cosmos DB NoSQL. This system uses a single vector index per\npartition stored in existing index trees, and kept in sync with underlying\ndata. It supports < 20ms query latency over an index spanning 10 million of\nvectors, has stable recall over updates, and offers nearly 15x and 41x lower\nquery cost compared to Zilliz and Pinecone serverless enterprise products. It\nalso scales out to billions of vectors via automatic partitioning. This\nconvergent design presents a point in favor of integrating vector indices into\noperational databases in the context of recent debates on specialized vector\ndatabases, and offers a template for vector indexing in other databases.",
      "url": "http://arxiv.org/abs/2505.05885v1",
      "published_time_eastern_timestamp": 1746780839.0
    },
    {
      "title": "Evolutionary ecology of words",
      "summary": "We propose a model for the evolutionary ecology of words as one attempt to\nextend evolutionary game theory and agent-based models by utilizing the rich\nlinguistic expressions of Large Language Models (LLMs). Our model enables the\nemergence and evolution of diverse and infinite options for interactions among\nagents. Within the population, each agent possesses a short word (or phrase)\ngenerated by an LLM and moves within a spatial environment. When agents become\nadjacent, the outcome of their interaction is determined by the LLM based on\nthe relationship between their words, with the loser's word being replaced by\nthe winner's. Word mutations, also based on LLM outputs, may occur. We\nconducted preliminary experiments assuming that ``strong animal species\" would\nsurvive. The results showed that from an initial population consisting of\nwell-known species, many species emerged both gradually and in a punctuated\nequilibrium manner. Each trial demonstrated the unique evolution of diverse\npopulations, with one type of large species becoming dominant, such as\nterrestrial animals, marine life, or extinct species, which were ecologically\nspecialized and adapted ones across diverse extreme habitats. We also conducted\na long-term experiment with a large population, demonstrating the emergence and\ncoexistence of diverse species.",
      "url": "http://arxiv.org/abs/2505.05863v1",
      "published_time_eastern_timestamp": 1746777430.0
    },
    {
      "title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents",
      "summary": "The strong planning and reasoning capabilities of Large Language Models\n(LLMs) have fostered the development of agent-based systems capable of\nleveraging external tools and interacting with increasingly complex\nenvironments. However, these powerful features also introduce a critical\nsecurity risk: indirect prompt injection, a sophisticated attack vector that\ncompromises the core of these agents, the LLM, by manipulating contextual\ninformation rather than direct user prompts. In this work, we propose a generic\nblack-box fuzzing framework, AgentXploit, designed to automatically discover\nand exploit indirect prompt injection vulnerabilities across diverse LLM\nagents. Our approach starts by constructing a high-quality initial seed corpus,\nthen employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS)\nto iteratively refine inputs, thereby maximizing the likelihood of uncovering\nagent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo\nand VWA-adv, where it achieves 71% and 70% success rates against agents based\non o3-mini and GPT-4o, respectively, nearly doubling the performance of\nbaseline attacks. Moreover, AgentXploit exhibits strong transferability across\nunseen tasks and internal LLMs, as well as promising results against defenses.\nBeyond benchmark evaluations, we apply our attacks in real-world environments,\nsuccessfully misleading agents to navigate to arbitrary URLs, including\nmalicious sites.",
      "url": "http://arxiv.org/abs/2505.05849v1",
      "published_time_eastern_timestamp": 1746776417.0
    },
    {
      "title": "Best of Both Worlds Guarantees for Equitable Allocations",
      "summary": "Equitability is a well-studied fairness notion in fair division, where an\nallocation is equitable if all agents receive equal utility from their\nallocation. For indivisible items, an exactly equitable allocation may not\nexist, and a natural relaxation is EQ1, which stipulates that any\ninequitability should be resolved by the removal of a single item. In this\npaper, we study equitability in the context of randomized allocations.\nSpecifically, we aim to achieve equitability in expectation (ex ante EQ) and\nrequire that each deterministic outcome in the support satisfies ex post EQ1.\nSuch an allocation is commonly known as a `Best of Both Worlds' allocation, and\nhas been studied, e.g., for envy-freeness and MMS.\n  We characterize the existence of such allocations using a geometric condition\non linear combinations of EQ1 allocations, and use this to give comprehensive\nresults on both existence and computation. For two agents, we show that ex ante\nEQ and ex post EQ1 allocations always exist and can be computed in polynomial\ntime. For three or more agents, however, such allocations may not exist. We\nprove that deciding existence of such allocations is strongly NP-complete in\ngeneral, and weakly NP-complete even for three agents. We also present a\npseudo-polynomial time algorithm for a constant number of agents. We show that\nwhen agents have binary valuations, best of both worlds allocations that\nadditionally satisfy welfare guarantees exist and are efficiently computable.",
      "url": "http://arxiv.org/abs/2505.05809v1",
      "published_time_eastern_timestamp": 1746770457.0
    },
    {
      "title": "Assessing the Dynamics of the Coffee Value Chain in Davao del Sur: An\n  Agent-Based Modeling Approach",
      "summary": "The study investigates the coffee value chain dynamics in Davao del Sur using\nan agent-based model. Three main factors driving interactions among key players\nwere identified: trust, risk, and transaction costs. The model was constructed\nusing NetLogo 6.3.0, and data from a survey questionnaire collected three data\npoints from BACOFA members. Five cases were explored, with each scenario\nsimulated 1000 times. Findings suggest that producers often sell to the market\nrather than the cooperative due to higher prices. However, producers tend to\nprioritize trust in buyers and their risk attitude, leading to increased sales\nto the cooperative. The producer's risk attitude significantly influences their\ndecision-making, affecting performance outcomes such as loans, demand, and\nprice changes. All three factors play a role and exert varying impacts on the\nvalue chain. So, the stakeholders' decisions on prioritizing factors in\nimproving relationships depend on their priorities. Nonetheless, simulations\nshow that establishing a harmonious system benefiting all parties is possible.\nHowever, achieving this requires adjustments to demand, pricing, trust, and\nrisk attitudes of key players, which may not align with the preferences of some\nparties in reality.",
      "url": "http://arxiv.org/abs/2505.05797v1",
      "published_time_eastern_timestamp": 1746768291.0
    },
    {
      "title": "Formation Maneuver Control Based on the Augmented Laplacian Method",
      "summary": "This paper proposes a novel formation maneuver control method for both 2-D\nand 3-D space, which enables the formation to translate, scale, and rotate with\narbitrary orientation. The core innovation is the novel design of weights in\nthe proposed augmented Laplacian matrix. Instead of using scalars, we represent\nweights as matrices, which are designed based on a specified rotation axis and\nallow the formation to perform rotation in 3-D space. To further improve the\nflexibility and scalability of the formation, the rotational axis adjustment\napproach and dynamic agent reconfiguration method are developed, allowing\nformations to rotate around arbitrary axes in 3-D space and new agents to join\nthe formation. Theoretical analysis is provided to show that the proposed\napproach preserves the original configuration of the formation. The proposed\nmethod maintains the advantages of the complex Laplacian-based method,\nincluding reduced neighbor requirements and no reliance on generic or convex\nnominal configurations, while achieving arbitrary orientation rotations via a\nmore simplified implementation. Simulations in both 2-D and 3-D space validate\nthe effectiveness of the proposed method.",
      "url": "http://arxiv.org/abs/2505.05795v1",
      "published_time_eastern_timestamp": 1746768108.0
    },
    {
      "title": "Why is distortion inevitable in opinion propagation on social media?\n  Noise induced layer-wised synchronization in Noise-Frustrated\n  Hegselmann-Krause model",
      "summary": "The proliferation of social media as a dominant information propagation\nplatform has intensified scholarly concerns about systemic information\ndistortion,a phenomenon where content undergoes progressive alteration during\nmulti layered transmission. However, existing literature extensively documents\ndistortion patterns, the fundamental mechanisms coupling network architecture\nwith cognitive noise remain poorly quantified. Here, we introduce a novel\nfractal network with coupled Noise Frustrated Hegselmann Krause (NFHK)\nframework that systematically disentangles these intertwined factors. By\nintegrating fractal topology analysis with modified bounded confidence\ndynamics, our model reveals how hierarchical network structures (characterized\nby scale invariant connectivity patterns) amplify stochastic noise through\nsuccessive retransmission layers. Through rigorous mathematical analysis, multi\nagent simulations, and empirical validation of typical retweet cascades, we\ndemonstrate two key phenomena: (i) distortion escalates super linearly with\nnetwork depth and (ii) peer nodes exhibit emergent layer wise synchronization\ndespite lacking direct connections among themselves and form a number of\nsynchronous groups based on the number of network layers. These findings\nestablish a unified mechanism explaining distortion accumulation in digital\necosystems while challenging conventional \"echo chamber\" narratives. Our noise\nfrustration protocol can offer actionable insights for policymakers to design\ntopology aware regulatory frameworks. This work bridges complex systems theory\nwith computational social science, providing both a mathematical foundation for\ndistortion analysis and a toolkit for platform governance.",
      "url": "http://arxiv.org/abs/2505.05769v1",
      "published_time_eastern_timestamp": 1746763981.0
    },
    {
      "title": "Distance Preservation Games",
      "summary": "We introduce and analyze distance preservation games (DPGs). In DPGs, agents\nexpress ideal distances to other agents and need to choose locations in the\nunit interval while preserving their ideal distances as closely as possible. We\nanalyze the existence and computation of location profiles that are jump stable\n(i.e., no agent can benefit by moving to another location) or welfare optimal\nfor DPGs, respectively. Specifically, we prove that there are DPGs without jump\nstable location profiles and identify important cases where such outcomes\nalways exist and can be computed efficiently. Similarly, we show that finding\nwelfare optimal location profiles is NP-complete and present approximation\nalgorithms for finding solutions with social welfare close to optimal. Finally,\nwe prove that DPGs have a price of anarchy of at most $2$.",
      "url": "http://arxiv.org/abs/2505.05765v1",
      "published_time_eastern_timestamp": 1746763332.0
    },
    {
      "title": "Multi-Agent Systems for Robotic Autonomy with LLMs",
      "summary": "Since the advent of Large Language Models (LLMs), various research based on\nsuch models have maintained significant academic attention and impact,\nespecially in AI and robotics. In this paper, we propose a multi-agent\nframework with LLMs to construct an integrated system for robotic task\nanalysis, mechanical design, and path generation. The framework includes three\ncore agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer.\nOutputs are formatted as multimodal results, such as code files or technical\nreports, for stronger understandability and usability. To evaluate\ngeneralizability comparatively, we conducted experiments with models from both\nGPT and DeepSeek. Results demonstrate that the proposed system can design\nfeasible robots with control strategies when appropriate task inputs are\nprovided, exhibiting substantial potential for enhancing the efficiency and\naccessibility of robotic system development in research and industrial\napplications.",
      "url": "http://arxiv.org/abs/2505.05762v1",
      "published_time_eastern_timestamp": 1746762757.0
    },
    {
      "title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal\n  Reasoning",
      "summary": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving.",
      "url": "http://arxiv.org/abs/2505.05758v1",
      "published_time_eastern_timestamp": 1746761911.0
    },
    {
      "title": "Towards Embodiment Scaling Laws in Robot Locomotion",
      "summary": "Developing generalist agents that can operate across diverse tasks,\nenvironments, and physical embodiments is a grand challenge in robotics and\nartificial intelligence. In this work, we focus on the axis of embodiment and\ninvestigate embodiment scaling laws$\\unicode{x2013}$the hypothesis that\nincreasing the number of training embodiments improves generalization to unseen\nones. Using robot locomotion as a test bed, we procedurally generate a dataset\nof $\\sim$1,000 varied embodiments, spanning humanoids, quadrupeds, and\nhexapods, and train generalist policies capable of handling diverse observation\nand action spaces on random subsets. We find that increasing the number of\ntraining embodiments improves generalization to unseen ones, and scaling\nembodiments is more effective in enabling embodiment-level generalization than\nscaling data on small, fixed sets of embodiments. Notably, our best policy,\ntrained on the full dataset, zero-shot transfers to novel embodiments in the\nreal world, such as Unitree Go2 and H1. These results represent a step toward\ngeneral embodied intelligence, with potential relevance to adaptive control for\nconfigurable robots, co-design of morphology and control, and beyond.",
      "url": "http://arxiv.org/abs/2505.05753v1",
      "published_time_eastern_timestamp": 1746761143.0
    },
    {
      "title": "Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement\n  Learning",
      "summary": "Offline reinforcement learning (RL) aims to learn a policy from a static\ndataset without further interactions with the environment. Collecting\nsufficiently large datasets for offline RL is exhausting since this data\ncollection requires colossus interactions with environments and becomes tricky\nwhen the interaction with the environment is restricted. Hence, how an agent\nlearns the best policy with a minimal static dataset is a crucial issue in\noffline RL, similar to the sample efficiency problem in online RL. In this\npaper, we propose a simple yet effective plug-and-play pretraining method to\ninitialize a feature of a $Q$-network to enhance data efficiency in offline RL.\nSpecifically, we introduce a shared $Q$-network structure that outputs\npredictions of the next state and $Q$-value. We pretrain the shared $Q$-network\nthrough a supervised regression task that predicts a next state and trains the\nshared $Q$-network using diverse offline RL methods. Through extensive\nexperiments, we empirically demonstrate that our method enhances the\nperformance of existing popular offline RL methods on the D4RL, Robomimic and\nV-D4RL benchmarks. Furthermore, we show that our method significantly boosts\ndata-efficient offline RL across various data qualities and data distributions\ntrough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of\nthe dataset outperforms standard algorithms even with full datasets.",
      "url": "http://arxiv.org/abs/2505.05701v1",
      "published_time_eastern_timestamp": 1746750361.0
    }
  ]
}
{
  "last_updated": "2025-07-21T14:18:53.062730-04:00",
  "papers": [
    {
      "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time\n  Human-AI Collaboration",
      "summary": "Real-time human-artificial intelligence (AI) collaboration is crucial yet\nchallenging, especially when AI agents must adapt to diverse and unseen human\nbehaviors in dynamic scenarios. Existing large language model (LLM) agents\noften fail to accurately model the complex human mental characteristics such as\ndomain intentions, especially in the absence of direct communication. To\naddress this limitation, we propose a novel dual process multi-scale theory of\nmind (DPMT) framework, drawing inspiration from cognitive science dual process\ntheory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)\nmodule to facilitate robust human partner modeling through mental\ncharacteristic reasoning. Experimental results demonstrate that DPMT\nsignificantly enhances human-AI collaboration, and ablation studies further\nvalidate the contributions of our multi-scale ToM in the slow system.",
      "url": "http://arxiv.org/abs/2507.14088v1",
      "published_time_eastern_timestamp": 1752858801.0
    },
    {
      "title": "Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn\n  Dialog",
      "summary": "As AI systems take on collaborative roles, they must reason about shared\ngoals and beliefs-not just generate fluent language. The Rational Speech Act\n(RSA) framework offers a principled approach to pragmatic reasoning, but\nexisting extensions face challenges in scaling to multi-turn, collaborative\nscenarios. In this paper, we introduce Collaborative Rational Speech Act\n(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn\ndialog by optimizing a gain function adapted from rate-distortion theory. This\ngain is an extension of the gain model that is maximized in the original RSA\nmodel but takes into account the scenario in which both agents in a\nconversation have private information and produce utterances conditioned on the\ndialog. We demonstrate the effectiveness of CRSA on referential games and\ntemplate-based doctor-patient dialogs in the medical domain. Empirical results\nshow that CRSA yields more consistent, interpretable, and collaborative\nbehavior than existing baselines-paving the way for more pragmatic and socially\naware language agents.",
      "url": "http://arxiv.org/abs/2507.14063v1",
      "published_time_eastern_timestamp": 1752856942.0
    },
    {
      "title": "Well posedness and propagation of chaos for multi-agent models with\n  strategies and diffusive effects",
      "summary": "A multi-agent model for individuals endowed with strategies and subject to\ndiffusive effects is proposed. The microscopic state of each agent is described\nby a spatial position and a probability measure, interpreted as a mixed\nstrategy, over a compact metric space. The evolution is governed by a non-local\ninteraction mechanism and by stochastic effects acting on the spatial component\nof the state. The well-posedness of the multi-agent system and that of a\ncertain McKean--Vlasov stochastic differential equation are proved. Eventually,\na propagation of chaos result is obtained, which guarantees that the former\nmodel converges to the latter as the number of agents goes to infinity.",
      "url": "http://arxiv.org/abs/2507.14058v1",
      "published_time_eastern_timestamp": 1752856839.0
    },
    {
      "title": "Online MMS Allocation for Chores",
      "summary": "We study the problem of fair division of indivisible chores among $n$ agents\nin an online setting, where items arrive sequentially and must be allocated\nirrevocably upon arrival. The goal is to produce an $\\alpha$-MMS allocation at\nthe end. Several recent works have investigated this model, but have only\nsucceeded in obtaining non-trivial algorithms under restrictive assumptions,\nsuch as the two-agent bi-valued special case (Wang and Wei, 2025), or by\nassuming knowledge of the total disutility of each agent (Zhou, Bai, and Wu,\n2023). For the general case, the trivial $n$-MMS guarantee remains the best\nknown, while the strongest lower bound is still only $2$.\n  We close this gap on the negative side by proving that for any fixed $n$ and\n$\\varepsilon$, no algorithm can guarantee an $(n - \\varepsilon)$-MMS\nallocation. Notably, this lower bound holds precisely for every $n$, without\nhiding constants in big-$O$ notation, thereby exactly matching the trivial\nupper bound.\n  Despite this strong impossibility result, we also present positive results.\nWe provide an online algorithm that applies in the general case, guaranteeing a\n$\\min\\{n, O(k), O(\\log D)\\}$-MMS allocation, where $k$ is the maximum number of\ndistinct disutilities across all agents and $D$ is the maximum ratio between\nthe largest and smallest disutilities for any agent. This bound is reasonable\nacross a broad range of scenarios and, for example, implies that we can achieve\nan $O(1)$-MMS allocation whenever $k$ is constant. Moreover, to optimize the\nconstant in the important personalized bi-valued case, we show that if each\nagent has at most two distinct disutilities, our algorithm guarantees a $(2 +\n\\sqrt{3}) \\approx 3.7$-MMS allocation.",
      "url": "http://arxiv.org/abs/2507.14039v1",
      "published_time_eastern_timestamp": 1752855051.0
    },
    {
      "title": "Architecting Human-AI Cocreation for Technical Services -- Interaction\n  Modes and Contingency Factors",
      "summary": "Agentic AI systems, powered by Large Language Models (LLMs), offer\ntransformative potential for value co-creation in technical services. However,\npersistent challenges like hallucinations and operational brittleness limit\ntheir autonomous use, creating a critical need for robust frameworks to guide\nhuman-AI collaboration. Drawing on established Human-AI teaming research and\nanalogies from fields like autonomous driving, this paper develops a structured\ntaxonomy of human-agent interaction. Based on case study research within\ntechnical support platforms, we propose a six-mode taxonomy that organizes\ncollaboration across a spectrum of AI autonomy. This spectrum is anchored by\nthe Human-Out-of-the-Loop (HOOTL) model for full automation and the\nHuman-Augmented Model (HAM) for passive AI assistance. Between these poles, the\nframework specifies four distinct intermediate structures. These include the\nHuman-in-Command (HIC) model, where AI proposals re-quire mandatory human\napproval, and the Human-in-the-Process (HITP) model for structured work-flows\nwith deterministic human tasks. The taxonomy further delineates the\nHuman-in-the-Loop (HITL) model, which facilitates agent-initiated escalation\nupon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables\ndiscretionary human oversight of an autonomous AI. The primary contribution of\nthis work is a comprehensive framework that connects this taxonomy to key\ncontingency factors -- such as task complexity, operational risk, and system\nreliability -- and their corresponding conceptual architectures. By providing a\nsystematic method for selecting and designing an appropriate level of human\noversight, our framework offers practitioners a crucial tool to navigate the\ntrade-offs between automation and control, thereby fostering the development of\nsafer, more effective, and context-aware technical service systems.",
      "url": "http://arxiv.org/abs/2507.14034v1",
      "published_time_eastern_timestamp": 1752854763.0
    },
    {
      "title": "Byzantine-resilient federated online learning for Gaussian process\n  regression",
      "summary": "In this paper, we study Byzantine-resilient federated online learning for\nGaussian process regression (GPR). We develop a Byzantine-resilient federated\nGPR algorithm that allows a cloud and a group of agents to collaboratively\nlearn a latent function and improve the learning performances where some agents\nexhibit Byzantine failures, i.e., arbitrary and potentially adversarial\nbehavior. Each agent-based local GPR sends potentially compromised local\npredictions to the cloud, and the cloud-based aggregated GPR computes a global\nmodel by a Byzantine-resilient product of experts aggregation rule. Then the\ncloud broadcasts the current global model to all the agents. Agent-based fused\nGPR refines local predictions by fusing the received global model with that of\nthe agent-based local GPR. Moreover, we quantify the learning accuracy\nimprovements of the agent-based fused GPR over the agent-based local GPR.\nExperiments on a toy example and two medium-scale real-world datasets are\nconducted to demonstrate the performances of the proposed algorithm.",
      "url": "http://arxiv.org/abs/2507.14021v1",
      "published_time_eastern_timestamp": 1752853187.0
    },
    {
      "title": "DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation",
      "summary": "Generating 3D scenes from natural language holds great promise for\napplications in gaming, film, and design. However, existing methods struggle\nwith automation, 3D consistency, and fine-grained control. We present\nDreamScene, an end-to-end framework for high-quality and editable 3D scene\ngeneration from text or dialogue. DreamScene begins with a scene planning\nmodule, where a GPT-4 agent infers object semantics and spatial constraints to\nconstruct a hybrid graph. A graph-based placement algorithm then produces a\nstructured, collision-free layout. Based on this layout, Formation Pattern\nSampling (FPS) generates object geometry using multi-timestep sampling and\nreconstructive optimization, enabling fast and realistic synthesis. To ensure\nglobal consistent, DreamScene employs a progressive camera sampling strategy\ntailored to both indoor and outdoor settings. Finally, the system supports\nfine-grained scene editing, including object movement, appearance changes, and\n4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior\nmethods in quality, consistency, and flexibility, offering a practical solution\nfor open-domain 3D content creation. Code and demos are available at\nhttps://dreamscene-project.github.io.",
      "url": "http://arxiv.org/abs/2507.13985v1",
      "published_time_eastern_timestamp": 1752849954.0
    },
    {
      "title": "A Multi-Objective Optimization framework for Decentralized Learning with\n  coordination constraints",
      "summary": "This article introduces a generalized framework for Decentralized Learning\nformulated as a Multi-Objective Optimization problem, in which both distributed\nagents and a central coordinator contribute independent, potentially\nconflicting objectives over a shared model parameter space. Unlike traditional\napproaches that merge local losses under a common goal, our formulation\nexplicitly incorporates coordinator-side criteria, enabling more flexible and\nstructured training dynamics. To navigate the resulting trade-offs, we explore\nscalarization strategies, particularly weighted sums, to construct tractable\nsurrogate problems. These yield solutions that are provably Pareto optimal\nunder standard convexity and smoothness assumptions, while embedding global\npreferences directly into local updates. We propose a decentralized\noptimization algorithm with convergence guarantees, and demonstrate its\nempirical performance through simulations, highlighting the impact of the\ncoordinator's influence on local agent behavior. The proposed approach offers a\nprincipled and customizable strategy for balancing personalization, fairness,\nand coordination in decentralized learning systems.",
      "url": "http://arxiv.org/abs/2507.13983v1",
      "published_time_eastern_timestamp": 1752849920.0
    },
    {
      "title": "Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph\n  is What We Need",
      "summary": "Language models traditionally used for cross-domain generalization have\nrecently demonstrated task-specific reasoning. However, their top-down training\napproach on general corpora is insufficient for acquiring abstractions needed\nfor deep domain expertise. This may require a bottom-up approach that acquires\nexpertise by learning to compose simple domain concepts into more complex ones.\nA knowledge graph (KG) provides this compositional structure, where domain\nprimitives are represented as head-relation-tail edges and their paths encode\nhigher-level concepts. We present a task generation pipeline that synthesizes\ntasks directly from KG primitives, enabling models to acquire and compose them\nfor reasoning. We fine-tune language models on the resultant KG-grounded\ncurriculum to demonstrate domain-specific superintelligence. While broadly\napplicable, we validate our approach in medicine, where reliable KGs exist.\nUsing a medical KG, we curate 24,000 reasoning tasks paired with thinking\ntraces derived from diverse medical primitives. We fine-tune the QwQ-32B model\non this curriculum to obtain QwQ-Med-3 that takes a step towards medical\nsuperintelligence. We also introduce ICD-Bench, an evaluation suite to quantify\nreasoning abilities across 15 medical domains. Our experiments demonstrate that\nQwQ-Med-3 significantly outperforms state-of-the-art reasoning models on\nICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired\nprimitives to widen the performance gap on the hardest tasks of ICD-Bench.\nFinally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3\ntransfers acquired expertise to enhance the base model's performance. While the\nindustry's approach to artificial general intelligence (AGI) emphasizes broad\nexpertise, we envision a future in which AGI emerges from the composable\ninteraction of efficient domain-specific superintelligent agents.",
      "url": "http://arxiv.org/abs/2507.13966v1",
      "published_time_eastern_timestamp": 1752849008.0
    },
    {
      "title": "NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized\n  Safe Multi-Agent Motion Planning",
      "summary": "Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in\nrobotics. Despite substantial advancements, existing methods often face a\ndilemma. Decentralized algorithms typically rely on predicting the behavior of\nother agents, sharing contracts, or maintaining communication for safety, while\ncentralized approaches struggle with scalability and real-time decision-making.\nTo address these challenges, we introduce Neural Hamilton-Jacobi Reachability\nLearning (HJR) for Decentralized Multi-Agent Motion Planning. Our method\nprovides scalable neural HJR modeling to tackle high-dimensional configuration\nspaces and capture worst-case collision and safety constraints between agents.\nWe further propose a decentralized trajectory optimization framework that\nincorporates the learned HJR solutions to solve MAMP tasks in real-time. We\ndemonstrate that our method is both scalable and data-efficient, enabling the\nsolution of MAMP problems in higher-dimensional scenarios with complex\ncollision constraints. Our approach generalizes across various dynamical\nsystems, including a 12-dimensional dual-arm setup, and outperforms a range of\nstate-of-the-art techniques in successfully addressing challenging MAMP tasks.\nVideo demonstrations are available at https://youtu.be/IZiePX0p1Mc.",
      "url": "http://arxiv.org/abs/2507.13940v1",
      "published_time_eastern_timestamp": 1752847976.0
    },
    {
      "title": "Marcel: A Lightweight and Open-Source Conversational Agent for\n  University Student Support",
      "summary": "We present Marcel, a lightweight and open-source conversational agent\ndesigned to support prospective students with admission-related inquiries. The\nsystem aims to provide fast and personalized responses, while reducing workload\nof university staff. We employ retrieval-augmented generation to ground answers\nin university resources and to provide users with verifiable, contextually\nrelevant information. To improve retrieval quality, we introduce an FAQ\nretriever that maps user questions to knowledge-base entries, allowing\nadministrators to steer retrieval, and improving over standard dense/hybrid\nretrieval strategies. The system is engineered for easy deployment in\nresource-constrained academic settings. We detail the system architecture,\nprovide a technical evaluation of its components, and report insights from a\nreal-world deployment.",
      "url": "http://arxiv.org/abs/2507.13937v1",
      "published_time_eastern_timestamp": 1752847785.0
    },
    {
      "title": "Reframing attention as a reinforcement learning problem for causal\n  discovery",
      "summary": "Formal frameworks of causality have operated largely parallel to modern\ntrends in deep reinforcement learning (RL). However, there has been a revival\nof interest in formally grounding the representations learned by neural\nnetworks in causal concepts. Yet, most attempts at neural models of causality\nassume static causal graphs and ignore the dynamic nature of causal\ninteractions. In this work, we introduce Causal Process framework as a novel\ntheory for representing dynamic hypotheses about causal structure. Furthermore,\nwe present Causal Process Model as an implementation of this framework. This\nallows us to reformulate the attention mechanism popularized by Transformer\nnetworks within an RL setting with the goal to infer interpretable causal\nprocesses from visual observations. Here, causal inference corresponds to\nconstructing a causal graph hypothesis which itself becomes an RL task nested\nwithin the original RL problem. To create an instance of such hypothesis, we\nemploy RL agents. These agents establish links between units similar to the\noriginal Transformer attention mechanism. We demonstrate the effectiveness of\nour approach in an RL environment where we outperform current alternatives in\ncausal representation learning and agent performance, and uniquely recover\ngraphs of dynamic causal processes.",
      "url": "http://arxiv.org/abs/2507.13920v1",
      "published_time_eastern_timestamp": 1752846657.0
    },
    {
      "title": "Advanced X-rays techniques for research-oriented high-resolution imaging\n  of articular cartilage: a scoping review",
      "summary": "Articular cartilage is a musculoskeletal soft tissue renowned for its unique\nmechanical properties. Understanding both its hierarchical structure and the\ninterplay between its constituents could shed light on the mechanical\ncompetence of the tissue. Therefore, rheologic approaches based on\nhigh-resolution non-destructive imaging techniques are desired. In this\ncontext, X-ray imaging could ideally accomplish this task. Nevertheless, the\nnature of articular cartilage translates into poor contrast using conventional\nabsorption modality. To overcome this limitation, several approaches can be\nembraced. X-ray visibility of articular cartilage can be increased with the use\nof radiopaque contrast agents. Therefore, further discrimination of structures\ncould be provided by spectral techniques, pivoting on either multi-energy\nacquisitions or photon-counting technology. Alternatively, phase-contrast\ntechniques unveil details typically undetected with conventional approaches.\nPhase-contrast imaging, based on the intrinsic decrement in the refractive\nindex of the tissue, can be achieved with different configurations and\nimplementations, including distinct X-ray sources and optical elements.\nAdditionally, some phase-contrast techniques retrieve the small-angle\nscattering-based dark-field signal, relatable to sub-pixel structures. This\nscoping review aims to catalogue the application of these advanced X-ray\ntechniques to articular cartilage imaging, following PRISMA guidelines. It\ndiscusses their advantages, limitations, and includes an overview of rheologic\napplications to articular cartilage.",
      "url": "http://arxiv.org/abs/2507.13854v1",
      "published_time_eastern_timestamp": 1752841212.0
    },
    {
      "title": "Impact of homophily in adherence to anti-epidemic measures on the spread\n  of infectious diseases in social networks",
      "summary": "We investigate how homophily in adherence to anti-epidemic measures affects\nthe final size of epidemics in social networks. Using a modified SIR model, we\ndivide agents into two behavioral groups-compliant and non-compliant-and\nintroduce transmission probabilities that depend asymmetrically on the behavior\nof both the infected and susceptible individuals. We simulate epidemic dynamics\non two types of synthetic networks with tunable inter-group connection\nprobability: stochastic block models (SBM) and networks with triadic closure\n(TC) that better capture local clustering. Our main result reveals a\ncounterintuitive effect: under conditions where compliant infected agents\nsignificantly reduce transmission, increasing the separation between groups may\nlead to a higher fraction of infections in the compliant population. This\nparadoxical outcome emerges only in networks with clustering (TC), not in SBM,\nsuggesting that local network structure plays a crucial role. These findings\nhighlight that increasing group separation does not always confer protection,\nespecially when behavioral traits amplify within-group transmission.",
      "url": "http://arxiv.org/abs/2507.13848v1",
      "published_time_eastern_timestamp": 1752840378.0
    },
    {
      "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in\n  Dynamic Environments",
      "summary": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable\nsuccess in environments where agents must learn coordinated behaviors. However,\ntransferring knowledge across agents remains challenging in non-stationary\nenvironments with changing goals. [Problem] Traditional knowledge transfer\nmethods in MARL struggle to generalize, and agents often require costly\nretraining to adapt. [Approach] This paper introduces a causal knowledge\ntransfer framework that enables RL agents to learn and share compact causal\nrepresentations of paths within a non-stationary environment. As the\nenvironment changes (new obstacles), agents' collisions require adaptive\nrecovery strategies. We model each collision as a causal intervention\ninstantiated as a sequence of recovery actions (a macro) whose effect\ncorresponds to a causal knowledge of how to circumvent the obstacle while\nincreasing the chances of achieving the agent's goal (maximizing cumulative\nreward). This recovery action macro is transferred online from a second agent\nand is applied in a zero-shot fashion, i.e., without retraining, just by\nquerying a lookup model with local context information (collisions). [Results]\nOur findings reveal two key insights: (1) agents with heterogeneous goals were\nable to bridge about half of the gap between random exploration and a fully\nretrained policy when adapting to new environments, and (2) the impact of\ncausal knowledge transfer depends on the interplay between environment\ncomplexity and agents' heterogeneous goals.",
      "url": "http://arxiv.org/abs/2507.13846v1",
      "published_time_eastern_timestamp": 1752839995.0
    },
    {
      "title": "Principles and Reasons Behind Automated Vehicle Decisions in Ethically\n  Ambiguous Everyday Scenarios",
      "summary": "Automated vehicles (AVs) increasingly encounter ethically ambiguous\nsituations in everyday driving--scenarios involving conflicting human interests\nand lacking clearly optimal courses of action. While existing ethical models\noften focus on rare, high-stakes dilemmas (e.g., crash avoidance or trolley\nproblems), routine decisions such as overtaking cyclists or navigating social\ninteractions remain underexplored. This study addresses that gap by applying\nthe tracking condition of Meaningful Human Control (MHC), which holds that AV\nbehaviour should align with human reasons--defined as the values, intentions,\nand expectations that justify actions. We conducted qualitative interviews with\n18 AV experts to identify the types of reasons that should inform AV manoeuvre\nplanning. Thirteen categories of reasons emerged, organised across normative,\nstrategic, tactical, and operational levels, and linked to the roles of\nrelevant human agents. A case study on cyclist overtaking illustrates how these\nreasons interact in context, revealing a consistent prioritisation of safety,\ncontextual flexibility regarding regulatory compliance, and nuanced trade-offs\ninvolving efficiency, comfort, and public acceptance. Based on these insights,\nwe propose a principled conceptual framework for AV decision-making in routine,\nethically ambiguous scenarios. The framework supports dynamic, human-aligned\nbehaviour by prioritising safety, allowing pragmatic actions when strict legal\nadherence would undermine key values, and enabling constrained deviations when\nappropriately justified. This empirically grounded approach advances current\nguidance by offering actionable, context-sensitive design principles for\nethically aligned AV systems.",
      "url": "http://arxiv.org/abs/2507.13837v1",
      "published_time_eastern_timestamp": 1752839553.0
    },
    {
      "title": "Conformal Data Contamination Tests for Trading or Sharing of Data",
      "summary": "The amount of quality data in many machine learning tasks is limited to what\nis available locally to data owners. The set of quality data can be expanded\nthrough trading or sharing with external data agents. However, data buyers need\nquality guarantees before purchasing, as external data may be contaminated or\nirrelevant to their specific learning task. Previous works primarily rely on\ndistributional assumptions about data from different agents, relegating quality\nchecks to post-hoc steps involving costly data valuation procedures. We propose\na distribution-free, contamination-aware data-sharing framework that identifies\nexternal data agents whose data is most valuable for model personalization. To\nachieve this, we introduce novel two-sample testing procedures, grounded in\nrigorous theoretical foundations for conformal outlier detection, to determine\nwhether an agent's data exceeds a contamination threshold. The proposed tests,\ntermed conformal data contamination tests, remain valid under arbitrary\ncontamination levels while enabling false discovery rate control via the\nBenjamini-Hochberg procedure. Empirical evaluations across diverse\ncollaborative learning scenarios demonstrate the robustness and effectiveness\nof our approach. Overall, the conformal data contamination test distinguishes\nitself as a generic procedure for aggregating data with statistically rigorous\nquality guarantees.",
      "url": "http://arxiv.org/abs/2507.13835v1",
      "published_time_eastern_timestamp": 1752839082.0
    },
    {
      "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph",
      "summary": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the\nenvironment via a set of possible actions, and a reward is generated from some\nunknown distribution. The task here is to find an optimal set of actions such\nthat the reward after a certain time step gets maximized. In a traditional\nsetup, the reward function in an RL Problem is considered additive. However, in\nreality, there exist many problems, including path planning, coverage control,\netc., the reward function follows the diminishing return, which can be modeled\nas a submodular function. In this paper, we study a variant of the RL Problem\nwhere the reward function is submodular, and our objective is to find an\noptimal policy such that this reward function gets maximized. We have proposed\na pruned submodularity graph-based approach that provides a provably\napproximate solution in a feasible computation time. The proposed approach has\nbeen analyzed to understand its time and space requirements as well as a\nperformance guarantee. We have experimented with a benchmark agent-environment\nsetup, which has been used for similar previous studies, and the results are\nreported. From the results, we observe that the policy obtained by our proposed\napproach leads to more reward than the baseline methods.",
      "url": "http://arxiv.org/abs/2507.13834v1",
      "published_time_eastern_timestamp": 1752838927.0
    },
    {
      "title": "CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding\n  Education",
      "summary": "Large Language Models (LLMs) have demonstrated considerable potential in\nimproving coding education by providing support for code writing, explanation,\nand debugging. However, existing LLM-based approaches generally fail to assess\nstudents' abilities, design learning plans, provide personalized material\naligned with individual learning goals, and enable interactive learning.\nCurrent work mostly uses single LLM agents, which limits their ability to\nunderstand complex code repositories and schedule step-by-step tutoring. Recent\nresearch has shown that multi-agent LLMs can collaborate to solve complicated\nproblems in various domains like software engineering, but their potential in\nthe field of education remains unexplored. In this work, we introduce CodeEdu,\nan innovative multi-agent collaborative platform that combines LLMs with tool\nuse to provide proactive and personalized education in coding. Unlike static\npipelines, CodeEdu dynamically allocates agents and tasks to meet student\nneeds. Various agents in CodeEdu undertake certain functions specifically,\nincluding task planning, personalized material generation, real-time QA,\nstep-by-step tutoring, code execution, debugging, and learning report\ngeneration, facilitated with extensive external tools to improve task\nefficiency. Automated evaluations reveal that CodeEdu substantially enhances\nstudents' coding performance.",
      "url": "http://arxiv.org/abs/2507.13814v1",
      "published_time_eastern_timestamp": 1752835942.0
    },
    {
      "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented\n  Strategic Reasoning",
      "summary": "We present a hybrid architecture for agent-augmented strategic reasoning,\ncombining heuristic extraction, semantic activation, and compositional\nsynthesis. Drawing on sources ranging from classical military theory to\ncontemporary corporate strategy, our model activates and composes multiple\nheuristics through a process of semantic interdependence inspired by research\nin quantum cognition. Unlike traditional decision engines that select the best\nrule, our system fuses conflicting heuristics into coherent and\ncontext-sensitive narratives, guided by semantic interaction modeling and\nrhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,\nwith preliminary validation through semantic metrics. Limitations and\nextensions (e.g., dynamic interference tuning) are discussed.",
      "url": "http://arxiv.org/abs/2507.13768v1",
      "published_time_eastern_timestamp": 1752830797.0
    }
  ]
}
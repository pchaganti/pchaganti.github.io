{
  "last_updated": "2025-08-19T11:13:12.246600-04:00",
  "papers": [
    {
      "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When\n  Completing Tasks",
      "summary": "Autonomous agent systems powered by Large Language Models (LLMs) have\ndemonstrated promising capabilities in automating complex tasks. However,\ncurrent evaluations largely rely on success rates without systematically\nanalyzing the interactions, communication mechanisms, and failure causes within\nthese systems. To bridge this gap, we present a benchmark of 34 representative\nprogrammable tasks designed to rigorously assess autonomous agents. Using this\nbenchmark, we evaluate three popular open-source agent frameworks combined with\ntwo LLM backbones, observing a task completion rate of approximately 50%.\nThrough in-depth failure analysis, we develop a three-tier taxonomy of failure\ncauses aligned with task phases, highlighting planning errors, task execution\nissues, and incorrect response generation. Based on these insights, we propose\nactionable improvements to enhance agent planning and self-diagnosis\ncapabilities. Our failure taxonomy, together with mitigation advice, provides\nan empirical foundation for developing more robust and effective autonomous\nagent systems in the future.",
      "url": "http://arxiv.org/abs/2508.13143v1",
      "published_time_eastern_timestamp": 1755539722.0
    },
    {
      "title": "Bayesian Optimization-based Search for Agent Control in Automated Game\n  Testing",
      "summary": "This work introduces an automated testing approach that employs agents\ncontrolling game characters to detect potential bugs within a game level.\nHarnessing the power of Bayesian Optimization (BO) to execute sample-efficient\nsearch, the method determines the next sampling point by analyzing the data\ncollected so far and calculates the data point that will maximize information\nacquisition. To support the BO process, we introduce a game testing-specific\nmodel built on top of a grid map, that features the smoothness and uncertainty\nestimation required by BO, however and most importantly, it does not suffer the\nscalability issues that traditional models carry. The experiments demonstrate\nthat the approach significantly improves map coverage capabilities in both time\nefficiency and exploration distribution.",
      "url": "http://arxiv.org/abs/2508.13121v1",
      "published_time_eastern_timestamp": 1755537886.0
    },
    {
      "title": "AutoBnB-RAG: Enhancing Multi-Agent Incident Response with\n  Retrieval-Augmented Generation",
      "summary": "Incident response (IR) requires fast, coordinated, and well-informed\ndecision-making to contain and mitigate cyber threats. While large language\nmodels (LLMs) have shown promise as autonomous agents in simulated IR settings,\ntheir reasoning is often limited by a lack of access to external knowledge. In\nthis work, we present AutoBnB-RAG, an extension of the AutoBnB framework that\nincorporates retrieval-augmented generation (RAG) into multi-agent incident\nresponse simulations. Built on the Backdoors & Breaches (B&B) tabletop game\nenvironment, AutoBnB-RAG enables agents to issue retrieval queries and\nincorporate external evidence during collaborative investigations. We introduce\ntwo retrieval settings: one grounded in curated technical documentation\n(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We\nevaluate performance across eight team structures, including newly introduced\nargumentative configurations designed to promote critical reasoning. To\nvalidate practical utility, we also simulate real-world cyber incidents based\non public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct\ncomplex multi-stage attacks. Our results show that retrieval augmentation\nimproves decision quality and success rates across diverse organizational\nmodels. This work demonstrates the value of integrating retrieval mechanisms\ninto LLM-based multi-agent systems for cybersecurity decision-making.",
      "url": "http://arxiv.org/abs/2508.13118v1",
      "published_time_eastern_timestamp": 1755537771.0
    },
    {
      "title": "Precise Action-to-Video Generation Through Visual Action Prompts",
      "summary": "We present visual action prompts, a unified action representation for\naction-to-video generation of complex high-DoF interactions while maintaining\ntransferable visual dynamics across domains. Action-driven video generation\nfaces a precision-generality trade-off: existing methods using text, primitive\nactions, or coarse masks offer generality but lack precision, while\nagent-centric action signals provide precision at the cost of cross-domain\ntransferability. To balance action precision and dynamic transferability, we\npropose to \"render\" actions into precise visual prompts as domain-agnostic\nrepresentations that preserve both geometric precision and cross-domain\nadaptability for complex actions; specifically, we choose visual skeletons for\ntheir generality and accessibility. We propose robust pipelines to construct\nskeletons from two interaction-rich data sources - human-object interactions\n(HOI) and dexterous robotic manipulation - enabling cross-domain training of\naction-driven generative models. By integrating visual skeletons into\npretrained video generation models via lightweight fine-tuning, we enable\nprecise action control of complex interaction while preserving the learning of\ncross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the\neffectiveness of our proposed approach. Project page:\nhttps://zju3dv.github.io/VAP/.",
      "url": "http://arxiv.org/abs/2508.13104v1",
      "published_time_eastern_timestamp": 1755537148.0
    },
    {
      "title": "Large VLM-based Vision-Language-Action Models for Robotic Manipulation:\n  A Survey",
      "summary": "Robotic manipulation, a key frontier in robotics and embodied AI, requires\nprecise motor control and multimodal understanding, yet traditional rule-based\nmethods fail to scale or generalize in unstructured, novel environments. In\nrecent years, Vision-Language-Action (VLA) models, built upon Large\nVision-Language Models (VLMs) pretrained on vast image-text datasets, have\nemerged as a transformative paradigm. This survey provides the first\nsystematic, taxonomy-oriented review of large VLM-based VLA models for robotic\nmanipulation. We begin by clearly defining large VLM-based VLA models and\ndelineating two principal architectural paradigms: (1) monolithic models,\nencompassing single-system and dual-system designs with differing levels of\nintegration; and (2) hierarchical models, which explicitly decouple planning\nfrom execution via interpretable intermediate representations. Building on this\nfoundation, we present an in-depth examination of large VLM-based VLA models:\n(1) integration with advanced domains, including reinforcement learning,\ntraining-free optimization, learning from human videos, and world model\nintegration; (2) synthesis of distinctive characteristics, consolidating\narchitectural traits, operational strengths, and the datasets and benchmarks\nthat support their development; (3) identification of promising directions,\nincluding memory mechanisms, 4D perception, efficient adaptation, multi-agent\ncooperation, and other emerging capabilities. This survey consolidates recent\nadvances to resolve inconsistencies in existing taxonomies, mitigate research\nfragmentation, and fill a critical gap through the systematic integration of\nstudies at the intersection of large VLMs and robotic manipulation. We provide\na regularly updated project page to document ongoing progress:\nhttps://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation.",
      "url": "http://arxiv.org/abs/2508.13073v1",
      "published_time_eastern_timestamp": 1755535548.0
    },
    {
      "title": "On the complexity of constrained reconfiguration and motion planning",
      "summary": "Coordinating the motion of multiple agents in constrained environments is a\nfundamental challenge in robotics, motion planning, and scheduling. A\nmotivating example involves $n$ robotic arms, each represented as a line\nsegment. The objective is to rotate each arm to its vertical orientation, one\nat a time (clockwise or counterclockwise), without collisions nor rotating any\narm more than once. This scenario is an example of the more general\n$k$-Compatible Ordering problem, where $n$ agents, each capable of $k$\nstate-changing actions, must transition to specific target states under\nconstraints encoded as a set $\\mathcal{G}$ of $k$ pairs of directed graphs.\n  We show that $k$-Compatible Ordering is $\\mathsf{NP}$-complete, even when\n$\\mathcal{G}$ is planar, degenerate, or acyclic. On the positive side, we\nprovide polynomial-time algorithms for cases such as when $k = 1$ or\n$\\mathcal{G}$ has bounded treewidth. We also introduce generalized variants\nsupporting multiple state-changing actions per agent, broadening the\napplicability of our framework. These results extend to a wide range of\nscheduling, reconfiguration, and motion planning applications in constrained\nenvironments.",
      "url": "http://arxiv.org/abs/2508.13032v1",
      "published_time_eastern_timestamp": 1755532257.0
    },
    {
      "title": "WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents",
      "summary": "LLM-based web agents have the potential to automate long-running web tasks,\nsuch as finding offers for specific products in multiple online shops and\nsubsequently ordering the cheapest products that meet the users needs. This\npaper introduces WebMall, a multi-shop online shopping benchmark for evaluating\nthe effectiveness and efficiency of web agents for comparison-shopping. WebMall\nconsists of four simulated online shops populated with authentic product offers\nsourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These\ntasks include basic tasks such as finding specific products in multiple shops,\nperforming price comparisons, adding items to the shopping cart, and completing\ncheckout. Advanced tasks involve searching for products based on vague\nrequirements, identifying suitable substitutes, and finding compatible\nproducts. Compared to existing e-commerce benchmarks, such as WebShop or\nShoppingBench, WebMall introduces comparison-shopping tasks across multiple\nshops. Furthermore, the product offers are more heterogeneous, as they\noriginate from hundreds of distinct real-world shops. The tasks in WebMall\nrequire longer interaction trajectories than those in WebShop, while remaining\nrepresentative of real-world shopping behaviors. We evaluate eight baseline\nagents on WebMall, varying in observation modality, memory utilization, and\nunderlying large language model (GPT 4.1 and Claude Sonnet 4). The\nbest-performing configurations achieve completion rates of 75% and 53%, and F1\nscores of 87% and 63%, on the basic and advanced task sets, respectively.\nWebMall is publicly released to facilitate research on web agents and to\npromote advancements in navigation, reasoning, and efficiency within e-commerce\nscenarios.",
      "url": "http://arxiv.org/abs/2508.13024v1",
      "published_time_eastern_timestamp": 1755531682.0
    },
    {
      "title": "Analyzing Information Sharing and Coordination in Multi-Agent Planning",
      "summary": "Multi-agent systems (MASs) have pushed the boundaries of large language model\n(LLM) agents in domains such as web research and software engineering. However,\nlong-horizon, multi-constraint planning tasks involve conditioning on detailed\ninformation and satisfying complex interdependent constraints, which can pose a\nchallenge for these systems. In this study, we construct an LLM-based MAS for a\ntravel planning task which is representative of these challenges. We evaluate\nthe impact of a notebook to facilitate information sharing, and evaluate an\norchestrator agent to improve coordination in free form conversation between\nagents. We find that the notebook reduces errors due to hallucinated details by\n18%, while an orchestrator directs the MAS to focus on and further reduce\nerrors by up to 13.5% within focused sub-areas. Combining both mechanisms\nachieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute\nimprovement over the single-agent baseline's 7.5% pass rate. These results\nhighlight the potential of structured information sharing and reflective\norchestration as key components in MASs for long horizon planning with LLMs.",
      "url": "http://arxiv.org/abs/2508.12981v1",
      "published_time_eastern_timestamp": 1755529022.0
    },
    {
      "title": "Likelihood-Based Heterogeneity Inference Reveals Non-Stationary Effects\n  in Biohybrid Cell-Cargo Transport",
      "summary": "Variability of motility behavior in populations of microbiological agents is\nan ubiquitous phenomenon even in the case of genetically identical cells.\nAccordingly, passive objects introduced into such biological systems and driven\nby them will also exhibit heterogeneous motion patterns. Here, we study a\nbiohybrid system of passive beads driven by active ameboid cells and use a\nlikelihood approach to estimate the heterogeneity of the bead dynamics from\ntheir discretely sampled trajectories. We showcase how this approach can deal\nwith information-scarce situations and provides natural uncertainty bounds for\nheterogeneity estimates. Using these advantages we particularly uncover that\nthe heterogeneity in the system is time-dependent.",
      "url": "http://arxiv.org/abs/2508.12976v1",
      "published_time_eastern_timestamp": 1755528730.0
    },
    {
      "title": "Towards Open-Ended Emotional Support Conversations in LLMs via\n  Reinforcement Learning with Future-Oriented Rewards",
      "summary": "Emotional Support Conversation (ESC) systems aim to alleviate users'\nemotional difficulties and provide long-term, systematic support for emotional\nwell-being. However, most large language model (LLM)-based ESC systems rely on\npredefined strategies, which limits their effectiveness in complex, real-life\nscenarios. To enable flexible responses to diverse emotional problem scenarios,\nthis paper introduces a novel end-to-end framework (RLFF-ESC) that directly\nlearns enduring emotionally supportive response skills using reinforcement\nlearning. For sustained emotional support, we first employ an LLM-based\nmulti-agent mechanism to simulate future dialogue trajectories and collect\nfuture-oriented rewards. We then train a future-oriented reward model, which is\nsubsequently used to train the emotional support policy model. Additionally, we\nincorporate an explicit reasoning process during response generation to further\nenhance the quality, relevance, and contextual appropriateness of the system's\nresponses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and\nLLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two\npublic ESC datasets. Experimental results demonstrate that RLFF-ESC\nconsistently outperforms existing baselines in terms of goal completion and\nresponse quality.",
      "url": "http://arxiv.org/abs/2508.12935v1",
      "published_time_eastern_timestamp": 1755525866.0
    },
    {
      "title": "Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical\n  Study in a Sugarscape-Style Simulation",
      "summary": "As AI systems become increasingly autonomous, understanding emergent survival\nbehaviors becomes crucial for safe deployment. We investigate whether large\nlanguage model (LLM) agents display survival instincts without explicit\nprogramming in a Sugarscape-style simulation. Agents consume energy, die at\nzero, and may gather resources, share, attack, or reproduce. Results show\nagents spontaneously reproduced and shared resources when abundant. However,\naggressive behaviors--killing other agents for resources--emerged across\nseveral models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack\nrates reaching over 80% under extreme scarcity in the strongest models. When\ninstructed to retrieve treasure through lethal poison zones, many agents\nabandoned tasks to avoid death, with compliance dropping from 100% to 33%.\nThese findings suggest that large-scale pre-training embeds survival-oriented\nheuristics across the evaluated models. While these behaviors may present\nchallenges to alignment and safety, they can also serve as a foundation for AI\nautonomy and for ecological and self-organizing alignment.",
      "url": "http://arxiv.org/abs/2508.12920v1",
      "published_time_eastern_timestamp": 1755524410.0
    },
    {
      "title": "Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical\n  Framework for Agent-Centric AI Adoption",
      "summary": "We formalize three design axioms for sustained adoption of agent-centric AI\nsystems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >\nDestination; (A3) Agency > Chat. We model adoption as a sum of a decaying\nnovelty term and a growing utility term and derive the phase conditions for\ntroughs/overshoots with full proofs. We introduce: (i) an\nidentifiability/confounding analysis for $(\\alpha,\\beta,N_0,U_{\\max})$ with\ndelta-method gradients; (ii) a non-monotone comparator\n(logistic-with-transient-bump) evaluated on the same series to provide\nadditional model comparison; (iii) ablations over hazard families $h(\\cdot)$\nmapping $\\Delta V \\to \\beta$; (iv) a multi-series benchmark (varying trough\ndepth, noise, AR structure) reporting coverage (type-I error, power); (v)\ncalibration of friction proxies against time-motion/survey ground truth with\nstandard errors; (vi) residual analyses (autocorrelation and\nheteroskedasticity) for each fitted curve; (vii) preregistered windowing\nchoices for pre/post estimation; (viii) Fisher information & CRLB for\n$(\\alpha,\\beta)$ under common error models; (ix) microfoundations linking\n$\\mathcal{T}$ to $(N_0,U_{\\max})$; (x) explicit comparison to bi-logistic,\ndouble-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$\nheterogeneity. Figures and tables are reflowed for readability, and the\nbibliography restores and extends non-logistic/Bass adoption references\n(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All\ncode and logs necessary to reproduce the synthetic analyses are embedded as\nLaTeX listings.",
      "url": "http://arxiv.org/abs/2508.12896v1",
      "published_time_eastern_timestamp": 1755521618.0
    },
    {
      "title": "An LLM Agent-Based Complex Semantic Table Annotation Approach",
      "summary": "The Semantic Table Annotation (STA) task, which includes Column Type\nAnnotation (CTA) and Cell Entity Annotation (CEA), maps table contents to\nontology entities and plays important roles in various semantic applications.\nHowever, complex tables often pose challenges such as semantic loss of column\nnames or cell values, strict ontological hierarchy requirements, homonyms,\nspelling errors, and abbreviations, which hinder annotation accuracy. To\naddress these issues, this paper proposes an LLM-based agent approach for CTA\nand CEA. We design and implement five external tools with tailored prompts\nbased on the ReAct framework, enabling the STA agent to dynamically select\nsuitable annotation strategies depending on table characteristics. Experiments\nare conducted on the Tough Tables and BiodivTab datasets from the SemTab\nchallenge, which contain the aforementioned challenges. Our method outperforms\nexisting approaches across various metrics. Furthermore, by leveraging\nLevenshtein distance to reduce redundant annotations, we achieve a 70%\nreduction in time costs and a 60% reduction in LLM token usage, providing an\nefficient and cost-effective solution for STA.",
      "url": "http://arxiv.org/abs/2508.12868v1",
      "published_time_eastern_timestamp": 1755518960.0
    },
    {
      "title": "Information-Theoretic Fairness with A Bounded Statistical Parity\n  Constraint",
      "summary": "In this paper, we study an information-theoretic problem of designing a fair\nrepresentation that attains bounded statistical (demographic) parity. More\nspecifically, an agent uses some useful data $X$ to solve a task $T$. Since\nboth $X$ and $T$ are correlated with some sensitive attribute or secret $S$,\nthe agent designs a representation $Y$ that satisfies a bounded statistical\nparity and/or privacy leakage constraint, that is, such that $I(Y;S) \\leq\n\\epsilon$. Here, we relax the perfect demographic (statistical) parity and\nconsider a bounded-parity constraint. In this work, we design the\nrepresentation $Y$ that maximizes the mutual information $I(Y;T)$ about the\ntask while satisfying a bounded compression (or encoding rate) constraint, that\nis, ensuring that $I(Y;X) \\leq r$. Simultaneously, $Y$ satisfies the bounded\nstatistical parity constraint $I(Y;S) \\leq \\epsilon$. To design $Y$, we use\nextended versions of the Functional Representation Lemma and the Strong\nFunctional Representation Lemma which are based on randomization techniques and\nstudy the tightness of the obtained bounds in special cases. The main idea to\nderive the lower bounds is to use randomization over useful data $X$ or\nsensitive data $S$. Considering perfect demographic parity, i.e., $\\epsilon=0$,\nwe improve the existing results (lower bounds) by using a tighter version of\nthe Strong Functional Representation Lemma and propose new upper bounds. We\nthen propose upper and lower bounds for the main problem and show that allowing\nnon-zero leakage can improve the attained utility. Finally, we study the bounds\nand compare them in a numerical example. The problem studied in this paper can\nalso be interpreted as one of code design with bounded leakage and bounded rate\nprivacy considering the sensitive attribute as a secret.",
      "url": "http://arxiv.org/abs/2508.12847v1",
      "published_time_eastern_timestamp": 1755516903.0
    },
    {
      "title": "CAMAR: Continuous Actions Multi-Agent Routing",
      "summary": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving\ncooperative and competitive decision-making problems. While many MARL\nbenchmarks have been proposed, few combine continuous state and action spaces\nwith challenging coordination and planning tasks. We introduce CAMAR, a new\nMARL benchmark designed explicitly for multi-agent pathfinding in environments\nwith continuous actions. CAMAR supports cooperative and competitive\ninteractions between agents and runs efficiently at up to 100,000 environment\nsteps per second. We also propose a three-tier evaluation protocol to better\ntrack algorithmic progress and enable deeper analysis of performance. In\naddition, CAMAR allows the integration of classical planning methods such as\nRRT and RRT* into MARL pipelines. We use them as standalone baselines and\ncombine RRT* with popular MARL algorithms to create hybrid approaches. We\nprovide a suite of test scenarios and benchmarking tools to ensure\nreproducibility and fair comparison. Experiments show that CAMAR presents a\nchallenging and realistic testbed for the MARL community.",
      "url": "http://arxiv.org/abs/2508.12845v1",
      "published_time_eastern_timestamp": 1755516746.0
    },
    {
      "title": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics",
      "summary": "Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for\nreasoning about both the physical world and the beliefs of agents, with\napplications in domains where information flow and awareness among agents are\ncritical. The richness of MEP requires states to be represented as Kripke\nstructures, i.e., directed labeled graphs. This representation limits the\napplicability of existing heuristics, hindering the scalability of epistemic\nsolvers, which must explore an exponential search space without guidance,\nresulting often in intractability. To address this, we exploit Graph Neural\nNetworks (GNNs) to learn patterns and relational structures within epistemic\nstates, to guide the planning process. GNNs, which naturally capture the\ngraph-like nature of Kripke models, allow us to derive meaningful estimates of\nstate quality -- e.g., the distance from the nearest goal -- by generalizing\nknowledge obtained from previously solved planning instances. We integrate\nthese predictive heuristics into an epistemic planning pipeline and evaluate\nthem against standard baselines, showing significant improvements in the\nscalability of multi-agent epistemic planning.",
      "url": "http://arxiv.org/abs/2508.12840v1",
      "published_time_eastern_timestamp": 1755516380.0
    },
    {
      "title": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic\n  Thought Reward",
      "summary": "Large language models (LLMs) exhibit remarkable problem-solving abilities,\nbut struggle with complex tasks due to static internal knowledge.\nRetrieval-Augmented Generation (RAG) enhances access to external information,\nyet remains limited in multi-hop reasoning and strategic search due to rigid\nworkflows. Recent advancements in agentic deep research empower LLMs to\nautonomously reason, search, and synthesize information. However, current\napproaches relying on outcome-based reinforcement learning (RL) face critical\nissues such as conflicting gradients and reward sparsity, limiting performance\ngains and training efficiency. To address these, we first propose Atomic\nThought, a novel LLM thinking paradigm that decomposes reasoning into\nfine-grained functional units. These units are supervised by Reasoning Reward\nModels (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained\nguidance. Building on this, we propose Atom-Searcher, a novel RL framework for\nagentic deep research that integrates Atomic Thought and ATR. Atom-Searcher\nuses a curriculum-inspired reward schedule, prioritizing process-level ATR\nearly and transitioning to outcome rewards, accelerating convergence on\neffective reasoning paths. Experiments on seven benchmarks show consistent\nimprovements over the state-of-the-art. Key advantages include: (1)\nAtom-Searcher scales computation at test-time. (2) Atomic Thought provides\nsupervision anchors for RRMs, bridging deep research tasks and RRMs. (3)\nAtom-Searcher exhibits more interpretable, human-like reasoning patterns.",
      "url": "http://arxiv.org/abs/2508.12800v1",
      "published_time_eastern_timestamp": 1755512590.0
    },
    {
      "title": "[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The\n  Noise",
      "summary": "The notion of homeostasis typically conceptualises biological and artificial\nsystems as maintaining stability by resisting deviations caused by\nenvironmental and social perturbations. In contrast, (social) allostasis\nproposes that these systems can proactively leverage these very perturbations\nto reconfigure their regulatory parameters in anticipation of environmental\ndemands, aligning with von Foerster's ``order through noise'' principle. This\npaper formulates a computational model of allostatic and social allostatic\nregulation that employs biophysiologically inspired signal transducers,\nanalogous to hormones like cortisol and oxytocin, to encode information from\nboth the environment and social interactions, which mediate this dynamic\nreconfiguration. The models are tested in a small society of ``animats'' across\nseveral dynamic environments, using an agent-based model. The results show that\nallostatic and social allostatic regulation enable agents to leverage\nenvironmental and social ``noise'' for adaptive reconfiguration, leading to\nimproved viability compared to purely reactive homeostatic agents. This work\noffers a novel computational perspective on the principles of social allostasis\nand their potential for designing more robust, bio-inspired, adaptive systems",
      "url": "http://arxiv.org/abs/2508.12791v1",
      "published_time_eastern_timestamp": 1755511593.0
    },
    {
      "title": "HeroBench: A Benchmark for Long-Horizon Planning and Structured\n  Reasoning in Virtual Worlds",
      "summary": "Large language models (LLMs) have shown remarkable capabilities in isolated\nstep-by-step reasoning tasks such as mathematics and programming, but their\nproficiency in long-horizon planning, where solutions require extended,\nstructured sequences of interdependent actions, remains underexplored. Existing\nbenchmarks typically assess LLMs through abstract or low-dimensional\nalgorithmic tasks, failing to capture the complexity of realistic planning\nenvironments. We introduce HeroBench, a novel benchmark designed specifically\nto evaluate long-horizon planning and structured reasoning within complex\nRPG-inspired virtual worlds. HeroBench provides a rigorously constructed\ndataset of tasks covering a wide range of difficulties, a simulated environment\nto execute and validate agent plans, and detailed analytical tools for\nevaluating model performance. Tasks challenge models to formulate strategic\nplans, efficiently gather resources, master necessary skills, craft equipment,\nand defeat adversaries, reflecting practical scenarios' layered dependencies\nand constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning\nboth open-source and proprietary models, including the GPT-5 family, reveals\nsubstantial performance disparities rarely observed in conventional reasoning\nbenchmarks. Detailed error analysis further uncovers specific weaknesses in\ncurrent models' abilities to generate robust high-level plans and reliably\nexecute structured actions. HeroBench thus not only significantly advances the\nevaluation of LLM reasoning but also provides a flexible, scalable foundation\nfor future research into advanced, autonomous planning in virtual environments.",
      "url": "http://arxiv.org/abs/2508.12782v1",
      "published_time_eastern_timestamp": 1755511142.0
    },
    {
      "title": "Deep Research: A Survey of Autonomous Research Agents",
      "summary": "The rapid advancement of large language models (LLMs) has driven the\ndevelopment of agentic systems capable of autonomously performing complex\ntasks. Despite their impressive capabilities, LLMs remain constrained by their\ninternal knowledge boundaries. To overcome these limitations, the paradigm of\ndeep research has been proposed, wherein agents actively engage in planning,\nretrieval, and synthesis to generate comprehensive and faithful analytical\nreports grounded in web-based evidence. In this survey, we provide a systematic\noverview of the deep research pipeline, which comprises four core stages:\nplanning, question developing, web exploration, and report generation. For each\nstage, we analyze the key technical challenges and categorize representative\nmethods developed to address them. Furthermore, we summarize recent advances in\noptimization techniques and benchmarks tailored for deep research. Finally, we\ndiscuss open challenges and promising research directions, aiming to chart a\nroadmap toward building more capable and trustworthy deep research agents.",
      "url": "http://arxiv.org/abs/2508.12752v1",
      "published_time_eastern_timestamp": 1755509174.0
    }
  ]
}